{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MLP with extended physics loss function (Option 1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running the models using the 'modelling' package**\n",
    "\n",
    "A notebook through which different modelling configurations can be ran, using the ``modelling`` package. It follows the steps of:\n",
    "- preparing packages;\n",
    "- setting \"global\" variables;\n",
    "- getting the data;\n",
    "- defining hyperparameters;\n",
    "- running a grid search and/or training a model; and\n",
    "- evaluation.\n",
    "In the modelling package, variations can be made to the models and training functions to experiment. Don't forget to restart the notebook after making changes there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading models, go to the ``src/results/models``:\n",
    "- Baseline NO2 2017 with MLP and MSE loss: ``best_mlp_no2_baseline.pth``\n",
    "- Exp 1: NO2 2017 with MLP and option 1 simple physics loss: ``best_mlp_no2_adjusted_dist.pth`` (naming because I updated the distance between T and B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script...\n",
      "\n",
      "Running __init__.py for data pipeline...\n",
      "Modelling package initialized\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachel/forecasting_smog_PEML/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting script...\")\n",
    "\n",
    "\n",
    "from modelling.MLP import BasicMLP\n",
    "from modelling import *\n",
    "\n",
    "\n",
    "import optuna\n",
    "import threading\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GPU when available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set \"global\" variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/rachel/forecasting_smog_PEML/src')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR:  /home/rachel/forecasting_smog_PEML\n",
      "MODEL_PATH:  /home/rachel/forecasting_smog_PEML/src/results/models\n",
      "MINMAX_PATH:  /home/rachel/forecasting_smog_PEML/data/data_combined/pollutants_minmax.csv\n"
     ]
    }
   ],
   "source": [
    "HABROK = bool(0)                  # set to True if using HABROK; it will print\n",
    "                                  # all stdout to a .txt file to log progress\n",
    "\n",
    "BASE_DIR = Path.cwd().parents[0] # set it to the root directory of the project, not src\n",
    "MODEL_PATH = BASE_DIR /\"src\" / \"results\" / \"models\"\n",
    "MINMAX_PATH = BASE_DIR  / \"data\" / \"data_combined\" / \"pollutants_minmax.csv\"\n",
    "\n",
    "print(\"BASE_DIR: \", BASE_DIR)\n",
    "print(\"MODEL_PATH: \", MODEL_PATH)\n",
    "print(\"MINMAX_PATH: \", MINMAX_PATH)\n",
    "\n",
    "torch.manual_seed(34)             # set seed for reproducibility\n",
    "\n",
    "N_HOURS_U = 24 * 3               # number of hours to use for input (number of days * 24 hours)\n",
    "N_HOURS_Y = 24                    # number of hours to predict (1 day * 24 hours)\n",
    "N_HOURS_STEP = 24                 # \"sampling rate\" in hours of the data; e.g. 24 \n",
    "                                  # means sample an I/O-pair every 24 hours\n",
    "                                  # the contaminants and meteorological vars\n",
    "\n",
    "# Change this according to the data you want to use\n",
    "YEARS = [2017]\n",
    "TRAIN_YEARS = [2017]\n",
    "VAL_YEARS = [2017]\n",
    "TEST_YEARS = [2017]\n",
    "\n",
    "LOSS_FUNC = \"Physics_Linear_MSE\" # choose from \"MSE\" and \"Physics_Linear_MSE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load in data and create PyTorch *Datasets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported train_2017_combined_u.csv\n",
      "Imported train_2017_combined_y.csv\n",
      "Imported val_2017_combined_u.csv\n",
      "Imported val_2017_combined_y.csv\n",
      "Imported test_2017_combined_u.csv\n",
      "Imported test_2017_combined_y.csv\n",
      "Successfully loaded data\n"
     ]
    }
   ],
   "source": [
    "# Load in data and create PyTorch Datasets. To tune\n",
    "# which exact .csv files get extracted, change the\n",
    "# lists in the get_dataframes() definition\n",
    "\n",
    "train_input_frames = get_dataframes('train', 'u', YEARS)\n",
    "train_output_frames = get_dataframes('train', 'y', YEARS)\n",
    "\n",
    "val_input_frames = get_dataframes('val', 'u', YEARS)\n",
    "val_output_frames = get_dataframes('val', 'y', YEARS)\n",
    "\n",
    "test_input_frames = get_dataframes('test', 'u', YEARS)\n",
    "test_output_frames = get_dataframes('test', 'y', YEARS) \n",
    "\n",
    "print(\"Successfully loaded data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(\n",
    "    train_input_frames,  # list of input training dataframes\n",
    "    train_output_frames, # list of output training dataframes\n",
    "    len(TRAIN_YEARS),                   # number of dataframes put in for both\n",
    "                         # (basically len(train_input_frames) and\n",
    "                         # len(train_output_frames) must be equal)\n",
    "    N_HOURS_U,           # number of hours of input data\n",
    "    N_HOURS_Y,           # number of hours of output data\n",
    "    N_HOURS_STEP,        # number of hours between each input/output pair\n",
    ")\n",
    "val_dataset = TimeSeriesDataset(\n",
    "    val_input_frames,    # etc.\n",
    "    val_output_frames,\n",
    "    len(VAL_YEARS),\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "test_dataset = TimeSeriesDataset(\n",
    "    test_input_frames,\n",
    "    test_output_frames,\n",
    "    len(TEST_YEARS),\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "del train_input_frames, train_output_frames\n",
    "del val_input_frames, val_output_frames\n",
    "del test_input_frames, test_output_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                           DD   FF        FH        FX       NO2         P  \\\n",
       " DateTime                                                                     \n",
       " 2017-08-01 00:00:00  0.166667  0.1  0.111111  0.000000  0.242115  0.562982   \n",
       " 2017-08-01 01:00:00  0.000000  0.0  0.111111  0.052632  0.223158  0.570694   \n",
       " 2017-08-01 02:00:00  0.000000  0.0  0.000000  0.000000  0.165911  0.560411   \n",
       " 2017-08-01 03:00:00  0.277778  0.1  0.000000  0.000000  0.142363  0.555270   \n",
       " 2017-08-01 04:00:00  0.805556  0.2  0.111111  0.105263  0.156297  0.555270   \n",
       " ...                       ...  ...       ...       ...       ...       ...   \n",
       " 2017-11-16 19:00:00  0.750000  0.2  0.333333  0.210526  0.523871  0.789203   \n",
       " 2017-11-16 20:00:00  0.972222  0.3  0.333333  0.421053  0.512314  0.814910   \n",
       " 2017-11-16 21:00:00  0.888889  0.1  0.222222  0.263158  0.232880  0.827763   \n",
       " 2017-11-16 22:00:00  0.944444  0.2  0.111111  0.105263  0.108123  0.832905   \n",
       " 2017-11-16 23:00:00  0.861111  0.1  0.222222  0.105263  0.205120  0.845758   \n",
       " \n",
       "                       SQ         T        TD  \n",
       " DateTime                                      \n",
       " 2017-08-01 00:00:00  0.0  0.536667  0.726852  \n",
       " 2017-08-01 01:00:00  0.0  0.546667  0.740741  \n",
       " 2017-08-01 02:00:00  0.0  0.506667  0.689815  \n",
       " 2017-08-01 03:00:00  0.0  0.463333  0.634259  \n",
       " 2017-08-01 04:00:00  0.0  0.493333  0.662037  \n",
       " ...                  ...       ...       ...  \n",
       " 2017-11-16 19:00:00  0.0  0.390000  0.513889  \n",
       " 2017-11-16 20:00:00  0.0  0.353333  0.462963  \n",
       " 2017-11-16 21:00:00  0.0  0.330000  0.435185  \n",
       " 2017-11-16 22:00:00  0.0  0.306667  0.407407  \n",
       " 2017-11-16 23:00:00  0.0  0.250000  0.319444  \n",
       " \n",
       " [2592 rows x 9 columns]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                          NO2\n",
       " DateTime                     \n",
       " 2017-08-01 00:00:00  0.223698\n",
       " 2017-08-01 01:00:00  0.145496\n",
       " 2017-08-01 02:00:00  0.275978\n",
       " 2017-08-01 03:00:00  0.423742\n",
       " 2017-08-01 04:00:00  0.478721\n",
       " ...                       ...\n",
       " 2017-11-16 19:00:00  0.606502\n",
       " 2017-11-16 20:00:00  0.456470\n",
       " 2017-11-16 21:00:00  0.483258\n",
       " 2017-11-16 22:00:00  0.468784\n",
       " 2017-11-16 23:00:00  0.473428\n",
       " \n",
       " [2592 rows x 1 columns]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.pairs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.1000, 0.1111, 0.0000, 0.2421, 0.5630, 0.0000, 0.5367, 0.7269],\n",
       "        [0.0000, 0.0000, 0.1111, 0.0526, 0.2232, 0.5707, 0.0000, 0.5467, 0.7407],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.1659, 0.5604, 0.0000, 0.5067, 0.6898],\n",
       "        [0.2778, 0.1000, 0.0000, 0.0000, 0.1424, 0.5553, 0.0000, 0.4633, 0.6343],\n",
       "        [0.8056, 0.2000, 0.1111, 0.1053, 0.1563, 0.5553, 0.0000, 0.4933, 0.6620],\n",
       "        [0.0000, 0.0000, 0.1111, 0.1053, 0.3135, 0.5681, 0.3000, 0.6200, 0.7593],\n",
       "        [0.7222, 0.1000, 0.1111, 0.0526, 0.5326, 0.5913, 0.0000, 0.6433, 0.7269],\n",
       "        [0.7500, 0.1000, 0.1111, 0.1053, 0.5367, 0.5938, 0.0000, 0.6500, 0.7037],\n",
       "        [0.7222, 0.2000, 0.2222, 0.1053, 0.5172, 0.5964, 0.0000, 0.6733, 0.6574],\n",
       "        [0.7500, 0.2000, 0.2222, 0.2105, 0.4459, 0.5990, 0.3000, 0.7133, 0.6157],\n",
       "        [0.6111, 0.2000, 0.2222, 0.1579, 0.3129, 0.6041, 0.0000, 0.7167, 0.6019],\n",
       "        [0.6111, 0.2000, 0.2222, 0.1579, 0.3478, 0.6067, 0.0000, 0.7133, 0.5926],\n",
       "        [0.6528, 0.1000, 0.2222, 0.1053, 0.3649, 0.6041, 0.2000, 0.7800, 0.6435],\n",
       "        [0.6944, 0.2000, 0.2222, 0.1053, 0.3019, 0.6015, 0.2000, 0.7867, 0.4861],\n",
       "        [0.7222, 0.2000, 0.2222, 0.2105, 0.2268, 0.5990, 0.4000, 0.7733, 0.5046],\n",
       "        [0.6111, 0.2000, 0.2222, 0.1579, 0.2246, 0.6015, 0.1000, 0.7633, 0.5972],\n",
       "        [0.6944, 0.2000, 0.2222, 0.2105, 0.2855, 0.6041, 0.7000, 0.7700, 0.5880],\n",
       "        [0.5833, 0.2000, 0.2222, 0.1579, 0.2469, 0.6015, 0.2000, 0.7267, 0.6435],\n",
       "        [0.7222, 0.2000, 0.2222, 0.1579, 0.2171, 0.6144, 0.2000, 0.6967, 0.6944],\n",
       "        [0.6944, 0.1000, 0.1111, 0.1053, 0.2834, 0.6298, 0.0000, 0.5933, 0.7130],\n",
       "        [0.4167, 0.1000, 0.1111, 0.0526, 0.3918, 0.6298, 0.0000, 0.5267, 0.6944],\n",
       "        [0.4722, 0.1000, 0.1111, 0.0000, 0.4752, 0.6375, 0.0000, 0.5200, 0.6991],\n",
       "        [0.4722, 0.1000, 0.1111, 0.0526, 0.5745, 0.6298, 0.0000, 0.5067, 0.6852],\n",
       "        [0.5000, 0.1000, 0.1111, 0.1053, 0.5891, 0.6247, 0.0000, 0.5033, 0.6713],\n",
       "        [0.0000, 0.0000, 0.1111, 0.0526, 0.5491, 0.6298, 0.0000, 0.5000, 0.6806],\n",
       "        [0.4444, 0.1000, 0.1111, 0.0526, 0.5092, 0.6221, 0.0000, 0.5300, 0.6944],\n",
       "        [0.4167, 0.2000, 0.1111, 0.0526, 0.3212, 0.6144, 0.0000, 0.5267, 0.6898],\n",
       "        [0.3889, 0.1000, 0.2222, 0.1053, 0.2835, 0.6118, 0.0000, 0.5467, 0.6898],\n",
       "        [0.5000, 0.1000, 0.1111, 0.0526, 0.4099, 0.6144, 0.0000, 0.5533, 0.7083],\n",
       "        [0.5833, 0.2000, 0.2222, 0.1579, 0.4797, 0.6272, 0.0000, 0.6067, 0.7083],\n",
       "        [0.6389, 0.2000, 0.2222, 0.2105, 0.5086, 0.6272, 0.0000, 0.6333, 0.6991],\n",
       "        [0.6667, 0.4000, 0.3333, 0.2632, 0.4155, 0.6375, 0.0000, 0.6567, 0.6574],\n",
       "        [0.6667, 0.4000, 0.4444, 0.3158, 0.3375, 0.6478, 0.1000, 0.6800, 0.6574],\n",
       "        [0.6389, 0.3000, 0.3333, 0.3684, 0.2610, 0.6478, 0.1000, 0.7067, 0.6713],\n",
       "        [0.5556, 0.4000, 0.4444, 0.2632, 0.2420, 0.6555, 0.3000, 0.7300, 0.6296],\n",
       "        [0.5833, 0.4000, 0.4444, 0.3158, 0.2146, 0.6427, 0.2000, 0.7433, 0.5741],\n",
       "        [0.5556, 0.3000, 0.3333, 0.2632, 0.1782, 0.6221, 0.1000, 0.7600, 0.5370],\n",
       "        [0.5000, 0.4000, 0.4444, 0.2632, 0.1985, 0.6195, 0.0000, 0.7533, 0.5556],\n",
       "        [0.5000, 0.5000, 0.4444, 0.3684, 0.2416, 0.5964, 0.0000, 0.7600, 0.6204],\n",
       "        [0.5833, 0.5000, 0.4444, 0.4737, 0.2883, 0.5938, 0.0000, 0.7267, 0.5833],\n",
       "        [0.5833, 0.4000, 0.7778, 0.5789, 0.2718, 0.6093, 0.0000, 0.5933, 0.6806],\n",
       "        [0.5556, 0.2000, 0.3333, 0.3158, 0.1936, 0.5964, 0.0000, 0.5600, 0.7083],\n",
       "        [0.4861, 0.1000, 0.1111, 0.1579, 0.2238, 0.5835, 0.0000, 0.5533, 0.7361],\n",
       "        [0.4167, 0.2000, 0.2222, 0.1579, 0.2430, 0.5656, 0.0000, 0.5533, 0.7269],\n",
       "        [0.3889, 0.2000, 0.2222, 0.1579, 0.3154, 0.5681, 0.0000, 0.5567, 0.7315],\n",
       "        [0.4444, 0.3000, 0.2222, 0.1579, 0.2860, 0.5553, 0.0000, 0.5800, 0.7639],\n",
       "        [0.5000, 0.3000, 0.3333, 0.2632, 0.2077, 0.5373, 0.0000, 0.5967, 0.7778],\n",
       "        [0.5000, 0.2000, 0.2222, 0.2105, 0.1640, 0.5167, 0.0000, 0.6000, 0.7778],\n",
       "        [0.4444, 0.3000, 0.3333, 0.2632, 0.1525, 0.4961, 0.0000, 0.5967, 0.7824],\n",
       "        [0.4722, 0.4000, 0.3333, 0.3158, 0.1328, 0.4730, 0.0000, 0.6000, 0.7824],\n",
       "        [0.5000, 0.4000, 0.4444, 0.3158, 0.1252, 0.4422, 0.0000, 0.6100, 0.7639],\n",
       "        [0.4722, 0.2000, 0.3333, 0.2632, 0.1161, 0.4293, 0.0000, 0.6000, 0.7639],\n",
       "        [0.4722, 0.2000, 0.2222, 0.1579, 0.1766, 0.4165, 0.0000, 0.5967, 0.7731],\n",
       "        [0.5556, 0.4000, 0.3333, 0.3158, 0.2840, 0.4139, 0.0000, 0.6533, 0.8056],\n",
       "        [0.5833, 0.5000, 0.4444, 0.4211, 0.3435, 0.4010, 0.5000, 0.6967, 0.8009],\n",
       "        [0.5833, 0.6000, 0.5556, 0.4737, 0.3057, 0.3985, 0.0000, 0.6867, 0.8194],\n",
       "        [0.5833, 0.6000, 0.5556, 0.4737, 0.2615, 0.4036, 0.0000, 0.6633, 0.8519],\n",
       "        [0.6389, 0.5000, 0.6667, 0.5789, 0.2453, 0.4190, 0.0000, 0.6133, 0.7454],\n",
       "        [0.6389, 0.7000, 0.7778, 0.6316, 0.1434, 0.4216, 0.6000, 0.7067, 0.6806],\n",
       "        [0.6667, 0.9000, 0.8889, 0.7368, 0.1046, 0.4267, 0.7000, 0.7467, 0.6435],\n",
       "        [0.6667, 0.8000, 0.7778, 0.7368, 0.0607, 0.4319, 0.8000, 0.7667, 0.6019],\n",
       "        [0.6667, 0.9000, 1.0000, 0.8947, 0.0700, 0.4319, 1.0000, 0.7867, 0.6065],\n",
       "        [0.6944, 0.8000, 0.8889, 0.7895, 0.0594, 0.4422, 0.4000, 0.7400, 0.6389],\n",
       "        [0.6667, 0.8000, 0.7778, 0.6842, 0.0823, 0.4370, 0.5000, 0.7633, 0.6389],\n",
       "        [0.6667, 0.7000, 0.8889, 0.7368, 0.1016, 0.4473, 1.0000, 0.7467, 0.6944],\n",
       "        [0.6389, 0.9000, 0.8889, 0.8421, 0.1005, 0.4550, 0.5000, 0.7067, 0.5278],\n",
       "        [0.6667, 0.7000, 1.0000, 0.8947, 0.0701, 0.4627, 0.3000, 0.6900, 0.5602],\n",
       "        [0.6389, 1.0000, 0.8889, 0.9474, 0.0572, 0.4653, 0.0000, 0.6800, 0.5648],\n",
       "        [0.6667, 0.9000, 0.8889, 0.8421, 0.0533, 0.4627, 0.0000, 0.6567, 0.5741],\n",
       "        [0.6667, 0.7000, 0.7778, 0.7368, 0.0475, 0.4627, 0.0000, 0.6300, 0.6019],\n",
       "        [0.6389, 0.4000, 0.5556, 0.5789, 0.0376, 0.4576, 0.0000, 0.6100, 0.6204],\n",
       "        [0.6111, 0.5000, 0.4444, 0.4211, 0.0373, 0.4499, 0.0000, 0.5933, 0.6296]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.pairs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1965],\n",
       "        [0.1501],\n",
       "        [0.1518],\n",
       "        [0.2622],\n",
       "        [0.5524],\n",
       "        [0.4840],\n",
       "        [0.3544],\n",
       "        [0.2754],\n",
       "        [0.1948],\n",
       "        [0.1734],\n",
       "        [0.1505],\n",
       "        [0.1352],\n",
       "        [0.0778],\n",
       "        [0.1184],\n",
       "        [0.1293],\n",
       "        [0.1238],\n",
       "        [0.1043],\n",
       "        [0.0997],\n",
       "        [0.0812],\n",
       "        [0.0823],\n",
       "        [0.1155],\n",
       "        [0.0837],\n",
       "        [0.0570],\n",
       "        [0.1006]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.pairs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO2 index:  4\n",
      "DD index (wind direction):  0\n",
      "FH index (Hourly wind speed):  2\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_dataset.u[0] is a pandas Index object with column names\n",
    "column_names = list(train_dataset.u[0])  # Convert Index to list\n",
    "\n",
    "# Now, find the indices of the columns 'NO2', 'DD', 'FH'\n",
    "no2_idx = column_names.index('NO2')\n",
    "dd_idx = column_names.index('DD')\n",
    "fh_idx = column_names.index('FH')\n",
    "\n",
    "print(\"NO2 index: \", no2_idx)\n",
    "print(\"DD index (wind direction): \", dd_idx)\n",
    "print(\"FH index (Hourly wind speed): \", fh_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime\n",
       "2017-08-01 00:00:00    0.242115\n",
       "2017-08-01 01:00:00    0.223158\n",
       "2017-08-01 02:00:00    0.165911\n",
       "2017-08-01 03:00:00    0.142363\n",
       "2017-08-01 04:00:00    0.156297\n",
       "                         ...   \n",
       "2017-11-16 19:00:00    0.523871\n",
       "2017-11-16 20:00:00    0.512314\n",
       "2017-11-16 21:00:00    0.232880\n",
       "2017-11-16 22:00:00    0.108123\n",
       "2017-11-16 23:00:00    0.205120\n",
       "Name: NO2, Length: 2592, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.u[0].iloc[:,no2_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime\n",
       "2017-08-01 00:00:00    0.166667\n",
       "2017-08-01 01:00:00    0.000000\n",
       "2017-08-01 02:00:00    0.000000\n",
       "2017-08-01 03:00:00    0.277778\n",
       "2017-08-01 04:00:00    0.805556\n",
       "                         ...   \n",
       "2017-11-16 19:00:00    0.750000\n",
       "2017-11-16 20:00:00    0.972222\n",
       "2017-11-16 21:00:00    0.888889\n",
       "2017-11-16 22:00:00    0.944444\n",
       "2017-11-16 23:00:00    0.861111\n",
       "Name: DD, Length: 2592, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.u[0].iloc[:,dd_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime\n",
       "2017-08-01 00:00:00    0.111111\n",
       "2017-08-01 01:00:00    0.111111\n",
       "2017-08-01 02:00:00    0.000000\n",
       "2017-08-01 03:00:00    0.000000\n",
       "2017-08-01 04:00:00    0.111111\n",
       "                         ...   \n",
       "2017-11-16 19:00:00    0.333333\n",
       "2017-11-16 20:00:00    0.333333\n",
       "2017-11-16 21:00:00    0.222222\n",
       "2017-11-16 22:00:00    0.111111\n",
       "2017-11-16 23:00:00    0.222222\n",
       "Name: FH, Length: 2592, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.u[0].iloc[:,fh_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Start hyperparameter searching with Optuna**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:12:49,239] A new study created in RDB with name: mlp_hyperparameter_optimization_phy_linear\n",
      "/tmp/ipykernel_14326/652868241.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
      "/tmp/ipykernel_14326/652868241.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-8, 1e-3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.146355 - Val Loss: 0.312983\n",
      "Epoch 2/50 - Train Loss: 0.145583 - Val Loss: 0.308783\n",
      "Epoch 3/50 - Train Loss: 0.136798 - Val Loss: 0.304634\n",
      "Epoch 4/50 - Train Loss: 0.151040 - Val Loss: 0.300514\n",
      "Epoch 5/50 - Train Loss: 0.152854 - Val Loss: 0.296433\n",
      "Epoch 6/50 - Train Loss: 0.136781 - Val Loss: 0.292445\n",
      "Epoch 7/50 - Train Loss: 0.142438 - Val Loss: 0.288559\n",
      "Epoch 8/50 - Train Loss: 0.134709 - Val Loss: 0.284645\n",
      "Epoch 9/50 - Train Loss: 0.140377 - Val Loss: 0.280787\n",
      "Epoch 10/50 - Train Loss: 0.129283 - Val Loss: 0.276970\n",
      "Epoch 11/50 - Train Loss: 0.124393 - Val Loss: 0.273307\n",
      "Epoch 12/50 - Train Loss: 0.124134 - Val Loss: 0.269600\n",
      "Epoch 13/50 - Train Loss: 0.115389 - Val Loss: 0.266009\n",
      "Epoch 14/50 - Train Loss: 0.119721 - Val Loss: 0.262411\n",
      "Epoch 15/50 - Train Loss: 0.129500 - Val Loss: 0.258882\n",
      "Epoch 16/50 - Train Loss: 0.121691 - Val Loss: 0.255243\n",
      "Epoch 17/50 - Train Loss: 0.125361 - Val Loss: 0.251549\n",
      "Epoch 18/50 - Train Loss: 0.114106 - Val Loss: 0.248020\n",
      "Epoch 19/50 - Train Loss: 0.100685 - Val Loss: 0.244761\n",
      "Epoch 20/50 - Train Loss: 0.107570 - Val Loss: 0.241673\n",
      "Epoch 21/50 - Train Loss: 0.107370 - Val Loss: 0.238523\n",
      "Epoch 22/50 - Train Loss: 0.106560 - Val Loss: 0.235411\n",
      "Epoch 23/50 - Train Loss: 0.104275 - Val Loss: 0.232281\n",
      "Epoch 24/50 - Train Loss: 0.103550 - Val Loss: 0.229162\n",
      "Epoch 25/50 - Train Loss: 0.106397 - Val Loss: 0.225990\n",
      "Epoch 26/50 - Train Loss: 0.093828 - Val Loss: 0.222949\n",
      "Epoch 27/50 - Train Loss: 0.096999 - Val Loss: 0.219980\n",
      "Epoch 28/50 - Train Loss: 0.098175 - Val Loss: 0.216925\n",
      "Epoch 29/50 - Train Loss: 0.093867 - Val Loss: 0.213833\n",
      "Epoch 30/50 - Train Loss: 0.094774 - Val Loss: 0.210748\n",
      "Epoch 31/50 - Train Loss: 0.096729 - Val Loss: 0.207645\n",
      "Epoch 32/50 - Train Loss: 0.095518 - Val Loss: 0.204470\n",
      "Epoch 33/50 - Train Loss: 0.082029 - Val Loss: 0.201364\n",
      "Epoch 34/50 - Train Loss: 0.088680 - Val Loss: 0.198332\n",
      "Epoch 35/50 - Train Loss: 0.081917 - Val Loss: 0.195208\n",
      "Epoch 36/50 - Train Loss: 0.083699 - Val Loss: 0.191926\n",
      "Epoch 37/50 - Train Loss: 0.083746 - Val Loss: 0.188546\n",
      "Epoch 38/50 - Train Loss: 0.084047 - Val Loss: 0.185022\n",
      "Epoch 39/50 - Train Loss: 0.074771 - Val Loss: 0.181514\n",
      "Epoch 40/50 - Train Loss: 0.075088 - Val Loss: 0.178015\n",
      "Epoch 41/50 - Train Loss: 0.074275 - Val Loss: 0.174586\n",
      "Epoch 42/50 - Train Loss: 0.076465 - Val Loss: 0.171084\n",
      "Epoch 43/50 - Train Loss: 0.067969 - Val Loss: 0.167537\n",
      "Epoch 44/50 - Train Loss: 0.067981 - Val Loss: 0.164077\n",
      "Epoch 45/50 - Train Loss: 0.070820 - Val Loss: 0.160654\n",
      "Epoch 46/50 - Train Loss: 0.061378 - Val Loss: 0.157221\n",
      "Epoch 47/50 - Train Loss: 0.063452 - Val Loss: 0.154014\n",
      "Epoch 48/50 - Train Loss: 0.065678 - Val Loss: 0.150941\n",
      "Epoch 49/50 - Train Loss: 0.063978 - Val Loss: 0.147632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:13:24,694] Trial 0 finished with value: 0.14432156085968018 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 60, 'lr': 2.755285351775891e-05, 'weight_decay': 3.8018050850427953e-07, 'batch_size': 16}. Best is trial 0 with value: 0.14432156085968018.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.059153 - Val Loss: 0.144322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14326/652868241.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
      "/tmp/ipykernel_14326/652868241.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-8, 1e-3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.118765 - Val Loss: 0.257729\n",
      "Epoch 2/50 - Train Loss: 0.112229 - Val Loss: 0.249363\n",
      "Epoch 3/50 - Train Loss: 0.120660 - Val Loss: 0.241273\n",
      "Epoch 4/50 - Train Loss: 0.113165 - Val Loss: 0.233294\n",
      "Epoch 5/50 - Train Loss: 0.100506 - Val Loss: 0.225394\n",
      "Epoch 6/50 - Train Loss: 0.102150 - Val Loss: 0.217668\n",
      "Epoch 7/50 - Train Loss: 0.101425 - Val Loss: 0.210037\n",
      "Epoch 8/50 - Train Loss: 0.092232 - Val Loss: 0.202485\n",
      "Epoch 9/50 - Train Loss: 0.095877 - Val Loss: 0.195015\n",
      "Epoch 10/50 - Train Loss: 0.077892 - Val Loss: 0.187500\n",
      "Epoch 11/50 - Train Loss: 0.077665 - Val Loss: 0.180206\n",
      "Epoch 12/50 - Train Loss: 0.077700 - Val Loss: 0.172924\n",
      "Epoch 13/50 - Train Loss: 0.067459 - Val Loss: 0.165706\n",
      "Epoch 14/50 - Train Loss: 0.065272 - Val Loss: 0.158682\n",
      "Epoch 15/50 - Train Loss: 0.071579 - Val Loss: 0.151492\n",
      "Epoch 16/50 - Train Loss: 0.065638 - Val Loss: 0.144182\n",
      "Epoch 17/50 - Train Loss: 0.062388 - Val Loss: 0.137173\n",
      "Epoch 18/50 - Train Loss: 0.050949 - Val Loss: 0.130392\n",
      "Epoch 19/50 - Train Loss: 0.053614 - Val Loss: 0.124051\n",
      "Epoch 20/50 - Train Loss: 0.048339 - Val Loss: 0.118044\n",
      "Epoch 21/50 - Train Loss: 0.048002 - Val Loss: 0.112372\n",
      "Epoch 22/50 - Train Loss: 0.046595 - Val Loss: 0.107276\n",
      "Epoch 23/50 - Train Loss: 0.046909 - Val Loss: 0.102565\n",
      "Epoch 24/50 - Train Loss: 0.041083 - Val Loss: 0.098314\n",
      "Epoch 25/50 - Train Loss: 0.040302 - Val Loss: 0.094903\n",
      "Epoch 26/50 - Train Loss: 0.046984 - Val Loss: 0.092426\n",
      "Epoch 27/50 - Train Loss: 0.043035 - Val Loss: 0.090613\n",
      "Epoch 28/50 - Train Loss: 0.046741 - Val Loss: 0.089809\n",
      "Epoch 29/50 - Train Loss: 0.044947 - Val Loss: 0.089435\n",
      "Epoch 30/50 - Train Loss: 0.039205 - Val Loss: 0.089286\n",
      "Epoch 31/50 - Train Loss: 0.040967 - Val Loss: 0.089256\n",
      "Epoch 32/50 - Train Loss: 0.048930 - Val Loss: 0.089356\n",
      "Epoch 33/50 - Train Loss: 0.044074 - Val Loss: 0.089190\n",
      "Epoch 34/50 - Train Loss: 0.037409 - Val Loss: 0.089058\n",
      "Epoch 35/50 - Train Loss: 0.042041 - Val Loss: 0.088886\n",
      "Epoch 36/50 - Train Loss: 0.040022 - Val Loss: 0.088720\n",
      "Epoch 37/50 - Train Loss: 0.039398 - Val Loss: 0.088624\n",
      "Epoch 38/50 - Train Loss: 0.050013 - Val Loss: 0.088948\n",
      "Epoch 39/50 - Train Loss: 0.043554 - Val Loss: 0.088831\n",
      "Epoch 40/50 - Train Loss: 0.042359 - Val Loss: 0.088382\n",
      "Epoch 41/50 - Train Loss: 0.039328 - Val Loss: 0.087973\n",
      "Epoch 42/50 - Train Loss: 0.044122 - Val Loss: 0.087687\n",
      "Epoch 43/50 - Train Loss: 0.038523 - Val Loss: 0.086666\n",
      "Epoch 44/50 - Train Loss: 0.043628 - Val Loss: 0.085993\n",
      "Epoch 45/50 - Train Loss: 0.038924 - Val Loss: 0.085547\n",
      "Epoch 46/50 - Train Loss: 0.039697 - Val Loss: 0.084775\n",
      "Epoch 47/50 - Train Loss: 0.040686 - Val Loss: 0.084120\n",
      "Epoch 48/50 - Train Loss: 0.040901 - Val Loss: 0.083922\n",
      "Epoch 49/50 - Train Loss: 0.041891 - Val Loss: 0.083572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:13:46,023] Trial 1 finished with value: 0.08228302001953125 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 97, 'lr': 8.208755756757446e-05, 'weight_decay': 3.6865732013796275e-08, 'batch_size': 32}. Best is trial 1 with value: 0.08228302001953125.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.040966 - Val Loss: 0.082283\n",
      "Epoch 1/50 - Train Loss: 0.108507 - Val Loss: 0.054421\n",
      "Epoch 2/50 - Train Loss: 0.045783 - Val Loss: 0.058667\n",
      "Epoch 3/50 - Train Loss: 0.032964 - Val Loss: 0.049405\n",
      "Epoch 4/50 - Train Loss: 0.033211 - Val Loss: 0.046552\n",
      "Epoch 5/50 - Train Loss: 0.031445 - Val Loss: 0.051621\n",
      "Epoch 6/50 - Train Loss: 0.031644 - Val Loss: 0.045210\n",
      "Epoch 7/50 - Train Loss: 0.033422 - Val Loss: 0.045199\n",
      "Epoch 8/50 - Train Loss: 0.032745 - Val Loss: 0.045562\n",
      "Epoch 9/50 - Train Loss: 0.032483 - Val Loss: 0.048050\n",
      "Epoch 10/50 - Train Loss: 0.030581 - Val Loss: 0.044749\n",
      "Epoch 11/50 - Train Loss: 0.032471 - Val Loss: 0.048603\n",
      "Epoch 12/50 - Train Loss: 0.031399 - Val Loss: 0.052687\n",
      "Epoch 13/50 - Train Loss: 0.033545 - Val Loss: 0.049725\n",
      "Epoch 14/50 - Train Loss: 0.028398 - Val Loss: 0.046175\n",
      "Epoch 15/50 - Train Loss: 0.029417 - Val Loss: 0.045395\n",
      "Epoch 16/50 - Train Loss: 0.028693 - Val Loss: 0.050613\n",
      "Epoch 17/50 - Train Loss: 0.030706 - Val Loss: 0.044804\n",
      "Epoch 18/50 - Train Loss: 0.030559 - Val Loss: 0.045443\n",
      "Epoch 19/50 - Train Loss: 0.030757 - Val Loss: 0.045244\n",
      "Epoch 20/50 - Train Loss: 0.031172 - Val Loss: 0.047271\n",
      "Epoch 21/50 - Train Loss: 0.031164 - Val Loss: 0.060619\n",
      "Epoch 22/50 - Train Loss: 0.034108 - Val Loss: 0.056991\n",
      "Epoch 23/50 - Train Loss: 0.032342 - Val Loss: 0.043963\n",
      "Epoch 24/50 - Train Loss: 0.031878 - Val Loss: 0.043616\n",
      "Epoch 25/50 - Train Loss: 0.031181 - Val Loss: 0.043811\n",
      "Epoch 26/50 - Train Loss: 0.032019 - Val Loss: 0.051009\n",
      "Epoch 27/50 - Train Loss: 0.030156 - Val Loss: 0.043827\n",
      "Epoch 28/50 - Train Loss: 0.032109 - Val Loss: 0.044015\n",
      "Epoch 29/50 - Train Loss: 0.029121 - Val Loss: 0.046327\n",
      "Epoch 30/50 - Train Loss: 0.028964 - Val Loss: 0.045316\n",
      "Epoch 31/50 - Train Loss: 0.028232 - Val Loss: 0.044837\n",
      "Epoch 32/50 - Train Loss: 0.030869 - Val Loss: 0.045658\n",
      "Epoch 33/50 - Train Loss: 0.029024 - Val Loss: 0.043971\n",
      "Epoch 34/50 - Train Loss: 0.031399 - Val Loss: 0.046071\n",
      "Epoch 35/50 - Train Loss: 0.028978 - Val Loss: 0.047754\n",
      "Epoch 36/50 - Train Loss: 0.028005 - Val Loss: 0.044887\n",
      "Epoch 37/50 - Train Loss: 0.028635 - Val Loss: 0.046822\n",
      "Epoch 38/50 - Train Loss: 0.031153 - Val Loss: 0.049142\n",
      "Epoch 39/50 - Train Loss: 0.031511 - Val Loss: 0.044706\n",
      "Epoch 40/50 - Train Loss: 0.031400 - Val Loss: 0.045716\n",
      "Epoch 41/50 - Train Loss: 0.030462 - Val Loss: 0.045159\n",
      "Epoch 42/50 - Train Loss: 0.031264 - Val Loss: 0.048005\n",
      "Epoch 43/50 - Train Loss: 0.031774 - Val Loss: 0.046825\n",
      "Epoch 44/50 - Train Loss: 0.031602 - Val Loss: 0.046306\n",
      "Epoch 45/50 - Train Loss: 0.029640 - Val Loss: 0.044289\n",
      "Epoch 46/50 - Train Loss: 0.027336 - Val Loss: 0.044676\n",
      "Epoch 47/50 - Train Loss: 0.030020 - Val Loss: 0.045399\n",
      "Epoch 48/50 - Train Loss: 0.030125 - Val Loss: 0.044425\n",
      "Epoch 49/50 - Train Loss: 0.027680 - Val Loss: 0.044069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:14:15,433] Trial 2 finished with value: 0.04361645753184954 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 256, 'lr': 0.003951472939338471, 'weight_decay': 1.0833850735920747e-08, 'batch_size': 8}. Best is trial 2 with value: 0.04361645753184954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.027929 - Val Loss: 0.045769\n",
      "Epoch 1/50 - Train Loss: 0.185504 - Val Loss: 0.263143\n",
      "Epoch 2/50 - Train Loss: 0.100148 - Val Loss: 0.151925\n",
      "Epoch 3/50 - Train Loss: 0.053530 - Val Loss: 0.096767\n",
      "Epoch 4/50 - Train Loss: 0.050988 - Val Loss: 0.080148\n",
      "Epoch 5/50 - Train Loss: 0.059969 - Val Loss: 0.076952\n",
      "Epoch 6/50 - Train Loss: 0.059098 - Val Loss: 0.080470\n",
      "Epoch 7/50 - Train Loss: 0.046305 - Val Loss: 0.090377\n",
      "Epoch 8/50 - Train Loss: 0.040621 - Val Loss: 0.099439\n",
      "Epoch 9/50 - Train Loss: 0.047775 - Val Loss: 0.100879\n",
      "Epoch 10/50 - Train Loss: 0.048402 - Val Loss: 0.091478\n",
      "Epoch 11/50 - Train Loss: 0.040867 - Val Loss: 0.079863\n",
      "Epoch 12/50 - Train Loss: 0.038294 - Val Loss: 0.072251\n",
      "Epoch 13/50 - Train Loss: 0.033785 - Val Loss: 0.067951\n",
      "Epoch 14/50 - Train Loss: 0.038212 - Val Loss: 0.066410\n",
      "Epoch 15/50 - Train Loss: 0.037618 - Val Loss: 0.065773\n",
      "Epoch 16/50 - Train Loss: 0.036680 - Val Loss: 0.066837\n",
      "Epoch 17/50 - Train Loss: 0.032412 - Val Loss: 0.065225\n",
      "Epoch 18/50 - Train Loss: 0.032305 - Val Loss: 0.062527\n",
      "Epoch 19/50 - Train Loss: 0.028318 - Val Loss: 0.058887\n",
      "Epoch 20/50 - Train Loss: 0.035964 - Val Loss: 0.055634\n",
      "Epoch 21/50 - Train Loss: 0.037569 - Val Loss: 0.054202\n",
      "Epoch 22/50 - Train Loss: 0.030101 - Val Loss: 0.054488\n",
      "Epoch 23/50 - Train Loss: 0.036650 - Val Loss: 0.055154\n",
      "Epoch 24/50 - Train Loss: 0.034300 - Val Loss: 0.052887\n",
      "Epoch 25/50 - Train Loss: 0.034844 - Val Loss: 0.050972\n",
      "Epoch 26/50 - Train Loss: 0.035169 - Val Loss: 0.051094\n",
      "Epoch 27/50 - Train Loss: 0.032976 - Val Loss: 0.050757\n",
      "Epoch 28/50 - Train Loss: 0.031764 - Val Loss: 0.049969\n",
      "Epoch 29/50 - Train Loss: 0.031501 - Val Loss: 0.049196\n",
      "Epoch 30/50 - Train Loss: 0.033925 - Val Loss: 0.048873\n",
      "Epoch 31/50 - Train Loss: 0.034869 - Val Loss: 0.048615\n",
      "Epoch 32/50 - Train Loss: 0.030842 - Val Loss: 0.047565\n",
      "Epoch 33/50 - Train Loss: 0.035486 - Val Loss: 0.046922\n",
      "Epoch 34/50 - Train Loss: 0.034752 - Val Loss: 0.047132\n",
      "Epoch 35/50 - Train Loss: 0.028308 - Val Loss: 0.047502\n",
      "Epoch 36/50 - Train Loss: 0.028693 - Val Loss: 0.047291\n",
      "Epoch 37/50 - Train Loss: 0.035994 - Val Loss: 0.046788\n",
      "Epoch 38/50 - Train Loss: 0.029298 - Val Loss: 0.046412\n",
      "Epoch 39/50 - Train Loss: 0.029050 - Val Loss: 0.046576\n",
      "Epoch 40/50 - Train Loss: 0.038191 - Val Loss: 0.046899\n",
      "Epoch 41/50 - Train Loss: 0.031699 - Val Loss: 0.046294\n",
      "Epoch 42/50 - Train Loss: 0.032699 - Val Loss: 0.046497\n",
      "Epoch 43/50 - Train Loss: 0.032786 - Val Loss: 0.046585\n",
      "Epoch 44/50 - Train Loss: 0.032188 - Val Loss: 0.046507\n",
      "Epoch 45/50 - Train Loss: 0.032474 - Val Loss: 0.046365\n",
      "Epoch 46/50 - Train Loss: 0.033671 - Val Loss: 0.045950\n",
      "Epoch 47/50 - Train Loss: 0.035319 - Val Loss: 0.046179\n",
      "Epoch 48/50 - Train Loss: 0.030671 - Val Loss: 0.045849\n",
      "Epoch 49/50 - Train Loss: 0.033030 - Val Loss: 0.045911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:14:31,763] Trial 3 finished with value: 0.04584948718547821 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 236, 'lr': 0.0002600889092598319, 'weight_decay': 4.2618455388795615e-07, 'batch_size': 32}. Best is trial 2 with value: 0.04361645753184954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030071 - Val Loss: 0.046174\n",
      "Epoch 1/50 - Train Loss: 0.117175 - Val Loss: 0.243957\n",
      "Epoch 2/50 - Train Loss: 0.113844 - Val Loss: 0.240601\n",
      "Epoch 3/50 - Train Loss: 0.108406 - Val Loss: 0.237366\n",
      "Epoch 4/50 - Train Loss: 0.106085 - Val Loss: 0.234200\n",
      "Epoch 5/50 - Train Loss: 0.103759 - Val Loss: 0.231080\n",
      "Epoch 6/50 - Train Loss: 0.106221 - Val Loss: 0.227973\n",
      "Epoch 7/50 - Train Loss: 0.105757 - Val Loss: 0.224866\n",
      "Epoch 8/50 - Train Loss: 0.105851 - Val Loss: 0.221776\n",
      "Epoch 9/50 - Train Loss: 0.102228 - Val Loss: 0.218742\n",
      "Epoch 10/50 - Train Loss: 0.097988 - Val Loss: 0.215759\n",
      "Epoch 11/50 - Train Loss: 0.094183 - Val Loss: 0.212844\n",
      "Epoch 12/50 - Train Loss: 0.094401 - Val Loss: 0.209950\n",
      "Epoch 13/50 - Train Loss: 0.092879 - Val Loss: 0.207157\n",
      "Epoch 14/50 - Train Loss: 0.092701 - Val Loss: 0.204428\n",
      "Epoch 15/50 - Train Loss: 0.089387 - Val Loss: 0.201639\n",
      "Epoch 16/50 - Train Loss: 0.086371 - Val Loss: 0.198995\n",
      "Epoch 17/50 - Train Loss: 0.083358 - Val Loss: 0.196280\n",
      "Epoch 18/50 - Train Loss: 0.083088 - Val Loss: 0.193720\n",
      "Epoch 19/50 - Train Loss: 0.088624 - Val Loss: 0.191126\n",
      "Epoch 20/50 - Train Loss: 0.093167 - Val Loss: 0.188370\n",
      "Epoch 21/50 - Train Loss: 0.083770 - Val Loss: 0.185686\n",
      "Epoch 22/50 - Train Loss: 0.076640 - Val Loss: 0.183083\n",
      "Epoch 23/50 - Train Loss: 0.080125 - Val Loss: 0.180562\n",
      "Epoch 24/50 - Train Loss: 0.073515 - Val Loss: 0.178035\n",
      "Epoch 25/50 - Train Loss: 0.078217 - Val Loss: 0.175535\n",
      "Epoch 26/50 - Train Loss: 0.076211 - Val Loss: 0.173011\n",
      "Epoch 27/50 - Train Loss: 0.071778 - Val Loss: 0.170481\n",
      "Epoch 28/50 - Train Loss: 0.077761 - Val Loss: 0.168062\n",
      "Epoch 29/50 - Train Loss: 0.067090 - Val Loss: 0.165611\n",
      "Epoch 30/50 - Train Loss: 0.075201 - Val Loss: 0.163099\n",
      "Epoch 31/50 - Train Loss: 0.070985 - Val Loss: 0.160679\n",
      "Epoch 32/50 - Train Loss: 0.064946 - Val Loss: 0.158247\n",
      "Epoch 33/50 - Train Loss: 0.070746 - Val Loss: 0.155808\n",
      "Epoch 34/50 - Train Loss: 0.065945 - Val Loss: 0.153308\n",
      "Epoch 35/50 - Train Loss: 0.072419 - Val Loss: 0.150880\n",
      "Epoch 36/50 - Train Loss: 0.066063 - Val Loss: 0.148431\n",
      "Epoch 37/50 - Train Loss: 0.064326 - Val Loss: 0.145925\n",
      "Epoch 38/50 - Train Loss: 0.061596 - Val Loss: 0.143431\n",
      "Epoch 39/50 - Train Loss: 0.060952 - Val Loss: 0.141080\n",
      "Epoch 40/50 - Train Loss: 0.061792 - Val Loss: 0.138811\n",
      "Epoch 41/50 - Train Loss: 0.056948 - Val Loss: 0.136570\n",
      "Epoch 42/50 - Train Loss: 0.059893 - Val Loss: 0.134359\n",
      "Epoch 43/50 - Train Loss: 0.054143 - Val Loss: 0.132201\n",
      "Epoch 44/50 - Train Loss: 0.052310 - Val Loss: 0.130046\n",
      "Epoch 45/50 - Train Loss: 0.053602 - Val Loss: 0.127851\n",
      "Epoch 46/50 - Train Loss: 0.053359 - Val Loss: 0.125761\n",
      "Epoch 47/50 - Train Loss: 0.054941 - Val Loss: 0.123689\n",
      "Epoch 48/50 - Train Loss: 0.051988 - Val Loss: 0.121686\n",
      "Epoch 49/50 - Train Loss: 0.053644 - Val Loss: 0.119647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:14:49,340] Trial 4 finished with value: 0.11770317330956459 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 83, 'lr': 1.4086784408392199e-05, 'weight_decay': 6.425029868754466e-07, 'batch_size': 16}. Best is trial 2 with value: 0.04361645753184954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.051689 - Val Loss: 0.117703\n",
      "Epoch 1/50 - Train Loss: 0.138880 - Val Loss: 0.248164\n",
      "Epoch 2/50 - Train Loss: 0.095396 - Val Loss: 0.183314\n",
      "Epoch 3/50 - Train Loss: 0.068277 - Val Loss: 0.126597\n",
      "Epoch 4/50 - Train Loss: 0.049323 - Val Loss: 0.089207\n",
      "Epoch 5/50 - Train Loss: 0.047023 - Val Loss: 0.073701\n",
      "Epoch 6/50 - Train Loss: 0.046811 - Val Loss: 0.072204\n",
      "Epoch 7/50 - Train Loss: 0.043745 - Val Loss: 0.077250\n",
      "Epoch 8/50 - Train Loss: 0.047148 - Val Loss: 0.082028\n",
      "Epoch 9/50 - Train Loss: 0.041409 - Val Loss: 0.080358\n",
      "Epoch 10/50 - Train Loss: 0.038740 - Val Loss: 0.072264\n",
      "Epoch 11/50 - Train Loss: 0.039100 - Val Loss: 0.066993\n",
      "Epoch 12/50 - Train Loss: 0.038464 - Val Loss: 0.066477\n",
      "Epoch 13/50 - Train Loss: 0.037883 - Val Loss: 0.069860\n",
      "Epoch 14/50 - Train Loss: 0.034456 - Val Loss: 0.064706\n",
      "Epoch 15/50 - Train Loss: 0.034094 - Val Loss: 0.061241\n",
      "Epoch 16/50 - Train Loss: 0.035453 - Val Loss: 0.060002\n",
      "Epoch 17/50 - Train Loss: 0.031791 - Val Loss: 0.062528\n",
      "Epoch 18/50 - Train Loss: 0.030944 - Val Loss: 0.056720\n",
      "Epoch 19/50 - Train Loss: 0.033302 - Val Loss: 0.057264\n",
      "Epoch 20/50 - Train Loss: 0.035319 - Val Loss: 0.059597\n",
      "Epoch 21/50 - Train Loss: 0.035294 - Val Loss: 0.055078\n",
      "Epoch 22/50 - Train Loss: 0.031945 - Val Loss: 0.053824\n",
      "Epoch 23/50 - Train Loss: 0.033034 - Val Loss: 0.054332\n",
      "Epoch 24/50 - Train Loss: 0.032242 - Val Loss: 0.054365\n",
      "Epoch 25/50 - Train Loss: 0.035557 - Val Loss: 0.053289\n",
      "Epoch 26/50 - Train Loss: 0.033801 - Val Loss: 0.053994\n",
      "Epoch 27/50 - Train Loss: 0.034475 - Val Loss: 0.052249\n",
      "Epoch 28/50 - Train Loss: 0.031585 - Val Loss: 0.051276\n",
      "Epoch 29/50 - Train Loss: 0.032846 - Val Loss: 0.051251\n",
      "Epoch 30/50 - Train Loss: 0.034250 - Val Loss: 0.050798\n",
      "Epoch 31/50 - Train Loss: 0.032128 - Val Loss: 0.051741\n",
      "Epoch 32/50 - Train Loss: 0.030540 - Val Loss: 0.050023\n",
      "Epoch 33/50 - Train Loss: 0.033926 - Val Loss: 0.049298\n",
      "Epoch 34/50 - Train Loss: 0.032907 - Val Loss: 0.051170\n",
      "Epoch 35/50 - Train Loss: 0.030498 - Val Loss: 0.049104\n",
      "Epoch 36/50 - Train Loss: 0.030813 - Val Loss: 0.050021\n",
      "Epoch 37/50 - Train Loss: 0.033255 - Val Loss: 0.051089\n",
      "Epoch 38/50 - Train Loss: 0.030521 - Val Loss: 0.048097\n",
      "Epoch 39/50 - Train Loss: 0.032221 - Val Loss: 0.048992\n",
      "Epoch 40/50 - Train Loss: 0.028487 - Val Loss: 0.049663\n",
      "Epoch 41/50 - Train Loss: 0.028752 - Val Loss: 0.048541\n",
      "Epoch 42/50 - Train Loss: 0.032401 - Val Loss: 0.047915\n",
      "Epoch 43/50 - Train Loss: 0.031398 - Val Loss: 0.050203\n",
      "Epoch 44/50 - Train Loss: 0.031618 - Val Loss: 0.049354\n",
      "Epoch 45/50 - Train Loss: 0.030716 - Val Loss: 0.048091\n",
      "Epoch 46/50 - Train Loss: 0.033032 - Val Loss: 0.048956\n",
      "Epoch 47/50 - Train Loss: 0.030326 - Val Loss: 0.049493\n",
      "Epoch 48/50 - Train Loss: 0.030522 - Val Loss: 0.047664\n",
      "Epoch 49/50 - Train Loss: 0.031918 - Val Loss: 0.048126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:15:14,403] Trial 5 finished with value: 0.04766356199979782 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 156, 'lr': 0.00016057455091405027, 'weight_decay': 0.0005247384822086854, 'batch_size': 16}. Best is trial 2 with value: 0.04361645753184954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033504 - Val Loss: 0.049685\n",
      "Epoch 1/50 - Train Loss: 0.088695 - Val Loss: 0.098418\n",
      "Epoch 2/50 - Train Loss: 0.090840 - Val Loss: 0.085846\n",
      "Epoch 3/50 - Train Loss: 0.047490 - Val Loss: 0.137029\n",
      "Epoch 4/50 - Train Loss: 0.065993 - Val Loss: 0.132171\n",
      "Epoch 5/50 - Train Loss: 0.049590 - Val Loss: 0.089214\n",
      "Epoch 6/50 - Train Loss: 0.045404 - Val Loss: 0.059402\n",
      "Epoch 7/50 - Train Loss: 0.048093 - Val Loss: 0.057022\n",
      "Epoch 8/50 - Train Loss: 0.037869 - Val Loss: 0.062409\n",
      "Epoch 9/50 - Train Loss: 0.035240 - Val Loss: 0.071414\n",
      "Epoch 10/50 - Train Loss: 0.041544 - Val Loss: 0.071655\n",
      "Epoch 11/50 - Train Loss: 0.043214 - Val Loss: 0.063407\n",
      "Epoch 12/50 - Train Loss: 0.040654 - Val Loss: 0.054178\n",
      "Epoch 13/50 - Train Loss: 0.031455 - Val Loss: 0.050439\n",
      "Epoch 14/50 - Train Loss: 0.038897 - Val Loss: 0.052323\n",
      "Epoch 15/50 - Train Loss: 0.031483 - Val Loss: 0.052748\n",
      "Epoch 16/50 - Train Loss: 0.031331 - Val Loss: 0.046967\n",
      "Epoch 17/50 - Train Loss: 0.030806 - Val Loss: 0.045747\n",
      "Epoch 18/50 - Train Loss: 0.030696 - Val Loss: 0.047246\n",
      "Epoch 19/50 - Train Loss: 0.038048 - Val Loss: 0.048778\n",
      "Epoch 20/50 - Train Loss: 0.030034 - Val Loss: 0.046222\n",
      "Epoch 21/50 - Train Loss: 0.037886 - Val Loss: 0.045791\n",
      "Epoch 22/50 - Train Loss: 0.038129 - Val Loss: 0.046962\n",
      "Epoch 23/50 - Train Loss: 0.038131 - Val Loss: 0.047985\n",
      "Epoch 24/50 - Train Loss: 0.038485 - Val Loss: 0.046394\n",
      "Epoch 25/50 - Train Loss: 0.037527 - Val Loss: 0.045564\n",
      "Epoch 26/50 - Train Loss: 0.037248 - Val Loss: 0.046472\n",
      "Epoch 27/50 - Train Loss: 0.038158 - Val Loss: 0.047227\n",
      "Epoch 28/50 - Train Loss: 0.029736 - Val Loss: 0.045370\n",
      "Epoch 29/50 - Train Loss: 0.038308 - Val Loss: 0.045917\n",
      "Epoch 30/50 - Train Loss: 0.029356 - Val Loss: 0.046703\n",
      "Epoch 31/50 - Train Loss: 0.029069 - Val Loss: 0.045151\n",
      "Epoch 32/50 - Train Loss: 0.029090 - Val Loss: 0.044993\n",
      "Epoch 33/50 - Train Loss: 0.036524 - Val Loss: 0.045504\n",
      "Epoch 34/50 - Train Loss: 0.038044 - Val Loss: 0.045583\n",
      "Epoch 35/50 - Train Loss: 0.029712 - Val Loss: 0.044905\n",
      "Epoch 36/50 - Train Loss: 0.037940 - Val Loss: 0.045239\n",
      "Epoch 37/50 - Train Loss: 0.030197 - Val Loss: 0.045081\n",
      "Epoch 38/50 - Train Loss: 0.036041 - Val Loss: 0.044850\n",
      "Epoch 39/50 - Train Loss: 0.035748 - Val Loss: 0.045666\n",
      "Epoch 40/50 - Train Loss: 0.036576 - Val Loss: 0.046031\n",
      "Epoch 41/50 - Train Loss: 0.036154 - Val Loss: 0.045054\n",
      "Epoch 42/50 - Train Loss: 0.036597 - Val Loss: 0.045275\n",
      "Epoch 43/50 - Train Loss: 0.029282 - Val Loss: 0.047068\n",
      "Epoch 44/50 - Train Loss: 0.036534 - Val Loss: 0.045027\n",
      "Epoch 45/50 - Train Loss: 0.035610 - Val Loss: 0.044941\n",
      "Epoch 46/50 - Train Loss: 0.028548 - Val Loss: 0.045482\n",
      "Epoch 47/50 - Train Loss: 0.027929 - Val Loss: 0.045170\n",
      "Epoch 48/50 - Train Loss: 0.035849 - Val Loss: 0.044759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:15:23,964] Trial 6 finished with value: 0.04473080858588219 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 110, 'lr': 0.0057930423339026425, 'weight_decay': 1.7629762485156052e-07, 'batch_size': 64}. Best is trial 2 with value: 0.04361645753184954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Train Loss: 0.036381 - Val Loss: 0.044807\n",
      "Epoch 50/50 - Train Loss: 0.035251 - Val Loss: 0.044731\n",
      "Epoch 1/50 - Train Loss: 0.058414 - Val Loss: 0.155406\n",
      "Epoch 2/50 - Train Loss: 0.072877 - Val Loss: 0.148567\n",
      "Epoch 3/50 - Train Loss: 0.070540 - Val Loss: 0.142117\n",
      "Epoch 4/50 - Train Loss: 0.064164 - Val Loss: 0.136121\n",
      "Epoch 5/50 - Train Loss: 0.056129 - Val Loss: 0.130477\n",
      "Epoch 6/50 - Train Loss: 0.056970 - Val Loss: 0.125202\n",
      "Epoch 7/50 - Train Loss: 0.049791 - Val Loss: 0.120192\n",
      "Epoch 8/50 - Train Loss: 0.056609 - Val Loss: 0.115491\n",
      "Epoch 9/50 - Train Loss: 0.045174 - Val Loss: 0.111156\n",
      "Epoch 10/50 - Train Loss: 0.054739 - Val Loss: 0.107113\n",
      "Epoch 11/50 - Train Loss: 0.053796 - Val Loss: 0.103445\n",
      "Epoch 12/50 - Train Loss: 0.045978 - Val Loss: 0.099995\n",
      "Epoch 13/50 - Train Loss: 0.044738 - Val Loss: 0.096958\n",
      "Epoch 14/50 - Train Loss: 0.042439 - Val Loss: 0.094353\n",
      "Epoch 15/50 - Train Loss: 0.042012 - Val Loss: 0.092478\n",
      "Epoch 16/50 - Train Loss: 0.045786 - Val Loss: 0.091176\n",
      "Epoch 17/50 - Train Loss: 0.042985 - Val Loss: 0.090454\n",
      "Epoch 18/50 - Train Loss: 0.045804 - Val Loss: 0.089875\n",
      "Epoch 19/50 - Train Loss: 0.048306 - Val Loss: 0.089493\n",
      "Epoch 20/50 - Train Loss: 0.045409 - Val Loss: 0.089093\n",
      "Epoch 21/50 - Train Loss: 0.038408 - Val Loss: 0.088258\n",
      "Epoch 22/50 - Train Loss: 0.044425 - Val Loss: 0.087789\n",
      "Epoch 23/50 - Train Loss: 0.042331 - Val Loss: 0.087278\n",
      "Epoch 24/50 - Train Loss: 0.046867 - Val Loss: 0.086933\n",
      "Epoch 25/50 - Train Loss: 0.045409 - Val Loss: 0.086633\n",
      "Epoch 26/50 - Train Loss: 0.044460 - Val Loss: 0.085836\n",
      "Epoch 27/50 - Train Loss: 0.045472 - Val Loss: 0.085224\n",
      "Epoch 28/50 - Train Loss: 0.046771 - Val Loss: 0.084601\n",
      "Epoch 29/50 - Train Loss: 0.045584 - Val Loss: 0.084043\n",
      "Epoch 30/50 - Train Loss: 0.045159 - Val Loss: 0.083639\n",
      "Epoch 31/50 - Train Loss: 0.045785 - Val Loss: 0.083373\n",
      "Epoch 32/50 - Train Loss: 0.043751 - Val Loss: 0.083784\n",
      "Epoch 33/50 - Train Loss: 0.044010 - Val Loss: 0.084331\n",
      "Epoch 34/50 - Train Loss: 0.044396 - Val Loss: 0.084980\n",
      "Epoch 35/50 - Train Loss: 0.044996 - Val Loss: 0.084917\n",
      "Epoch 36/50 - Train Loss: 0.042482 - Val Loss: 0.084413\n",
      "Epoch 37/50 - Train Loss: 0.046684 - Val Loss: 0.084181\n",
      "Epoch 38/50 - Train Loss: 0.042091 - Val Loss: 0.083395\n",
      "Epoch 39/50 - Train Loss: 0.046057 - Val Loss: 0.082114\n",
      "Epoch 40/50 - Train Loss: 0.044621 - Val Loss: 0.080919\n",
      "Epoch 41/50 - Train Loss: 0.038145 - Val Loss: 0.079487\n",
      "Epoch 42/50 - Train Loss: 0.038892 - Val Loss: 0.078703\n",
      "Epoch 43/50 - Train Loss: 0.044151 - Val Loss: 0.078246\n",
      "Epoch 44/50 - Train Loss: 0.047621 - Val Loss: 0.078026\n",
      "Epoch 45/50 - Train Loss: 0.036659 - Val Loss: 0.077903\n",
      "Epoch 46/50 - Train Loss: 0.036549 - Val Loss: 0.078110\n",
      "Epoch 47/50 - Train Loss: 0.046769 - Val Loss: 0.077967\n",
      "Epoch 48/50 - Train Loss: 0.036069 - Val Loss: 0.076504\n",
      "Epoch 49/50 - Train Loss: 0.037615 - Val Loss: 0.075422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:15:36,949] Trial 7 finished with value: 0.07442893087863922 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 59, 'lr': 0.00010852071264511989, 'weight_decay': 5.8893985576584674e-08, 'batch_size': 32}. Best is trial 2 with value: 0.04361645753184954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.039611 - Val Loss: 0.074429\n",
      "Epoch 1/50 - Train Loss: 0.121054 - Val Loss: 0.211188\n",
      "Epoch 2/50 - Train Loss: 0.072950 - Val Loss: 0.155428\n",
      "Epoch 3/50 - Train Loss: 0.061397 - Val Loss: 0.113756\n",
      "Epoch 4/50 - Train Loss: 0.049052 - Val Loss: 0.086518\n",
      "Epoch 5/50 - Train Loss: 0.051567 - Val Loss: 0.079260\n",
      "Epoch 6/50 - Train Loss: 0.045186 - Val Loss: 0.083102\n",
      "Epoch 7/50 - Train Loss: 0.048017 - Val Loss: 0.089485\n",
      "Epoch 8/50 - Train Loss: 0.048081 - Val Loss: 0.088943\n",
      "Epoch 9/50 - Train Loss: 0.044343 - Val Loss: 0.085091\n",
      "Epoch 10/50 - Train Loss: 0.039261 - Val Loss: 0.080096\n",
      "Epoch 11/50 - Train Loss: 0.040473 - Val Loss: 0.079117\n",
      "Epoch 12/50 - Train Loss: 0.038353 - Val Loss: 0.080812\n",
      "Epoch 13/50 - Train Loss: 0.038409 - Val Loss: 0.071618\n",
      "Epoch 14/50 - Train Loss: 0.039556 - Val Loss: 0.070561\n",
      "Epoch 15/50 - Train Loss: 0.039300 - Val Loss: 0.068311\n",
      "Epoch 16/50 - Train Loss: 0.035049 - Val Loss: 0.066727\n",
      "Epoch 17/50 - Train Loss: 0.034347 - Val Loss: 0.062093\n",
      "Epoch 18/50 - Train Loss: 0.033594 - Val Loss: 0.060218\n",
      "Epoch 19/50 - Train Loss: 0.035770 - Val Loss: 0.057059\n",
      "Epoch 20/50 - Train Loss: 0.034823 - Val Loss: 0.057156\n",
      "Epoch 21/50 - Train Loss: 0.035497 - Val Loss: 0.053149\n",
      "Epoch 22/50 - Train Loss: 0.032495 - Val Loss: 0.050795\n",
      "Epoch 23/50 - Train Loss: 0.031900 - Val Loss: 0.051362\n",
      "Epoch 24/50 - Train Loss: 0.031771 - Val Loss: 0.048637\n",
      "Epoch 25/50 - Train Loss: 0.031903 - Val Loss: 0.049704\n",
      "Epoch 26/50 - Train Loss: 0.032841 - Val Loss: 0.047821\n",
      "Epoch 27/50 - Train Loss: 0.030715 - Val Loss: 0.047691\n",
      "Epoch 28/50 - Train Loss: 0.031421 - Val Loss: 0.048059\n",
      "Epoch 29/50 - Train Loss: 0.032127 - Val Loss: 0.047150\n",
      "Epoch 30/50 - Train Loss: 0.031207 - Val Loss: 0.047151\n",
      "Epoch 31/50 - Train Loss: 0.033728 - Val Loss: 0.047061\n",
      "Epoch 32/50 - Train Loss: 0.030439 - Val Loss: 0.047453\n",
      "Epoch 33/50 - Train Loss: 0.031430 - Val Loss: 0.047081\n",
      "Epoch 34/50 - Train Loss: 0.030674 - Val Loss: 0.046040\n",
      "Epoch 35/50 - Train Loss: 0.032653 - Val Loss: 0.048462\n",
      "Epoch 36/50 - Train Loss: 0.029962 - Val Loss: 0.046094\n",
      "Epoch 37/50 - Train Loss: 0.031521 - Val Loss: 0.047019\n",
      "Epoch 38/50 - Train Loss: 0.031419 - Val Loss: 0.046720\n",
      "Epoch 39/50 - Train Loss: 0.028909 - Val Loss: 0.047021\n",
      "Epoch 40/50 - Train Loss: 0.031165 - Val Loss: 0.046947\n",
      "Epoch 41/50 - Train Loss: 0.030135 - Val Loss: 0.047281\n",
      "Epoch 42/50 - Train Loss: 0.032175 - Val Loss: 0.047334\n",
      "Epoch 43/50 - Train Loss: 0.027925 - Val Loss: 0.046220\n",
      "Epoch 44/50 - Train Loss: 0.031079 - Val Loss: 0.048021\n",
      "Epoch 45/50 - Train Loss: 0.035460 - Val Loss: 0.047263\n",
      "Epoch 46/50 - Train Loss: 0.028956 - Val Loss: 0.047238\n",
      "Epoch 47/50 - Train Loss: 0.031551 - Val Loss: 0.048265\n",
      "Epoch 48/50 - Train Loss: 0.029808 - Val Loss: 0.046884\n",
      "Epoch 49/50 - Train Loss: 0.030196 - Val Loss: 0.045749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:15:52,887] Trial 8 finished with value: 0.045749375596642494 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 53, 'lr': 0.0005810558701297278, 'weight_decay': 2.2690747184413168e-08, 'batch_size': 16}. Best is trial 2 with value: 0.04361645753184954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.034629 - Val Loss: 0.047852\n",
      "Epoch 1/50 - Train Loss: 0.305782 - Val Loss: 0.422250\n",
      "Epoch 2/50 - Train Loss: 0.211506 - Val Loss: 0.343708\n",
      "Epoch 3/50 - Train Loss: 0.168306 - Val Loss: 0.277446\n",
      "Epoch 4/50 - Train Loss: 0.136095 - Val Loss: 0.223168\n",
      "Epoch 5/50 - Train Loss: 0.104552 - Val Loss: 0.179459\n",
      "Epoch 6/50 - Train Loss: 0.076440 - Val Loss: 0.146660\n",
      "Epoch 7/50 - Train Loss: 0.060457 - Val Loss: 0.123035\n",
      "Epoch 8/50 - Train Loss: 0.054364 - Val Loss: 0.108759\n",
      "Epoch 9/50 - Train Loss: 0.050160 - Val Loss: 0.098893\n",
      "Epoch 10/50 - Train Loss: 0.047193 - Val Loss: 0.092653\n",
      "Epoch 11/50 - Train Loss: 0.047494 - Val Loss: 0.088177\n",
      "Epoch 12/50 - Train Loss: 0.045045 - Val Loss: 0.086556\n",
      "Epoch 13/50 - Train Loss: 0.047043 - Val Loss: 0.084879\n",
      "Epoch 14/50 - Train Loss: 0.042038 - Val Loss: 0.082758\n",
      "Epoch 15/50 - Train Loss: 0.044773 - Val Loss: 0.082668\n",
      "Epoch 16/50 - Train Loss: 0.040568 - Val Loss: 0.080071\n",
      "Epoch 17/50 - Train Loss: 0.042136 - Val Loss: 0.079670\n",
      "Epoch 18/50 - Train Loss: 0.040620 - Val Loss: 0.078376\n",
      "Epoch 19/50 - Train Loss: 0.038388 - Val Loss: 0.076606\n",
      "Epoch 20/50 - Train Loss: 0.040248 - Val Loss: 0.075733\n",
      "Epoch 21/50 - Train Loss: 0.041534 - Val Loss: 0.074298\n",
      "Epoch 22/50 - Train Loss: 0.036778 - Val Loss: 0.073960\n",
      "Epoch 23/50 - Train Loss: 0.038348 - Val Loss: 0.073577\n",
      "Epoch 24/50 - Train Loss: 0.037589 - Val Loss: 0.072825\n",
      "Epoch 25/50 - Train Loss: 0.035258 - Val Loss: 0.071319\n",
      "Epoch 26/50 - Train Loss: 0.035804 - Val Loss: 0.070539\n",
      "Epoch 27/50 - Train Loss: 0.037149 - Val Loss: 0.069068\n",
      "Epoch 28/50 - Train Loss: 0.036595 - Val Loss: 0.068048\n",
      "Epoch 29/50 - Train Loss: 0.035003 - Val Loss: 0.066227\n",
      "Epoch 30/50 - Train Loss: 0.035025 - Val Loss: 0.066463\n",
      "Epoch 31/50 - Train Loss: 0.036343 - Val Loss: 0.065544\n",
      "Epoch 32/50 - Train Loss: 0.037362 - Val Loss: 0.064870\n",
      "Epoch 33/50 - Train Loss: 0.035537 - Val Loss: 0.063796\n",
      "Epoch 34/50 - Train Loss: 0.032702 - Val Loss: 0.063088\n",
      "Epoch 35/50 - Train Loss: 0.034184 - Val Loss: 0.062276\n",
      "Epoch 36/50 - Train Loss: 0.034041 - Val Loss: 0.061230\n",
      "Epoch 37/50 - Train Loss: 0.034376 - Val Loss: 0.059415\n",
      "Epoch 38/50 - Train Loss: 0.031897 - Val Loss: 0.059382\n",
      "Epoch 39/50 - Train Loss: 0.031666 - Val Loss: 0.058228\n",
      "Epoch 40/50 - Train Loss: 0.033800 - Val Loss: 0.057640\n",
      "Epoch 41/50 - Train Loss: 0.032335 - Val Loss: 0.057137\n",
      "Epoch 42/50 - Train Loss: 0.033772 - Val Loss: 0.056790\n",
      "Epoch 43/50 - Train Loss: 0.035828 - Val Loss: 0.055888\n",
      "Epoch 44/50 - Train Loss: 0.032229 - Val Loss: 0.055441\n",
      "Epoch 45/50 - Train Loss: 0.031626 - Val Loss: 0.054277\n",
      "Epoch 46/50 - Train Loss: 0.032237 - Val Loss: 0.053342\n",
      "Epoch 47/50 - Train Loss: 0.030601 - Val Loss: 0.053786\n",
      "Epoch 48/50 - Train Loss: 0.034460 - Val Loss: 0.053423\n",
      "Epoch 49/50 - Train Loss: 0.034177 - Val Loss: 0.052265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:16:19,213] Trial 9 finished with value: 0.051743898540735245 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 159, 'lr': 5.071270108691581e-05, 'weight_decay': 0.00011957258455691142, 'batch_size': 8}. Best is trial 2 with value: 0.04361645753184954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.032482 - Val Loss: 0.051744\n",
      "Epoch 1/50 - Train Loss: 0.058257 - Val Loss: 0.081888\n",
      "Epoch 2/50 - Train Loss: 0.047183 - Val Loss: 0.078047\n",
      "Epoch 3/50 - Train Loss: 0.042090 - Val Loss: 0.062828\n",
      "Epoch 4/50 - Train Loss: 0.035538 - Val Loss: 0.051482\n",
      "Epoch 5/50 - Train Loss: 0.034152 - Val Loss: 0.059113\n",
      "Epoch 6/50 - Train Loss: 0.035986 - Val Loss: 0.046080\n",
      "Epoch 7/50 - Train Loss: 0.032785 - Val Loss: 0.044986\n",
      "Epoch 8/50 - Train Loss: 0.035635 - Val Loss: 0.045106\n",
      "Epoch 9/50 - Train Loss: 0.034523 - Val Loss: 0.047063\n",
      "Epoch 10/50 - Train Loss: 0.030990 - Val Loss: 0.046667\n",
      "Epoch 11/50 - Train Loss: 0.029302 - Val Loss: 0.046803\n",
      "Epoch 12/50 - Train Loss: 0.036713 - Val Loss: 0.060083\n",
      "Epoch 13/50 - Train Loss: 0.034614 - Val Loss: 0.044365\n",
      "Epoch 14/50 - Train Loss: 0.030304 - Val Loss: 0.045013\n",
      "Epoch 15/50 - Train Loss: 0.028997 - Val Loss: 0.044677\n",
      "Epoch 16/50 - Train Loss: 0.032768 - Val Loss: 0.044314\n",
      "Epoch 17/50 - Train Loss: 0.028950 - Val Loss: 0.044834\n",
      "Epoch 18/50 - Train Loss: 0.031350 - Val Loss: 0.060341\n",
      "Epoch 19/50 - Train Loss: 0.032676 - Val Loss: 0.055087\n",
      "Epoch 20/50 - Train Loss: 0.034356 - Val Loss: 0.044600\n",
      "Epoch 21/50 - Train Loss: 0.032639 - Val Loss: 0.044786\n",
      "Epoch 22/50 - Train Loss: 0.029325 - Val Loss: 0.048806\n",
      "Epoch 23/50 - Train Loss: 0.033606 - Val Loss: 0.046335\n",
      "Epoch 24/50 - Train Loss: 0.029361 - Val Loss: 0.046844\n",
      "Epoch 25/50 - Train Loss: 0.031541 - Val Loss: 0.045843\n",
      "Epoch 26/50 - Train Loss: 0.030519 - Val Loss: 0.048891\n",
      "Epoch 27/50 - Train Loss: 0.033918 - Val Loss: 0.046445\n",
      "Epoch 28/50 - Train Loss: 0.028233 - Val Loss: 0.048134\n",
      "Epoch 29/50 - Train Loss: 0.026465 - Val Loss: 0.045070\n",
      "Epoch 30/50 - Train Loss: 0.031368 - Val Loss: 0.045928\n",
      "Epoch 31/50 - Train Loss: 0.033123 - Val Loss: 0.057283\n",
      "Epoch 32/50 - Train Loss: 0.030524 - Val Loss: 0.044739\n",
      "Epoch 33/50 - Train Loss: 0.028936 - Val Loss: 0.046480\n",
      "Epoch 34/50 - Train Loss: 0.030453 - Val Loss: 0.044965\n",
      "Epoch 35/50 - Train Loss: 0.033979 - Val Loss: 0.052639\n",
      "Epoch 36/50 - Train Loss: 0.030698 - Val Loss: 0.045424\n",
      "Epoch 37/50 - Train Loss: 0.029046 - Val Loss: 0.049318\n",
      "Epoch 38/50 - Train Loss: 0.030698 - Val Loss: 0.053295\n",
      "Epoch 39/50 - Train Loss: 0.031927 - Val Loss: 0.049000\n",
      "Epoch 40/50 - Train Loss: 0.030331 - Val Loss: 0.047152\n",
      "Epoch 41/50 - Train Loss: 0.029875 - Val Loss: 0.044727\n",
      "Epoch 42/50 - Train Loss: 0.030549 - Val Loss: 0.055153\n",
      "Epoch 43/50 - Train Loss: 0.030748 - Val Loss: 0.044202\n",
      "Epoch 44/50 - Train Loss: 0.030552 - Val Loss: 0.045151\n",
      "Epoch 45/50 - Train Loss: 0.029590 - Val Loss: 0.048049\n",
      "Epoch 46/50 - Train Loss: 0.028044 - Val Loss: 0.046167\n",
      "Epoch 47/50 - Train Loss: 0.030846 - Val Loss: 0.045150\n",
      "Epoch 48/50 - Train Loss: 0.031274 - Val Loss: 0.059138\n",
      "Epoch 49/50 - Train Loss: 0.029540 - Val Loss: 0.046845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:17:19,302] Trial 10 finished with value: 0.0442019651333491 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 242, 'lr': 0.0054143353084148745, 'weight_decay': 7.5771453634786526e-06, 'batch_size': 8}. Best is trial 2 with value: 0.04361645753184954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.032094 - Val Loss: 0.054623\n",
      "Epoch 1/50 - Train Loss: 0.183692 - Val Loss: 0.177454\n",
      "Epoch 2/50 - Train Loss: 0.069864 - Val Loss: 0.124268\n",
      "Epoch 3/50 - Train Loss: 0.044523 - Val Loss: 0.083425\n",
      "Epoch 4/50 - Train Loss: 0.041562 - Val Loss: 0.090988\n",
      "Epoch 5/50 - Train Loss: 0.040879 - Val Loss: 0.048577\n",
      "Epoch 6/50 - Train Loss: 0.032233 - Val Loss: 0.055340\n",
      "Epoch 7/50 - Train Loss: 0.032531 - Val Loss: 0.045976\n",
      "Epoch 8/50 - Train Loss: 0.035994 - Val Loss: 0.048579\n",
      "Epoch 9/50 - Train Loss: 0.033288 - Val Loss: 0.045689\n",
      "Epoch 10/50 - Train Loss: 0.031988 - Val Loss: 0.051212\n",
      "Epoch 11/50 - Train Loss: 0.033647 - Val Loss: 0.047739\n",
      "Epoch 12/50 - Train Loss: 0.033608 - Val Loss: 0.046879\n",
      "Epoch 13/50 - Train Loss: 0.031267 - Val Loss: 0.046282\n",
      "Epoch 14/50 - Train Loss: 0.031235 - Val Loss: 0.054325\n",
      "Epoch 15/50 - Train Loss: 0.032102 - Val Loss: 0.055229\n",
      "Epoch 16/50 - Train Loss: 0.034926 - Val Loss: 0.050490\n",
      "Epoch 17/50 - Train Loss: 0.034046 - Val Loss: 0.051349\n",
      "Epoch 18/50 - Train Loss: 0.035598 - Val Loss: 0.062996\n",
      "Epoch 19/50 - Train Loss: 0.034702 - Val Loss: 0.048631\n",
      "Epoch 20/50 - Train Loss: 0.032346 - Val Loss: 0.047998\n",
      "Epoch 21/50 - Train Loss: 0.029827 - Val Loss: 0.045430\n",
      "Epoch 22/50 - Train Loss: 0.031536 - Val Loss: 0.052993\n",
      "Epoch 23/50 - Train Loss: 0.031484 - Val Loss: 0.045475\n",
      "Epoch 24/50 - Train Loss: 0.031962 - Val Loss: 0.044978\n",
      "Epoch 25/50 - Train Loss: 0.031125 - Val Loss: 0.044615\n",
      "Epoch 26/50 - Train Loss: 0.029737 - Val Loss: 0.047591\n",
      "Epoch 27/50 - Train Loss: 0.031223 - Val Loss: 0.053339\n",
      "Epoch 28/50 - Train Loss: 0.032855 - Val Loss: 0.049324\n",
      "Epoch 29/50 - Train Loss: 0.029092 - Val Loss: 0.045293\n",
      "Epoch 30/50 - Train Loss: 0.032254 - Val Loss: 0.044541\n",
      "Epoch 31/50 - Train Loss: 0.030205 - Val Loss: 0.045036\n",
      "Epoch 32/50 - Train Loss: 0.030984 - Val Loss: 0.044588\n",
      "Epoch 33/50 - Train Loss: 0.030975 - Val Loss: 0.052585\n",
      "Epoch 34/50 - Train Loss: 0.030869 - Val Loss: 0.047942\n",
      "Epoch 35/50 - Train Loss: 0.032877 - Val Loss: 0.046375\n",
      "Epoch 36/50 - Train Loss: 0.033632 - Val Loss: 0.051160\n",
      "Epoch 37/50 - Train Loss: 0.033604 - Val Loss: 0.044286\n",
      "Epoch 38/50 - Train Loss: 0.030848 - Val Loss: 0.044157\n",
      "Epoch 39/50 - Train Loss: 0.031524 - Val Loss: 0.045877\n",
      "Epoch 40/50 - Train Loss: 0.031089 - Val Loss: 0.057767\n",
      "Epoch 41/50 - Train Loss: 0.031450 - Val Loss: 0.046093\n",
      "Epoch 42/50 - Train Loss: 0.029273 - Val Loss: 0.046855\n",
      "Epoch 43/50 - Train Loss: 0.031352 - Val Loss: 0.051679\n",
      "Epoch 44/50 - Train Loss: 0.031136 - Val Loss: 0.043518\n",
      "Epoch 45/50 - Train Loss: 0.027514 - Val Loss: 0.044580\n",
      "Epoch 46/50 - Train Loss: 0.029611 - Val Loss: 0.044675\n",
      "Epoch 47/50 - Train Loss: 0.030160 - Val Loss: 0.058330\n",
      "Epoch 48/50 - Train Loss: 0.030292 - Val Loss: 0.045988\n",
      "Epoch 49/50 - Train Loss: 0.031917 - Val Loss: 0.048886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:18:27,435] Trial 11 finished with value: 0.043518380572398506 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 255, 'lr': 0.009287770955318247, 'weight_decay': 1.3581788325846429e-05, 'batch_size': 8}. Best is trial 11 with value: 0.043518380572398506.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.029534 - Val Loss: 0.058464\n",
      "Epoch 1/50 - Train Loss: 0.059672 - Val Loss: 0.075454\n",
      "Epoch 2/50 - Train Loss: 0.038375 - Val Loss: 0.052943\n",
      "Epoch 3/50 - Train Loss: 0.038930 - Val Loss: 0.060745\n",
      "Epoch 4/50 - Train Loss: 0.034651 - Val Loss: 0.048966\n",
      "Epoch 5/50 - Train Loss: 0.032721 - Val Loss: 0.048931\n",
      "Epoch 6/50 - Train Loss: 0.031243 - Val Loss: 0.045349\n",
      "Epoch 7/50 - Train Loss: 0.032599 - Val Loss: 0.049574\n",
      "Epoch 8/50 - Train Loss: 0.030625 - Val Loss: 0.048034\n",
      "Epoch 9/50 - Train Loss: 0.030644 - Val Loss: 0.049209\n",
      "Epoch 10/50 - Train Loss: 0.030966 - Val Loss: 0.045860\n",
      "Epoch 11/50 - Train Loss: 0.034076 - Val Loss: 0.059930\n",
      "Epoch 12/50 - Train Loss: 0.036688 - Val Loss: 0.064820\n",
      "Epoch 13/50 - Train Loss: 0.034218 - Val Loss: 0.060231\n",
      "Epoch 14/50 - Train Loss: 0.030212 - Val Loss: 0.071751\n",
      "Epoch 15/50 - Train Loss: 0.034207 - Val Loss: 0.051499\n",
      "Epoch 16/50 - Train Loss: 0.029636 - Val Loss: 0.044428\n",
      "Epoch 17/50 - Train Loss: 0.030272 - Val Loss: 0.049091\n",
      "Epoch 18/50 - Train Loss: 0.029314 - Val Loss: 0.046432\n",
      "Epoch 19/50 - Train Loss: 0.032751 - Val Loss: 0.048184\n",
      "Epoch 20/50 - Train Loss: 0.031156 - Val Loss: 0.045518\n",
      "Epoch 21/50 - Train Loss: 0.032144 - Val Loss: 0.048604\n",
      "Epoch 22/50 - Train Loss: 0.029747 - Val Loss: 0.045304\n",
      "Epoch 23/50 - Train Loss: 0.030643 - Val Loss: 0.045110\n",
      "Epoch 24/50 - Train Loss: 0.029418 - Val Loss: 0.044717\n",
      "Epoch 25/50 - Train Loss: 0.028811 - Val Loss: 0.065166\n",
      "Epoch 26/50 - Train Loss: 0.031831 - Val Loss: 0.052415\n",
      "Epoch 27/50 - Train Loss: 0.032963 - Val Loss: 0.049567\n",
      "Epoch 28/50 - Train Loss: 0.033430 - Val Loss: 0.057603\n",
      "Epoch 29/50 - Train Loss: 0.032456 - Val Loss: 0.050852\n",
      "Epoch 30/50 - Train Loss: 0.029905 - Val Loss: 0.048262\n",
      "Epoch 31/50 - Train Loss: 0.029453 - Val Loss: 0.045974\n",
      "Epoch 32/50 - Train Loss: 0.029642 - Val Loss: 0.048123\n",
      "Epoch 33/50 - Train Loss: 0.032245 - Val Loss: 0.045083\n",
      "Epoch 34/50 - Train Loss: 0.028542 - Val Loss: 0.044937\n",
      "Epoch 35/50 - Train Loss: 0.031568 - Val Loss: 0.045602\n",
      "Epoch 36/50 - Train Loss: 0.031822 - Val Loss: 0.045300\n",
      "Epoch 37/50 - Train Loss: 0.031740 - Val Loss: 0.045275\n",
      "Epoch 38/50 - Train Loss: 0.032215 - Val Loss: 0.044901\n",
      "Epoch 39/50 - Train Loss: 0.028204 - Val Loss: 0.045298\n",
      "Epoch 40/50 - Train Loss: 0.030254 - Val Loss: 0.053586\n",
      "Epoch 41/50 - Train Loss: 0.028786 - Val Loss: 0.044065\n",
      "Epoch 42/50 - Train Loss: 0.030932 - Val Loss: 0.045137\n",
      "Epoch 43/50 - Train Loss: 0.031276 - Val Loss: 0.044223\n",
      "Epoch 44/50 - Train Loss: 0.027352 - Val Loss: 0.048706\n",
      "Epoch 45/50 - Train Loss: 0.030027 - Val Loss: 0.044746\n",
      "Epoch 46/50 - Train Loss: 0.028496 - Val Loss: 0.044511\n",
      "Epoch 47/50 - Train Loss: 0.030306 - Val Loss: 0.049605\n",
      "Epoch 48/50 - Train Loss: 0.029861 - Val Loss: 0.046149\n",
      "Epoch 49/50 - Train Loss: 0.028773 - Val Loss: 0.044030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:19:17,663] Trial 12 finished with value: 0.04402986541390419 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 195, 'lr': 0.0017101881709508076, 'weight_decay': 9.347809590384195e-06, 'batch_size': 8}. Best is trial 11 with value: 0.043518380572398506.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.029276 - Val Loss: 0.045384\n",
      "Epoch 1/50 - Train Loss: 0.062327 - Val Loss: 0.089524\n",
      "Epoch 2/50 - Train Loss: 0.045299 - Val Loss: 0.099010\n",
      "Epoch 3/50 - Train Loss: 0.035506 - Val Loss: 0.090193\n",
      "Epoch 4/50 - Train Loss: 0.035274 - Val Loss: 0.061975\n",
      "Epoch 5/50 - Train Loss: 0.034041 - Val Loss: 0.046082\n",
      "Epoch 6/50 - Train Loss: 0.032898 - Val Loss: 0.050276\n",
      "Epoch 7/50 - Train Loss: 0.033641 - Val Loss: 0.048878\n",
      "Epoch 8/50 - Train Loss: 0.036166 - Val Loss: 0.049046\n",
      "Epoch 9/50 - Train Loss: 0.029548 - Val Loss: 0.047785\n",
      "Epoch 10/50 - Train Loss: 0.031055 - Val Loss: 0.045328\n",
      "Epoch 11/50 - Train Loss: 0.031614 - Val Loss: 0.046706\n",
      "Epoch 12/50 - Train Loss: 0.033944 - Val Loss: 0.049627\n",
      "Epoch 13/50 - Train Loss: 0.033858 - Val Loss: 0.061353\n",
      "Epoch 14/50 - Train Loss: 0.029526 - Val Loss: 0.045024\n",
      "Epoch 15/50 - Train Loss: 0.034236 - Val Loss: 0.045920\n",
      "Epoch 16/50 - Train Loss: 0.035315 - Val Loss: 0.045070\n",
      "Epoch 17/50 - Train Loss: 0.031023 - Val Loss: 0.045875\n",
      "Epoch 18/50 - Train Loss: 0.031040 - Val Loss: 0.046997\n",
      "Epoch 19/50 - Train Loss: 0.030652 - Val Loss: 0.045628\n",
      "Epoch 20/50 - Train Loss: 0.032796 - Val Loss: 0.044381\n",
      "Epoch 21/50 - Train Loss: 0.032101 - Val Loss: 0.051471\n",
      "Epoch 22/50 - Train Loss: 0.031332 - Val Loss: 0.046209\n",
      "Epoch 23/50 - Train Loss: 0.032665 - Val Loss: 0.049252\n",
      "Epoch 24/50 - Train Loss: 0.032177 - Val Loss: 0.062803\n",
      "Epoch 25/50 - Train Loss: 0.032311 - Val Loss: 0.045077\n",
      "Epoch 26/50 - Train Loss: 0.031518 - Val Loss: 0.045217\n",
      "Epoch 27/50 - Train Loss: 0.028797 - Val Loss: 0.046827\n",
      "Epoch 28/50 - Train Loss: 0.031139 - Val Loss: 0.049221\n",
      "Epoch 29/50 - Train Loss: 0.030522 - Val Loss: 0.047880\n",
      "Epoch 30/50 - Train Loss: 0.030873 - Val Loss: 0.044613\n",
      "Epoch 31/50 - Train Loss: 0.029415 - Val Loss: 0.047338\n",
      "Epoch 32/50 - Train Loss: 0.028503 - Val Loss: 0.044355\n",
      "Epoch 33/50 - Train Loss: 0.030384 - Val Loss: 0.048106\n",
      "Epoch 34/50 - Train Loss: 0.030587 - Val Loss: 0.045046\n",
      "Epoch 35/50 - Train Loss: 0.031446 - Val Loss: 0.045434\n",
      "Epoch 36/50 - Train Loss: 0.030915 - Val Loss: 0.046957\n",
      "Epoch 37/50 - Train Loss: 0.030399 - Val Loss: 0.048713\n",
      "Epoch 38/50 - Train Loss: 0.031282 - Val Loss: 0.045561\n",
      "Epoch 39/50 - Train Loss: 0.027350 - Val Loss: 0.045021\n",
      "Epoch 40/50 - Train Loss: 0.029290 - Val Loss: 0.045924\n",
      "Epoch 41/50 - Train Loss: 0.030767 - Val Loss: 0.046208\n",
      "Epoch 42/50 - Train Loss: 0.031753 - Val Loss: 0.045355\n",
      "Epoch 43/50 - Train Loss: 0.035146 - Val Loss: 0.057651\n",
      "Epoch 44/50 - Train Loss: 0.034097 - Val Loss: 0.050211\n",
      "Epoch 45/50 - Train Loss: 0.029461 - Val Loss: 0.044481\n",
      "Epoch 46/50 - Train Loss: 0.031519 - Val Loss: 0.046034\n",
      "Epoch 47/50 - Train Loss: 0.029489 - Val Loss: 0.051058\n",
      "Epoch 48/50 - Train Loss: 0.028292 - Val Loss: 0.048044\n",
      "Epoch 49/50 - Train Loss: 0.030516 - Val Loss: 0.045450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:20:21,950] Trial 13 finished with value: 0.044354976465304695 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 206, 'lr': 0.001978147041463345, 'weight_decay': 3.799048752923443e-05, 'batch_size': 8}. Best is trial 11 with value: 0.043518380572398506.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.027834 - Val Loss: 0.045010\n",
      "Epoch 1/50 - Train Loss: 0.169790 - Val Loss: 0.196034\n",
      "Epoch 2/50 - Train Loss: 0.052635 - Val Loss: 0.092902\n",
      "Epoch 3/50 - Train Loss: 0.044287 - Val Loss: 0.073801\n",
      "Epoch 4/50 - Train Loss: 0.035664 - Val Loss: 0.066167\n",
      "Epoch 5/50 - Train Loss: 0.034664 - Val Loss: 0.047580\n",
      "Epoch 6/50 - Train Loss: 0.034888 - Val Loss: 0.056812\n",
      "Epoch 7/50 - Train Loss: 0.033437 - Val Loss: 0.046500\n",
      "Epoch 8/50 - Train Loss: 0.034389 - Val Loss: 0.051971\n",
      "Epoch 9/50 - Train Loss: 0.035899 - Val Loss: 0.045552\n",
      "Epoch 10/50 - Train Loss: 0.034788 - Val Loss: 0.066440\n",
      "Epoch 11/50 - Train Loss: 0.032279 - Val Loss: 0.045672\n",
      "Epoch 12/50 - Train Loss: 0.029749 - Val Loss: 0.044544\n",
      "Epoch 13/50 - Train Loss: 0.030623 - Val Loss: 0.044418\n",
      "Epoch 14/50 - Train Loss: 0.033753 - Val Loss: 0.055638\n",
      "Epoch 15/50 - Train Loss: 0.034746 - Val Loss: 0.059243\n",
      "Epoch 16/50 - Train Loss: 0.031741 - Val Loss: 0.053376\n",
      "Epoch 17/50 - Train Loss: 0.032990 - Val Loss: 0.047782\n",
      "Epoch 18/50 - Train Loss: 0.033069 - Val Loss: 0.044529\n",
      "Epoch 19/50 - Train Loss: 0.033171 - Val Loss: 0.044689\n",
      "Epoch 20/50 - Train Loss: 0.035275 - Val Loss: 0.050240\n",
      "Epoch 21/50 - Train Loss: 0.030489 - Val Loss: 0.044120\n",
      "Epoch 22/50 - Train Loss: 0.028831 - Val Loss: 0.050692\n",
      "Epoch 23/50 - Train Loss: 0.031687 - Val Loss: 0.047587\n",
      "Epoch 24/50 - Train Loss: 0.031220 - Val Loss: 0.048019\n",
      "Epoch 25/50 - Train Loss: 0.030710 - Val Loss: 0.050451\n",
      "Epoch 26/50 - Train Loss: 0.030709 - Val Loss: 0.053712\n",
      "Epoch 27/50 - Train Loss: 0.030973 - Val Loss: 0.045867\n",
      "Epoch 28/50 - Train Loss: 0.031172 - Val Loss: 0.044245\n",
      "Epoch 29/50 - Train Loss: 0.035869 - Val Loss: 0.051225\n",
      "Epoch 30/50 - Train Loss: 0.033581 - Val Loss: 0.050919\n",
      "Epoch 31/50 - Train Loss: 0.031492 - Val Loss: 0.047458\n",
      "Epoch 32/50 - Train Loss: 0.030568 - Val Loss: 0.044790\n",
      "Epoch 33/50 - Train Loss: 0.028196 - Val Loss: 0.044743\n",
      "Epoch 34/50 - Train Loss: 0.029566 - Val Loss: 0.050514\n",
      "Epoch 35/50 - Train Loss: 0.031101 - Val Loss: 0.045087\n",
      "Epoch 36/50 - Train Loss: 0.032167 - Val Loss: 0.044157\n",
      "Epoch 37/50 - Train Loss: 0.030678 - Val Loss: 0.043580\n",
      "Epoch 38/50 - Train Loss: 0.033178 - Val Loss: 0.067253\n",
      "Epoch 39/50 - Train Loss: 0.032342 - Val Loss: 0.053109\n",
      "Epoch 40/50 - Train Loss: 0.032501 - Val Loss: 0.048320\n",
      "Epoch 41/50 - Train Loss: 0.033725 - Val Loss: 0.046336\n",
      "Epoch 42/50 - Train Loss: 0.029783 - Val Loss: 0.046811\n",
      "Epoch 43/50 - Train Loss: 0.030339 - Val Loss: 0.045921\n",
      "Epoch 44/50 - Train Loss: 0.030225 - Val Loss: 0.050220\n",
      "Epoch 45/50 - Train Loss: 0.031556 - Val Loss: 0.050370\n",
      "Epoch 46/50 - Train Loss: 0.029625 - Val Loss: 0.043348\n",
      "Epoch 47/50 - Train Loss: 0.030231 - Val Loss: 0.044035\n",
      "Epoch 48/50 - Train Loss: 0.030753 - Val Loss: 0.050006\n",
      "Epoch 49/50 - Train Loss: 0.027854 - Val Loss: 0.044421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:21:15,494] Trial 14 finished with value: 0.043348429103692375 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 256, 'lr': 0.008049375758057212, 'weight_decay': 2.5805519845568786e-06, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.032146 - Val Loss: 0.052168\n",
      "Epoch 1/50 - Train Loss: 0.213503 - Val Loss: 0.259626\n",
      "Epoch 2/50 - Train Loss: 0.144586 - Val Loss: 0.250255\n",
      "Epoch 3/50 - Train Loss: 0.104092 - Val Loss: 0.157595\n",
      "Epoch 4/50 - Train Loss: 0.062223 - Val Loss: 0.074064\n",
      "Epoch 5/50 - Train Loss: 0.069947 - Val Loss: 0.105096\n",
      "Epoch 6/50 - Train Loss: 0.055692 - Val Loss: 0.113820\n",
      "Epoch 7/50 - Train Loss: 0.046640 - Val Loss: 0.093462\n",
      "Epoch 8/50 - Train Loss: 0.041273 - Val Loss: 0.073600\n",
      "Epoch 9/50 - Train Loss: 0.042514 - Val Loss: 0.072186\n",
      "Epoch 10/50 - Train Loss: 0.041073 - Val Loss: 0.080419\n",
      "Epoch 11/50 - Train Loss: 0.048913 - Val Loss: 0.085938\n",
      "Epoch 12/50 - Train Loss: 0.047679 - Val Loss: 0.080769\n",
      "Epoch 13/50 - Train Loss: 0.045963 - Val Loss: 0.069056\n",
      "Epoch 14/50 - Train Loss: 0.035367 - Val Loss: 0.052439\n",
      "Epoch 15/50 - Train Loss: 0.033439 - Val Loss: 0.047110\n",
      "Epoch 16/50 - Train Loss: 0.032429 - Val Loss: 0.051313\n",
      "Epoch 17/50 - Train Loss: 0.039237 - Val Loss: 0.057695\n",
      "Epoch 18/50 - Train Loss: 0.038679 - Val Loss: 0.048962\n",
      "Epoch 19/50 - Train Loss: 0.038327 - Val Loss: 0.049137\n",
      "Epoch 20/50 - Train Loss: 0.029960 - Val Loss: 0.045955\n",
      "Epoch 21/50 - Train Loss: 0.031086 - Val Loss: 0.051206\n",
      "Epoch 22/50 - Train Loss: 0.037767 - Val Loss: 0.046332\n",
      "Epoch 23/50 - Train Loss: 0.037821 - Val Loss: 0.054133\n",
      "Epoch 24/50 - Train Loss: 0.038199 - Val Loss: 0.051563\n",
      "Epoch 25/50 - Train Loss: 0.037004 - Val Loss: 0.045771\n",
      "Epoch 26/50 - Train Loss: 0.037455 - Val Loss: 0.048770\n",
      "Epoch 27/50 - Train Loss: 0.036610 - Val Loss: 0.047476\n",
      "Epoch 28/50 - Train Loss: 0.038094 - Val Loss: 0.048944\n",
      "Epoch 29/50 - Train Loss: 0.036076 - Val Loss: 0.047248\n",
      "Epoch 30/50 - Train Loss: 0.028399 - Val Loss: 0.044616\n",
      "Epoch 31/50 - Train Loss: 0.037006 - Val Loss: 0.044646\n",
      "Epoch 32/50 - Train Loss: 0.028806 - Val Loss: 0.044566\n",
      "Epoch 33/50 - Train Loss: 0.036145 - Val Loss: 0.049703\n",
      "Epoch 34/50 - Train Loss: 0.029495 - Val Loss: 0.046453\n",
      "Epoch 35/50 - Train Loss: 0.032161 - Val Loss: 0.048110\n",
      "Epoch 36/50 - Train Loss: 0.038641 - Val Loss: 0.047739\n",
      "Epoch 37/50 - Train Loss: 0.028772 - Val Loss: 0.046268\n",
      "Epoch 38/50 - Train Loss: 0.030765 - Val Loss: 0.047797\n",
      "Epoch 39/50 - Train Loss: 0.040264 - Val Loss: 0.054873\n",
      "Epoch 40/50 - Train Loss: 0.029828 - Val Loss: 0.045339\n",
      "Epoch 41/50 - Train Loss: 0.040248 - Val Loss: 0.047303\n",
      "Epoch 42/50 - Train Loss: 0.039098 - Val Loss: 0.058955\n",
      "Epoch 43/50 - Train Loss: 0.032189 - Val Loss: 0.046781\n",
      "Epoch 44/50 - Train Loss: 0.029224 - Val Loss: 0.047245\n",
      "Epoch 45/50 - Train Loss: 0.038470 - Val Loss: 0.048708\n",
      "Epoch 46/50 - Train Loss: 0.038028 - Val Loss: 0.051296\n",
      "Epoch 47/50 - Train Loss: 0.037214 - Val Loss: 0.047725\n",
      "Epoch 48/50 - Train Loss: 0.037926 - Val Loss: 0.049069\n",
      "Epoch 49/50 - Train Loss: 0.036438 - Val Loss: 0.052739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:21:33,869] Trial 15 finished with value: 0.04456594958901405 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 203, 'lr': 0.008899285481655578, 'weight_decay': 2.668855855448703e-06, 'batch_size': 64}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.029336 - Val Loss: 0.047260\n",
      "Epoch 1/50 - Train Loss: 0.106576 - Val Loss: 0.067633\n",
      "Epoch 2/50 - Train Loss: 0.054786 - Val Loss: 0.082964\n",
      "Epoch 3/50 - Train Loss: 0.042908 - Val Loss: 0.082922\n",
      "Epoch 4/50 - Train Loss: 0.038028 - Val Loss: 0.053570\n",
      "Epoch 5/50 - Train Loss: 0.035056 - Val Loss: 0.060827\n",
      "Epoch 6/50 - Train Loss: 0.033090 - Val Loss: 0.054750\n",
      "Epoch 7/50 - Train Loss: 0.032477 - Val Loss: 0.051431\n",
      "Epoch 8/50 - Train Loss: 0.032126 - Val Loss: 0.051073\n",
      "Epoch 9/50 - Train Loss: 0.033542 - Val Loss: 0.049773\n",
      "Epoch 10/50 - Train Loss: 0.033913 - Val Loss: 0.046032\n",
      "Epoch 11/50 - Train Loss: 0.031422 - Val Loss: 0.045468\n",
      "Epoch 12/50 - Train Loss: 0.033585 - Val Loss: 0.046694\n",
      "Epoch 13/50 - Train Loss: 0.031637 - Val Loss: 0.044747\n",
      "Epoch 14/50 - Train Loss: 0.032582 - Val Loss: 0.044878\n",
      "Epoch 15/50 - Train Loss: 0.030731 - Val Loss: 0.044112\n",
      "Epoch 16/50 - Train Loss: 0.034532 - Val Loss: 0.045576\n",
      "Epoch 17/50 - Train Loss: 0.029856 - Val Loss: 0.046899\n",
      "Epoch 18/50 - Train Loss: 0.029078 - Val Loss: 0.044513\n",
      "Epoch 19/50 - Train Loss: 0.030092 - Val Loss: 0.044181\n",
      "Epoch 20/50 - Train Loss: 0.032127 - Val Loss: 0.045393\n",
      "Epoch 21/50 - Train Loss: 0.031889 - Val Loss: 0.046399\n",
      "Epoch 22/50 - Train Loss: 0.033104 - Val Loss: 0.045102\n",
      "Epoch 23/50 - Train Loss: 0.028674 - Val Loss: 0.048524\n",
      "Epoch 24/50 - Train Loss: 0.032137 - Val Loss: 0.044410\n",
      "Epoch 25/50 - Train Loss: 0.027957 - Val Loss: 0.048307\n",
      "Epoch 26/50 - Train Loss: 0.030450 - Val Loss: 0.045417\n",
      "Epoch 27/50 - Train Loss: 0.030686 - Val Loss: 0.044400\n",
      "Epoch 28/50 - Train Loss: 0.032622 - Val Loss: 0.045029\n",
      "Epoch 29/50 - Train Loss: 0.032429 - Val Loss: 0.044625\n",
      "Epoch 30/50 - Train Loss: 0.028697 - Val Loss: 0.045260\n",
      "Epoch 31/50 - Train Loss: 0.029717 - Val Loss: 0.044632\n",
      "Epoch 32/50 - Train Loss: 0.028117 - Val Loss: 0.047598\n",
      "Epoch 33/50 - Train Loss: 0.030220 - Val Loss: 0.056067\n",
      "Epoch 34/50 - Train Loss: 0.031783 - Val Loss: 0.054978\n",
      "Epoch 35/50 - Train Loss: 0.031907 - Val Loss: 0.054903\n",
      "Epoch 36/50 - Train Loss: 0.034238 - Val Loss: 0.061189\n",
      "Epoch 37/50 - Train Loss: 0.034246 - Val Loss: 0.052800\n",
      "Epoch 38/50 - Train Loss: 0.030020 - Val Loss: 0.049217\n",
      "Epoch 39/50 - Train Loss: 0.031595 - Val Loss: 0.045811\n",
      "Epoch 40/50 - Train Loss: 0.031021 - Val Loss: 0.048764\n",
      "Epoch 41/50 - Train Loss: 0.032795 - Val Loss: 0.046836\n",
      "Epoch 42/50 - Train Loss: 0.028088 - Val Loss: 0.044504\n",
      "Epoch 43/50 - Train Loss: 0.029365 - Val Loss: 0.045041\n",
      "Epoch 44/50 - Train Loss: 0.031185 - Val Loss: 0.052128\n",
      "Epoch 45/50 - Train Loss: 0.027598 - Val Loss: 0.045159\n",
      "Epoch 46/50 - Train Loss: 0.030610 - Val Loss: 0.045403\n",
      "Epoch 47/50 - Train Loss: 0.029743 - Val Loss: 0.045597\n",
      "Epoch 48/50 - Train Loss: 0.029590 - Val Loss: 0.045334\n",
      "Epoch 49/50 - Train Loss: 0.027860 - Val Loss: 0.048429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:22:34,726] Trial 16 finished with value: 0.04411208132902781 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 218, 'lr': 0.0005969703942425369, 'weight_decay': 2.1150931783251297e-06, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.027899 - Val Loss: 0.047119\n",
      "Epoch 1/50 - Train Loss: 0.084743 - Val Loss: 0.138563\n",
      "Epoch 2/50 - Train Loss: 0.043918 - Val Loss: 0.075046\n",
      "Epoch 3/50 - Train Loss: 0.036891 - Val Loss: 0.057148\n",
      "Epoch 4/50 - Train Loss: 0.036171 - Val Loss: 0.046685\n",
      "Epoch 5/50 - Train Loss: 0.033310 - Val Loss: 0.045836\n",
      "Epoch 6/50 - Train Loss: 0.029647 - Val Loss: 0.048394\n",
      "Epoch 7/50 - Train Loss: 0.030902 - Val Loss: 0.046278\n",
      "Epoch 8/50 - Train Loss: 0.029750 - Val Loss: 0.061072\n",
      "Epoch 9/50 - Train Loss: 0.032490 - Val Loss: 0.046320\n",
      "Epoch 10/50 - Train Loss: 0.029627 - Val Loss: 0.045408\n",
      "Epoch 11/50 - Train Loss: 0.030980 - Val Loss: 0.048015\n",
      "Epoch 12/50 - Train Loss: 0.031783 - Val Loss: 0.054892\n",
      "Epoch 13/50 - Train Loss: 0.035370 - Val Loss: 0.044894\n",
      "Epoch 14/50 - Train Loss: 0.032963 - Val Loss: 0.047935\n",
      "Epoch 15/50 - Train Loss: 0.033724 - Val Loss: 0.051287\n",
      "Epoch 16/50 - Train Loss: 0.032773 - Val Loss: 0.045174\n",
      "Epoch 17/50 - Train Loss: 0.030400 - Val Loss: 0.044800\n",
      "Epoch 18/50 - Train Loss: 0.032552 - Val Loss: 0.048256\n",
      "Epoch 19/50 - Train Loss: 0.032855 - Val Loss: 0.044512\n",
      "Epoch 20/50 - Train Loss: 0.031870 - Val Loss: 0.046147\n",
      "Epoch 21/50 - Train Loss: 0.031645 - Val Loss: 0.046767\n",
      "Epoch 22/50 - Train Loss: 0.032250 - Val Loss: 0.047828\n",
      "Epoch 23/50 - Train Loss: 0.030689 - Val Loss: 0.051450\n",
      "Epoch 24/50 - Train Loss: 0.031120 - Val Loss: 0.049202\n",
      "Epoch 25/50 - Train Loss: 0.029405 - Val Loss: 0.047398\n",
      "Epoch 26/50 - Train Loss: 0.029682 - Val Loss: 0.047075\n",
      "Epoch 27/50 - Train Loss: 0.032043 - Val Loss: 0.044386\n",
      "Epoch 28/50 - Train Loss: 0.029631 - Val Loss: 0.044963\n",
      "Epoch 29/50 - Train Loss: 0.031697 - Val Loss: 0.047475\n",
      "Epoch 30/50 - Train Loss: 0.032101 - Val Loss: 0.054816\n",
      "Epoch 31/50 - Train Loss: 0.030662 - Val Loss: 0.046899\n",
      "Epoch 32/50 - Train Loss: 0.031779 - Val Loss: 0.053230\n",
      "Epoch 33/50 - Train Loss: 0.030634 - Val Loss: 0.046968\n",
      "Epoch 34/50 - Train Loss: 0.029129 - Val Loss: 0.044403\n",
      "Epoch 35/50 - Train Loss: 0.032507 - Val Loss: 0.048808\n",
      "Epoch 36/50 - Train Loss: 0.029710 - Val Loss: 0.046998\n",
      "Epoch 37/50 - Train Loss: 0.029020 - Val Loss: 0.044395\n",
      "Epoch 38/50 - Train Loss: 0.027928 - Val Loss: 0.044935\n",
      "Epoch 39/50 - Train Loss: 0.032574 - Val Loss: 0.047443\n",
      "Epoch 40/50 - Train Loss: 0.031380 - Val Loss: 0.044712\n",
      "Epoch 41/50 - Train Loss: 0.032782 - Val Loss: 0.050051\n",
      "Epoch 42/50 - Train Loss: 0.033159 - Val Loss: 0.045221\n",
      "Epoch 43/50 - Train Loss: 0.030452 - Val Loss: 0.045494\n",
      "Epoch 44/50 - Train Loss: 0.030953 - Val Loss: 0.045221\n",
      "Epoch 45/50 - Train Loss: 0.030335 - Val Loss: 0.044591\n",
      "Epoch 46/50 - Train Loss: 0.030414 - Val Loss: 0.045563\n",
      "Epoch 47/50 - Train Loss: 0.028609 - Val Loss: 0.044560\n",
      "Epoch 48/50 - Train Loss: 0.030669 - Val Loss: 0.044201\n",
      "Epoch 49/50 - Train Loss: 0.032179 - Val Loss: 0.044845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:23:22,370] Trial 17 finished with value: 0.04420097048083941 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 176, 'lr': 0.0021824928235100825, 'weight_decay': 3.2819754083685115e-05, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031815 - Val Loss: 0.045034\n",
      "Epoch 1/50 - Train Loss: 0.142438 - Val Loss: 0.108952\n",
      "Epoch 2/50 - Train Loss: 0.047170 - Val Loss: 0.104438\n",
      "Epoch 3/50 - Train Loss: 0.045358 - Val Loss: 0.075905\n",
      "Epoch 4/50 - Train Loss: 0.041304 - Val Loss: 0.083001\n",
      "Epoch 5/50 - Train Loss: 0.041838 - Val Loss: 0.080463\n",
      "Epoch 6/50 - Train Loss: 0.040267 - Val Loss: 0.077444\n",
      "Epoch 7/50 - Train Loss: 0.036505 - Val Loss: 0.063390\n",
      "Epoch 8/50 - Train Loss: 0.034743 - Val Loss: 0.053213\n",
      "Epoch 9/50 - Train Loss: 0.035152 - Val Loss: 0.051828\n",
      "Epoch 10/50 - Train Loss: 0.034039 - Val Loss: 0.050154\n",
      "Epoch 11/50 - Train Loss: 0.032246 - Val Loss: 0.047007\n",
      "Epoch 12/50 - Train Loss: 0.032610 - Val Loss: 0.047009\n",
      "Epoch 13/50 - Train Loss: 0.030738 - Val Loss: 0.045730\n",
      "Epoch 14/50 - Train Loss: 0.034636 - Val Loss: 0.050993\n",
      "Epoch 15/50 - Train Loss: 0.031511 - Val Loss: 0.047959\n",
      "Epoch 16/50 - Train Loss: 0.033524 - Val Loss: 0.046249\n",
      "Epoch 17/50 - Train Loss: 0.032097 - Val Loss: 0.051111\n",
      "Epoch 18/50 - Train Loss: 0.032207 - Val Loss: 0.048036\n",
      "Epoch 19/50 - Train Loss: 0.031451 - Val Loss: 0.064221\n",
      "Epoch 20/50 - Train Loss: 0.031002 - Val Loss: 0.056442\n",
      "Epoch 21/50 - Train Loss: 0.030672 - Val Loss: 0.050310\n",
      "Epoch 22/50 - Train Loss: 0.030206 - Val Loss: 0.051532\n",
      "Epoch 23/50 - Train Loss: 0.031540 - Val Loss: 0.058726\n",
      "Epoch 24/50 - Train Loss: 0.031295 - Val Loss: 0.051158\n",
      "Epoch 25/50 - Train Loss: 0.030531 - Val Loss: 0.056217\n",
      "Epoch 26/50 - Train Loss: 0.029989 - Val Loss: 0.046927\n",
      "Epoch 27/50 - Train Loss: 0.031443 - Val Loss: 0.045870\n",
      "Epoch 28/50 - Train Loss: 0.030952 - Val Loss: 0.046220\n",
      "Epoch 29/50 - Train Loss: 0.032974 - Val Loss: 0.050721\n",
      "Epoch 30/50 - Train Loss: 0.031275 - Val Loss: 0.046752\n",
      "Epoch 31/50 - Train Loss: 0.029582 - Val Loss: 0.048633\n",
      "Epoch 32/50 - Train Loss: 0.032837 - Val Loss: 0.048987\n",
      "Epoch 33/50 - Train Loss: 0.032885 - Val Loss: 0.048056\n",
      "Epoch 34/50 - Train Loss: 0.029407 - Val Loss: 0.045021\n",
      "Epoch 35/50 - Train Loss: 0.029842 - Val Loss: 0.051324\n",
      "Epoch 36/50 - Train Loss: 0.031494 - Val Loss: 0.046120\n",
      "Epoch 37/50 - Train Loss: 0.032533 - Val Loss: 0.048969\n",
      "Epoch 38/50 - Train Loss: 0.030950 - Val Loss: 0.046265\n",
      "Epoch 39/50 - Train Loss: 0.029855 - Val Loss: 0.045397\n",
      "Epoch 40/50 - Train Loss: 0.031813 - Val Loss: 0.045447\n",
      "Epoch 41/50 - Train Loss: 0.029904 - Val Loss: 0.045466\n",
      "Epoch 42/50 - Train Loss: 0.033020 - Val Loss: 0.046405\n",
      "Epoch 43/50 - Train Loss: 0.029377 - Val Loss: 0.046001\n",
      "Epoch 44/50 - Train Loss: 0.034030 - Val Loss: 0.045790\n",
      "Epoch 45/50 - Train Loss: 0.031641 - Val Loss: 0.046227\n",
      "Epoch 46/50 - Train Loss: 0.031542 - Val Loss: 0.046120\n",
      "Epoch 47/50 - Train Loss: 0.032059 - Val Loss: 0.047096\n",
      "Epoch 48/50 - Train Loss: 0.030302 - Val Loss: 0.045205\n",
      "Epoch 49/50 - Train Loss: 0.032680 - Val Loss: 0.052527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:24:11,776] Trial 18 finished with value: 0.04502132907509804 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 127, 'lr': 0.0007858261203129482, 'weight_decay': 0.0006407382252915884, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031537 - Val Loss: 0.046157\n",
      "Epoch 1/50 - Train Loss: 0.281602 - Val Loss: 0.274484\n",
      "Epoch 2/50 - Train Loss: 0.156973 - Val Loss: 0.278356\n",
      "Epoch 3/50 - Train Loss: 0.116366 - Val Loss: 0.188212\n",
      "Epoch 4/50 - Train Loss: 0.064828 - Val Loss: 0.105348\n",
      "Epoch 5/50 - Train Loss: 0.113215 - Val Loss: 0.120127\n",
      "Epoch 6/50 - Train Loss: 0.054143 - Val Loss: 0.157885\n",
      "Epoch 7/50 - Train Loss: 0.076537 - Val Loss: 0.148339\n",
      "Epoch 8/50 - Train Loss: 0.058546 - Val Loss: 0.115121\n",
      "Epoch 9/50 - Train Loss: 0.051897 - Val Loss: 0.077829\n",
      "Epoch 10/50 - Train Loss: 0.053340 - Val Loss: 0.068804\n",
      "Epoch 11/50 - Train Loss: 0.046299 - Val Loss: 0.075632\n",
      "Epoch 12/50 - Train Loss: 0.049586 - Val Loss: 0.085060\n",
      "Epoch 13/50 - Train Loss: 0.042494 - Val Loss: 0.092405\n",
      "Epoch 14/50 - Train Loss: 0.041880 - Val Loss: 0.093341\n",
      "Epoch 15/50 - Train Loss: 0.050700 - Val Loss: 0.089832\n",
      "Epoch 16/50 - Train Loss: 0.049114 - Val Loss: 0.083840\n",
      "Epoch 17/50 - Train Loss: 0.049217 - Val Loss: 0.078782\n",
      "Epoch 18/50 - Train Loss: 0.047012 - Val Loss: 0.075258\n",
      "Epoch 19/50 - Train Loss: 0.036924 - Val Loss: 0.059736\n",
      "Epoch 20/50 - Train Loss: 0.042620 - Val Loss: 0.052132\n",
      "Epoch 21/50 - Train Loss: 0.031955 - Val Loss: 0.049647\n",
      "Epoch 22/50 - Train Loss: 0.040974 - Val Loss: 0.048849\n",
      "Epoch 23/50 - Train Loss: 0.040811 - Val Loss: 0.056724\n",
      "Epoch 24/50 - Train Loss: 0.034085 - Val Loss: 0.055260\n",
      "Epoch 25/50 - Train Loss: 0.031410 - Val Loss: 0.052155\n",
      "Epoch 26/50 - Train Loss: 0.038715 - Val Loss: 0.057358\n",
      "Epoch 27/50 - Train Loss: 0.038999 - Val Loss: 0.055038\n",
      "Epoch 28/50 - Train Loss: 0.038854 - Val Loss: 0.047720\n",
      "Epoch 29/50 - Train Loss: 0.038966 - Val Loss: 0.048769\n",
      "Epoch 30/50 - Train Loss: 0.038775 - Val Loss: 0.051142\n",
      "Epoch 31/50 - Train Loss: 0.030198 - Val Loss: 0.047358\n",
      "Epoch 32/50 - Train Loss: 0.036988 - Val Loss: 0.047747\n",
      "Epoch 33/50 - Train Loss: 0.029587 - Val Loss: 0.048799\n",
      "Epoch 34/50 - Train Loss: 0.036667 - Val Loss: 0.047548\n",
      "Epoch 35/50 - Train Loss: 0.037169 - Val Loss: 0.047677\n",
      "Epoch 36/50 - Train Loss: 0.036075 - Val Loss: 0.049542\n",
      "Epoch 37/50 - Train Loss: 0.029824 - Val Loss: 0.047770\n",
      "Epoch 38/50 - Train Loss: 0.028835 - Val Loss: 0.046599\n",
      "Epoch 39/50 - Train Loss: 0.037598 - Val Loss: 0.048919\n",
      "Epoch 40/50 - Train Loss: 0.030043 - Val Loss: 0.045712\n",
      "Epoch 41/50 - Train Loss: 0.030505 - Val Loss: 0.045360\n",
      "Epoch 42/50 - Train Loss: 0.029439 - Val Loss: 0.050088\n",
      "Epoch 43/50 - Train Loss: 0.029661 - Val Loss: 0.045722\n",
      "Epoch 44/50 - Train Loss: 0.038078 - Val Loss: 0.047799\n",
      "Epoch 45/50 - Train Loss: 0.029123 - Val Loss: 0.051871\n",
      "Epoch 46/50 - Train Loss: 0.036923 - Val Loss: 0.046814\n",
      "Epoch 47/50 - Train Loss: 0.032481 - Val Loss: 0.046651\n",
      "Epoch 48/50 - Train Loss: 0.029350 - Val Loss: 0.049361\n",
      "Epoch 49/50 - Train Loss: 0.036593 - Val Loss: 0.046284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:24:30,620] Trial 19 finished with value: 0.045360464602708817 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 227, 'lr': 0.009214188258807293, 'weight_decay': 1.9554211961776103e-05, 'batch_size': 64}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.036442 - Val Loss: 0.045409\n",
      "Epoch 1/50 - Train Loss: 0.132987 - Val Loss: 0.222530\n",
      "Epoch 2/50 - Train Loss: 0.053715 - Val Loss: 0.092585\n",
      "Epoch 3/50 - Train Loss: 0.038529 - Val Loss: 0.049351\n",
      "Epoch 4/50 - Train Loss: 0.036558 - Val Loss: 0.071803\n",
      "Epoch 5/50 - Train Loss: 0.036064 - Val Loss: 0.051941\n",
      "Epoch 6/50 - Train Loss: 0.035594 - Val Loss: 0.051281\n",
      "Epoch 7/50 - Train Loss: 0.033298 - Val Loss: 0.046297\n",
      "Epoch 8/50 - Train Loss: 0.030932 - Val Loss: 0.047525\n",
      "Epoch 9/50 - Train Loss: 0.030741 - Val Loss: 0.049828\n",
      "Epoch 10/50 - Train Loss: 0.031572 - Val Loss: 0.049943\n",
      "Epoch 11/50 - Train Loss: 0.034226 - Val Loss: 0.053019\n",
      "Epoch 12/50 - Train Loss: 0.035913 - Val Loss: 0.044903\n",
      "Epoch 13/50 - Train Loss: 0.033079 - Val Loss: 0.048534\n",
      "Epoch 14/50 - Train Loss: 0.033254 - Val Loss: 0.046103\n",
      "Epoch 15/50 - Train Loss: 0.030459 - Val Loss: 0.044777\n",
      "Epoch 16/50 - Train Loss: 0.031720 - Val Loss: 0.051187\n",
      "Epoch 17/50 - Train Loss: 0.033199 - Val Loss: 0.054263\n",
      "Epoch 18/50 - Train Loss: 0.031790 - Val Loss: 0.045096\n",
      "Epoch 19/50 - Train Loss: 0.030526 - Val Loss: 0.046600\n",
      "Epoch 20/50 - Train Loss: 0.028936 - Val Loss: 0.045181\n",
      "Epoch 21/50 - Train Loss: 0.030916 - Val Loss: 0.048172\n",
      "Epoch 22/50 - Train Loss: 0.030023 - Val Loss: 0.046204\n",
      "Epoch 23/50 - Train Loss: 0.030057 - Val Loss: 0.049148\n",
      "Epoch 24/50 - Train Loss: 0.032276 - Val Loss: 0.052903\n",
      "Epoch 25/50 - Train Loss: 0.032016 - Val Loss: 0.052251\n",
      "Epoch 26/50 - Train Loss: 0.035562 - Val Loss: 0.048325\n",
      "Epoch 27/50 - Train Loss: 0.036659 - Val Loss: 0.054952\n",
      "Epoch 28/50 - Train Loss: 0.032198 - Val Loss: 0.044389\n",
      "Epoch 29/50 - Train Loss: 0.034108 - Val Loss: 0.048869\n",
      "Epoch 30/50 - Train Loss: 0.033028 - Val Loss: 0.065823\n",
      "Epoch 31/50 - Train Loss: 0.032043 - Val Loss: 0.047009\n",
      "Epoch 32/50 - Train Loss: 0.030778 - Val Loss: 0.047273\n",
      "Epoch 33/50 - Train Loss: 0.029268 - Val Loss: 0.044269\n",
      "Epoch 34/50 - Train Loss: 0.031838 - Val Loss: 0.046201\n",
      "Epoch 35/50 - Train Loss: 0.031411 - Val Loss: 0.047349\n",
      "Epoch 36/50 - Train Loss: 0.030516 - Val Loss: 0.044213\n",
      "Epoch 37/50 - Train Loss: 0.028975 - Val Loss: 0.044304\n",
      "Epoch 38/50 - Train Loss: 0.032635 - Val Loss: 0.045743\n",
      "Epoch 39/50 - Train Loss: 0.028469 - Val Loss: 0.044910\n",
      "Epoch 40/50 - Train Loss: 0.033097 - Val Loss: 0.050506\n",
      "Epoch 41/50 - Train Loss: 0.032059 - Val Loss: 0.044668\n",
      "Epoch 42/50 - Train Loss: 0.030037 - Val Loss: 0.048753\n",
      "Epoch 43/50 - Train Loss: 0.029584 - Val Loss: 0.044855\n",
      "Epoch 44/50 - Train Loss: 0.031958 - Val Loss: 0.049621\n",
      "Epoch 45/50 - Train Loss: 0.035800 - Val Loss: 0.072890\n",
      "Epoch 46/50 - Train Loss: 0.034698 - Val Loss: 0.056772\n",
      "Epoch 47/50 - Train Loss: 0.031858 - Val Loss: 0.045927\n",
      "Epoch 48/50 - Train Loss: 0.032371 - Val Loss: 0.044305\n",
      "Epoch 49/50 - Train Loss: 0.028783 - Val Loss: 0.047192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:25:35,343] Trial 20 finished with value: 0.04410590107242266 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 256, 'lr': 0.002849348337176904, 'weight_decay': 0.00014703582004940968, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031258 - Val Loss: 0.044106\n",
      "Epoch 1/50 - Train Loss: 0.069902 - Val Loss: 0.084335\n",
      "Epoch 2/50 - Train Loss: 0.039858 - Val Loss: 0.050451\n",
      "Epoch 3/50 - Train Loss: 0.033906 - Val Loss: 0.046822\n",
      "Epoch 4/50 - Train Loss: 0.031914 - Val Loss: 0.053728\n",
      "Epoch 5/50 - Train Loss: 0.033930 - Val Loss: 0.048743\n",
      "Epoch 6/50 - Train Loss: 0.032880 - Val Loss: 0.048766\n",
      "Epoch 7/50 - Train Loss: 0.032913 - Val Loss: 0.049136\n",
      "Epoch 8/50 - Train Loss: 0.031363 - Val Loss: 0.044551\n",
      "Epoch 9/50 - Train Loss: 0.031242 - Val Loss: 0.062730\n",
      "Epoch 10/50 - Train Loss: 0.033424 - Val Loss: 0.048262\n",
      "Epoch 11/50 - Train Loss: 0.030934 - Val Loss: 0.055407\n",
      "Epoch 12/50 - Train Loss: 0.030623 - Val Loss: 0.044021\n",
      "Epoch 13/50 - Train Loss: 0.031077 - Val Loss: 0.045520\n",
      "Epoch 14/50 - Train Loss: 0.029588 - Val Loss: 0.050170\n",
      "Epoch 15/50 - Train Loss: 0.034321 - Val Loss: 0.045712\n",
      "Epoch 16/50 - Train Loss: 0.031314 - Val Loss: 0.047729\n",
      "Epoch 17/50 - Train Loss: 0.033456 - Val Loss: 0.045812\n",
      "Epoch 18/50 - Train Loss: 0.031213 - Val Loss: 0.044479\n",
      "Epoch 19/50 - Train Loss: 0.032453 - Val Loss: 0.046665\n",
      "Epoch 20/50 - Train Loss: 0.031743 - Val Loss: 0.045679\n",
      "Epoch 21/50 - Train Loss: 0.031705 - Val Loss: 0.063807\n",
      "Epoch 22/50 - Train Loss: 0.029322 - Val Loss: 0.045624\n",
      "Epoch 23/50 - Train Loss: 0.028038 - Val Loss: 0.045183\n",
      "Epoch 24/50 - Train Loss: 0.029518 - Val Loss: 0.047625\n",
      "Epoch 25/50 - Train Loss: 0.030040 - Val Loss: 0.044464\n",
      "Epoch 26/50 - Train Loss: 0.030075 - Val Loss: 0.045902\n",
      "Epoch 27/50 - Train Loss: 0.029300 - Val Loss: 0.044374\n",
      "Epoch 28/50 - Train Loss: 0.029447 - Val Loss: 0.046609\n",
      "Epoch 29/50 - Train Loss: 0.028184 - Val Loss: 0.046525\n",
      "Epoch 30/50 - Train Loss: 0.031289 - Val Loss: 0.044404\n",
      "Epoch 31/50 - Train Loss: 0.029258 - Val Loss: 0.046572\n",
      "Epoch 32/50 - Train Loss: 0.032298 - Val Loss: 0.056759\n",
      "Epoch 33/50 - Train Loss: 0.031213 - Val Loss: 0.060006\n",
      "Epoch 34/50 - Train Loss: 0.030957 - Val Loss: 0.047278\n",
      "Epoch 35/50 - Train Loss: 0.030248 - Val Loss: 0.045725\n",
      "Epoch 36/50 - Train Loss: 0.028264 - Val Loss: 0.044501\n",
      "Epoch 37/50 - Train Loss: 0.027272 - Val Loss: 0.045131\n",
      "Epoch 38/50 - Train Loss: 0.031642 - Val Loss: 0.044640\n",
      "Epoch 39/50 - Train Loss: 0.030701 - Val Loss: 0.051995\n",
      "Epoch 40/50 - Train Loss: 0.028768 - Val Loss: 0.052612\n",
      "Epoch 41/50 - Train Loss: 0.029801 - Val Loss: 0.044700\n",
      "Epoch 42/50 - Train Loss: 0.029414 - Val Loss: 0.045382\n",
      "Epoch 43/50 - Train Loss: 0.029998 - Val Loss: 0.050747\n",
      "Epoch 44/50 - Train Loss: 0.030497 - Val Loss: 0.044935\n",
      "Epoch 45/50 - Train Loss: 0.030382 - Val Loss: 0.045212\n",
      "Epoch 46/50 - Train Loss: 0.031014 - Val Loss: 0.046688\n",
      "Epoch 47/50 - Train Loss: 0.031197 - Val Loss: 0.045293\n",
      "Epoch 48/50 - Train Loss: 0.028730 - Val Loss: 0.045805\n",
      "Epoch 49/50 - Train Loss: 0.027120 - Val Loss: 0.046229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:26:20,572] Trial 21 finished with value: 0.04402051493525505 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 252, 'lr': 0.00553841655512949, 'weight_decay': 1.098878649053242e-08, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.027909 - Val Loss: 0.046265\n",
      "Epoch 1/50 - Train Loss: 0.170700 - Val Loss: 0.174759\n",
      "Epoch 2/50 - Train Loss: 0.052384 - Val Loss: 0.092938\n",
      "Epoch 3/50 - Train Loss: 0.041540 - Val Loss: 0.062028\n",
      "Epoch 4/50 - Train Loss: 0.036486 - Val Loss: 0.046343\n",
      "Epoch 5/50 - Train Loss: 0.034301 - Val Loss: 0.049855\n",
      "Epoch 6/50 - Train Loss: 0.035605 - Val Loss: 0.044618\n",
      "Epoch 7/50 - Train Loss: 0.030564 - Val Loss: 0.044951\n",
      "Epoch 8/50 - Train Loss: 0.032045 - Val Loss: 0.046422\n",
      "Epoch 9/50 - Train Loss: 0.031905 - Val Loss: 0.049025\n",
      "Epoch 10/50 - Train Loss: 0.030906 - Val Loss: 0.049853\n",
      "Epoch 11/50 - Train Loss: 0.029018 - Val Loss: 0.044047\n",
      "Epoch 12/50 - Train Loss: 0.033683 - Val Loss: 0.050290\n",
      "Epoch 13/50 - Train Loss: 0.029595 - Val Loss: 0.045835\n",
      "Epoch 14/50 - Train Loss: 0.035191 - Val Loss: 0.061091\n",
      "Epoch 15/50 - Train Loss: 0.032054 - Val Loss: 0.055400\n",
      "Epoch 16/50 - Train Loss: 0.029765 - Val Loss: 0.054604\n",
      "Epoch 17/50 - Train Loss: 0.030062 - Val Loss: 0.050096\n",
      "Epoch 18/50 - Train Loss: 0.031678 - Val Loss: 0.047852\n",
      "Epoch 19/50 - Train Loss: 0.031030 - Val Loss: 0.045465\n",
      "Epoch 20/50 - Train Loss: 0.029256 - Val Loss: 0.045268\n",
      "Epoch 21/50 - Train Loss: 0.028796 - Val Loss: 0.047748\n",
      "Epoch 22/50 - Train Loss: 0.030867 - Val Loss: 0.057507\n",
      "Epoch 23/50 - Train Loss: 0.031839 - Val Loss: 0.050593\n",
      "Epoch 24/50 - Train Loss: 0.031583 - Val Loss: 0.045375\n",
      "Epoch 25/50 - Train Loss: 0.030854 - Val Loss: 0.052097\n",
      "Epoch 26/50 - Train Loss: 0.031954 - Val Loss: 0.047202\n",
      "Epoch 27/50 - Train Loss: 0.034200 - Val Loss: 0.046272\n",
      "Epoch 28/50 - Train Loss: 0.033388 - Val Loss: 0.044780\n",
      "Epoch 29/50 - Train Loss: 0.030182 - Val Loss: 0.046219\n",
      "Epoch 30/50 - Train Loss: 0.029668 - Val Loss: 0.044998\n",
      "Epoch 31/50 - Train Loss: 0.028915 - Val Loss: 0.044926\n",
      "Epoch 32/50 - Train Loss: 0.030900 - Val Loss: 0.045723\n",
      "Epoch 33/50 - Train Loss: 0.029206 - Val Loss: 0.044942\n",
      "Epoch 34/50 - Train Loss: 0.029148 - Val Loss: 0.044951\n",
      "Epoch 35/50 - Train Loss: 0.028587 - Val Loss: 0.044833\n",
      "Epoch 36/50 - Train Loss: 0.032799 - Val Loss: 0.048733\n",
      "Epoch 37/50 - Train Loss: 0.032574 - Val Loss: 0.046135\n",
      "Epoch 38/50 - Train Loss: 0.031100 - Val Loss: 0.044638\n",
      "Epoch 39/50 - Train Loss: 0.029843 - Val Loss: 0.046440\n",
      "Epoch 40/50 - Train Loss: 0.030598 - Val Loss: 0.045852\n",
      "Epoch 41/50 - Train Loss: 0.030973 - Val Loss: 0.044759\n",
      "Epoch 42/50 - Train Loss: 0.032007 - Val Loss: 0.046680\n",
      "Epoch 43/50 - Train Loss: 0.028508 - Val Loss: 0.045254\n",
      "Epoch 44/50 - Train Loss: 0.029294 - Val Loss: 0.050422\n",
      "Epoch 45/50 - Train Loss: 0.028629 - Val Loss: 0.044624\n",
      "Epoch 46/50 - Train Loss: 0.030775 - Val Loss: 0.045781\n",
      "Epoch 47/50 - Train Loss: 0.032343 - Val Loss: 0.045973\n",
      "Epoch 48/50 - Train Loss: 0.029932 - Val Loss: 0.048512\n",
      "Epoch 49/50 - Train Loss: 0.028779 - Val Loss: 0.045107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:27:13,205] Trial 22 finished with value: 0.044047017892201744 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 256, 'lr': 0.0037071094148789807, 'weight_decay': 1.1939264120168437e-06, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.027146 - Val Loss: 0.046180\n",
      "Epoch 1/50 - Train Loss: 0.077220 - Val Loss: 0.143418\n",
      "Epoch 2/50 - Train Loss: 0.048542 - Val Loss: 0.088995\n",
      "Epoch 3/50 - Train Loss: 0.040290 - Val Loss: 0.056342\n",
      "Epoch 4/50 - Train Loss: 0.033896 - Val Loss: 0.048373\n",
      "Epoch 5/50 - Train Loss: 0.033844 - Val Loss: 0.048977\n",
      "Epoch 6/50 - Train Loss: 0.031069 - Val Loss: 0.046028\n",
      "Epoch 7/50 - Train Loss: 0.033151 - Val Loss: 0.046046\n",
      "Epoch 8/50 - Train Loss: 0.034684 - Val Loss: 0.045767\n",
      "Epoch 9/50 - Train Loss: 0.033523 - Val Loss: 0.045555\n",
      "Epoch 10/50 - Train Loss: 0.032148 - Val Loss: 0.047749\n",
      "Epoch 11/50 - Train Loss: 0.030405 - Val Loss: 0.045347\n",
      "Epoch 12/50 - Train Loss: 0.031472 - Val Loss: 0.044610\n",
      "Epoch 13/50 - Train Loss: 0.033397 - Val Loss: 0.045513\n",
      "Epoch 14/50 - Train Loss: 0.030517 - Val Loss: 0.045316\n",
      "Epoch 15/50 - Train Loss: 0.034199 - Val Loss: 0.046354\n",
      "Epoch 16/50 - Train Loss: 0.030611 - Val Loss: 0.051104\n",
      "Epoch 17/50 - Train Loss: 0.029627 - Val Loss: 0.044536\n",
      "Epoch 18/50 - Train Loss: 0.031451 - Val Loss: 0.048684\n",
      "Epoch 19/50 - Train Loss: 0.029479 - Val Loss: 0.048652\n",
      "Epoch 20/50 - Train Loss: 0.030041 - Val Loss: 0.044556\n",
      "Epoch 21/50 - Train Loss: 0.031255 - Val Loss: 0.044973\n",
      "Epoch 22/50 - Train Loss: 0.031145 - Val Loss: 0.044847\n",
      "Epoch 23/50 - Train Loss: 0.030124 - Val Loss: 0.045706\n",
      "Epoch 24/50 - Train Loss: 0.029521 - Val Loss: 0.054260\n",
      "Epoch 25/50 - Train Loss: 0.030270 - Val Loss: 0.044785\n",
      "Epoch 26/50 - Train Loss: 0.030520 - Val Loss: 0.044703\n",
      "Epoch 27/50 - Train Loss: 0.032202 - Val Loss: 0.046588\n",
      "Epoch 28/50 - Train Loss: 0.029232 - Val Loss: 0.045764\n",
      "Epoch 29/50 - Train Loss: 0.031686 - Val Loss: 0.044988\n",
      "Epoch 30/50 - Train Loss: 0.028477 - Val Loss: 0.044447\n",
      "Epoch 31/50 - Train Loss: 0.028811 - Val Loss: 0.044854\n",
      "Epoch 32/50 - Train Loss: 0.033762 - Val Loss: 0.046752\n",
      "Epoch 33/50 - Train Loss: 0.033668 - Val Loss: 0.044626\n",
      "Epoch 34/50 - Train Loss: 0.031046 - Val Loss: 0.045193\n",
      "Epoch 35/50 - Train Loss: 0.028936 - Val Loss: 0.045062\n",
      "Epoch 36/50 - Train Loss: 0.029484 - Val Loss: 0.048307\n",
      "Epoch 37/50 - Train Loss: 0.028668 - Val Loss: 0.045645\n",
      "Epoch 38/50 - Train Loss: 0.029909 - Val Loss: 0.055543\n",
      "Epoch 39/50 - Train Loss: 0.031751 - Val Loss: 0.050811\n",
      "Epoch 40/50 - Train Loss: 0.028915 - Val Loss: 0.044397\n",
      "Epoch 41/50 - Train Loss: 0.031038 - Val Loss: 0.045793\n",
      "Epoch 42/50 - Train Loss: 0.032732 - Val Loss: 0.045257\n",
      "Epoch 43/50 - Train Loss: 0.028885 - Val Loss: 0.044346\n",
      "Epoch 44/50 - Train Loss: 0.031408 - Val Loss: 0.047509\n",
      "Epoch 45/50 - Train Loss: 0.030706 - Val Loss: 0.044399\n",
      "Epoch 46/50 - Train Loss: 0.032003 - Val Loss: 0.044745\n",
      "Epoch 47/50 - Train Loss: 0.028443 - Val Loss: 0.044767\n",
      "Epoch 48/50 - Train Loss: 0.029297 - Val Loss: 0.045591\n",
      "Epoch 49/50 - Train Loss: 0.030245 - Val Loss: 0.044905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:27:57,282] Trial 23 finished with value: 0.04434638718763987 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 225, 'lr': 0.0013340394016671906, 'weight_decay': 1.6718888568856654e-07, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033109 - Val Loss: 0.046466\n",
      "Epoch 1/50 - Train Loss: 0.076501 - Val Loss: 0.081524\n",
      "Epoch 2/50 - Train Loss: 0.046780 - Val Loss: 0.075183\n",
      "Epoch 3/50 - Train Loss: 0.043903 - Val Loss: 0.078295\n",
      "Epoch 4/50 - Train Loss: 0.038798 - Val Loss: 0.093137\n",
      "Epoch 5/50 - Train Loss: 0.036874 - Val Loss: 0.053091\n",
      "Epoch 6/50 - Train Loss: 0.032547 - Val Loss: 0.049147\n",
      "Epoch 7/50 - Train Loss: 0.032671 - Val Loss: 0.049124\n",
      "Epoch 8/50 - Train Loss: 0.030988 - Val Loss: 0.046957\n",
      "Epoch 9/50 - Train Loss: 0.035546 - Val Loss: 0.048426\n",
      "Epoch 10/50 - Train Loss: 0.034059 - Val Loss: 0.051952\n",
      "Epoch 11/50 - Train Loss: 0.032930 - Val Loss: 0.047123\n",
      "Epoch 12/50 - Train Loss: 0.032205 - Val Loss: 0.051535\n",
      "Epoch 13/50 - Train Loss: 0.031960 - Val Loss: 0.046647\n",
      "Epoch 14/50 - Train Loss: 0.032379 - Val Loss: 0.046662\n",
      "Epoch 15/50 - Train Loss: 0.030821 - Val Loss: 0.050555\n",
      "Epoch 16/50 - Train Loss: 0.031896 - Val Loss: 0.046506\n",
      "Epoch 17/50 - Train Loss: 0.033614 - Val Loss: 0.048136\n",
      "Epoch 18/50 - Train Loss: 0.031243 - Val Loss: 0.045475\n",
      "Epoch 19/50 - Train Loss: 0.029696 - Val Loss: 0.045118\n",
      "Epoch 20/50 - Train Loss: 0.033909 - Val Loss: 0.046659\n",
      "Epoch 21/50 - Train Loss: 0.033727 - Val Loss: 0.047390\n",
      "Epoch 22/50 - Train Loss: 0.033479 - Val Loss: 0.047736\n",
      "Epoch 23/50 - Train Loss: 0.029485 - Val Loss: 0.050274\n",
      "Epoch 24/50 - Train Loss: 0.032376 - Val Loss: 0.050142\n",
      "Epoch 25/50 - Train Loss: 0.030429 - Val Loss: 0.045852\n",
      "Epoch 26/50 - Train Loss: 0.029138 - Val Loss: 0.046457\n",
      "Epoch 27/50 - Train Loss: 0.030696 - Val Loss: 0.048192\n",
      "Epoch 28/50 - Train Loss: 0.032316 - Val Loss: 0.046538\n",
      "Epoch 29/50 - Train Loss: 0.031044 - Val Loss: 0.045981\n",
      "Epoch 30/50 - Train Loss: 0.030487 - Val Loss: 0.045974\n",
      "Epoch 31/50 - Train Loss: 0.028958 - Val Loss: 0.046049\n",
      "Epoch 32/50 - Train Loss: 0.032487 - Val Loss: 0.047002\n",
      "Epoch 33/50 - Train Loss: 0.031885 - Val Loss: 0.046570\n",
      "Epoch 34/50 - Train Loss: 0.029096 - Val Loss: 0.047272\n",
      "Epoch 35/50 - Train Loss: 0.027532 - Val Loss: 0.046351\n",
      "Epoch 36/50 - Train Loss: 0.031750 - Val Loss: 0.050986\n",
      "Epoch 37/50 - Train Loss: 0.032513 - Val Loss: 0.046492\n",
      "Epoch 38/50 - Train Loss: 0.029921 - Val Loss: 0.048053\n",
      "Epoch 39/50 - Train Loss: 0.032092 - Val Loss: 0.054639\n",
      "Epoch 40/50 - Train Loss: 0.029881 - Val Loss: 0.048305\n",
      "Epoch 41/50 - Train Loss: 0.029352 - Val Loss: 0.049231\n",
      "Epoch 42/50 - Train Loss: 0.027620 - Val Loss: 0.050552\n",
      "Epoch 43/50 - Train Loss: 0.032090 - Val Loss: 0.047457\n",
      "Epoch 44/50 - Train Loss: 0.030018 - Val Loss: 0.046203\n",
      "Epoch 45/50 - Train Loss: 0.029968 - Val Loss: 0.047019\n",
      "Epoch 46/50 - Train Loss: 0.030441 - Val Loss: 0.048712\n",
      "Epoch 47/50 - Train Loss: 0.030715 - Val Loss: 0.047624\n",
      "Epoch 48/50 - Train Loss: 0.029041 - Val Loss: 0.050120\n",
      "Epoch 49/50 - Train Loss: 0.033768 - Val Loss: 0.048108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:28:56,879] Trial 24 finished with value: 0.04511757815877596 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 190, 'lr': 0.009334146887664202, 'weight_decay': 6.02782130763685e-06, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.035503 - Val Loss: 0.047496\n",
      "Epoch 1/50 - Train Loss: 0.078138 - Val Loss: 0.059146\n",
      "Epoch 2/50 - Train Loss: 0.045359 - Val Loss: 0.051921\n",
      "Epoch 3/50 - Train Loss: 0.034206 - Val Loss: 0.046165\n",
      "Epoch 4/50 - Train Loss: 0.035017 - Val Loss: 0.045376\n",
      "Epoch 5/50 - Train Loss: 0.034097 - Val Loss: 0.047197\n",
      "Epoch 6/50 - Train Loss: 0.033740 - Val Loss: 0.046561\n",
      "Epoch 7/50 - Train Loss: 0.032245 - Val Loss: 0.045314\n",
      "Epoch 8/50 - Train Loss: 0.032413 - Val Loss: 0.046215\n",
      "Epoch 9/50 - Train Loss: 0.035459 - Val Loss: 0.051282\n",
      "Epoch 10/50 - Train Loss: 0.030937 - Val Loss: 0.044934\n",
      "Epoch 11/50 - Train Loss: 0.030320 - Val Loss: 0.044267\n",
      "Epoch 12/50 - Train Loss: 0.030959 - Val Loss: 0.045480\n",
      "Epoch 13/50 - Train Loss: 0.030552 - Val Loss: 0.044933\n",
      "Epoch 14/50 - Train Loss: 0.032823 - Val Loss: 0.046032\n",
      "Epoch 15/50 - Train Loss: 0.029504 - Val Loss: 0.044689\n",
      "Epoch 16/50 - Train Loss: 0.029789 - Val Loss: 0.058661\n",
      "Epoch 17/50 - Train Loss: 0.036902 - Val Loss: 0.045334\n",
      "Epoch 18/50 - Train Loss: 0.030507 - Val Loss: 0.047231\n",
      "Epoch 19/50 - Train Loss: 0.029847 - Val Loss: 0.045878\n",
      "Epoch 20/50 - Train Loss: 0.030479 - Val Loss: 0.048619\n",
      "Epoch 21/50 - Train Loss: 0.029744 - Val Loss: 0.046541\n",
      "Epoch 22/50 - Train Loss: 0.030642 - Val Loss: 0.047131\n",
      "Epoch 23/50 - Train Loss: 0.034323 - Val Loss: 0.060047\n",
      "Epoch 24/50 - Train Loss: 0.032881 - Val Loss: 0.045283\n",
      "Epoch 25/50 - Train Loss: 0.029621 - Val Loss: 0.044955\n",
      "Epoch 26/50 - Train Loss: 0.029614 - Val Loss: 0.044753\n",
      "Epoch 27/50 - Train Loss: 0.031438 - Val Loss: 0.045200\n",
      "Epoch 28/50 - Train Loss: 0.030535 - Val Loss: 0.044245\n",
      "Epoch 29/50 - Train Loss: 0.032017 - Val Loss: 0.069947\n",
      "Epoch 30/50 - Train Loss: 0.034213 - Val Loss: 0.044736\n",
      "Epoch 31/50 - Train Loss: 0.034042 - Val Loss: 0.057768\n",
      "Epoch 32/50 - Train Loss: 0.033587 - Val Loss: 0.049649\n",
      "Epoch 33/50 - Train Loss: 0.031238 - Val Loss: 0.048460\n",
      "Epoch 34/50 - Train Loss: 0.030384 - Val Loss: 0.044631\n",
      "Epoch 35/50 - Train Loss: 0.030658 - Val Loss: 0.044301\n",
      "Epoch 36/50 - Train Loss: 0.030586 - Val Loss: 0.044521\n",
      "Epoch 37/50 - Train Loss: 0.030371 - Val Loss: 0.044243\n",
      "Epoch 38/50 - Train Loss: 0.030783 - Val Loss: 0.047281\n",
      "Epoch 39/50 - Train Loss: 0.032032 - Val Loss: 0.046274\n",
      "Epoch 40/50 - Train Loss: 0.029824 - Val Loss: 0.045104\n",
      "Epoch 41/50 - Train Loss: 0.030279 - Val Loss: 0.047228\n",
      "Epoch 42/50 - Train Loss: 0.030648 - Val Loss: 0.053611\n",
      "Epoch 43/50 - Train Loss: 0.029387 - Val Loss: 0.047741\n",
      "Epoch 44/50 - Train Loss: 0.028577 - Val Loss: 0.044134\n",
      "Epoch 45/50 - Train Loss: 0.030375 - Val Loss: 0.044446\n",
      "Epoch 46/50 - Train Loss: 0.029559 - Val Loss: 0.044712\n",
      "Epoch 47/50 - Train Loss: 0.027876 - Val Loss: 0.044151\n",
      "Epoch 48/50 - Train Loss: 0.032344 - Val Loss: 0.046941\n",
      "Epoch 49/50 - Train Loss: 0.033195 - Val Loss: 0.048998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:29:32,707] Trial 25 finished with value: 0.04413407916824023 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 232, 'lr': 0.003834898249803661, 'weight_decay': 8.054731723198902e-05, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030886 - Val Loss: 0.046141\n",
      "Epoch 1/50 - Train Loss: 0.084166 - Val Loss: 0.124632\n",
      "Epoch 2/50 - Train Loss: 0.048338 - Val Loss: 0.063595\n",
      "Epoch 3/50 - Train Loss: 0.039282 - Val Loss: 0.066325\n",
      "Epoch 4/50 - Train Loss: 0.036726 - Val Loss: 0.064298\n",
      "Epoch 5/50 - Train Loss: 0.033323 - Val Loss: 0.048534\n",
      "Epoch 6/50 - Train Loss: 0.034602 - Val Loss: 0.048334\n",
      "Epoch 7/50 - Train Loss: 0.031620 - Val Loss: 0.051014\n",
      "Epoch 8/50 - Train Loss: 0.031950 - Val Loss: 0.045512\n",
      "Epoch 9/50 - Train Loss: 0.033008 - Val Loss: 0.049374\n",
      "Epoch 10/50 - Train Loss: 0.030730 - Val Loss: 0.046721\n",
      "Epoch 11/50 - Train Loss: 0.030562 - Val Loss: 0.047140\n",
      "Epoch 12/50 - Train Loss: 0.033305 - Val Loss: 0.046014\n",
      "Epoch 13/50 - Train Loss: 0.031341 - Val Loss: 0.044617\n",
      "Epoch 14/50 - Train Loss: 0.031748 - Val Loss: 0.045397\n",
      "Epoch 15/50 - Train Loss: 0.030726 - Val Loss: 0.047956\n",
      "Epoch 16/50 - Train Loss: 0.031828 - Val Loss: 0.047486\n",
      "Epoch 17/50 - Train Loss: 0.031884 - Val Loss: 0.044214\n",
      "Epoch 18/50 - Train Loss: 0.032717 - Val Loss: 0.053942\n",
      "Epoch 19/50 - Train Loss: 0.034105 - Val Loss: 0.065277\n",
      "Epoch 20/50 - Train Loss: 0.034911 - Val Loss: 0.056304\n",
      "Epoch 21/50 - Train Loss: 0.030702 - Val Loss: 0.056302\n",
      "Epoch 22/50 - Train Loss: 0.031266 - Val Loss: 0.050265\n",
      "Epoch 23/50 - Train Loss: 0.031151 - Val Loss: 0.046348\n",
      "Epoch 24/50 - Train Loss: 0.027721 - Val Loss: 0.050082\n",
      "Epoch 25/50 - Train Loss: 0.033079 - Val Loss: 0.059684\n",
      "Epoch 26/50 - Train Loss: 0.029562 - Val Loss: 0.059537\n",
      "Epoch 27/50 - Train Loss: 0.031828 - Val Loss: 0.048542\n",
      "Epoch 28/50 - Train Loss: 0.031497 - Val Loss: 0.051454\n",
      "Epoch 29/50 - Train Loss: 0.030688 - Val Loss: 0.056725\n",
      "Epoch 30/50 - Train Loss: 0.031913 - Val Loss: 0.045771\n",
      "Epoch 31/50 - Train Loss: 0.030286 - Val Loss: 0.044173\n",
      "Epoch 32/50 - Train Loss: 0.029344 - Val Loss: 0.045661\n",
      "Epoch 33/50 - Train Loss: 0.029137 - Val Loss: 0.045983\n",
      "Epoch 34/50 - Train Loss: 0.030892 - Val Loss: 0.047008\n",
      "Epoch 35/50 - Train Loss: 0.032147 - Val Loss: 0.045119\n",
      "Epoch 36/50 - Train Loss: 0.028752 - Val Loss: 0.044760\n",
      "Epoch 37/50 - Train Loss: 0.028151 - Val Loss: 0.046085\n",
      "Epoch 38/50 - Train Loss: 0.030015 - Val Loss: 0.046026\n",
      "Epoch 39/50 - Train Loss: 0.029806 - Val Loss: 0.045225\n",
      "Epoch 40/50 - Train Loss: 0.030229 - Val Loss: 0.046570\n",
      "Epoch 41/50 - Train Loss: 0.029248 - Val Loss: 0.045711\n",
      "Epoch 42/50 - Train Loss: 0.029877 - Val Loss: 0.046685\n",
      "Epoch 43/50 - Train Loss: 0.028632 - Val Loss: 0.046165\n",
      "Epoch 44/50 - Train Loss: 0.029217 - Val Loss: 0.047633\n",
      "Epoch 45/50 - Train Loss: 0.029574 - Val Loss: 0.046125\n",
      "Epoch 46/50 - Train Loss: 0.027423 - Val Loss: 0.044879\n",
      "Epoch 47/50 - Train Loss: 0.027098 - Val Loss: 0.046316\n",
      "Epoch 48/50 - Train Loss: 0.031141 - Val Loss: 0.045161\n",
      "Epoch 49/50 - Train Loss: 0.027805 - Val Loss: 0.044860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:30:18,659] Trial 26 finished with value: 0.044172911594311394 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 214, 'lr': 0.0010329250912151087, 'weight_decay': 1.6029589246174987e-07, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031166 - Val Loss: 0.049149\n",
      "Epoch 1/50 - Train Loss: 0.183302 - Val Loss: 0.079043\n",
      "Epoch 2/50 - Train Loss: 0.064326 - Val Loss: 0.105494\n",
      "Epoch 3/50 - Train Loss: 0.054944 - Val Loss: 0.113534\n",
      "Epoch 4/50 - Train Loss: 0.051213 - Val Loss: 0.072655\n",
      "Epoch 5/50 - Train Loss: 0.050898 - Val Loss: 0.072382\n",
      "Epoch 6/50 - Train Loss: 0.040092 - Val Loss: 0.090115\n",
      "Epoch 7/50 - Train Loss: 0.039907 - Val Loss: 0.078438\n",
      "Epoch 8/50 - Train Loss: 0.043399 - Val Loss: 0.061924\n",
      "Epoch 9/50 - Train Loss: 0.035504 - Val Loss: 0.066231\n",
      "Epoch 10/50 - Train Loss: 0.035619 - Val Loss: 0.058696\n",
      "Epoch 11/50 - Train Loss: 0.032345 - Val Loss: 0.052012\n",
      "Epoch 12/50 - Train Loss: 0.033436 - Val Loss: 0.052968\n",
      "Epoch 13/50 - Train Loss: 0.031497 - Val Loss: 0.049321\n",
      "Epoch 14/50 - Train Loss: 0.038665 - Val Loss: 0.054545\n",
      "Epoch 15/50 - Train Loss: 0.030605 - Val Loss: 0.048411\n",
      "Epoch 16/50 - Train Loss: 0.040390 - Val Loss: 0.054851\n",
      "Epoch 17/50 - Train Loss: 0.038560 - Val Loss: 0.049646\n",
      "Epoch 18/50 - Train Loss: 0.037981 - Val Loss: 0.050294\n",
      "Epoch 19/50 - Train Loss: 0.036601 - Val Loss: 0.048197\n",
      "Epoch 20/50 - Train Loss: 0.028423 - Val Loss: 0.047680\n",
      "Epoch 21/50 - Train Loss: 0.037528 - Val Loss: 0.051177\n",
      "Epoch 22/50 - Train Loss: 0.029378 - Val Loss: 0.046666\n",
      "Epoch 23/50 - Train Loss: 0.037664 - Val Loss: 0.052786\n",
      "Epoch 24/50 - Train Loss: 0.030699 - Val Loss: 0.048925\n",
      "Epoch 25/50 - Train Loss: 0.029861 - Val Loss: 0.046798\n",
      "Epoch 26/50 - Train Loss: 0.029724 - Val Loss: 0.052354\n",
      "Epoch 27/50 - Train Loss: 0.037999 - Val Loss: 0.046136\n",
      "Epoch 28/50 - Train Loss: 0.029937 - Val Loss: 0.047938\n",
      "Epoch 29/50 - Train Loss: 0.030202 - Val Loss: 0.048337\n",
      "Epoch 30/50 - Train Loss: 0.037275 - Val Loss: 0.048130\n",
      "Epoch 31/50 - Train Loss: 0.029669 - Val Loss: 0.046883\n",
      "Epoch 32/50 - Train Loss: 0.038072 - Val Loss: 0.047389\n",
      "Epoch 33/50 - Train Loss: 0.037069 - Val Loss: 0.049015\n",
      "Epoch 34/50 - Train Loss: 0.030048 - Val Loss: 0.046433\n",
      "Epoch 35/50 - Train Loss: 0.038549 - Val Loss: 0.050195\n",
      "Epoch 36/50 - Train Loss: 0.030151 - Val Loss: 0.050478\n",
      "Epoch 37/50 - Train Loss: 0.036915 - Val Loss: 0.046591\n",
      "Epoch 38/50 - Train Loss: 0.029282 - Val Loss: 0.049526\n",
      "Epoch 39/50 - Train Loss: 0.038366 - Val Loss: 0.047329\n",
      "Epoch 40/50 - Train Loss: 0.032644 - Val Loss: 0.047062\n",
      "Epoch 41/50 - Train Loss: 0.027248 - Val Loss: 0.053068\n",
      "Epoch 42/50 - Train Loss: 0.030164 - Val Loss: 0.049223\n",
      "Epoch 43/50 - Train Loss: 0.037515 - Val Loss: 0.046751\n",
      "Epoch 44/50 - Train Loss: 0.037060 - Val Loss: 0.049028\n",
      "Epoch 45/50 - Train Loss: 0.037130 - Val Loss: 0.046290\n",
      "Epoch 46/50 - Train Loss: 0.028697 - Val Loss: 0.046418\n",
      "Epoch 47/50 - Train Loss: 0.037877 - Val Loss: 0.047915\n",
      "Epoch 48/50 - Train Loss: 0.029821 - Val Loss: 0.045866\n",
      "Epoch 49/50 - Train Loss: 0.036919 - Val Loss: 0.050450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:30:34,889] Trial 27 finished with value: 0.045866064727306366 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 180, 'lr': 0.004122997693958749, 'weight_decay': 0.00027340085127850323, 'batch_size': 64}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030247 - Val Loss: 0.047554\n",
      "Epoch 1/50 - Train Loss: 0.228510 - Val Loss: 0.321072\n",
      "Epoch 2/50 - Train Loss: 0.128768 - Val Loss: 0.204866\n",
      "Epoch 3/50 - Train Loss: 0.069665 - Val Loss: 0.084803\n",
      "Epoch 4/50 - Train Loss: 0.064340 - Val Loss: 0.072818\n",
      "Epoch 5/50 - Train Loss: 0.057099 - Val Loss: 0.093311\n",
      "Epoch 6/50 - Train Loss: 0.052988 - Val Loss: 0.108953\n",
      "Epoch 7/50 - Train Loss: 0.053256 - Val Loss: 0.094438\n",
      "Epoch 8/50 - Train Loss: 0.039706 - Val Loss: 0.072846\n",
      "Epoch 9/50 - Train Loss: 0.048062 - Val Loss: 0.071758\n",
      "Epoch 10/50 - Train Loss: 0.037832 - Val Loss: 0.085551\n",
      "Epoch 11/50 - Train Loss: 0.047425 - Val Loss: 0.089726\n",
      "Epoch 12/50 - Train Loss: 0.040956 - Val Loss: 0.074410\n",
      "Epoch 13/50 - Train Loss: 0.037132 - Val Loss: 0.061731\n",
      "Epoch 14/50 - Train Loss: 0.045093 - Val Loss: 0.062703\n",
      "Epoch 15/50 - Train Loss: 0.038570 - Val Loss: 0.071308\n",
      "Epoch 16/50 - Train Loss: 0.035181 - Val Loss: 0.069707\n",
      "Epoch 17/50 - Train Loss: 0.037074 - Val Loss: 0.053959\n",
      "Epoch 18/50 - Train Loss: 0.036316 - Val Loss: 0.052755\n",
      "Epoch 19/50 - Train Loss: 0.032329 - Val Loss: 0.056651\n",
      "Epoch 20/50 - Train Loss: 0.032212 - Val Loss: 0.051717\n",
      "Epoch 21/50 - Train Loss: 0.025967 - Val Loss: 0.048151\n",
      "Epoch 22/50 - Train Loss: 0.035115 - Val Loss: 0.050578\n",
      "Epoch 23/50 - Train Loss: 0.030689 - Val Loss: 0.051752\n",
      "Epoch 24/50 - Train Loss: 0.032787 - Val Loss: 0.048368\n",
      "Epoch 25/50 - Train Loss: 0.027587 - Val Loss: 0.048114\n",
      "Epoch 26/50 - Train Loss: 0.030125 - Val Loss: 0.049465\n",
      "Epoch 27/50 - Train Loss: 0.036413 - Val Loss: 0.048991\n",
      "Epoch 28/50 - Train Loss: 0.029617 - Val Loss: 0.047436\n",
      "Epoch 29/50 - Train Loss: 0.033817 - Val Loss: 0.047275\n",
      "Epoch 30/50 - Train Loss: 0.029014 - Val Loss: 0.047798\n",
      "Epoch 31/50 - Train Loss: 0.034576 - Val Loss: 0.046079\n",
      "Epoch 32/50 - Train Loss: 0.034086 - Val Loss: 0.048045\n",
      "Epoch 33/50 - Train Loss: 0.032173 - Val Loss: 0.047475\n",
      "Epoch 34/50 - Train Loss: 0.031439 - Val Loss: 0.047348\n",
      "Epoch 35/50 - Train Loss: 0.032593 - Val Loss: 0.049230\n",
      "Epoch 36/50 - Train Loss: 0.033249 - Val Loss: 0.047766\n",
      "Epoch 37/50 - Train Loss: 0.029093 - Val Loss: 0.047053\n",
      "Epoch 38/50 - Train Loss: 0.035360 - Val Loss: 0.046103\n",
      "Epoch 39/50 - Train Loss: 0.026737 - Val Loss: 0.046022\n",
      "Epoch 40/50 - Train Loss: 0.033288 - Val Loss: 0.045967\n",
      "Epoch 41/50 - Train Loss: 0.036946 - Val Loss: 0.047411\n",
      "Epoch 42/50 - Train Loss: 0.032611 - Val Loss: 0.046947\n",
      "Epoch 43/50 - Train Loss: 0.036710 - Val Loss: 0.047847\n",
      "Epoch 44/50 - Train Loss: 0.028761 - Val Loss: 0.047160\n",
      "Epoch 45/50 - Train Loss: 0.034590 - Val Loss: 0.045875\n",
      "Epoch 46/50 - Train Loss: 0.033725 - Val Loss: 0.049481\n",
      "Epoch 47/50 - Train Loss: 0.036875 - Val Loss: 0.046839\n",
      "Epoch 48/50 - Train Loss: 0.031864 - Val Loss: 0.046327\n",
      "Epoch 49/50 - Train Loss: 0.035023 - Val Loss: 0.050535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:31:04,284] Trial 28 finished with value: 0.04564586281776428 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 242, 'lr': 0.0004119023618321001, 'weight_decay': 1.2923252998693598e-05, 'batch_size': 32}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.027618 - Val Loss: 0.045646\n",
      "Epoch 1/50 - Train Loss: 0.101637 - Val Loss: 0.072307\n",
      "Epoch 2/50 - Train Loss: 0.060332 - Val Loss: 0.128765\n",
      "Epoch 3/50 - Train Loss: 0.051432 - Val Loss: 0.068883\n",
      "Epoch 4/50 - Train Loss: 0.041838 - Val Loss: 0.082893\n",
      "Epoch 5/50 - Train Loss: 0.041319 - Val Loss: 0.093204\n",
      "Epoch 6/50 - Train Loss: 0.044412 - Val Loss: 0.073819\n",
      "Epoch 7/50 - Train Loss: 0.044193 - Val Loss: 0.078816\n",
      "Epoch 8/50 - Train Loss: 0.039384 - Val Loss: 0.063430\n",
      "Epoch 9/50 - Train Loss: 0.035459 - Val Loss: 0.047543\n",
      "Epoch 10/50 - Train Loss: 0.035391 - Val Loss: 0.053267\n",
      "Epoch 11/50 - Train Loss: 0.036100 - Val Loss: 0.051088\n",
      "Epoch 12/50 - Train Loss: 0.034004 - Val Loss: 0.065554\n",
      "Epoch 13/50 - Train Loss: 0.035639 - Val Loss: 0.045702\n",
      "Epoch 14/50 - Train Loss: 0.035916 - Val Loss: 0.052834\n",
      "Epoch 15/50 - Train Loss: 0.037279 - Val Loss: 0.049961\n",
      "Epoch 16/50 - Train Loss: 0.031899 - Val Loss: 0.045214\n",
      "Epoch 17/50 - Train Loss: 0.027926 - Val Loss: 0.044044\n",
      "Epoch 18/50 - Train Loss: 0.033352 - Val Loss: 0.044580\n",
      "Epoch 19/50 - Train Loss: 0.032917 - Val Loss: 0.046066\n",
      "Epoch 20/50 - Train Loss: 0.029950 - Val Loss: 0.044227\n",
      "Epoch 21/50 - Train Loss: 0.025254 - Val Loss: 0.044155\n",
      "Epoch 22/50 - Train Loss: 0.030065 - Val Loss: 0.044424\n",
      "Epoch 23/50 - Train Loss: 0.029561 - Val Loss: 0.044443\n",
      "Epoch 24/50 - Train Loss: 0.030213 - Val Loss: 0.048628\n",
      "Epoch 25/50 - Train Loss: 0.033322 - Val Loss: 0.044411\n",
      "Epoch 26/50 - Train Loss: 0.029146 - Val Loss: 0.044071\n",
      "Epoch 27/50 - Train Loss: 0.034368 - Val Loss: 0.044977\n",
      "Epoch 28/50 - Train Loss: 0.031537 - Val Loss: 0.044672\n",
      "Epoch 29/50 - Train Loss: 0.030500 - Val Loss: 0.049652\n",
      "Epoch 30/50 - Train Loss: 0.027845 - Val Loss: 0.045438\n",
      "Epoch 31/50 - Train Loss: 0.030848 - Val Loss: 0.045139\n",
      "Epoch 32/50 - Train Loss: 0.031842 - Val Loss: 0.047476\n",
      "Epoch 33/50 - Train Loss: 0.035881 - Val Loss: 0.055669\n",
      "Epoch 34/50 - Train Loss: 0.032473 - Val Loss: 0.046389\n",
      "Epoch 35/50 - Train Loss: 0.029075 - Val Loss: 0.044413\n",
      "Epoch 36/50 - Train Loss: 0.029041 - Val Loss: 0.044263\n",
      "Epoch 37/50 - Train Loss: 0.031886 - Val Loss: 0.045958\n",
      "Epoch 38/50 - Train Loss: 0.029125 - Val Loss: 0.044329\n",
      "Epoch 39/50 - Train Loss: 0.031143 - Val Loss: 0.044200\n",
      "Epoch 40/50 - Train Loss: 0.029769 - Val Loss: 0.043845\n",
      "Epoch 41/50 - Train Loss: 0.031839 - Val Loss: 0.048258\n",
      "Epoch 42/50 - Train Loss: 0.029700 - Val Loss: 0.044226\n",
      "Epoch 43/50 - Train Loss: 0.029781 - Val Loss: 0.045012\n",
      "Epoch 44/50 - Train Loss: 0.029452 - Val Loss: 0.043875\n",
      "Epoch 45/50 - Train Loss: 0.028281 - Val Loss: 0.043773\n",
      "Epoch 46/50 - Train Loss: 0.029542 - Val Loss: 0.044633\n",
      "Epoch 47/50 - Train Loss: 0.032121 - Val Loss: 0.045813\n",
      "Epoch 48/50 - Train Loss: 0.030987 - Val Loss: 0.045310\n",
      "Epoch 49/50 - Train Loss: 0.032082 - Val Loss: 0.048546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:31:36,552] Trial 29 finished with value: 0.043773120269179344 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 136, 'lr': 0.002673792647560745, 'weight_decay': 1.2566776643433154e-06, 'batch_size': 16}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031940 - Val Loss: 0.045314\n",
      "Epoch 1/50 - Train Loss: 0.123077 - Val Loss: 0.095480\n",
      "Epoch 2/50 - Train Loss: 0.037897 - Val Loss: 0.059191\n",
      "Epoch 3/50 - Train Loss: 0.033911 - Val Loss: 0.048575\n",
      "Epoch 4/50 - Train Loss: 0.031858 - Val Loss: 0.047485\n",
      "Epoch 5/50 - Train Loss: 0.031208 - Val Loss: 0.045024\n",
      "Epoch 6/50 - Train Loss: 0.033141 - Val Loss: 0.050836\n",
      "Epoch 7/50 - Train Loss: 0.033068 - Val Loss: 0.045458\n",
      "Epoch 8/50 - Train Loss: 0.033018 - Val Loss: 0.048939\n",
      "Epoch 9/50 - Train Loss: 0.031979 - Val Loss: 0.046074\n",
      "Epoch 10/50 - Train Loss: 0.030342 - Val Loss: 0.046283\n",
      "Epoch 11/50 - Train Loss: 0.030470 - Val Loss: 0.045920\n",
      "Epoch 12/50 - Train Loss: 0.034251 - Val Loss: 0.045778\n",
      "Epoch 13/50 - Train Loss: 0.029333 - Val Loss: 0.051468\n",
      "Epoch 14/50 - Train Loss: 0.032482 - Val Loss: 0.054129\n",
      "Epoch 15/50 - Train Loss: 0.030044 - Val Loss: 0.048673\n",
      "Epoch 16/50 - Train Loss: 0.032752 - Val Loss: 0.045039\n",
      "Epoch 17/50 - Train Loss: 0.031458 - Val Loss: 0.045522\n",
      "Epoch 18/50 - Train Loss: 0.033527 - Val Loss: 0.045314\n",
      "Epoch 19/50 - Train Loss: 0.030546 - Val Loss: 0.046908\n",
      "Epoch 20/50 - Train Loss: 0.030180 - Val Loss: 0.046390\n",
      "Epoch 21/50 - Train Loss: 0.033057 - Val Loss: 0.045603\n",
      "Epoch 22/50 - Train Loss: 0.031918 - Val Loss: 0.050046\n",
      "Epoch 23/50 - Train Loss: 0.031823 - Val Loss: 0.048923\n",
      "Epoch 24/50 - Train Loss: 0.035600 - Val Loss: 0.044784\n",
      "Epoch 25/50 - Train Loss: 0.031227 - Val Loss: 0.044490\n",
      "Epoch 26/50 - Train Loss: 0.029763 - Val Loss: 0.044865\n",
      "Epoch 27/50 - Train Loss: 0.030359 - Val Loss: 0.051961\n",
      "Epoch 28/50 - Train Loss: 0.033305 - Val Loss: 0.064159\n",
      "Epoch 29/50 - Train Loss: 0.034507 - Val Loss: 0.044491\n",
      "Epoch 30/50 - Train Loss: 0.032617 - Val Loss: 0.046423\n",
      "Epoch 31/50 - Train Loss: 0.029826 - Val Loss: 0.044714\n",
      "Epoch 32/50 - Train Loss: 0.031141 - Val Loss: 0.045295\n",
      "Epoch 33/50 - Train Loss: 0.028260 - Val Loss: 0.044681\n",
      "Epoch 34/50 - Train Loss: 0.030052 - Val Loss: 0.044511\n",
      "Epoch 35/50 - Train Loss: 0.028161 - Val Loss: 0.045614\n",
      "Epoch 36/50 - Train Loss: 0.030515 - Val Loss: 0.044073\n",
      "Epoch 37/50 - Train Loss: 0.029983 - Val Loss: 0.044046\n",
      "Epoch 38/50 - Train Loss: 0.027081 - Val Loss: 0.045111\n",
      "Epoch 39/50 - Train Loss: 0.028531 - Val Loss: 0.046981\n",
      "Epoch 40/50 - Train Loss: 0.030781 - Val Loss: 0.045568\n",
      "Epoch 41/50 - Train Loss: 0.030747 - Val Loss: 0.044549\n",
      "Epoch 42/50 - Train Loss: 0.028150 - Val Loss: 0.045839\n",
      "Epoch 43/50 - Train Loss: 0.029199 - Val Loss: 0.045066\n",
      "Epoch 44/50 - Train Loss: 0.029326 - Val Loss: 0.045438\n",
      "Epoch 45/50 - Train Loss: 0.030451 - Val Loss: 0.046079\n",
      "Epoch 46/50 - Train Loss: 0.029331 - Val Loss: 0.044989\n",
      "Epoch 47/50 - Train Loss: 0.028133 - Val Loss: 0.046389\n",
      "Epoch 48/50 - Train Loss: 0.030438 - Val Loss: 0.046591\n",
      "Epoch 49/50 - Train Loss: 0.033167 - Val Loss: 0.045138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:32:04,145] Trial 30 finished with value: 0.044045962393283844 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 243, 'lr': 0.006155959961377384, 'weight_decay': 4.300871402805441e-06, 'batch_size': 8}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.032281 - Val Loss: 0.058481\n",
      "Epoch 1/50 - Train Loss: 0.112362 - Val Loss: 0.074179\n",
      "Epoch 2/50 - Train Loss: 0.050410 - Val Loss: 0.100790\n",
      "Epoch 3/50 - Train Loss: 0.043117 - Val Loss: 0.064448\n",
      "Epoch 4/50 - Train Loss: 0.042436 - Val Loss: 0.083988\n",
      "Epoch 5/50 - Train Loss: 0.040135 - Val Loss: 0.057376\n",
      "Epoch 6/50 - Train Loss: 0.039070 - Val Loss: 0.053197\n",
      "Epoch 7/50 - Train Loss: 0.035358 - Val Loss: 0.047872\n",
      "Epoch 8/50 - Train Loss: 0.031003 - Val Loss: 0.050879\n",
      "Epoch 9/50 - Train Loss: 0.032465 - Val Loss: 0.050093\n",
      "Epoch 10/50 - Train Loss: 0.033436 - Val Loss: 0.048988\n",
      "Epoch 11/50 - Train Loss: 0.032818 - Val Loss: 0.046084\n",
      "Epoch 12/50 - Train Loss: 0.029284 - Val Loss: 0.045727\n",
      "Epoch 13/50 - Train Loss: 0.033582 - Val Loss: 0.051345\n",
      "Epoch 14/50 - Train Loss: 0.032354 - Val Loss: 0.046354\n",
      "Epoch 15/50 - Train Loss: 0.030746 - Val Loss: 0.044792\n",
      "Epoch 16/50 - Train Loss: 0.033050 - Val Loss: 0.045602\n",
      "Epoch 17/50 - Train Loss: 0.030382 - Val Loss: 0.045268\n",
      "Epoch 18/50 - Train Loss: 0.035475 - Val Loss: 0.046703\n",
      "Epoch 19/50 - Train Loss: 0.032937 - Val Loss: 0.050206\n",
      "Epoch 20/50 - Train Loss: 0.030627 - Val Loss: 0.044699\n",
      "Epoch 21/50 - Train Loss: 0.033326 - Val Loss: 0.044481\n",
      "Epoch 22/50 - Train Loss: 0.032046 - Val Loss: 0.049132\n",
      "Epoch 23/50 - Train Loss: 0.030781 - Val Loss: 0.047224\n",
      "Epoch 24/50 - Train Loss: 0.030163 - Val Loss: 0.045069\n",
      "Epoch 25/50 - Train Loss: 0.030304 - Val Loss: 0.045680\n",
      "Epoch 26/50 - Train Loss: 0.032834 - Val Loss: 0.044632\n",
      "Epoch 27/50 - Train Loss: 0.030295 - Val Loss: 0.059588\n",
      "Epoch 28/50 - Train Loss: 0.032786 - Val Loss: 0.047681\n",
      "Epoch 29/50 - Train Loss: 0.030673 - Val Loss: 0.044353\n",
      "Epoch 30/50 - Train Loss: 0.029860 - Val Loss: 0.047827\n",
      "Epoch 31/50 - Train Loss: 0.032487 - Val Loss: 0.049910\n",
      "Epoch 32/50 - Train Loss: 0.030524 - Val Loss: 0.044237\n",
      "Epoch 33/50 - Train Loss: 0.030654 - Val Loss: 0.044718\n",
      "Epoch 34/50 - Train Loss: 0.035287 - Val Loss: 0.045387\n",
      "Epoch 35/50 - Train Loss: 0.034049 - Val Loss: 0.062572\n",
      "Epoch 36/50 - Train Loss: 0.038437 - Val Loss: 0.047882\n",
      "Epoch 37/50 - Train Loss: 0.033450 - Val Loss: 0.045472\n",
      "Epoch 38/50 - Train Loss: 0.029275 - Val Loss: 0.046416\n",
      "Epoch 39/50 - Train Loss: 0.032307 - Val Loss: 0.046124\n",
      "Epoch 40/50 - Train Loss: 0.029623 - Val Loss: 0.045813\n",
      "Epoch 41/50 - Train Loss: 0.033620 - Val Loss: 0.051316\n",
      "Epoch 42/50 - Train Loss: 0.029692 - Val Loss: 0.044922\n",
      "Epoch 43/50 - Train Loss: 0.034489 - Val Loss: 0.044685\n",
      "Epoch 44/50 - Train Loss: 0.035072 - Val Loss: 0.053412\n",
      "Epoch 45/50 - Train Loss: 0.031044 - Val Loss: 0.045271\n",
      "Epoch 46/50 - Train Loss: 0.029997 - Val Loss: 0.045112\n",
      "Epoch 47/50 - Train Loss: 0.028619 - Val Loss: 0.045181\n",
      "Epoch 48/50 - Train Loss: 0.031366 - Val Loss: 0.044596\n",
      "Epoch 49/50 - Train Loss: 0.030420 - Val Loss: 0.045651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:32:37,165] Trial 31 finished with value: 0.04423658736050129 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 130, 'lr': 0.0028681986430519647, 'weight_decay': 1.4044083694597092e-06, 'batch_size': 16}. Best is trial 14 with value: 0.043348429103692375.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.032254 - Val Loss: 0.044657\n",
      "Epoch 1/50 - Train Loss: 0.092593 - Val Loss: 0.108056\n",
      "Epoch 2/50 - Train Loss: 0.047675 - Val Loss: 0.095491\n",
      "Epoch 3/50 - Train Loss: 0.043472 - Val Loss: 0.085720\n",
      "Epoch 4/50 - Train Loss: 0.040023 - Val Loss: 0.075127\n",
      "Epoch 5/50 - Train Loss: 0.032509 - Val Loss: 0.049276\n",
      "Epoch 6/50 - Train Loss: 0.037790 - Val Loss: 0.050149\n",
      "Epoch 7/50 - Train Loss: 0.036226 - Val Loss: 0.048484\n",
      "Epoch 8/50 - Train Loss: 0.034273 - Val Loss: 0.053461\n",
      "Epoch 9/50 - Train Loss: 0.031308 - Val Loss: 0.049806\n",
      "Epoch 10/50 - Train Loss: 0.034059 - Val Loss: 0.044452\n",
      "Epoch 11/50 - Train Loss: 0.032595 - Val Loss: 0.045825\n",
      "Epoch 12/50 - Train Loss: 0.033311 - Val Loss: 0.047365\n",
      "Epoch 13/50 - Train Loss: 0.034621 - Val Loss: 0.052684\n",
      "Epoch 14/50 - Train Loss: 0.030366 - Val Loss: 0.044384\n",
      "Epoch 15/50 - Train Loss: 0.033143 - Val Loss: 0.044674\n",
      "Epoch 16/50 - Train Loss: 0.030860 - Val Loss: 0.045002\n",
      "Epoch 17/50 - Train Loss: 0.031151 - Val Loss: 0.047314\n",
      "Epoch 18/50 - Train Loss: 0.033171 - Val Loss: 0.044556\n",
      "Epoch 19/50 - Train Loss: 0.032268 - Val Loss: 0.045890\n",
      "Epoch 20/50 - Train Loss: 0.035955 - Val Loss: 0.045298\n",
      "Epoch 21/50 - Train Loss: 0.035529 - Val Loss: 0.069878\n",
      "Epoch 22/50 - Train Loss: 0.035838 - Val Loss: 0.045221\n",
      "Epoch 23/50 - Train Loss: 0.033316 - Val Loss: 0.044528\n",
      "Epoch 24/50 - Train Loss: 0.030953 - Val Loss: 0.056598\n",
      "Epoch 25/50 - Train Loss: 0.030063 - Val Loss: 0.044613\n",
      "Epoch 26/50 - Train Loss: 0.028567 - Val Loss: 0.047148\n",
      "Epoch 27/50 - Train Loss: 0.031850 - Val Loss: 0.049341\n",
      "Epoch 28/50 - Train Loss: 0.031355 - Val Loss: 0.045899\n",
      "Epoch 29/50 - Train Loss: 0.030421 - Val Loss: 0.049371\n",
      "Epoch 30/50 - Train Loss: 0.028237 - Val Loss: 0.046767\n",
      "Epoch 31/50 - Train Loss: 0.029825 - Val Loss: 0.046994\n",
      "Epoch 32/50 - Train Loss: 0.030931 - Val Loss: 0.043347\n",
      "Epoch 33/50 - Train Loss: 0.032291 - Val Loss: 0.046210\n",
      "Epoch 34/50 - Train Loss: 0.033126 - Val Loss: 0.043625\n",
      "Epoch 35/50 - Train Loss: 0.029180 - Val Loss: 0.044845\n",
      "Epoch 36/50 - Train Loss: 0.032532 - Val Loss: 0.060243\n",
      "Epoch 37/50 - Train Loss: 0.030943 - Val Loss: 0.050365\n",
      "Epoch 38/50 - Train Loss: 0.034730 - Val Loss: 0.044987\n",
      "Epoch 39/50 - Train Loss: 0.028687 - Val Loss: 0.043644\n",
      "Epoch 40/50 - Train Loss: 0.031012 - Val Loss: 0.050178\n",
      "Epoch 41/50 - Train Loss: 0.030408 - Val Loss: 0.059065\n",
      "Epoch 42/50 - Train Loss: 0.029965 - Val Loss: 0.057329\n",
      "Epoch 43/50 - Train Loss: 0.033223 - Val Loss: 0.044489\n",
      "Epoch 44/50 - Train Loss: 0.031802 - Val Loss: 0.043976\n",
      "Epoch 45/50 - Train Loss: 0.028751 - Val Loss: 0.049758\n",
      "Epoch 46/50 - Train Loss: 0.031624 - Val Loss: 0.044222\n",
      "Epoch 47/50 - Train Loss: 0.031731 - Val Loss: 0.047719\n",
      "Epoch 48/50 - Train Loss: 0.031613 - Val Loss: 0.050653\n",
      "Epoch 49/50 - Train Loss: 0.029648 - Val Loss: 0.044840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:33:00,531] Trial 32 finished with value: 0.04334702715277672 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 83, 'lr': 0.00939424778694716, 'weight_decay': 7.163526021398771e-07, 'batch_size': 16}. Best is trial 32 with value: 0.04334702715277672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030101 - Val Loss: 0.045464\n",
      "Epoch 1/50 - Train Loss: 0.093508 - Val Loss: 0.160183\n",
      "Epoch 2/50 - Train Loss: 0.057794 - Val Loss: 0.064965\n",
      "Epoch 3/50 - Train Loss: 0.044367 - Val Loss: 0.078704\n",
      "Epoch 4/50 - Train Loss: 0.041006 - Val Loss: 0.068876\n",
      "Epoch 5/50 - Train Loss: 0.036984 - Val Loss: 0.056729\n",
      "Epoch 6/50 - Train Loss: 0.034799 - Val Loss: 0.048068\n",
      "Epoch 7/50 - Train Loss: 0.037155 - Val Loss: 0.045591\n",
      "Epoch 8/50 - Train Loss: 0.035210 - Val Loss: 0.055886\n",
      "Epoch 9/50 - Train Loss: 0.033427 - Val Loss: 0.052806\n",
      "Epoch 10/50 - Train Loss: 0.029767 - Val Loss: 0.043558\n",
      "Epoch 11/50 - Train Loss: 0.031903 - Val Loss: 0.047371\n",
      "Epoch 12/50 - Train Loss: 0.036595 - Val Loss: 0.066856\n",
      "Epoch 13/50 - Train Loss: 0.033324 - Val Loss: 0.045312\n",
      "Epoch 14/50 - Train Loss: 0.030469 - Val Loss: 0.045815\n",
      "Epoch 15/50 - Train Loss: 0.032666 - Val Loss: 0.044250\n",
      "Epoch 16/50 - Train Loss: 0.034247 - Val Loss: 0.045352\n",
      "Epoch 17/50 - Train Loss: 0.029121 - Val Loss: 0.045355\n",
      "Epoch 18/50 - Train Loss: 0.033768 - Val Loss: 0.044107\n",
      "Epoch 19/50 - Train Loss: 0.032858 - Val Loss: 0.050768\n",
      "Epoch 20/50 - Train Loss: 0.030911 - Val Loss: 0.046388\n",
      "Epoch 21/50 - Train Loss: 0.033032 - Val Loss: 0.046759\n",
      "Epoch 22/50 - Train Loss: 0.030622 - Val Loss: 0.044437\n",
      "Epoch 23/50 - Train Loss: 0.030167 - Val Loss: 0.049825\n",
      "Epoch 24/50 - Train Loss: 0.031762 - Val Loss: 0.044993\n",
      "Epoch 25/50 - Train Loss: 0.031477 - Val Loss: 0.046525\n",
      "Epoch 26/50 - Train Loss: 0.028348 - Val Loss: 0.046153\n",
      "Epoch 27/50 - Train Loss: 0.030303 - Val Loss: 0.048558\n",
      "Epoch 28/50 - Train Loss: 0.026722 - Val Loss: 0.047687\n",
      "Epoch 29/50 - Train Loss: 0.032552 - Val Loss: 0.045025\n",
      "Epoch 30/50 - Train Loss: 0.030611 - Val Loss: 0.044682\n",
      "Epoch 31/50 - Train Loss: 0.032037 - Val Loss: 0.048685\n",
      "Epoch 32/50 - Train Loss: 0.029607 - Val Loss: 0.044718\n",
      "Epoch 33/50 - Train Loss: 0.029665 - Val Loss: 0.045276\n",
      "Epoch 34/50 - Train Loss: 0.033271 - Val Loss: 0.045719\n",
      "Epoch 35/50 - Train Loss: 0.032402 - Val Loss: 0.046533\n",
      "Epoch 36/50 - Train Loss: 0.029723 - Val Loss: 0.044671\n",
      "Epoch 37/50 - Train Loss: 0.033411 - Val Loss: 0.043892\n",
      "Epoch 38/50 - Train Loss: 0.031258 - Val Loss: 0.043849\n",
      "Epoch 39/50 - Train Loss: 0.029034 - Val Loss: 0.046246\n",
      "Epoch 40/50 - Train Loss: 0.031092 - Val Loss: 0.044642\n",
      "Epoch 41/50 - Train Loss: 0.031619 - Val Loss: 0.050563\n",
      "Epoch 42/50 - Train Loss: 0.030996 - Val Loss: 0.053154\n",
      "Epoch 43/50 - Train Loss: 0.030878 - Val Loss: 0.046957\n",
      "Epoch 44/50 - Train Loss: 0.034400 - Val Loss: 0.044777\n",
      "Epoch 45/50 - Train Loss: 0.035237 - Val Loss: 0.049594\n",
      "Epoch 46/50 - Train Loss: 0.030668 - Val Loss: 0.048311\n",
      "Epoch 47/50 - Train Loss: 0.034383 - Val Loss: 0.049068\n",
      "Epoch 48/50 - Train Loss: 0.031781 - Val Loss: 0.046011\n",
      "Epoch 49/50 - Train Loss: 0.029434 - Val Loss: 0.046903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:33:26,767] Trial 33 finished with value: 0.04355771839618683 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 103, 'lr': 0.0090372886706926, 'weight_decay': 4.750927366668741e-07, 'batch_size': 16}. Best is trial 32 with value: 0.04334702715277672.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.032777 - Val Loss: 0.046624\n",
      "Epoch 1/50 - Train Loss: 0.098987 - Val Loss: 0.139756\n",
      "Epoch 2/50 - Train Loss: 0.049671 - Val Loss: 0.061490\n",
      "Epoch 3/50 - Train Loss: 0.040372 - Val Loss: 0.104322\n",
      "Epoch 4/50 - Train Loss: 0.044071 - Val Loss: 0.065537\n",
      "Epoch 5/50 - Train Loss: 0.041659 - Val Loss: 0.062914\n",
      "Epoch 6/50 - Train Loss: 0.035338 - Val Loss: 0.058763\n",
      "Epoch 7/50 - Train Loss: 0.033880 - Val Loss: 0.053987\n",
      "Epoch 8/50 - Train Loss: 0.035002 - Val Loss: 0.050784\n",
      "Epoch 9/50 - Train Loss: 0.031705 - Val Loss: 0.062335\n",
      "Epoch 10/50 - Train Loss: 0.032661 - Val Loss: 0.054303\n",
      "Epoch 11/50 - Train Loss: 0.036067 - Val Loss: 0.061787\n",
      "Epoch 12/50 - Train Loss: 0.031210 - Val Loss: 0.045641\n",
      "Epoch 13/50 - Train Loss: 0.032200 - Val Loss: 0.047272\n",
      "Epoch 14/50 - Train Loss: 0.031229 - Val Loss: 0.048065\n",
      "Epoch 15/50 - Train Loss: 0.030936 - Val Loss: 0.045711\n",
      "Epoch 16/50 - Train Loss: 0.037653 - Val Loss: 0.044398\n",
      "Epoch 17/50 - Train Loss: 0.031179 - Val Loss: 0.061418\n",
      "Epoch 18/50 - Train Loss: 0.032525 - Val Loss: 0.056489\n",
      "Epoch 19/50 - Train Loss: 0.034195 - Val Loss: 0.044294\n",
      "Epoch 20/50 - Train Loss: 0.033505 - Val Loss: 0.054738\n",
      "Epoch 21/50 - Train Loss: 0.034775 - Val Loss: 0.053579\n",
      "Epoch 22/50 - Train Loss: 0.034298 - Val Loss: 0.044065\n",
      "Epoch 23/50 - Train Loss: 0.031868 - Val Loss: 0.048700\n",
      "Epoch 24/50 - Train Loss: 0.033334 - Val Loss: 0.044904\n",
      "Epoch 25/50 - Train Loss: 0.032546 - Val Loss: 0.045297\n",
      "Epoch 26/50 - Train Loss: 0.030008 - Val Loss: 0.043956\n",
      "Epoch 27/50 - Train Loss: 0.032214 - Val Loss: 0.046455\n",
      "Epoch 28/50 - Train Loss: 0.028796 - Val Loss: 0.048991\n",
      "Epoch 29/50 - Train Loss: 0.032835 - Val Loss: 0.044001\n",
      "Epoch 30/50 - Train Loss: 0.034548 - Val Loss: 0.047465\n",
      "Epoch 31/50 - Train Loss: 0.030652 - Val Loss: 0.044105\n",
      "Epoch 32/50 - Train Loss: 0.031414 - Val Loss: 0.045954\n",
      "Epoch 33/50 - Train Loss: 0.032470 - Val Loss: 0.047812\n",
      "Epoch 34/50 - Train Loss: 0.030018 - Val Loss: 0.044535\n",
      "Epoch 35/50 - Train Loss: 0.028118 - Val Loss: 0.046772\n",
      "Epoch 36/50 - Train Loss: 0.031119 - Val Loss: 0.045073\n",
      "Epoch 37/50 - Train Loss: 0.029920 - Val Loss: 0.043981\n",
      "Epoch 38/50 - Train Loss: 0.031589 - Val Loss: 0.043804\n",
      "Epoch 39/50 - Train Loss: 0.030938 - Val Loss: 0.043888\n",
      "Epoch 40/50 - Train Loss: 0.030739 - Val Loss: 0.045182\n",
      "Epoch 41/50 - Train Loss: 0.031602 - Val Loss: 0.045476\n",
      "Epoch 42/50 - Train Loss: 0.030068 - Val Loss: 0.047442\n",
      "Epoch 43/50 - Train Loss: 0.028056 - Val Loss: 0.044237\n",
      "Epoch 44/50 - Train Loss: 0.032453 - Val Loss: 0.049711\n",
      "Epoch 45/50 - Train Loss: 0.033017 - Val Loss: 0.047827\n",
      "Epoch 46/50 - Train Loss: 0.030739 - Val Loss: 0.048698\n",
      "Epoch 47/50 - Train Loss: 0.030442 - Val Loss: 0.051678\n",
      "Epoch 48/50 - Train Loss: 0.031124 - Val Loss: 0.045640\n",
      "Epoch 49/50 - Train Loss: 0.032302 - Val Loss: 0.043309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:33:46,982] Trial 34 finished with value: 0.04330885037779808 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 75, 'lr': 0.009299478229191074, 'weight_decay': 6.092267359045626e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.035503 - Val Loss: 0.045575\n",
      "Epoch 1/50 - Train Loss: 0.090420 - Val Loss: 0.064639\n",
      "Epoch 2/50 - Train Loss: 0.049217 - Val Loss: 0.094561\n",
      "Epoch 3/50 - Train Loss: 0.045405 - Val Loss: 0.088074\n",
      "Epoch 4/50 - Train Loss: 0.044399 - Val Loss: 0.078708\n",
      "Epoch 5/50 - Train Loss: 0.041162 - Val Loss: 0.082482\n",
      "Epoch 6/50 - Train Loss: 0.044565 - Val Loss: 0.078557\n",
      "Epoch 7/50 - Train Loss: 0.045835 - Val Loss: 0.083579\n",
      "Epoch 8/50 - Train Loss: 0.043606 - Val Loss: 0.076397\n",
      "Epoch 9/50 - Train Loss: 0.038463 - Val Loss: 0.067624\n",
      "Epoch 10/50 - Train Loss: 0.036985 - Val Loss: 0.055415\n",
      "Epoch 11/50 - Train Loss: 0.036478 - Val Loss: 0.055707\n",
      "Epoch 12/50 - Train Loss: 0.030736 - Val Loss: 0.052111\n",
      "Epoch 13/50 - Train Loss: 0.031384 - Val Loss: 0.049075\n",
      "Epoch 14/50 - Train Loss: 0.030847 - Val Loss: 0.049458\n",
      "Epoch 15/50 - Train Loss: 0.030801 - Val Loss: 0.051576\n",
      "Epoch 16/50 - Train Loss: 0.036872 - Val Loss: 0.048493\n",
      "Epoch 17/50 - Train Loss: 0.036150 - Val Loss: 0.046852\n",
      "Epoch 18/50 - Train Loss: 0.030513 - Val Loss: 0.065620\n",
      "Epoch 19/50 - Train Loss: 0.037279 - Val Loss: 0.048667\n",
      "Epoch 20/50 - Train Loss: 0.035274 - Val Loss: 0.050738\n",
      "Epoch 21/50 - Train Loss: 0.035552 - Val Loss: 0.056084\n",
      "Epoch 22/50 - Train Loss: 0.032517 - Val Loss: 0.045823\n",
      "Epoch 23/50 - Train Loss: 0.035797 - Val Loss: 0.051270\n",
      "Epoch 24/50 - Train Loss: 0.029547 - Val Loss: 0.048721\n",
      "Epoch 25/50 - Train Loss: 0.030709 - Val Loss: 0.045568\n",
      "Epoch 26/50 - Train Loss: 0.029843 - Val Loss: 0.052815\n",
      "Epoch 27/50 - Train Loss: 0.031726 - Val Loss: 0.044880\n",
      "Epoch 28/50 - Train Loss: 0.033129 - Val Loss: 0.049287\n",
      "Epoch 29/50 - Train Loss: 0.031952 - Val Loss: 0.047238\n",
      "Epoch 30/50 - Train Loss: 0.031219 - Val Loss: 0.048591\n",
      "Epoch 31/50 - Train Loss: 0.033576 - Val Loss: 0.046968\n",
      "Epoch 32/50 - Train Loss: 0.030517 - Val Loss: 0.048158\n",
      "Epoch 33/50 - Train Loss: 0.030293 - Val Loss: 0.050723\n",
      "Epoch 34/50 - Train Loss: 0.029649 - Val Loss: 0.045792\n",
      "Epoch 35/50 - Train Loss: 0.030119 - Val Loss: 0.049139\n",
      "Epoch 36/50 - Train Loss: 0.032662 - Val Loss: 0.046430\n",
      "Epoch 37/50 - Train Loss: 0.034848 - Val Loss: 0.046033\n",
      "Epoch 38/50 - Train Loss: 0.031524 - Val Loss: 0.046173\n",
      "Epoch 39/50 - Train Loss: 0.034611 - Val Loss: 0.047727\n",
      "Epoch 40/50 - Train Loss: 0.032781 - Val Loss: 0.045691\n",
      "Epoch 41/50 - Train Loss: 0.027573 - Val Loss: 0.044886\n",
      "Epoch 42/50 - Train Loss: 0.032847 - Val Loss: 0.046070\n",
      "Epoch 43/50 - Train Loss: 0.032527 - Val Loss: 0.047008\n",
      "Epoch 44/50 - Train Loss: 0.030074 - Val Loss: 0.045087\n",
      "Epoch 45/50 - Train Loss: 0.031970 - Val Loss: 0.044888\n",
      "Epoch 46/50 - Train Loss: 0.030703 - Val Loss: 0.048594\n",
      "Epoch 47/50 - Train Loss: 0.032087 - Val Loss: 0.044968\n",
      "Epoch 48/50 - Train Loss: 0.033718 - Val Loss: 0.044402\n",
      "Epoch 49/50 - Train Loss: 0.028199 - Val Loss: 0.047567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:34:06,024] Trial 35 finished with value: 0.04440160281956196 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 37, 'lr': 0.006388038540855613, 'weight_decay': 2.8099928799544804e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031040 - Val Loss: 0.044650\n",
      "Epoch 1/50 - Train Loss: 0.091992 - Val Loss: 0.110242\n",
      "Epoch 2/50 - Train Loss: 0.045495 - Val Loss: 0.088306\n",
      "Epoch 3/50 - Train Loss: 0.042974 - Val Loss: 0.068683\n",
      "Epoch 4/50 - Train Loss: 0.044520 - Val Loss: 0.059947\n",
      "Epoch 5/50 - Train Loss: 0.037322 - Val Loss: 0.072893\n",
      "Epoch 6/50 - Train Loss: 0.033062 - Val Loss: 0.051837\n",
      "Epoch 7/50 - Train Loss: 0.033407 - Val Loss: 0.046284\n",
      "Epoch 8/50 - Train Loss: 0.032762 - Val Loss: 0.047459\n",
      "Epoch 9/50 - Train Loss: 0.034040 - Val Loss: 0.045772\n",
      "Epoch 10/50 - Train Loss: 0.031922 - Val Loss: 0.049889\n",
      "Epoch 11/50 - Train Loss: 0.037483 - Val Loss: 0.044999\n",
      "Epoch 12/50 - Train Loss: 0.035593 - Val Loss: 0.049441\n",
      "Epoch 13/50 - Train Loss: 0.032164 - Val Loss: 0.044835\n",
      "Epoch 14/50 - Train Loss: 0.034764 - Val Loss: 0.046113\n",
      "Epoch 15/50 - Train Loss: 0.032737 - Val Loss: 0.049729\n",
      "Epoch 16/50 - Train Loss: 0.030868 - Val Loss: 0.053510\n",
      "Epoch 17/50 - Train Loss: 0.035065 - Val Loss: 0.052510\n",
      "Epoch 18/50 - Train Loss: 0.032672 - Val Loss: 0.045943\n",
      "Epoch 19/50 - Train Loss: 0.035382 - Val Loss: 0.048373\n",
      "Epoch 20/50 - Train Loss: 0.030120 - Val Loss: 0.053024\n",
      "Epoch 21/50 - Train Loss: 0.034314 - Val Loss: 0.046077\n",
      "Epoch 22/50 - Train Loss: 0.030552 - Val Loss: 0.044338\n",
      "Epoch 23/50 - Train Loss: 0.026836 - Val Loss: 0.047288\n",
      "Epoch 24/50 - Train Loss: 0.032492 - Val Loss: 0.047760\n",
      "Epoch 25/50 - Train Loss: 0.030815 - Val Loss: 0.045141\n",
      "Epoch 26/50 - Train Loss: 0.033127 - Val Loss: 0.044138\n",
      "Epoch 27/50 - Train Loss: 0.030251 - Val Loss: 0.044441\n",
      "Epoch 28/50 - Train Loss: 0.028141 - Val Loss: 0.045061\n",
      "Epoch 29/50 - Train Loss: 0.029577 - Val Loss: 0.045932\n",
      "Epoch 30/50 - Train Loss: 0.032631 - Val Loss: 0.045557\n",
      "Epoch 31/50 - Train Loss: 0.031571 - Val Loss: 0.044398\n",
      "Epoch 32/50 - Train Loss: 0.029193 - Val Loss: 0.044348\n",
      "Epoch 33/50 - Train Loss: 0.032077 - Val Loss: 0.048680\n",
      "Epoch 34/50 - Train Loss: 0.036472 - Val Loss: 0.044104\n",
      "Epoch 35/50 - Train Loss: 0.029085 - Val Loss: 0.044914\n",
      "Epoch 36/50 - Train Loss: 0.029898 - Val Loss: 0.044116\n",
      "Epoch 37/50 - Train Loss: 0.029934 - Val Loss: 0.044803\n",
      "Epoch 38/50 - Train Loss: 0.028868 - Val Loss: 0.048833\n",
      "Epoch 39/50 - Train Loss: 0.029573 - Val Loss: 0.045434\n",
      "Epoch 40/50 - Train Loss: 0.031678 - Val Loss: 0.045248\n",
      "Epoch 41/50 - Train Loss: 0.030981 - Val Loss: 0.048938\n",
      "Epoch 42/50 - Train Loss: 0.031413 - Val Loss: 0.044558\n",
      "Epoch 43/50 - Train Loss: 0.031797 - Val Loss: 0.045624\n",
      "Epoch 44/50 - Train Loss: 0.029442 - Val Loss: 0.046039\n",
      "Epoch 45/50 - Train Loss: 0.030479 - Val Loss: 0.046500\n",
      "Epoch 46/50 - Train Loss: 0.028185 - Val Loss: 0.044221\n",
      "Epoch 47/50 - Train Loss: 0.032850 - Val Loss: 0.046616\n",
      "Epoch 48/50 - Train Loss: 0.030244 - Val Loss: 0.044307\n",
      "Epoch 49/50 - Train Loss: 0.030624 - Val Loss: 0.048227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:34:28,527] Trial 36 finished with value: 0.04405376315116882 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 79, 'lr': 0.009627716427990403, 'weight_decay': 7.53329947997509e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.032681 - Val Loss: 0.044054\n",
      "Epoch 1/50 - Train Loss: 0.074578 - Val Loss: 0.077360\n",
      "Epoch 2/50 - Train Loss: 0.046315 - Val Loss: 0.083768\n",
      "Epoch 3/50 - Train Loss: 0.046929 - Val Loss: 0.081356\n",
      "Epoch 4/50 - Train Loss: 0.041747 - Val Loss: 0.069416\n",
      "Epoch 5/50 - Train Loss: 0.039504 - Val Loss: 0.059471\n",
      "Epoch 6/50 - Train Loss: 0.038040 - Val Loss: 0.059244\n",
      "Epoch 7/50 - Train Loss: 0.034737 - Val Loss: 0.065301\n",
      "Epoch 8/50 - Train Loss: 0.033157 - Val Loss: 0.049962\n",
      "Epoch 9/50 - Train Loss: 0.031547 - Val Loss: 0.045072\n",
      "Epoch 10/50 - Train Loss: 0.029310 - Val Loss: 0.045007\n",
      "Epoch 11/50 - Train Loss: 0.034208 - Val Loss: 0.045252\n",
      "Epoch 12/50 - Train Loss: 0.036394 - Val Loss: 0.047138\n",
      "Epoch 13/50 - Train Loss: 0.033590 - Val Loss: 0.044455\n",
      "Epoch 14/50 - Train Loss: 0.031647 - Val Loss: 0.048304\n",
      "Epoch 15/50 - Train Loss: 0.034072 - Val Loss: 0.050332\n",
      "Epoch 16/50 - Train Loss: 0.029625 - Val Loss: 0.046722\n",
      "Epoch 17/50 - Train Loss: 0.033253 - Val Loss: 0.044223\n",
      "Epoch 18/50 - Train Loss: 0.030381 - Val Loss: 0.044459\n",
      "Epoch 19/50 - Train Loss: 0.034396 - Val Loss: 0.044471\n",
      "Epoch 20/50 - Train Loss: 0.029955 - Val Loss: 0.046968\n",
      "Epoch 21/50 - Train Loss: 0.031773 - Val Loss: 0.052111\n",
      "Epoch 22/50 - Train Loss: 0.030880 - Val Loss: 0.049384\n",
      "Epoch 23/50 - Train Loss: 0.030413 - Val Loss: 0.044931\n",
      "Epoch 24/50 - Train Loss: 0.029558 - Val Loss: 0.046286\n",
      "Epoch 25/50 - Train Loss: 0.032792 - Val Loss: 0.044161\n",
      "Epoch 26/50 - Train Loss: 0.033427 - Val Loss: 0.044572\n",
      "Epoch 27/50 - Train Loss: 0.029639 - Val Loss: 0.047409\n",
      "Epoch 28/50 - Train Loss: 0.032088 - Val Loss: 0.049053\n",
      "Epoch 29/50 - Train Loss: 0.025643 - Val Loss: 0.054013\n",
      "Epoch 30/50 - Train Loss: 0.035205 - Val Loss: 0.048508\n",
      "Epoch 31/50 - Train Loss: 0.033115 - Val Loss: 0.044608\n",
      "Epoch 32/50 - Train Loss: 0.031078 - Val Loss: 0.051453\n",
      "Epoch 33/50 - Train Loss: 0.029967 - Val Loss: 0.044848\n",
      "Epoch 34/50 - Train Loss: 0.032310 - Val Loss: 0.044753\n",
      "Epoch 35/50 - Train Loss: 0.033936 - Val Loss: 0.046361\n",
      "Epoch 36/50 - Train Loss: 0.032194 - Val Loss: 0.044538\n",
      "Epoch 37/50 - Train Loss: 0.031913 - Val Loss: 0.044387\n",
      "Epoch 38/50 - Train Loss: 0.031333 - Val Loss: 0.049919\n",
      "Epoch 39/50 - Train Loss: 0.027510 - Val Loss: 0.044574\n",
      "Epoch 40/50 - Train Loss: 0.031204 - Val Loss: 0.043699\n",
      "Epoch 41/50 - Train Loss: 0.029416 - Val Loss: 0.044805\n",
      "Epoch 42/50 - Train Loss: 0.031862 - Val Loss: 0.045893\n",
      "Epoch 43/50 - Train Loss: 0.027293 - Val Loss: 0.045398\n",
      "Epoch 44/50 - Train Loss: 0.028649 - Val Loss: 0.045252\n",
      "Epoch 45/50 - Train Loss: 0.030943 - Val Loss: 0.050017\n",
      "Epoch 46/50 - Train Loss: 0.030048 - Val Loss: 0.045372\n",
      "Epoch 47/50 - Train Loss: 0.032237 - Val Loss: 0.044422\n",
      "Epoch 48/50 - Train Loss: 0.032156 - Val Loss: 0.047525\n",
      "Epoch 49/50 - Train Loss: 0.030946 - Val Loss: 0.050861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:34:50,820] Trial 37 finished with value: 0.04369943216443062 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 77, 'lr': 0.004542953934640567, 'weight_decay': 3.490310492197638e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031007 - Val Loss: 0.047251\n",
      "Epoch 1/50 - Train Loss: 0.292702 - Val Loss: 0.523329\n",
      "Epoch 2/50 - Train Loss: 0.292698 - Val Loss: 0.517825\n",
      "Epoch 3/50 - Train Loss: 0.314501 - Val Loss: 0.512275\n",
      "Epoch 4/50 - Train Loss: 0.299359 - Val Loss: 0.506677\n",
      "Epoch 5/50 - Train Loss: 0.274536 - Val Loss: 0.501035\n",
      "Epoch 6/50 - Train Loss: 0.309059 - Val Loss: 0.495466\n",
      "Epoch 7/50 - Train Loss: 0.293279 - Val Loss: 0.489697\n",
      "Epoch 8/50 - Train Loss: 0.237424 - Val Loss: 0.484083\n",
      "Epoch 9/50 - Train Loss: 0.284957 - Val Loss: 0.478430\n",
      "Epoch 10/50 - Train Loss: 0.278761 - Val Loss: 0.472565\n",
      "Epoch 11/50 - Train Loss: 0.265109 - Val Loss: 0.466621\n",
      "Epoch 12/50 - Train Loss: 0.239367 - Val Loss: 0.460631\n",
      "Epoch 13/50 - Train Loss: 0.239906 - Val Loss: 0.454699\n",
      "Epoch 14/50 - Train Loss: 0.264257 - Val Loss: 0.448613\n",
      "Epoch 15/50 - Train Loss: 0.260747 - Val Loss: 0.442094\n",
      "Epoch 16/50 - Train Loss: 0.207217 - Val Loss: 0.435478\n",
      "Epoch 17/50 - Train Loss: 0.232970 - Val Loss: 0.428783\n",
      "Epoch 18/50 - Train Loss: 0.246471 - Val Loss: 0.421883\n",
      "Epoch 19/50 - Train Loss: 0.226633 - Val Loss: 0.414698\n",
      "Epoch 20/50 - Train Loss: 0.236089 - Val Loss: 0.407493\n",
      "Epoch 21/50 - Train Loss: 0.221333 - Val Loss: 0.400276\n",
      "Epoch 22/50 - Train Loss: 0.210120 - Val Loss: 0.393259\n",
      "Epoch 23/50 - Train Loss: 0.207554 - Val Loss: 0.385926\n",
      "Epoch 24/50 - Train Loss: 0.211030 - Val Loss: 0.378389\n",
      "Epoch 25/50 - Train Loss: 0.211656 - Val Loss: 0.370644\n",
      "Epoch 26/50 - Train Loss: 0.194301 - Val Loss: 0.362779\n",
      "Epoch 27/50 - Train Loss: 0.208143 - Val Loss: 0.354847\n",
      "Epoch 28/50 - Train Loss: 0.198645 - Val Loss: 0.346719\n",
      "Epoch 29/50 - Train Loss: 0.191984 - Val Loss: 0.338378\n",
      "Epoch 30/50 - Train Loss: 0.170658 - Val Loss: 0.330034\n",
      "Epoch 31/50 - Train Loss: 0.162708 - Val Loss: 0.321685\n",
      "Epoch 32/50 - Train Loss: 0.162066 - Val Loss: 0.313120\n",
      "Epoch 33/50 - Train Loss: 0.149910 - Val Loss: 0.304651\n",
      "Epoch 34/50 - Train Loss: 0.167249 - Val Loss: 0.296093\n",
      "Epoch 35/50 - Train Loss: 0.145974 - Val Loss: 0.287394\n",
      "Epoch 36/50 - Train Loss: 0.126732 - Val Loss: 0.278930\n",
      "Epoch 37/50 - Train Loss: 0.128720 - Val Loss: 0.270433\n",
      "Epoch 38/50 - Train Loss: 0.115940 - Val Loss: 0.262109\n",
      "Epoch 39/50 - Train Loss: 0.125282 - Val Loss: 0.253740\n",
      "Epoch 40/50 - Train Loss: 0.130542 - Val Loss: 0.245233\n",
      "Epoch 41/50 - Train Loss: 0.109876 - Val Loss: 0.236720\n",
      "Epoch 42/50 - Train Loss: 0.105524 - Val Loss: 0.227941\n",
      "Epoch 43/50 - Train Loss: 0.100849 - Val Loss: 0.218932\n",
      "Epoch 44/50 - Train Loss: 0.099974 - Val Loss: 0.209975\n",
      "Epoch 45/50 - Train Loss: 0.096438 - Val Loss: 0.201045\n",
      "Epoch 46/50 - Train Loss: 0.083623 - Val Loss: 0.192057\n",
      "Epoch 47/50 - Train Loss: 0.082518 - Val Loss: 0.183332\n",
      "Epoch 48/50 - Train Loss: 0.067612 - Val Loss: 0.175087\n",
      "Epoch 49/50 - Train Loss: 0.068973 - Val Loss: 0.167308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:35:09,833] Trial 38 finished with value: 0.1599903106689453 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 114, 'lr': 3.248037939570157e-05, 'weight_decay': 7.978971749537958e-08, 'batch_size': 32}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.061801 - Val Loss: 0.159990\n",
      "Epoch 1/50 - Train Loss: 0.121505 - Val Loss: 0.233848\n",
      "Epoch 2/50 - Train Loss: 0.095372 - Val Loss: 0.215369\n",
      "Epoch 3/50 - Train Loss: 0.084119 - Val Loss: 0.197411\n",
      "Epoch 4/50 - Train Loss: 0.085171 - Val Loss: 0.179207\n",
      "Epoch 5/50 - Train Loss: 0.069981 - Val Loss: 0.160730\n",
      "Epoch 6/50 - Train Loss: 0.067658 - Val Loss: 0.140746\n",
      "Epoch 7/50 - Train Loss: 0.053122 - Val Loss: 0.120497\n",
      "Epoch 8/50 - Train Loss: 0.047218 - Val Loss: 0.100937\n",
      "Epoch 9/50 - Train Loss: 0.044159 - Val Loss: 0.085858\n",
      "Epoch 10/50 - Train Loss: 0.044665 - Val Loss: 0.077541\n",
      "Epoch 11/50 - Train Loss: 0.042978 - Val Loss: 0.077278\n",
      "Epoch 12/50 - Train Loss: 0.045638 - Val Loss: 0.084170\n",
      "Epoch 13/50 - Train Loss: 0.041175 - Val Loss: 0.084816\n",
      "Epoch 14/50 - Train Loss: 0.043832 - Val Loss: 0.084110\n",
      "Epoch 15/50 - Train Loss: 0.042624 - Val Loss: 0.082151\n",
      "Epoch 16/50 - Train Loss: 0.039438 - Val Loss: 0.079893\n",
      "Epoch 17/50 - Train Loss: 0.041558 - Val Loss: 0.078684\n",
      "Epoch 18/50 - Train Loss: 0.041882 - Val Loss: 0.077584\n",
      "Epoch 19/50 - Train Loss: 0.041679 - Val Loss: 0.076415\n",
      "Epoch 20/50 - Train Loss: 0.039503 - Val Loss: 0.077071\n",
      "Epoch 21/50 - Train Loss: 0.040404 - Val Loss: 0.076452\n",
      "Epoch 22/50 - Train Loss: 0.040937 - Val Loss: 0.072697\n",
      "Epoch 23/50 - Train Loss: 0.041779 - Val Loss: 0.070884\n",
      "Epoch 24/50 - Train Loss: 0.038199 - Val Loss: 0.069360\n",
      "Epoch 25/50 - Train Loss: 0.038560 - Val Loss: 0.067176\n",
      "Epoch 26/50 - Train Loss: 0.032629 - Val Loss: 0.063739\n",
      "Epoch 27/50 - Train Loss: 0.034611 - Val Loss: 0.062759\n",
      "Epoch 28/50 - Train Loss: 0.031042 - Val Loss: 0.057769\n",
      "Epoch 29/50 - Train Loss: 0.031898 - Val Loss: 0.058656\n",
      "Epoch 30/50 - Train Loss: 0.033981 - Val Loss: 0.055428\n",
      "Epoch 31/50 - Train Loss: 0.033346 - Val Loss: 0.052966\n",
      "Epoch 32/50 - Train Loss: 0.033058 - Val Loss: 0.055457\n",
      "Epoch 33/50 - Train Loss: 0.033358 - Val Loss: 0.054644\n",
      "Epoch 34/50 - Train Loss: 0.035195 - Val Loss: 0.050213\n",
      "Epoch 35/50 - Train Loss: 0.033646 - Val Loss: 0.053390\n",
      "Epoch 36/50 - Train Loss: 0.032041 - Val Loss: 0.050899\n",
      "Epoch 37/50 - Train Loss: 0.034336 - Val Loss: 0.053145\n",
      "Epoch 38/50 - Train Loss: 0.033678 - Val Loss: 0.050114\n",
      "Epoch 39/50 - Train Loss: 0.034033 - Val Loss: 0.050269\n",
      "Epoch 40/50 - Train Loss: 0.031776 - Val Loss: 0.051590\n",
      "Epoch 41/50 - Train Loss: 0.030410 - Val Loss: 0.049440\n",
      "Epoch 42/50 - Train Loss: 0.029027 - Val Loss: 0.047814\n",
      "Epoch 43/50 - Train Loss: 0.032670 - Val Loss: 0.051773\n",
      "Epoch 44/50 - Train Loss: 0.034685 - Val Loss: 0.048199\n",
      "Epoch 45/50 - Train Loss: 0.030924 - Val Loss: 0.049006\n",
      "Epoch 46/50 - Train Loss: 0.032371 - Val Loss: 0.049680\n",
      "Epoch 47/50 - Train Loss: 0.034062 - Val Loss: 0.050570\n",
      "Epoch 48/50 - Train Loss: 0.030466 - Val Loss: 0.049056\n",
      "Epoch 49/50 - Train Loss: 0.033387 - Val Loss: 0.049086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:35:39,118] Trial 39 finished with value: 0.04781435430049896 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 91, 'lr': 0.0001618943843751213, 'weight_decay': 3.371199076736397e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.027975 - Val Loss: 0.048787\n",
      "Epoch 1/50 - Train Loss: 0.052349 - Val Loss: 0.069768\n",
      "Epoch 2/50 - Train Loss: 0.038767 - Val Loss: 0.049707\n",
      "Epoch 3/50 - Train Loss: 0.035802 - Val Loss: 0.055027\n",
      "Epoch 4/50 - Train Loss: 0.035389 - Val Loss: 0.055310\n",
      "Epoch 5/50 - Train Loss: 0.031893 - Val Loss: 0.049377\n",
      "Epoch 6/50 - Train Loss: 0.037123 - Val Loss: 0.048418\n",
      "Epoch 7/50 - Train Loss: 0.031702 - Val Loss: 0.050315\n",
      "Epoch 8/50 - Train Loss: 0.033371 - Val Loss: 0.045505\n",
      "Epoch 9/50 - Train Loss: 0.035001 - Val Loss: 0.044848\n",
      "Epoch 10/50 - Train Loss: 0.033762 - Val Loss: 0.051700\n",
      "Epoch 11/50 - Train Loss: 0.035190 - Val Loss: 0.049255\n",
      "Epoch 12/50 - Train Loss: 0.031286 - Val Loss: 0.047404\n",
      "Epoch 13/50 - Train Loss: 0.032174 - Val Loss: 0.047265\n",
      "Epoch 14/50 - Train Loss: 0.031538 - Val Loss: 0.051206\n",
      "Epoch 15/50 - Train Loss: 0.029849 - Val Loss: 0.045900\n",
      "Epoch 16/50 - Train Loss: 0.029589 - Val Loss: 0.044476\n",
      "Epoch 17/50 - Train Loss: 0.035201 - Val Loss: 0.046274\n",
      "Epoch 18/50 - Train Loss: 0.029556 - Val Loss: 0.048545\n",
      "Epoch 19/50 - Train Loss: 0.029989 - Val Loss: 0.045651\n",
      "Epoch 20/50 - Train Loss: 0.032621 - Val Loss: 0.044727\n",
      "Epoch 21/50 - Train Loss: 0.032493 - Val Loss: 0.045569\n",
      "Epoch 22/50 - Train Loss: 0.032325 - Val Loss: 0.045677\n",
      "Epoch 23/50 - Train Loss: 0.028217 - Val Loss: 0.044315\n",
      "Epoch 24/50 - Train Loss: 0.030241 - Val Loss: 0.044474\n",
      "Epoch 25/50 - Train Loss: 0.030320 - Val Loss: 0.046372\n",
      "Epoch 26/50 - Train Loss: 0.030769 - Val Loss: 0.048907\n",
      "Epoch 27/50 - Train Loss: 0.032166 - Val Loss: 0.047391\n",
      "Epoch 28/50 - Train Loss: 0.029085 - Val Loss: 0.045980\n",
      "Epoch 29/50 - Train Loss: 0.034968 - Val Loss: 0.050552\n",
      "Epoch 30/50 - Train Loss: 0.031590 - Val Loss: 0.044552\n",
      "Epoch 31/50 - Train Loss: 0.029531 - Val Loss: 0.045390\n",
      "Epoch 32/50 - Train Loss: 0.030980 - Val Loss: 0.044117\n",
      "Epoch 33/50 - Train Loss: 0.031982 - Val Loss: 0.044161\n",
      "Epoch 34/50 - Train Loss: 0.030245 - Val Loss: 0.045303\n",
      "Epoch 35/50 - Train Loss: 0.031444 - Val Loss: 0.044405\n",
      "Epoch 36/50 - Train Loss: 0.031643 - Val Loss: 0.051915\n",
      "Epoch 37/50 - Train Loss: 0.030185 - Val Loss: 0.048080\n",
      "Epoch 38/50 - Train Loss: 0.031561 - Val Loss: 0.044422\n",
      "Epoch 39/50 - Train Loss: 0.028719 - Val Loss: 0.043948\n",
      "Epoch 40/50 - Train Loss: 0.030349 - Val Loss: 0.044788\n",
      "Epoch 41/50 - Train Loss: 0.035358 - Val Loss: 0.045851\n",
      "Epoch 42/50 - Train Loss: 0.033777 - Val Loss: 0.052236\n",
      "Epoch 43/50 - Train Loss: 0.031347 - Val Loss: 0.047343\n",
      "Epoch 44/50 - Train Loss: 0.032951 - Val Loss: 0.044882\n",
      "Epoch 45/50 - Train Loss: 0.030492 - Val Loss: 0.045159\n",
      "Epoch 46/50 - Train Loss: 0.030887 - Val Loss: 0.054589\n",
      "Epoch 47/50 - Train Loss: 0.034385 - Val Loss: 0.045198\n",
      "Epoch 48/50 - Train Loss: 0.029492 - Val Loss: 0.044376\n",
      "Epoch 49/50 - Train Loss: 0.032258 - Val Loss: 0.045671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:35:56,980] Trial 40 finished with value: 0.04394753836095333 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 68, 'lr': 0.0067212589545273885, 'weight_decay': 1.880004646057603e-05, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031585 - Val Loss: 0.054477\n",
      "Epoch 1/50 - Train Loss: 0.311966 - Val Loss: 0.531729\n",
      "Epoch 2/50 - Train Loss: 0.310328 - Val Loss: 0.529040\n",
      "Epoch 3/50 - Train Loss: 0.300320 - Val Loss: 0.526400\n",
      "Epoch 4/50 - Train Loss: 0.287241 - Val Loss: 0.523863\n",
      "Epoch 5/50 - Train Loss: 0.296402 - Val Loss: 0.521368\n",
      "Epoch 6/50 - Train Loss: 0.288042 - Val Loss: 0.518919\n",
      "Epoch 7/50 - Train Loss: 0.285027 - Val Loss: 0.516496\n",
      "Epoch 8/50 - Train Loss: 0.272914 - Val Loss: 0.514151\n",
      "Epoch 9/50 - Train Loss: 0.275295 - Val Loss: 0.511825\n",
      "Epoch 10/50 - Train Loss: 0.294423 - Val Loss: 0.509469\n",
      "Epoch 11/50 - Train Loss: 0.271772 - Val Loss: 0.507161\n",
      "Epoch 12/50 - Train Loss: 0.276384 - Val Loss: 0.504959\n",
      "Epoch 13/50 - Train Loss: 0.281698 - Val Loss: 0.502684\n",
      "Epoch 14/50 - Train Loss: 0.288371 - Val Loss: 0.500377\n",
      "Epoch 15/50 - Train Loss: 0.283300 - Val Loss: 0.498022\n",
      "Epoch 16/50 - Train Loss: 0.280245 - Val Loss: 0.495634\n",
      "Epoch 17/50 - Train Loss: 0.261380 - Val Loss: 0.493137\n",
      "Epoch 18/50 - Train Loss: 0.262979 - Val Loss: 0.490609\n",
      "Epoch 19/50 - Train Loss: 0.259977 - Val Loss: 0.488114\n",
      "Epoch 20/50 - Train Loss: 0.257965 - Val Loss: 0.485688\n",
      "Epoch 21/50 - Train Loss: 0.267943 - Val Loss: 0.483167\n",
      "Epoch 22/50 - Train Loss: 0.230504 - Val Loss: 0.480768\n",
      "Epoch 23/50 - Train Loss: 0.259544 - Val Loss: 0.478390\n",
      "Epoch 24/50 - Train Loss: 0.259705 - Val Loss: 0.475923\n",
      "Epoch 25/50 - Train Loss: 0.266192 - Val Loss: 0.473395\n",
      "Epoch 26/50 - Train Loss: 0.253157 - Val Loss: 0.470808\n",
      "Epoch 27/50 - Train Loss: 0.257496 - Val Loss: 0.468156\n",
      "Epoch 28/50 - Train Loss: 0.257761 - Val Loss: 0.465557\n",
      "Epoch 29/50 - Train Loss: 0.252532 - Val Loss: 0.462874\n",
      "Epoch 30/50 - Train Loss: 0.241950 - Val Loss: 0.460204\n",
      "Epoch 31/50 - Train Loss: 0.245772 - Val Loss: 0.457531\n",
      "Epoch 32/50 - Train Loss: 0.258274 - Val Loss: 0.454884\n",
      "Epoch 33/50 - Train Loss: 0.237017 - Val Loss: 0.452137\n",
      "Epoch 34/50 - Train Loss: 0.242195 - Val Loss: 0.449418\n",
      "Epoch 35/50 - Train Loss: 0.249727 - Val Loss: 0.446662\n",
      "Epoch 36/50 - Train Loss: 0.235992 - Val Loss: 0.443824\n",
      "Epoch 37/50 - Train Loss: 0.238490 - Val Loss: 0.441033\n",
      "Epoch 38/50 - Train Loss: 0.231104 - Val Loss: 0.438252\n",
      "Epoch 39/50 - Train Loss: 0.215086 - Val Loss: 0.435580\n",
      "Epoch 40/50 - Train Loss: 0.211943 - Val Loss: 0.432810\n",
      "Epoch 41/50 - Train Loss: 0.210904 - Val Loss: 0.430176\n",
      "Epoch 42/50 - Train Loss: 0.229559 - Val Loss: 0.427507\n",
      "Epoch 43/50 - Train Loss: 0.225753 - Val Loss: 0.424634\n",
      "Epoch 44/50 - Train Loss: 0.214582 - Val Loss: 0.421665\n",
      "Epoch 45/50 - Train Loss: 0.224814 - Val Loss: 0.418549\n",
      "Epoch 46/50 - Train Loss: 0.230942 - Val Loss: 0.415413\n",
      "Epoch 47/50 - Train Loss: 0.207784 - Val Loss: 0.412135\n",
      "Epoch 48/50 - Train Loss: 0.212319 - Val Loss: 0.408866\n",
      "Epoch 49/50 - Train Loss: 0.220944 - Val Loss: 0.405503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:36:22,181] Trial 41 finished with value: 0.4020140469074249 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 104, 'lr': 1.0321414824939442e-05, 'weight_decay': 7.040584929258397e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.215369 - Val Loss: 0.402014\n",
      "Epoch 1/50 - Train Loss: 0.078408 - Val Loss: 0.122953\n",
      "Epoch 2/50 - Train Loss: 0.043836 - Val Loss: 0.074649\n",
      "Epoch 3/50 - Train Loss: 0.040089 - Val Loss: 0.055922\n",
      "Epoch 4/50 - Train Loss: 0.035015 - Val Loss: 0.049108\n",
      "Epoch 5/50 - Train Loss: 0.040087 - Val Loss: 0.067547\n",
      "Epoch 6/50 - Train Loss: 0.038095 - Val Loss: 0.066912\n",
      "Epoch 7/50 - Train Loss: 0.032150 - Val Loss: 0.046988\n",
      "Epoch 8/50 - Train Loss: 0.035244 - Val Loss: 0.052436\n",
      "Epoch 9/50 - Train Loss: 0.033401 - Val Loss: 0.048571\n",
      "Epoch 10/50 - Train Loss: 0.031167 - Val Loss: 0.045367\n",
      "Epoch 11/50 - Train Loss: 0.031951 - Val Loss: 0.047945\n",
      "Epoch 12/50 - Train Loss: 0.034877 - Val Loss: 0.055058\n",
      "Epoch 13/50 - Train Loss: 0.031046 - Val Loss: 0.044576\n",
      "Epoch 14/50 - Train Loss: 0.027876 - Val Loss: 0.044133\n",
      "Epoch 15/50 - Train Loss: 0.030069 - Val Loss: 0.065850\n",
      "Epoch 16/50 - Train Loss: 0.035766 - Val Loss: 0.047162\n",
      "Epoch 17/50 - Train Loss: 0.031119 - Val Loss: 0.044017\n",
      "Epoch 18/50 - Train Loss: 0.030075 - Val Loss: 0.044424\n",
      "Epoch 19/50 - Train Loss: 0.031624 - Val Loss: 0.046782\n",
      "Epoch 20/50 - Train Loss: 0.027986 - Val Loss: 0.047135\n",
      "Epoch 21/50 - Train Loss: 0.034370 - Val Loss: 0.050193\n",
      "Epoch 22/50 - Train Loss: 0.033047 - Val Loss: 0.047106\n",
      "Epoch 23/50 - Train Loss: 0.030823 - Val Loss: 0.045243\n",
      "Epoch 24/50 - Train Loss: 0.029712 - Val Loss: 0.048368\n",
      "Epoch 25/50 - Train Loss: 0.031171 - Val Loss: 0.046236\n",
      "Epoch 26/50 - Train Loss: 0.032985 - Val Loss: 0.045299\n",
      "Epoch 27/50 - Train Loss: 0.028495 - Val Loss: 0.049105\n",
      "Epoch 28/50 - Train Loss: 0.030288 - Val Loss: 0.050190\n",
      "Epoch 29/50 - Train Loss: 0.030453 - Val Loss: 0.050959\n",
      "Epoch 30/50 - Train Loss: 0.032386 - Val Loss: 0.045989\n",
      "Epoch 31/50 - Train Loss: 0.032592 - Val Loss: 0.044093\n",
      "Epoch 32/50 - Train Loss: 0.029019 - Val Loss: 0.044126\n",
      "Epoch 33/50 - Train Loss: 0.031346 - Val Loss: 0.044337\n",
      "Epoch 34/50 - Train Loss: 0.030428 - Val Loss: 0.044015\n",
      "Epoch 35/50 - Train Loss: 0.027088 - Val Loss: 0.049528\n",
      "Epoch 36/50 - Train Loss: 0.028199 - Val Loss: 0.049278\n",
      "Epoch 37/50 - Train Loss: 0.029795 - Val Loss: 0.047376\n",
      "Epoch 38/50 - Train Loss: 0.030312 - Val Loss: 0.045334\n",
      "Epoch 39/50 - Train Loss: 0.033869 - Val Loss: 0.049393\n",
      "Epoch 40/50 - Train Loss: 0.028825 - Val Loss: 0.044213\n",
      "Epoch 41/50 - Train Loss: 0.032710 - Val Loss: 0.047457\n",
      "Epoch 42/50 - Train Loss: 0.035631 - Val Loss: 0.046118\n",
      "Epoch 43/50 - Train Loss: 0.036711 - Val Loss: 0.048669\n",
      "Epoch 44/50 - Train Loss: 0.032458 - Val Loss: 0.057688\n",
      "Epoch 45/50 - Train Loss: 0.031586 - Val Loss: 0.044656\n",
      "Epoch 46/50 - Train Loss: 0.032225 - Val Loss: 0.046461\n",
      "Epoch 47/50 - Train Loss: 0.031484 - Val Loss: 0.060028\n",
      "Epoch 48/50 - Train Loss: 0.031301 - Val Loss: 0.044668\n",
      "Epoch 49/50 - Train Loss: 0.032951 - Val Loss: 0.043882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:36:45,034] Trial 42 finished with value: 0.04388168640434742 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 93, 'lr': 0.007364041195909641, 'weight_decay': 4.810171889147662e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033835 - Val Loss: 0.045797\n",
      "Epoch 1/50 - Train Loss: 0.094130 - Val Loss: 0.061641\n",
      "Epoch 2/50 - Train Loss: 0.056850 - Val Loss: 0.109599\n",
      "Epoch 3/50 - Train Loss: 0.047204 - Val Loss: 0.079271\n",
      "Epoch 4/50 - Train Loss: 0.045662 - Val Loss: 0.073667\n",
      "Epoch 5/50 - Train Loss: 0.042712 - Val Loss: 0.070232\n",
      "Epoch 6/50 - Train Loss: 0.038736 - Val Loss: 0.060480\n",
      "Epoch 7/50 - Train Loss: 0.031650 - Val Loss: 0.061920\n",
      "Epoch 8/50 - Train Loss: 0.033050 - Val Loss: 0.049918\n",
      "Epoch 9/50 - Train Loss: 0.035888 - Val Loss: 0.047909\n",
      "Epoch 10/50 - Train Loss: 0.032213 - Val Loss: 0.048604\n",
      "Epoch 11/50 - Train Loss: 0.032455 - Val Loss: 0.055954\n",
      "Epoch 12/50 - Train Loss: 0.032316 - Val Loss: 0.048765\n",
      "Epoch 13/50 - Train Loss: 0.033853 - Val Loss: 0.045470\n",
      "Epoch 14/50 - Train Loss: 0.033896 - Val Loss: 0.048817\n",
      "Epoch 15/50 - Train Loss: 0.030023 - Val Loss: 0.051068\n",
      "Epoch 16/50 - Train Loss: 0.031905 - Val Loss: 0.048291\n",
      "Epoch 17/50 - Train Loss: 0.031174 - Val Loss: 0.045785\n",
      "Epoch 18/50 - Train Loss: 0.032736 - Val Loss: 0.051070\n",
      "Epoch 19/50 - Train Loss: 0.031410 - Val Loss: 0.048666\n",
      "Epoch 20/50 - Train Loss: 0.031970 - Val Loss: 0.046606\n",
      "Epoch 21/50 - Train Loss: 0.032994 - Val Loss: 0.044860\n",
      "Epoch 22/50 - Train Loss: 0.029032 - Val Loss: 0.045845\n",
      "Epoch 23/50 - Train Loss: 0.031924 - Val Loss: 0.047598\n",
      "Epoch 24/50 - Train Loss: 0.032986 - Val Loss: 0.048267\n",
      "Epoch 25/50 - Train Loss: 0.029804 - Val Loss: 0.047702\n",
      "Epoch 26/50 - Train Loss: 0.031731 - Val Loss: 0.044423\n",
      "Epoch 27/50 - Train Loss: 0.033593 - Val Loss: 0.046992\n",
      "Epoch 28/50 - Train Loss: 0.032341 - Val Loss: 0.047594\n",
      "Epoch 29/50 - Train Loss: 0.031911 - Val Loss: 0.045989\n",
      "Epoch 30/50 - Train Loss: 0.029899 - Val Loss: 0.045180\n",
      "Epoch 31/50 - Train Loss: 0.032473 - Val Loss: 0.045116\n",
      "Epoch 32/50 - Train Loss: 0.030273 - Val Loss: 0.051090\n",
      "Epoch 33/50 - Train Loss: 0.030145 - Val Loss: 0.051000\n",
      "Epoch 34/50 - Train Loss: 0.032904 - Val Loss: 0.045229\n",
      "Epoch 35/50 - Train Loss: 0.032170 - Val Loss: 0.044639\n",
      "Epoch 36/50 - Train Loss: 0.031389 - Val Loss: 0.045359\n",
      "Epoch 37/50 - Train Loss: 0.030539 - Val Loss: 0.054698\n",
      "Epoch 38/50 - Train Loss: 0.031901 - Val Loss: 0.046247\n",
      "Epoch 39/50 - Train Loss: 0.030220 - Val Loss: 0.047349\n",
      "Epoch 40/50 - Train Loss: 0.028157 - Val Loss: 0.047061\n",
      "Epoch 41/50 - Train Loss: 0.031912 - Val Loss: 0.047805\n",
      "Epoch 42/50 - Train Loss: 0.029420 - Val Loss: 0.044886\n",
      "Epoch 43/50 - Train Loss: 0.031854 - Val Loss: 0.044867\n",
      "Epoch 44/50 - Train Loss: 0.031096 - Val Loss: 0.045385\n",
      "Epoch 45/50 - Train Loss: 0.029893 - Val Loss: 0.044795\n",
      "Epoch 46/50 - Train Loss: 0.029770 - Val Loss: 0.044906\n",
      "Epoch 47/50 - Train Loss: 0.030816 - Val Loss: 0.048964\n",
      "Epoch 48/50 - Train Loss: 0.034435 - Val Loss: 0.044930\n",
      "Epoch 49/50 - Train Loss: 0.024580 - Val Loss: 0.044504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:37:04,274] Trial 43 finished with value: 0.0444226898252964 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 49, 'lr': 0.004716127933637312, 'weight_decay': 2.1586965709921846e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031375 - Val Loss: 0.044903\n",
      "Epoch 1/50 - Train Loss: 0.056327 - Val Loss: 0.086739\n",
      "Epoch 2/50 - Train Loss: 0.042943 - Val Loss: 0.092006\n",
      "Epoch 3/50 - Train Loss: 0.046438 - Val Loss: 0.061413\n",
      "Epoch 4/50 - Train Loss: 0.041005 - Val Loss: 0.064319\n",
      "Epoch 5/50 - Train Loss: 0.032400 - Val Loss: 0.049881\n",
      "Epoch 6/50 - Train Loss: 0.035446 - Val Loss: 0.051081\n",
      "Epoch 7/50 - Train Loss: 0.032353 - Val Loss: 0.070165\n",
      "Epoch 8/50 - Train Loss: 0.035073 - Val Loss: 0.047610\n",
      "Epoch 9/50 - Train Loss: 0.036207 - Val Loss: 0.050004\n",
      "Epoch 10/50 - Train Loss: 0.033556 - Val Loss: 0.046389\n",
      "Epoch 11/50 - Train Loss: 0.030418 - Val Loss: 0.056178\n",
      "Epoch 12/50 - Train Loss: 0.034066 - Val Loss: 0.051441\n",
      "Epoch 13/50 - Train Loss: 0.033709 - Val Loss: 0.045751\n",
      "Epoch 14/50 - Train Loss: 0.028709 - Val Loss: 0.044820\n",
      "Epoch 15/50 - Train Loss: 0.034702 - Val Loss: 0.045166\n",
      "Epoch 16/50 - Train Loss: 0.034657 - Val Loss: 0.044174\n",
      "Epoch 17/50 - Train Loss: 0.033244 - Val Loss: 0.044345\n",
      "Epoch 18/50 - Train Loss: 0.034966 - Val Loss: 0.051860\n",
      "Epoch 19/50 - Train Loss: 0.035351 - Val Loss: 0.044588\n",
      "Epoch 20/50 - Train Loss: 0.033389 - Val Loss: 0.049465\n",
      "Epoch 21/50 - Train Loss: 0.032353 - Val Loss: 0.043878\n",
      "Epoch 22/50 - Train Loss: 0.030910 - Val Loss: 0.046261\n",
      "Epoch 23/50 - Train Loss: 0.032808 - Val Loss: 0.045926\n",
      "Epoch 24/50 - Train Loss: 0.030569 - Val Loss: 0.049611\n",
      "Epoch 25/50 - Train Loss: 0.035746 - Val Loss: 0.046439\n",
      "Epoch 26/50 - Train Loss: 0.034193 - Val Loss: 0.045278\n",
      "Epoch 27/50 - Train Loss: 0.032132 - Val Loss: 0.043833\n",
      "Epoch 28/50 - Train Loss: 0.031909 - Val Loss: 0.049294\n",
      "Epoch 29/50 - Train Loss: 0.032718 - Val Loss: 0.046160\n",
      "Epoch 30/50 - Train Loss: 0.030462 - Val Loss: 0.043810\n",
      "Epoch 31/50 - Train Loss: 0.032361 - Val Loss: 0.043657\n",
      "Epoch 32/50 - Train Loss: 0.029324 - Val Loss: 0.043759\n",
      "Epoch 33/50 - Train Loss: 0.030949 - Val Loss: 0.051006\n",
      "Epoch 34/50 - Train Loss: 0.034236 - Val Loss: 0.043853\n",
      "Epoch 35/50 - Train Loss: 0.032519 - Val Loss: 0.043507\n",
      "Epoch 36/50 - Train Loss: 0.031803 - Val Loss: 0.043938\n",
      "Epoch 37/50 - Train Loss: 0.031102 - Val Loss: 0.043376\n",
      "Epoch 38/50 - Train Loss: 0.028422 - Val Loss: 0.047129\n",
      "Epoch 39/50 - Train Loss: 0.030621 - Val Loss: 0.047970\n",
      "Epoch 40/50 - Train Loss: 0.030472 - Val Loss: 0.043786\n",
      "Epoch 41/50 - Train Loss: 0.032245 - Val Loss: 0.043862\n",
      "Epoch 42/50 - Train Loss: 0.033126 - Val Loss: 0.046954\n",
      "Epoch 43/50 - Train Loss: 0.030010 - Val Loss: 0.043760\n",
      "Epoch 44/50 - Train Loss: 0.029824 - Val Loss: 0.050221\n",
      "Epoch 45/50 - Train Loss: 0.032361 - Val Loss: 0.046618\n",
      "Epoch 46/50 - Train Loss: 0.030138 - Val Loss: 0.043513\n",
      "Epoch 47/50 - Train Loss: 0.029509 - Val Loss: 0.046620\n",
      "Epoch 48/50 - Train Loss: 0.033985 - Val Loss: 0.048182\n",
      "Epoch 49/50 - Train Loss: 0.033110 - Val Loss: 0.051168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:37:25,120] Trial 44 finished with value: 0.04337610490620136 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 68, 'lr': 0.0075822967981455675, 'weight_decay': 1.0840989952531855e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030832 - Val Loss: 0.054046\n",
      "Epoch 1/50 - Train Loss: 0.076077 - Val Loss: 0.084251\n",
      "Epoch 2/50 - Train Loss: 0.041600 - Val Loss: 0.071818\n",
      "Epoch 3/50 - Train Loss: 0.047739 - Val Loss: 0.089431\n",
      "Epoch 4/50 - Train Loss: 0.041692 - Val Loss: 0.091379\n",
      "Epoch 5/50 - Train Loss: 0.045824 - Val Loss: 0.083435\n",
      "Epoch 6/50 - Train Loss: 0.043721 - Val Loss: 0.074400\n",
      "Epoch 7/50 - Train Loss: 0.045722 - Val Loss: 0.082853\n",
      "Epoch 8/50 - Train Loss: 0.038537 - Val Loss: 0.082631\n",
      "Epoch 9/50 - Train Loss: 0.036955 - Val Loss: 0.069466\n",
      "Epoch 10/50 - Train Loss: 0.036067 - Val Loss: 0.059913\n",
      "Epoch 11/50 - Train Loss: 0.036610 - Val Loss: 0.057511\n",
      "Epoch 12/50 - Train Loss: 0.036618 - Val Loss: 0.048709\n",
      "Epoch 13/50 - Train Loss: 0.035778 - Val Loss: 0.059390\n",
      "Epoch 14/50 - Train Loss: 0.037288 - Val Loss: 0.054127\n",
      "Epoch 15/50 - Train Loss: 0.036178 - Val Loss: 0.057983\n",
      "Epoch 16/50 - Train Loss: 0.035592 - Val Loss: 0.048711\n",
      "Epoch 17/50 - Train Loss: 0.034934 - Val Loss: 0.047973\n",
      "Epoch 18/50 - Train Loss: 0.040101 - Val Loss: 0.050065\n",
      "Epoch 19/50 - Train Loss: 0.030549 - Val Loss: 0.048410\n",
      "Epoch 20/50 - Train Loss: 0.035059 - Val Loss: 0.048837\n",
      "Epoch 21/50 - Train Loss: 0.028996 - Val Loss: 0.047661\n",
      "Epoch 22/50 - Train Loss: 0.033051 - Val Loss: 0.046556\n",
      "Epoch 23/50 - Train Loss: 0.032774 - Val Loss: 0.047733\n",
      "Epoch 24/50 - Train Loss: 0.028423 - Val Loss: 0.047013\n",
      "Epoch 25/50 - Train Loss: 0.028109 - Val Loss: 0.047773\n",
      "Epoch 26/50 - Train Loss: 0.028800 - Val Loss: 0.045694\n",
      "Epoch 27/50 - Train Loss: 0.028188 - Val Loss: 0.046187\n",
      "Epoch 28/50 - Train Loss: 0.032493 - Val Loss: 0.045867\n",
      "Epoch 29/50 - Train Loss: 0.035170 - Val Loss: 0.049286\n",
      "Epoch 30/50 - Train Loss: 0.029456 - Val Loss: 0.047029\n",
      "Epoch 31/50 - Train Loss: 0.029920 - Val Loss: 0.045279\n",
      "Epoch 32/50 - Train Loss: 0.031192 - Val Loss: 0.044583\n",
      "Epoch 33/50 - Train Loss: 0.027619 - Val Loss: 0.045621\n",
      "Epoch 34/50 - Train Loss: 0.033794 - Val Loss: 0.046593\n",
      "Epoch 35/50 - Train Loss: 0.035213 - Val Loss: 0.048449\n",
      "Epoch 36/50 - Train Loss: 0.032996 - Val Loss: 0.045906\n",
      "Epoch 37/50 - Train Loss: 0.033984 - Val Loss: 0.046389\n",
      "Epoch 38/50 - Train Loss: 0.033821 - Val Loss: 0.047497\n",
      "Epoch 39/50 - Train Loss: 0.033870 - Val Loss: 0.046470\n",
      "Epoch 40/50 - Train Loss: 0.029625 - Val Loss: 0.049012\n",
      "Epoch 41/50 - Train Loss: 0.028158 - Val Loss: 0.047681\n",
      "Epoch 42/50 - Train Loss: 0.034089 - Val Loss: 0.045709\n",
      "Epoch 43/50 - Train Loss: 0.033997 - Val Loss: 0.045461\n",
      "Epoch 44/50 - Train Loss: 0.033096 - Val Loss: 0.046372\n",
      "Epoch 45/50 - Train Loss: 0.035452 - Val Loss: 0.047953\n",
      "Epoch 46/50 - Train Loss: 0.032280 - Val Loss: 0.049171\n",
      "Epoch 47/50 - Train Loss: 0.034437 - Val Loss: 0.046509\n",
      "Epoch 48/50 - Train Loss: 0.028131 - Val Loss: 0.045701\n",
      "Epoch 49/50 - Train Loss: 0.032628 - Val Loss: 0.045229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:37:42,734] Trial 45 finished with value: 0.04458273574709892 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 68, 'lr': 0.0032291801256658704, 'weight_decay': 8.089077024820684e-08, 'batch_size': 32}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.028456 - Val Loss: 0.048418\n",
      "Epoch 1/50 - Train Loss: 0.082419 - Val Loss: 0.117757\n",
      "Epoch 2/50 - Train Loss: 0.047796 - Val Loss: 0.068067\n",
      "Epoch 3/50 - Train Loss: 0.049449 - Val Loss: 0.075693\n",
      "Epoch 4/50 - Train Loss: 0.044306 - Val Loss: 0.090747\n",
      "Epoch 5/50 - Train Loss: 0.043234 - Val Loss: 0.081276\n",
      "Epoch 6/50 - Train Loss: 0.038638 - Val Loss: 0.068690\n",
      "Epoch 7/50 - Train Loss: 0.038662 - Val Loss: 0.071806\n",
      "Epoch 8/50 - Train Loss: 0.036234 - Val Loss: 0.060711\n",
      "Epoch 9/50 - Train Loss: 0.035427 - Val Loss: 0.056337\n",
      "Epoch 10/50 - Train Loss: 0.033964 - Val Loss: 0.050825\n",
      "Epoch 11/50 - Train Loss: 0.038436 - Val Loss: 0.052375\n",
      "Epoch 12/50 - Train Loss: 0.037870 - Val Loss: 0.053086\n",
      "Epoch 13/50 - Train Loss: 0.031364 - Val Loss: 0.047433\n",
      "Epoch 14/50 - Train Loss: 0.033426 - Val Loss: 0.049456\n",
      "Epoch 15/50 - Train Loss: 0.033877 - Val Loss: 0.045899\n",
      "Epoch 16/50 - Train Loss: 0.034964 - Val Loss: 0.047575\n",
      "Epoch 17/50 - Train Loss: 0.032361 - Val Loss: 0.047506\n",
      "Epoch 18/50 - Train Loss: 0.033696 - Val Loss: 0.047610\n",
      "Epoch 19/50 - Train Loss: 0.035402 - Val Loss: 0.047090\n",
      "Epoch 20/50 - Train Loss: 0.032753 - Val Loss: 0.045903\n",
      "Epoch 21/50 - Train Loss: 0.031574 - Val Loss: 0.048994\n",
      "Epoch 22/50 - Train Loss: 0.031873 - Val Loss: 0.045832\n",
      "Epoch 23/50 - Train Loss: 0.033080 - Val Loss: 0.047147\n",
      "Epoch 24/50 - Train Loss: 0.031285 - Val Loss: 0.046117\n",
      "Epoch 25/50 - Train Loss: 0.029749 - Val Loss: 0.048971\n",
      "Epoch 26/50 - Train Loss: 0.030672 - Val Loss: 0.045135\n",
      "Epoch 27/50 - Train Loss: 0.035657 - Val Loss: 0.051328\n",
      "Epoch 28/50 - Train Loss: 0.032814 - Val Loss: 0.045627\n",
      "Epoch 29/50 - Train Loss: 0.030221 - Val Loss: 0.048759\n",
      "Epoch 30/50 - Train Loss: 0.030908 - Val Loss: 0.046884\n",
      "Epoch 31/50 - Train Loss: 0.033836 - Val Loss: 0.049425\n",
      "Epoch 32/50 - Train Loss: 0.032362 - Val Loss: 0.044932\n",
      "Epoch 33/50 - Train Loss: 0.033377 - Val Loss: 0.050075\n",
      "Epoch 34/50 - Train Loss: 0.030277 - Val Loss: 0.045598\n",
      "Epoch 35/50 - Train Loss: 0.030690 - Val Loss: 0.045615\n",
      "Epoch 36/50 - Train Loss: 0.034804 - Val Loss: 0.047586\n",
      "Epoch 37/50 - Train Loss: 0.032735 - Val Loss: 0.045591\n",
      "Epoch 38/50 - Train Loss: 0.031031 - Val Loss: 0.047521\n",
      "Epoch 39/50 - Train Loss: 0.031105 - Val Loss: 0.047924\n",
      "Epoch 40/50 - Train Loss: 0.031574 - Val Loss: 0.044612\n",
      "Epoch 41/50 - Train Loss: 0.030787 - Val Loss: 0.046472\n",
      "Epoch 42/50 - Train Loss: 0.033026 - Val Loss: 0.045778\n",
      "Epoch 43/50 - Train Loss: 0.033684 - Val Loss: 0.046572\n",
      "Epoch 44/50 - Train Loss: 0.027500 - Val Loss: 0.045527\n",
      "Epoch 45/50 - Train Loss: 0.030245 - Val Loss: 0.044360\n",
      "Epoch 46/50 - Train Loss: 0.029552 - Val Loss: 0.047111\n",
      "Epoch 47/50 - Train Loss: 0.030029 - Val Loss: 0.044440\n",
      "Epoch 48/50 - Train Loss: 0.033228 - Val Loss: 0.053884\n",
      "Epoch 49/50 - Train Loss: 0.031468 - Val Loss: 0.044444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:38:02,364] Trial 46 finished with value: 0.0443604551255703 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 50, 'lr': 0.0014088090698482162, 'weight_decay': 2.9578846982789085e-08, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.029805 - Val Loss: 0.046525\n",
      "Epoch 1/50 - Train Loss: 0.129680 - Val Loss: 0.201785\n",
      "Epoch 2/50 - Train Loss: 0.057220 - Val Loss: 0.061324\n",
      "Epoch 3/50 - Train Loss: 0.049013 - Val Loss: 0.097719\n",
      "Epoch 4/50 - Train Loss: 0.043248 - Val Loss: 0.077736\n",
      "Epoch 5/50 - Train Loss: 0.043118 - Val Loss: 0.072603\n",
      "Epoch 6/50 - Train Loss: 0.034681 - Val Loss: 0.058311\n",
      "Epoch 7/50 - Train Loss: 0.033250 - Val Loss: 0.055110\n",
      "Epoch 8/50 - Train Loss: 0.033725 - Val Loss: 0.053500\n",
      "Epoch 9/50 - Train Loss: 0.032491 - Val Loss: 0.044815\n",
      "Epoch 10/50 - Train Loss: 0.032317 - Val Loss: 0.045062\n",
      "Epoch 11/50 - Train Loss: 0.032838 - Val Loss: 0.047201\n",
      "Epoch 12/50 - Train Loss: 0.035623 - Val Loss: 0.045533\n",
      "Epoch 13/50 - Train Loss: 0.033898 - Val Loss: 0.045135\n",
      "Epoch 14/50 - Train Loss: 0.029395 - Val Loss: 0.046069\n",
      "Epoch 15/50 - Train Loss: 0.030828 - Val Loss: 0.046430\n",
      "Epoch 16/50 - Train Loss: 0.032944 - Val Loss: 0.047052\n",
      "Epoch 17/50 - Train Loss: 0.029905 - Val Loss: 0.047731\n",
      "Epoch 18/50 - Train Loss: 0.031448 - Val Loss: 0.047569\n",
      "Epoch 19/50 - Train Loss: 0.032393 - Val Loss: 0.046492\n",
      "Epoch 20/50 - Train Loss: 0.030676 - Val Loss: 0.045007\n",
      "Epoch 21/50 - Train Loss: 0.033199 - Val Loss: 0.044873\n",
      "Epoch 22/50 - Train Loss: 0.033031 - Val Loss: 0.047837\n",
      "Epoch 23/50 - Train Loss: 0.030254 - Val Loss: 0.044925\n",
      "Epoch 24/50 - Train Loss: 0.030341 - Val Loss: 0.044136\n",
      "Epoch 25/50 - Train Loss: 0.033433 - Val Loss: 0.044782\n",
      "Epoch 26/50 - Train Loss: 0.033656 - Val Loss: 0.065419\n",
      "Epoch 27/50 - Train Loss: 0.033258 - Val Loss: 0.049025\n",
      "Epoch 28/50 - Train Loss: 0.033859 - Val Loss: 0.045440\n",
      "Epoch 29/50 - Train Loss: 0.032553 - Val Loss: 0.045228\n",
      "Epoch 30/50 - Train Loss: 0.030360 - Val Loss: 0.044834\n",
      "Epoch 31/50 - Train Loss: 0.030172 - Val Loss: 0.045401\n",
      "Epoch 32/50 - Train Loss: 0.034286 - Val Loss: 0.046393\n",
      "Epoch 33/50 - Train Loss: 0.034943 - Val Loss: 0.046285\n",
      "Epoch 34/50 - Train Loss: 0.033632 - Val Loss: 0.045964\n",
      "Epoch 35/50 - Train Loss: 0.025115 - Val Loss: 0.048824\n",
      "Epoch 36/50 - Train Loss: 0.032550 - Val Loss: 0.046245\n",
      "Epoch 37/50 - Train Loss: 0.029459 - Val Loss: 0.053115\n",
      "Epoch 38/50 - Train Loss: 0.033042 - Val Loss: 0.045494\n",
      "Epoch 39/50 - Train Loss: 0.035076 - Val Loss: 0.044329\n",
      "Epoch 40/50 - Train Loss: 0.032656 - Val Loss: 0.050855\n",
      "Epoch 41/50 - Train Loss: 0.030159 - Val Loss: 0.050735\n",
      "Epoch 42/50 - Train Loss: 0.033536 - Val Loss: 0.045494\n",
      "Epoch 43/50 - Train Loss: 0.031367 - Val Loss: 0.047579\n",
      "Epoch 44/50 - Train Loss: 0.034963 - Val Loss: 0.052077\n",
      "Epoch 45/50 - Train Loss: 0.030020 - Val Loss: 0.043892\n",
      "Epoch 46/50 - Train Loss: 0.029108 - Val Loss: 0.044457\n",
      "Epoch 47/50 - Train Loss: 0.031669 - Val Loss: 0.044758\n",
      "Epoch 48/50 - Train Loss: 0.026288 - Val Loss: 0.044362\n",
      "Epoch 49/50 - Train Loss: 0.029828 - Val Loss: 0.044577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:38:32,527] Trial 47 finished with value: 0.04389180988073349 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 154, 'lr': 0.006684081206339995, 'weight_decay': 1.1896672915683071e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.027624 - Val Loss: 0.044997\n",
      "Epoch 1/50 - Train Loss: 0.103198 - Val Loss: 0.077776\n",
      "Epoch 2/50 - Train Loss: 0.060096 - Val Loss: 0.072315\n",
      "Epoch 3/50 - Train Loss: 0.052221 - Val Loss: 0.094063\n",
      "Epoch 4/50 - Train Loss: 0.042911 - Val Loss: 0.101405\n",
      "Epoch 5/50 - Train Loss: 0.051484 - Val Loss: 0.096937\n",
      "Epoch 6/50 - Train Loss: 0.042408 - Val Loss: 0.087038\n",
      "Epoch 7/50 - Train Loss: 0.042647 - Val Loss: 0.081211\n",
      "Epoch 8/50 - Train Loss: 0.048415 - Val Loss: 0.081827\n",
      "Epoch 9/50 - Train Loss: 0.049918 - Val Loss: 0.085065\n",
      "Epoch 10/50 - Train Loss: 0.043800 - Val Loss: 0.085660\n",
      "Epoch 11/50 - Train Loss: 0.040621 - Val Loss: 0.083262\n",
      "Epoch 12/50 - Train Loss: 0.048966 - Val Loss: 0.077407\n",
      "Epoch 13/50 - Train Loss: 0.038220 - Val Loss: 0.066509\n",
      "Epoch 14/50 - Train Loss: 0.041311 - Val Loss: 0.051606\n",
      "Epoch 15/50 - Train Loss: 0.039804 - Val Loss: 0.052116\n",
      "Epoch 16/50 - Train Loss: 0.032327 - Val Loss: 0.048834\n",
      "Epoch 17/50 - Train Loss: 0.040249 - Val Loss: 0.056235\n",
      "Epoch 18/50 - Train Loss: 0.031763 - Val Loss: 0.052988\n",
      "Epoch 19/50 - Train Loss: 0.039974 - Val Loss: 0.053605\n",
      "Epoch 20/50 - Train Loss: 0.037771 - Val Loss: 0.050942\n",
      "Epoch 21/50 - Train Loss: 0.036843 - Val Loss: 0.047168\n",
      "Epoch 22/50 - Train Loss: 0.031971 - Val Loss: 0.045938\n",
      "Epoch 23/50 - Train Loss: 0.029619 - Val Loss: 0.047635\n",
      "Epoch 24/50 - Train Loss: 0.036417 - Val Loss: 0.048178\n",
      "Epoch 25/50 - Train Loss: 0.036545 - Val Loss: 0.050375\n",
      "Epoch 26/50 - Train Loss: 0.036723 - Val Loss: 0.047239\n",
      "Epoch 27/50 - Train Loss: 0.037538 - Val Loss: 0.046427\n",
      "Epoch 28/50 - Train Loss: 0.028974 - Val Loss: 0.047332\n",
      "Epoch 29/50 - Train Loss: 0.036713 - Val Loss: 0.048648\n",
      "Epoch 30/50 - Train Loss: 0.037945 - Val Loss: 0.046744\n",
      "Epoch 31/50 - Train Loss: 0.037172 - Val Loss: 0.049818\n",
      "Epoch 32/50 - Train Loss: 0.029234 - Val Loss: 0.045593\n",
      "Epoch 33/50 - Train Loss: 0.036518 - Val Loss: 0.046941\n",
      "Epoch 34/50 - Train Loss: 0.029379 - Val Loss: 0.045326\n",
      "Epoch 35/50 - Train Loss: 0.029044 - Val Loss: 0.045929\n",
      "Epoch 36/50 - Train Loss: 0.030632 - Val Loss: 0.045511\n",
      "Epoch 37/50 - Train Loss: 0.036098 - Val Loss: 0.045847\n",
      "Epoch 38/50 - Train Loss: 0.036488 - Val Loss: 0.048497\n",
      "Epoch 39/50 - Train Loss: 0.028388 - Val Loss: 0.045622\n",
      "Epoch 40/50 - Train Loss: 0.028166 - Val Loss: 0.045261\n",
      "Epoch 41/50 - Train Loss: 0.036764 - Val Loss: 0.045755\n",
      "Epoch 42/50 - Train Loss: 0.029613 - Val Loss: 0.045114\n",
      "Epoch 43/50 - Train Loss: 0.028317 - Val Loss: 0.046362\n",
      "Epoch 44/50 - Train Loss: 0.028868 - Val Loss: 0.044609\n",
      "Epoch 45/50 - Train Loss: 0.030511 - Val Loss: 0.044196\n",
      "Epoch 46/50 - Train Loss: 0.029036 - Val Loss: 0.045535\n",
      "Epoch 47/50 - Train Loss: 0.029145 - Val Loss: 0.045250\n",
      "Epoch 48/50 - Train Loss: 0.035949 - Val Loss: 0.047323\n",
      "Epoch 49/50 - Train Loss: 0.028281 - Val Loss: 0.047425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:38:48,522] Trial 48 finished with value: 0.04419649392366409 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 117, 'lr': 0.0048760122420038535, 'weight_decay': 2.2327570034515927e-07, 'batch_size': 64}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.028357 - Val Loss: 0.045799\n",
      "Epoch 1/50 - Train Loss: 0.084282 - Val Loss: 0.134636\n",
      "Epoch 2/50 - Train Loss: 0.047013 - Val Loss: 0.070292\n",
      "Epoch 3/50 - Train Loss: 0.045849 - Val Loss: 0.080134\n",
      "Epoch 4/50 - Train Loss: 0.043472 - Val Loss: 0.088945\n",
      "Epoch 5/50 - Train Loss: 0.041280 - Val Loss: 0.076183\n",
      "Epoch 6/50 - Train Loss: 0.039475 - Val Loss: 0.065954\n",
      "Epoch 7/50 - Train Loss: 0.039848 - Val Loss: 0.064950\n",
      "Epoch 8/50 - Train Loss: 0.036294 - Val Loss: 0.060135\n",
      "Epoch 9/50 - Train Loss: 0.035132 - Val Loss: 0.056411\n",
      "Epoch 10/50 - Train Loss: 0.032414 - Val Loss: 0.056457\n",
      "Epoch 11/50 - Train Loss: 0.031619 - Val Loss: 0.049211\n",
      "Epoch 12/50 - Train Loss: 0.034735 - Val Loss: 0.057541\n",
      "Epoch 13/50 - Train Loss: 0.032033 - Val Loss: 0.048367\n",
      "Epoch 14/50 - Train Loss: 0.031758 - Val Loss: 0.049309\n",
      "Epoch 15/50 - Train Loss: 0.033500 - Val Loss: 0.049464\n",
      "Epoch 16/50 - Train Loss: 0.032956 - Val Loss: 0.047356\n",
      "Epoch 17/50 - Train Loss: 0.030382 - Val Loss: 0.048012\n",
      "Epoch 18/50 - Train Loss: 0.030690 - Val Loss: 0.047219\n",
      "Epoch 19/50 - Train Loss: 0.027378 - Val Loss: 0.050885\n",
      "Epoch 20/50 - Train Loss: 0.032270 - Val Loss: 0.047278\n",
      "Epoch 21/50 - Train Loss: 0.029196 - Val Loss: 0.047409\n",
      "Epoch 22/50 - Train Loss: 0.033395 - Val Loss: 0.050535\n",
      "Epoch 23/50 - Train Loss: 0.029629 - Val Loss: 0.046461\n",
      "Epoch 24/50 - Train Loss: 0.031125 - Val Loss: 0.049681\n",
      "Epoch 25/50 - Train Loss: 0.032661 - Val Loss: 0.046433\n",
      "Epoch 26/50 - Train Loss: 0.034480 - Val Loss: 0.050912\n",
      "Epoch 27/50 - Train Loss: 0.030535 - Val Loss: 0.047856\n",
      "Epoch 28/50 - Train Loss: 0.032127 - Val Loss: 0.046273\n",
      "Epoch 29/50 - Train Loss: 0.030049 - Val Loss: 0.049603\n",
      "Epoch 30/50 - Train Loss: 0.030572 - Val Loss: 0.045950\n",
      "Epoch 31/50 - Train Loss: 0.032178 - Val Loss: 0.049134\n",
      "Epoch 32/50 - Train Loss: 0.033156 - Val Loss: 0.047776\n",
      "Epoch 33/50 - Train Loss: 0.031432 - Val Loss: 0.045197\n",
      "Epoch 34/50 - Train Loss: 0.028259 - Val Loss: 0.049890\n",
      "Epoch 35/50 - Train Loss: 0.033323 - Val Loss: 0.045124\n",
      "Epoch 36/50 - Train Loss: 0.032760 - Val Loss: 0.051895\n",
      "Epoch 37/50 - Train Loss: 0.030215 - Val Loss: 0.045220\n",
      "Epoch 38/50 - Train Loss: 0.030073 - Val Loss: 0.045225\n",
      "Epoch 39/50 - Train Loss: 0.031594 - Val Loss: 0.048374\n",
      "Epoch 40/50 - Train Loss: 0.029369 - Val Loss: 0.044942\n",
      "Epoch 41/50 - Train Loss: 0.027551 - Val Loss: 0.049011\n",
      "Epoch 42/50 - Train Loss: 0.031908 - Val Loss: 0.044978\n",
      "Epoch 43/50 - Train Loss: 0.030474 - Val Loss: 0.046475\n",
      "Epoch 44/50 - Train Loss: 0.032290 - Val Loss: 0.045344\n",
      "Epoch 45/50 - Train Loss: 0.029666 - Val Loss: 0.051393\n",
      "Epoch 46/50 - Train Loss: 0.031296 - Val Loss: 0.044602\n",
      "Epoch 47/50 - Train Loss: 0.031661 - Val Loss: 0.046645\n",
      "Epoch 48/50 - Train Loss: 0.030294 - Val Loss: 0.044444\n",
      "Epoch 49/50 - Train Loss: 0.029831 - Val Loss: 0.046393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:39:06,127] Trial 49 finished with value: 0.04444434493780136 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 43, 'lr': 0.002113731602457366, 'weight_decay': 5.179257986229917e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031760 - Val Loss: 0.046853\n",
      "Epoch 1/50 - Train Loss: 0.121759 - Val Loss: 0.074428\n",
      "Epoch 2/50 - Train Loss: 0.056793 - Val Loss: 0.127784\n",
      "Epoch 3/50 - Train Loss: 0.055235 - Val Loss: 0.078573\n",
      "Epoch 4/50 - Train Loss: 0.047586 - Val Loss: 0.081207\n",
      "Epoch 5/50 - Train Loss: 0.039811 - Val Loss: 0.092506\n",
      "Epoch 6/50 - Train Loss: 0.040714 - Val Loss: 0.083122\n",
      "Epoch 7/50 - Train Loss: 0.039701 - Val Loss: 0.081451\n",
      "Epoch 8/50 - Train Loss: 0.043674 - Val Loss: 0.081056\n",
      "Epoch 9/50 - Train Loss: 0.045585 - Val Loss: 0.063771\n",
      "Epoch 10/50 - Train Loss: 0.038519 - Val Loss: 0.053310\n",
      "Epoch 11/50 - Train Loss: 0.033947 - Val Loss: 0.049693\n",
      "Epoch 12/50 - Train Loss: 0.030704 - Val Loss: 0.051978\n",
      "Epoch 13/50 - Train Loss: 0.035904 - Val Loss: 0.052982\n",
      "Epoch 14/50 - Train Loss: 0.031166 - Val Loss: 0.053027\n",
      "Epoch 15/50 - Train Loss: 0.033758 - Val Loss: 0.049470\n",
      "Epoch 16/50 - Train Loss: 0.038758 - Val Loss: 0.050159\n",
      "Epoch 17/50 - Train Loss: 0.032126 - Val Loss: 0.059226\n",
      "Epoch 18/50 - Train Loss: 0.035042 - Val Loss: 0.054086\n",
      "Epoch 19/50 - Train Loss: 0.032118 - Val Loss: 0.051292\n",
      "Epoch 20/50 - Train Loss: 0.033023 - Val Loss: 0.046006\n",
      "Epoch 21/50 - Train Loss: 0.034358 - Val Loss: 0.049711\n",
      "Epoch 22/50 - Train Loss: 0.029211 - Val Loss: 0.049350\n",
      "Epoch 23/50 - Train Loss: 0.029804 - Val Loss: 0.047883\n",
      "Epoch 24/50 - Train Loss: 0.033725 - Val Loss: 0.047039\n",
      "Epoch 25/50 - Train Loss: 0.034442 - Val Loss: 0.049511\n",
      "Epoch 26/50 - Train Loss: 0.036508 - Val Loss: 0.048191\n",
      "Epoch 27/50 - Train Loss: 0.037806 - Val Loss: 0.049303\n",
      "Epoch 28/50 - Train Loss: 0.033140 - Val Loss: 0.045564\n",
      "Epoch 29/50 - Train Loss: 0.035148 - Val Loss: 0.044884\n",
      "Epoch 30/50 - Train Loss: 0.029680 - Val Loss: 0.050981\n",
      "Epoch 31/50 - Train Loss: 0.031402 - Val Loss: 0.049095\n",
      "Epoch 32/50 - Train Loss: 0.032202 - Val Loss: 0.048554\n",
      "Epoch 33/50 - Train Loss: 0.027347 - Val Loss: 0.047274\n",
      "Epoch 34/50 - Train Loss: 0.036940 - Val Loss: 0.046753\n",
      "Epoch 35/50 - Train Loss: 0.038871 - Val Loss: 0.053853\n",
      "Epoch 36/50 - Train Loss: 0.034176 - Val Loss: 0.047452\n",
      "Epoch 37/50 - Train Loss: 0.031833 - Val Loss: 0.046012\n",
      "Epoch 38/50 - Train Loss: 0.030178 - Val Loss: 0.046917\n",
      "Epoch 39/50 - Train Loss: 0.032152 - Val Loss: 0.048350\n",
      "Epoch 40/50 - Train Loss: 0.031789 - Val Loss: 0.047353\n",
      "Epoch 41/50 - Train Loss: 0.034964 - Val Loss: 0.047043\n",
      "Epoch 42/50 - Train Loss: 0.034865 - Val Loss: 0.047798\n",
      "Epoch 43/50 - Train Loss: 0.026524 - Val Loss: 0.046792\n",
      "Epoch 44/50 - Train Loss: 0.028292 - Val Loss: 0.045140\n",
      "Epoch 45/50 - Train Loss: 0.027272 - Val Loss: 0.045616\n",
      "Epoch 46/50 - Train Loss: 0.032240 - Val Loss: 0.049216\n",
      "Epoch 47/50 - Train Loss: 0.028937 - Val Loss: 0.046382\n",
      "Epoch 48/50 - Train Loss: 0.031320 - Val Loss: 0.052801\n",
      "Epoch 49/50 - Train Loss: 0.031984 - Val Loss: 0.047618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:39:23,556] Trial 50 finished with value: 0.044883567839860916 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 65, 'lr': 0.009997292410713048, 'weight_decay': 1.0680823541643869e-05, 'batch_size': 32}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.032910 - Val Loss: 0.047610\n",
      "Epoch 1/50 - Train Loss: 0.099699 - Val Loss: 0.162371\n",
      "Epoch 2/50 - Train Loss: 0.053083 - Val Loss: 0.060354\n",
      "Epoch 3/50 - Train Loss: 0.044554 - Val Loss: 0.090276\n",
      "Epoch 4/50 - Train Loss: 0.040208 - Val Loss: 0.064315\n",
      "Epoch 5/50 - Train Loss: 0.039279 - Val Loss: 0.051508\n",
      "Epoch 6/50 - Train Loss: 0.037205 - Val Loss: 0.049794\n",
      "Epoch 7/50 - Train Loss: 0.030724 - Val Loss: 0.049797\n",
      "Epoch 8/50 - Train Loss: 0.035115 - Val Loss: 0.047102\n",
      "Epoch 9/50 - Train Loss: 0.033763 - Val Loss: 0.055015\n",
      "Epoch 10/50 - Train Loss: 0.033708 - Val Loss: 0.062951\n",
      "Epoch 11/50 - Train Loss: 0.030162 - Val Loss: 0.047420\n",
      "Epoch 12/50 - Train Loss: 0.032393 - Val Loss: 0.047383\n",
      "Epoch 13/50 - Train Loss: 0.030877 - Val Loss: 0.046026\n",
      "Epoch 14/50 - Train Loss: 0.028685 - Val Loss: 0.049144\n",
      "Epoch 15/50 - Train Loss: 0.033266 - Val Loss: 0.054342\n",
      "Epoch 16/50 - Train Loss: 0.028377 - Val Loss: 0.048856\n",
      "Epoch 17/50 - Train Loss: 0.034029 - Val Loss: 0.044529\n",
      "Epoch 18/50 - Train Loss: 0.032316 - Val Loss: 0.049392\n",
      "Epoch 19/50 - Train Loss: 0.036937 - Val Loss: 0.048487\n",
      "Epoch 20/50 - Train Loss: 0.031770 - Val Loss: 0.047622\n",
      "Epoch 21/50 - Train Loss: 0.031386 - Val Loss: 0.050757\n",
      "Epoch 22/50 - Train Loss: 0.033202 - Val Loss: 0.049900\n",
      "Epoch 23/50 - Train Loss: 0.031919 - Val Loss: 0.044260\n",
      "Epoch 24/50 - Train Loss: 0.029360 - Val Loss: 0.044243\n",
      "Epoch 25/50 - Train Loss: 0.033839 - Val Loss: 0.045104\n",
      "Epoch 26/50 - Train Loss: 0.032269 - Val Loss: 0.044282\n",
      "Epoch 27/50 - Train Loss: 0.030926 - Val Loss: 0.044293\n",
      "Epoch 28/50 - Train Loss: 0.027254 - Val Loss: 0.046464\n",
      "Epoch 29/50 - Train Loss: 0.033842 - Val Loss: 0.048835\n",
      "Epoch 30/50 - Train Loss: 0.028225 - Val Loss: 0.044502\n",
      "Epoch 31/50 - Train Loss: 0.031789 - Val Loss: 0.044621\n",
      "Epoch 32/50 - Train Loss: 0.034020 - Val Loss: 0.044511\n",
      "Epoch 33/50 - Train Loss: 0.031942 - Val Loss: 0.044472\n",
      "Epoch 34/50 - Train Loss: 0.028183 - Val Loss: 0.045823\n",
      "Epoch 35/50 - Train Loss: 0.033861 - Val Loss: 0.049997\n",
      "Epoch 36/50 - Train Loss: 0.036922 - Val Loss: 0.054186\n",
      "Epoch 37/50 - Train Loss: 0.033689 - Val Loss: 0.048615\n",
      "Epoch 38/50 - Train Loss: 0.030869 - Val Loss: 0.044367\n",
      "Epoch 39/50 - Train Loss: 0.032835 - Val Loss: 0.044298\n",
      "Epoch 40/50 - Train Loss: 0.028618 - Val Loss: 0.047500\n",
      "Epoch 41/50 - Train Loss: 0.032666 - Val Loss: 0.049034\n",
      "Epoch 42/50 - Train Loss: 0.035882 - Val Loss: 0.047243\n",
      "Epoch 43/50 - Train Loss: 0.031411 - Val Loss: 0.055238\n",
      "Epoch 44/50 - Train Loss: 0.030125 - Val Loss: 0.052321\n",
      "Epoch 45/50 - Train Loss: 0.030939 - Val Loss: 0.046706\n",
      "Epoch 46/50 - Train Loss: 0.029955 - Val Loss: 0.044500\n",
      "Epoch 47/50 - Train Loss: 0.033604 - Val Loss: 0.046381\n",
      "Epoch 48/50 - Train Loss: 0.031502 - Val Loss: 0.055957\n",
      "Epoch 49/50 - Train Loss: 0.035272 - Val Loss: 0.047964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:39:49,619] Trial 51 finished with value: 0.04424307681620121 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 90, 'lr': 0.00761921431313154, 'weight_decay': 4.556684420502437e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030518 - Val Loss: 0.044624\n",
      "Epoch 1/50 - Train Loss: 0.102776 - Val Loss: 0.192157\n",
      "Epoch 2/50 - Train Loss: 0.054284 - Val Loss: 0.060042\n",
      "Epoch 3/50 - Train Loss: 0.048641 - Val Loss: 0.088807\n",
      "Epoch 4/50 - Train Loss: 0.041602 - Val Loss: 0.069390\n",
      "Epoch 5/50 - Train Loss: 0.041952 - Val Loss: 0.057270\n",
      "Epoch 6/50 - Train Loss: 0.036530 - Val Loss: 0.047850\n",
      "Epoch 7/50 - Train Loss: 0.032190 - Val Loss: 0.046745\n",
      "Epoch 8/50 - Train Loss: 0.035182 - Val Loss: 0.047613\n",
      "Epoch 9/50 - Train Loss: 0.031694 - Val Loss: 0.054458\n",
      "Epoch 10/50 - Train Loss: 0.030265 - Val Loss: 0.050975\n",
      "Epoch 11/50 - Train Loss: 0.033328 - Val Loss: 0.055172\n",
      "Epoch 12/50 - Train Loss: 0.033504 - Val Loss: 0.050835\n",
      "Epoch 13/50 - Train Loss: 0.031577 - Val Loss: 0.044464\n",
      "Epoch 14/50 - Train Loss: 0.029335 - Val Loss: 0.045783\n",
      "Epoch 15/50 - Train Loss: 0.036086 - Val Loss: 0.044784\n",
      "Epoch 16/50 - Train Loss: 0.030449 - Val Loss: 0.048451\n",
      "Epoch 17/50 - Train Loss: 0.029975 - Val Loss: 0.046369\n",
      "Epoch 18/50 - Train Loss: 0.031178 - Val Loss: 0.047478\n",
      "Epoch 19/50 - Train Loss: 0.031326 - Val Loss: 0.047607\n",
      "Epoch 20/50 - Train Loss: 0.031784 - Val Loss: 0.050227\n",
      "Epoch 21/50 - Train Loss: 0.030336 - Val Loss: 0.046499\n",
      "Epoch 22/50 - Train Loss: 0.031671 - Val Loss: 0.043774\n",
      "Epoch 23/50 - Train Loss: 0.029325 - Val Loss: 0.043824\n",
      "Epoch 24/50 - Train Loss: 0.032936 - Val Loss: 0.046000\n",
      "Epoch 25/50 - Train Loss: 0.033605 - Val Loss: 0.046592\n",
      "Epoch 26/50 - Train Loss: 0.032898 - Val Loss: 0.050958\n",
      "Epoch 27/50 - Train Loss: 0.027601 - Val Loss: 0.043980\n",
      "Epoch 28/50 - Train Loss: 0.030155 - Val Loss: 0.043628\n",
      "Epoch 29/50 - Train Loss: 0.032033 - Val Loss: 0.044403\n",
      "Epoch 30/50 - Train Loss: 0.030596 - Val Loss: 0.044338\n",
      "Epoch 31/50 - Train Loss: 0.031360 - Val Loss: 0.044504\n",
      "Epoch 32/50 - Train Loss: 0.037204 - Val Loss: 0.045645\n",
      "Epoch 33/50 - Train Loss: 0.034207 - Val Loss: 0.047803\n",
      "Epoch 34/50 - Train Loss: 0.030619 - Val Loss: 0.054407\n",
      "Epoch 35/50 - Train Loss: 0.031662 - Val Loss: 0.045098\n",
      "Epoch 36/50 - Train Loss: 0.028281 - Val Loss: 0.043989\n",
      "Epoch 37/50 - Train Loss: 0.030484 - Val Loss: 0.047617\n",
      "Epoch 38/50 - Train Loss: 0.032260 - Val Loss: 0.043793\n",
      "Epoch 39/50 - Train Loss: 0.030060 - Val Loss: 0.049619\n",
      "Epoch 40/50 - Train Loss: 0.032866 - Val Loss: 0.044626\n",
      "Epoch 41/50 - Train Loss: 0.030740 - Val Loss: 0.046441\n",
      "Epoch 42/50 - Train Loss: 0.031743 - Val Loss: 0.044087\n",
      "Epoch 43/50 - Train Loss: 0.030484 - Val Loss: 0.045458\n",
      "Epoch 44/50 - Train Loss: 0.026157 - Val Loss: 0.044696\n",
      "Epoch 45/50 - Train Loss: 0.029054 - Val Loss: 0.047533\n",
      "Epoch 46/50 - Train Loss: 0.032423 - Val Loss: 0.048364\n",
      "Epoch 47/50 - Train Loss: 0.031523 - Val Loss: 0.044408\n",
      "Epoch 48/50 - Train Loss: 0.031569 - Val Loss: 0.044791\n",
      "Epoch 49/50 - Train Loss: 0.030389 - Val Loss: 0.044697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:40:16,327] Trial 52 finished with value: 0.043628137558698654 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 103, 'lr': 0.007735741088001104, 'weight_decay': 9.018602899917861e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033178 - Val Loss: 0.044431\n",
      "Epoch 1/50 - Train Loss: 0.091865 - Val Loss: 0.080041\n",
      "Epoch 2/50 - Train Loss: 0.046615 - Val Loss: 0.085978\n",
      "Epoch 3/50 - Train Loss: 0.042454 - Val Loss: 0.071542\n",
      "Epoch 4/50 - Train Loss: 0.038697 - Val Loss: 0.054642\n",
      "Epoch 5/50 - Train Loss: 0.038792 - Val Loss: 0.080351\n",
      "Epoch 6/50 - Train Loss: 0.036212 - Val Loss: 0.048049\n",
      "Epoch 7/50 - Train Loss: 0.037315 - Val Loss: 0.054762\n",
      "Epoch 8/50 - Train Loss: 0.033342 - Val Loss: 0.058209\n",
      "Epoch 9/50 - Train Loss: 0.030853 - Val Loss: 0.046054\n",
      "Epoch 10/50 - Train Loss: 0.034556 - Val Loss: 0.045414\n",
      "Epoch 11/50 - Train Loss: 0.034079 - Val Loss: 0.047736\n",
      "Epoch 12/50 - Train Loss: 0.032387 - Val Loss: 0.047146\n",
      "Epoch 13/50 - Train Loss: 0.033865 - Val Loss: 0.049144\n",
      "Epoch 14/50 - Train Loss: 0.031482 - Val Loss: 0.044904\n",
      "Epoch 15/50 - Train Loss: 0.031690 - Val Loss: 0.053142\n",
      "Epoch 16/50 - Train Loss: 0.029562 - Val Loss: 0.046239\n",
      "Epoch 17/50 - Train Loss: 0.031777 - Val Loss: 0.045435\n",
      "Epoch 18/50 - Train Loss: 0.031990 - Val Loss: 0.046615\n",
      "Epoch 19/50 - Train Loss: 0.030065 - Val Loss: 0.048676\n",
      "Epoch 20/50 - Train Loss: 0.033498 - Val Loss: 0.046867\n",
      "Epoch 21/50 - Train Loss: 0.030045 - Val Loss: 0.044798\n",
      "Epoch 22/50 - Train Loss: 0.033227 - Val Loss: 0.046033\n",
      "Epoch 23/50 - Train Loss: 0.033237 - Val Loss: 0.059574\n",
      "Epoch 24/50 - Train Loss: 0.035849 - Val Loss: 0.044674\n",
      "Epoch 25/50 - Train Loss: 0.031387 - Val Loss: 0.044455\n",
      "Epoch 26/50 - Train Loss: 0.033746 - Val Loss: 0.053563\n",
      "Epoch 27/50 - Train Loss: 0.036118 - Val Loss: 0.054178\n",
      "Epoch 28/50 - Train Loss: 0.030473 - Val Loss: 0.044288\n",
      "Epoch 29/50 - Train Loss: 0.031285 - Val Loss: 0.044387\n",
      "Epoch 30/50 - Train Loss: 0.031132 - Val Loss: 0.051698\n",
      "Epoch 31/50 - Train Loss: 0.028577 - Val Loss: 0.046915\n",
      "Epoch 32/50 - Train Loss: 0.031047 - Val Loss: 0.049695\n",
      "Epoch 33/50 - Train Loss: 0.030600 - Val Loss: 0.045327\n",
      "Epoch 34/50 - Train Loss: 0.030339 - Val Loss: 0.044490\n",
      "Epoch 35/50 - Train Loss: 0.030108 - Val Loss: 0.047208\n",
      "Epoch 36/50 - Train Loss: 0.036195 - Val Loss: 0.047438\n",
      "Epoch 37/50 - Train Loss: 0.034919 - Val Loss: 0.050425\n",
      "Epoch 38/50 - Train Loss: 0.029722 - Val Loss: 0.046036\n",
      "Epoch 39/50 - Train Loss: 0.032220 - Val Loss: 0.044279\n",
      "Epoch 40/50 - Train Loss: 0.029838 - Val Loss: 0.044527\n",
      "Epoch 41/50 - Train Loss: 0.030273 - Val Loss: 0.055264\n",
      "Epoch 42/50 - Train Loss: 0.032205 - Val Loss: 0.051175\n",
      "Epoch 43/50 - Train Loss: 0.028378 - Val Loss: 0.044459\n",
      "Epoch 44/50 - Train Loss: 0.034445 - Val Loss: 0.055580\n",
      "Epoch 45/50 - Train Loss: 0.033036 - Val Loss: 0.049044\n",
      "Epoch 46/50 - Train Loss: 0.029046 - Val Loss: 0.044641\n",
      "Epoch 47/50 - Train Loss: 0.032201 - Val Loss: 0.046724\n",
      "Epoch 48/50 - Train Loss: 0.029491 - Val Loss: 0.051226\n",
      "Epoch 49/50 - Train Loss: 0.031349 - Val Loss: 0.044642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:40:37,248] Trial 53 finished with value: 0.04427872225642204 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 82, 'lr': 0.005235813740998371, 'weight_decay': 4.827040873502726e-08, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031372 - Val Loss: 0.044286\n",
      "Epoch 1/50 - Train Loss: 0.087444 - Val Loss: 0.140984\n",
      "Epoch 2/50 - Train Loss: 0.048716 - Val Loss: 0.067639\n",
      "Epoch 3/50 - Train Loss: 0.043925 - Val Loss: 0.086884\n",
      "Epoch 4/50 - Train Loss: 0.041330 - Val Loss: 0.067340\n",
      "Epoch 5/50 - Train Loss: 0.035704 - Val Loss: 0.053335\n",
      "Epoch 6/50 - Train Loss: 0.034626 - Val Loss: 0.053354\n",
      "Epoch 7/50 - Train Loss: 0.029246 - Val Loss: 0.049533\n",
      "Epoch 8/50 - Train Loss: 0.032156 - Val Loss: 0.045770\n",
      "Epoch 9/50 - Train Loss: 0.034442 - Val Loss: 0.045859\n",
      "Epoch 10/50 - Train Loss: 0.034293 - Val Loss: 0.044483\n",
      "Epoch 11/50 - Train Loss: 0.030963 - Val Loss: 0.055626\n",
      "Epoch 12/50 - Train Loss: 0.033052 - Val Loss: 0.055737\n",
      "Epoch 13/50 - Train Loss: 0.032678 - Val Loss: 0.046654\n",
      "Epoch 14/50 - Train Loss: 0.035413 - Val Loss: 0.044461\n",
      "Epoch 15/50 - Train Loss: 0.032163 - Val Loss: 0.044303\n",
      "Epoch 16/50 - Train Loss: 0.030131 - Val Loss: 0.045074\n",
      "Epoch 17/50 - Train Loss: 0.038356 - Val Loss: 0.047812\n",
      "Epoch 18/50 - Train Loss: 0.033157 - Val Loss: 0.052670\n",
      "Epoch 19/50 - Train Loss: 0.030937 - Val Loss: 0.044342\n",
      "Epoch 20/50 - Train Loss: 0.026985 - Val Loss: 0.044747\n",
      "Epoch 21/50 - Train Loss: 0.031109 - Val Loss: 0.044238\n",
      "Epoch 22/50 - Train Loss: 0.030744 - Val Loss: 0.045718\n",
      "Epoch 23/50 - Train Loss: 0.029900 - Val Loss: 0.044063\n",
      "Epoch 24/50 - Train Loss: 0.033709 - Val Loss: 0.046173\n",
      "Epoch 25/50 - Train Loss: 0.032548 - Val Loss: 0.043631\n",
      "Epoch 26/50 - Train Loss: 0.033166 - Val Loss: 0.045574\n",
      "Epoch 27/50 - Train Loss: 0.033563 - Val Loss: 0.045607\n",
      "Epoch 28/50 - Train Loss: 0.032343 - Val Loss: 0.044401\n",
      "Epoch 29/50 - Train Loss: 0.029322 - Val Loss: 0.045740\n",
      "Epoch 30/50 - Train Loss: 0.030562 - Val Loss: 0.045821\n",
      "Epoch 31/50 - Train Loss: 0.029765 - Val Loss: 0.045083\n",
      "Epoch 32/50 - Train Loss: 0.030737 - Val Loss: 0.048834\n",
      "Epoch 33/50 - Train Loss: 0.032709 - Val Loss: 0.048553\n",
      "Epoch 34/50 - Train Loss: 0.036154 - Val Loss: 0.043669\n",
      "Epoch 35/50 - Train Loss: 0.031968 - Val Loss: 0.044791\n",
      "Epoch 36/50 - Train Loss: 0.033218 - Val Loss: 0.046565\n",
      "Epoch 37/50 - Train Loss: 0.029474 - Val Loss: 0.044917\n",
      "Epoch 38/50 - Train Loss: 0.031844 - Val Loss: 0.049849\n",
      "Epoch 39/50 - Train Loss: 0.032630 - Val Loss: 0.044507\n",
      "Epoch 40/50 - Train Loss: 0.030322 - Val Loss: 0.046398\n",
      "Epoch 41/50 - Train Loss: 0.031052 - Val Loss: 0.047633\n",
      "Epoch 42/50 - Train Loss: 0.034281 - Val Loss: 0.045198\n",
      "Epoch 43/50 - Train Loss: 0.030477 - Val Loss: 0.044267\n",
      "Epoch 44/50 - Train Loss: 0.036382 - Val Loss: 0.046272\n",
      "Epoch 45/50 - Train Loss: 0.030621 - Val Loss: 0.045101\n",
      "Epoch 46/50 - Train Loss: 0.032417 - Val Loss: 0.048641\n",
      "Epoch 47/50 - Train Loss: 0.031757 - Val Loss: 0.049451\n",
      "Epoch 48/50 - Train Loss: 0.030487 - Val Loss: 0.046771\n",
      "Epoch 49/50 - Train Loss: 0.031206 - Val Loss: 0.045158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:40:57,655] Trial 54 finished with value: 0.043630797415971756 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 75, 'lr': 0.009977082575321043, 'weight_decay': 1.5273494000921712e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033732 - Val Loss: 0.045510\n",
      "Epoch 1/50 - Train Loss: 0.075696 - Val Loss: 0.061327\n",
      "Epoch 2/50 - Train Loss: 0.040817 - Val Loss: 0.097651\n",
      "Epoch 3/50 - Train Loss: 0.043900 - Val Loss: 0.073542\n",
      "Epoch 4/50 - Train Loss: 0.038584 - Val Loss: 0.071649\n",
      "Epoch 5/50 - Train Loss: 0.035462 - Val Loss: 0.057130\n",
      "Epoch 6/50 - Train Loss: 0.034159 - Val Loss: 0.055178\n",
      "Epoch 7/50 - Train Loss: 0.031827 - Val Loss: 0.046782\n",
      "Epoch 8/50 - Train Loss: 0.032093 - Val Loss: 0.046488\n",
      "Epoch 9/50 - Train Loss: 0.033020 - Val Loss: 0.050347\n",
      "Epoch 10/50 - Train Loss: 0.028537 - Val Loss: 0.053049\n",
      "Epoch 11/50 - Train Loss: 0.032309 - Val Loss: 0.044503\n",
      "Epoch 12/50 - Train Loss: 0.035629 - Val Loss: 0.056128\n",
      "Epoch 13/50 - Train Loss: 0.031165 - Val Loss: 0.045565\n",
      "Epoch 14/50 - Train Loss: 0.035273 - Val Loss: 0.050524\n",
      "Epoch 15/50 - Train Loss: 0.032350 - Val Loss: 0.047383\n",
      "Epoch 16/50 - Train Loss: 0.032693 - Val Loss: 0.047554\n",
      "Epoch 17/50 - Train Loss: 0.030538 - Val Loss: 0.050023\n",
      "Epoch 18/50 - Train Loss: 0.031060 - Val Loss: 0.045180\n",
      "Epoch 19/50 - Train Loss: 0.033765 - Val Loss: 0.046554\n",
      "Epoch 20/50 - Train Loss: 0.027905 - Val Loss: 0.051763\n",
      "Epoch 21/50 - Train Loss: 0.035897 - Val Loss: 0.044746\n",
      "Epoch 22/50 - Train Loss: 0.033646 - Val Loss: 0.053289\n",
      "Epoch 23/50 - Train Loss: 0.030020 - Val Loss: 0.045417\n",
      "Epoch 24/50 - Train Loss: 0.030406 - Val Loss: 0.044384\n",
      "Epoch 25/50 - Train Loss: 0.030990 - Val Loss: 0.047241\n",
      "Epoch 26/50 - Train Loss: 0.028270 - Val Loss: 0.044538\n",
      "Epoch 27/50 - Train Loss: 0.031136 - Val Loss: 0.047920\n",
      "Epoch 28/50 - Train Loss: 0.029969 - Val Loss: 0.045343\n",
      "Epoch 29/50 - Train Loss: 0.029509 - Val Loss: 0.045007\n",
      "Epoch 30/50 - Train Loss: 0.029288 - Val Loss: 0.048986\n",
      "Epoch 31/50 - Train Loss: 0.029841 - Val Loss: 0.044396\n",
      "Epoch 32/50 - Train Loss: 0.031994 - Val Loss: 0.047192\n",
      "Epoch 33/50 - Train Loss: 0.031142 - Val Loss: 0.046234\n",
      "Epoch 34/50 - Train Loss: 0.030115 - Val Loss: 0.044273\n",
      "Epoch 35/50 - Train Loss: 0.027637 - Val Loss: 0.053394\n",
      "Epoch 36/50 - Train Loss: 0.030961 - Val Loss: 0.044702\n",
      "Epoch 37/50 - Train Loss: 0.029468 - Val Loss: 0.053204\n",
      "Epoch 38/50 - Train Loss: 0.030360 - Val Loss: 0.044668\n",
      "Epoch 39/50 - Train Loss: 0.030517 - Val Loss: 0.044073\n",
      "Epoch 40/50 - Train Loss: 0.032427 - Val Loss: 0.059554\n",
      "Epoch 41/50 - Train Loss: 0.035182 - Val Loss: 0.044913\n",
      "Epoch 42/50 - Train Loss: 0.033559 - Val Loss: 0.050461\n",
      "Epoch 43/50 - Train Loss: 0.029943 - Val Loss: 0.044627\n",
      "Epoch 44/50 - Train Loss: 0.031476 - Val Loss: 0.043727\n",
      "Epoch 45/50 - Train Loss: 0.035214 - Val Loss: 0.050277\n",
      "Epoch 46/50 - Train Loss: 0.031226 - Val Loss: 0.048669\n",
      "Epoch 47/50 - Train Loss: 0.030447 - Val Loss: 0.043735\n",
      "Epoch 48/50 - Train Loss: 0.034953 - Val Loss: 0.047961\n",
      "Epoch 49/50 - Train Loss: 0.032222 - Val Loss: 0.045749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:41:15,429] Trial 55 finished with value: 0.043727049604058266 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 57, 'lr': 0.0036646737280261413, 'weight_decay': 5.141632508738916e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.027587 - Val Loss: 0.045119\n",
      "Epoch 1/50 - Train Loss: 0.234172 - Val Loss: 0.387780\n",
      "Epoch 2/50 - Train Loss: 0.226967 - Val Loss: 0.383133\n",
      "Epoch 3/50 - Train Loss: 0.225299 - Val Loss: 0.378542\n",
      "Epoch 4/50 - Train Loss: 0.226034 - Val Loss: 0.373999\n",
      "Epoch 5/50 - Train Loss: 0.225188 - Val Loss: 0.369497\n",
      "Epoch 6/50 - Train Loss: 0.224224 - Val Loss: 0.365034\n",
      "Epoch 7/50 - Train Loss: 0.215486 - Val Loss: 0.360596\n",
      "Epoch 8/50 - Train Loss: 0.176654 - Val Loss: 0.356272\n",
      "Epoch 9/50 - Train Loss: 0.209043 - Val Loss: 0.351943\n",
      "Epoch 10/50 - Train Loss: 0.199137 - Val Loss: 0.347620\n",
      "Epoch 11/50 - Train Loss: 0.198072 - Val Loss: 0.343313\n",
      "Epoch 12/50 - Train Loss: 0.170854 - Val Loss: 0.339104\n",
      "Epoch 13/50 - Train Loss: 0.194761 - Val Loss: 0.334848\n",
      "Epoch 14/50 - Train Loss: 0.189733 - Val Loss: 0.330495\n",
      "Epoch 15/50 - Train Loss: 0.185923 - Val Loss: 0.325987\n",
      "Epoch 16/50 - Train Loss: 0.158920 - Val Loss: 0.321427\n",
      "Epoch 17/50 - Train Loss: 0.155590 - Val Loss: 0.316878\n",
      "Epoch 18/50 - Train Loss: 0.176739 - Val Loss: 0.312255\n",
      "Epoch 19/50 - Train Loss: 0.154149 - Val Loss: 0.307640\n",
      "Epoch 20/50 - Train Loss: 0.144061 - Val Loss: 0.302989\n",
      "Epoch 21/50 - Train Loss: 0.169335 - Val Loss: 0.298199\n",
      "Epoch 22/50 - Train Loss: 0.134922 - Val Loss: 0.293348\n",
      "Epoch 23/50 - Train Loss: 0.135271 - Val Loss: 0.288510\n",
      "Epoch 24/50 - Train Loss: 0.133129 - Val Loss: 0.283716\n",
      "Epoch 25/50 - Train Loss: 0.127574 - Val Loss: 0.278859\n",
      "Epoch 26/50 - Train Loss: 0.127430 - Val Loss: 0.274049\n",
      "Epoch 27/50 - Train Loss: 0.123939 - Val Loss: 0.269146\n",
      "Epoch 28/50 - Train Loss: 0.117205 - Val Loss: 0.264285\n",
      "Epoch 29/50 - Train Loss: 0.118979 - Val Loss: 0.259348\n",
      "Epoch 30/50 - Train Loss: 0.116103 - Val Loss: 0.254399\n",
      "Epoch 31/50 - Train Loss: 0.114569 - Val Loss: 0.249492\n",
      "Epoch 32/50 - Train Loss: 0.110979 - Val Loss: 0.244487\n",
      "Epoch 33/50 - Train Loss: 0.108697 - Val Loss: 0.239521\n",
      "Epoch 34/50 - Train Loss: 0.110094 - Val Loss: 0.234528\n",
      "Epoch 35/50 - Train Loss: 0.097492 - Val Loss: 0.229479\n",
      "Epoch 36/50 - Train Loss: 0.116982 - Val Loss: 0.224263\n",
      "Epoch 37/50 - Train Loss: 0.109248 - Val Loss: 0.218871\n",
      "Epoch 38/50 - Train Loss: 0.088346 - Val Loss: 0.213490\n",
      "Epoch 39/50 - Train Loss: 0.107084 - Val Loss: 0.207990\n",
      "Epoch 40/50 - Train Loss: 0.085003 - Val Loss: 0.202414\n",
      "Epoch 41/50 - Train Loss: 0.096611 - Val Loss: 0.196804\n",
      "Epoch 42/50 - Train Loss: 0.095127 - Val Loss: 0.191128\n",
      "Epoch 43/50 - Train Loss: 0.075620 - Val Loss: 0.185432\n",
      "Epoch 44/50 - Train Loss: 0.074866 - Val Loss: 0.179827\n",
      "Epoch 45/50 - Train Loss: 0.082586 - Val Loss: 0.174266\n",
      "Epoch 46/50 - Train Loss: 0.077133 - Val Loss: 0.168685\n",
      "Epoch 47/50 - Train Loss: 0.075567 - Val Loss: 0.163165\n",
      "Epoch 48/50 - Train Loss: 0.062290 - Val Loss: 0.157816\n",
      "Epoch 49/50 - Train Loss: 0.071225 - Val Loss: 0.152514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:41:29,209] Trial 56 finished with value: 0.14726224541664124 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 103, 'lr': 7.328034613176992e-05, 'weight_decay': 2.728771710835039e-06, 'batch_size': 64}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.066627 - Val Loss: 0.147262\n",
      "Epoch 1/50 - Train Loss: 0.100025 - Val Loss: 0.081218\n",
      "Epoch 2/50 - Train Loss: 0.048835 - Val Loss: 0.070406\n",
      "Epoch 3/50 - Train Loss: 0.040508 - Val Loss: 0.077923\n",
      "Epoch 4/50 - Train Loss: 0.036792 - Val Loss: 0.054765\n",
      "Epoch 5/50 - Train Loss: 0.034422 - Val Loss: 0.062966\n",
      "Epoch 6/50 - Train Loss: 0.035100 - Val Loss: 0.053913\n",
      "Epoch 7/50 - Train Loss: 0.034010 - Val Loss: 0.052379\n",
      "Epoch 8/50 - Train Loss: 0.031954 - Val Loss: 0.046313\n",
      "Epoch 9/50 - Train Loss: 0.031765 - Val Loss: 0.047361\n",
      "Epoch 10/50 - Train Loss: 0.036549 - Val Loss: 0.050502\n",
      "Epoch 11/50 - Train Loss: 0.031384 - Val Loss: 0.047320\n",
      "Epoch 12/50 - Train Loss: 0.033972 - Val Loss: 0.045900\n",
      "Epoch 13/50 - Train Loss: 0.031218 - Val Loss: 0.050857\n",
      "Epoch 14/50 - Train Loss: 0.028425 - Val Loss: 0.046612\n",
      "Epoch 15/50 - Train Loss: 0.032129 - Val Loss: 0.045671\n",
      "Epoch 16/50 - Train Loss: 0.030398 - Val Loss: 0.048263\n",
      "Epoch 17/50 - Train Loss: 0.033629 - Val Loss: 0.048559\n",
      "Epoch 18/50 - Train Loss: 0.032656 - Val Loss: 0.045651\n",
      "Epoch 19/50 - Train Loss: 0.032468 - Val Loss: 0.045251\n",
      "Epoch 20/50 - Train Loss: 0.031171 - Val Loss: 0.051291\n",
      "Epoch 21/50 - Train Loss: 0.031484 - Val Loss: 0.050100\n",
      "Epoch 22/50 - Train Loss: 0.032530 - Val Loss: 0.048627\n",
      "Epoch 23/50 - Train Loss: 0.031602 - Val Loss: 0.049263\n",
      "Epoch 24/50 - Train Loss: 0.031540 - Val Loss: 0.045402\n",
      "Epoch 25/50 - Train Loss: 0.031052 - Val Loss: 0.044688\n",
      "Epoch 26/50 - Train Loss: 0.029770 - Val Loss: 0.044964\n",
      "Epoch 27/50 - Train Loss: 0.032867 - Val Loss: 0.048341\n",
      "Epoch 28/50 - Train Loss: 0.033685 - Val Loss: 0.049118\n",
      "Epoch 29/50 - Train Loss: 0.031800 - Val Loss: 0.046619\n",
      "Epoch 30/50 - Train Loss: 0.031275 - Val Loss: 0.045344\n",
      "Epoch 31/50 - Train Loss: 0.029685 - Val Loss: 0.049300\n",
      "Epoch 32/50 - Train Loss: 0.030145 - Val Loss: 0.046594\n",
      "Epoch 33/50 - Train Loss: 0.031651 - Val Loss: 0.050344\n",
      "Epoch 34/50 - Train Loss: 0.030130 - Val Loss: 0.046037\n",
      "Epoch 35/50 - Train Loss: 0.029517 - Val Loss: 0.044651\n",
      "Epoch 36/50 - Train Loss: 0.030493 - Val Loss: 0.045185\n",
      "Epoch 37/50 - Train Loss: 0.031488 - Val Loss: 0.045248\n",
      "Epoch 38/50 - Train Loss: 0.032094 - Val Loss: 0.045500\n",
      "Epoch 39/50 - Train Loss: 0.029708 - Val Loss: 0.045320\n",
      "Epoch 40/50 - Train Loss: 0.033594 - Val Loss: 0.047709\n",
      "Epoch 41/50 - Train Loss: 0.030993 - Val Loss: 0.047605\n",
      "Epoch 42/50 - Train Loss: 0.031051 - Val Loss: 0.046028\n",
      "Epoch 43/50 - Train Loss: 0.029073 - Val Loss: 0.044686\n",
      "Epoch 44/50 - Train Loss: 0.031081 - Val Loss: 0.045843\n",
      "Epoch 45/50 - Train Loss: 0.034408 - Val Loss: 0.049255\n",
      "Epoch 46/50 - Train Loss: 0.033734 - Val Loss: 0.052015\n",
      "Epoch 47/50 - Train Loss: 0.031727 - Val Loss: 0.046665\n",
      "Epoch 48/50 - Train Loss: 0.031336 - Val Loss: 0.044473\n",
      "Epoch 49/50 - Train Loss: 0.031269 - Val Loss: 0.044902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:41:51,318] Trial 57 finished with value: 0.04447280615568161 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 32, 'lr': 0.005656156164981346, 'weight_decay': 4.4318294643104625e-05, 'batch_size': 8}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030174 - Val Loss: 0.045234\n",
      "Epoch 1/50 - Train Loss: 0.136416 - Val Loss: 0.141717\n",
      "Epoch 2/50 - Train Loss: 0.044454 - Val Loss: 0.083638\n",
      "Epoch 3/50 - Train Loss: 0.041137 - Val Loss: 0.064928\n",
      "Epoch 4/50 - Train Loss: 0.036845 - Val Loss: 0.048597\n",
      "Epoch 5/50 - Train Loss: 0.034915 - Val Loss: 0.063789\n",
      "Epoch 6/50 - Train Loss: 0.037336 - Val Loss: 0.047700\n",
      "Epoch 7/50 - Train Loss: 0.034607 - Val Loss: 0.068553\n",
      "Epoch 8/50 - Train Loss: 0.033957 - Val Loss: 0.046521\n",
      "Epoch 9/50 - Train Loss: 0.033953 - Val Loss: 0.048710\n",
      "Epoch 10/50 - Train Loss: 0.030627 - Val Loss: 0.045048\n",
      "Epoch 11/50 - Train Loss: 0.028709 - Val Loss: 0.049314\n",
      "Epoch 12/50 - Train Loss: 0.036224 - Val Loss: 0.051509\n",
      "Epoch 13/50 - Train Loss: 0.032718 - Val Loss: 0.044947\n",
      "Epoch 14/50 - Train Loss: 0.030356 - Val Loss: 0.045253\n",
      "Epoch 15/50 - Train Loss: 0.033816 - Val Loss: 0.047062\n",
      "Epoch 16/50 - Train Loss: 0.031394 - Val Loss: 0.045632\n",
      "Epoch 17/50 - Train Loss: 0.030992 - Val Loss: 0.058553\n",
      "Epoch 18/50 - Train Loss: 0.031773 - Val Loss: 0.047552\n",
      "Epoch 19/50 - Train Loss: 0.030068 - Val Loss: 0.046739\n",
      "Epoch 20/50 - Train Loss: 0.028654 - Val Loss: 0.045905\n",
      "Epoch 21/50 - Train Loss: 0.032651 - Val Loss: 0.045104\n",
      "Epoch 22/50 - Train Loss: 0.032246 - Val Loss: 0.046212\n",
      "Epoch 23/50 - Train Loss: 0.034823 - Val Loss: 0.054520\n",
      "Epoch 24/50 - Train Loss: 0.033603 - Val Loss: 0.046005\n",
      "Epoch 25/50 - Train Loss: 0.031072 - Val Loss: 0.045066\n",
      "Epoch 26/50 - Train Loss: 0.030464 - Val Loss: 0.047012\n",
      "Epoch 27/50 - Train Loss: 0.029219 - Val Loss: 0.048132\n",
      "Epoch 28/50 - Train Loss: 0.032232 - Val Loss: 0.044160\n",
      "Epoch 29/50 - Train Loss: 0.033263 - Val Loss: 0.045767\n",
      "Epoch 30/50 - Train Loss: 0.028834 - Val Loss: 0.048505\n",
      "Epoch 31/50 - Train Loss: 0.030663 - Val Loss: 0.048585\n",
      "Epoch 32/50 - Train Loss: 0.030163 - Val Loss: 0.052727\n",
      "Epoch 33/50 - Train Loss: 0.032104 - Val Loss: 0.044728\n",
      "Epoch 34/50 - Train Loss: 0.034173 - Val Loss: 0.053485\n",
      "Epoch 35/50 - Train Loss: 0.030917 - Val Loss: 0.044712\n",
      "Epoch 36/50 - Train Loss: 0.029317 - Val Loss: 0.045725\n",
      "Epoch 37/50 - Train Loss: 0.030615 - Val Loss: 0.046178\n",
      "Epoch 38/50 - Train Loss: 0.029446 - Val Loss: 0.047310\n",
      "Epoch 39/50 - Train Loss: 0.031469 - Val Loss: 0.049137\n",
      "Epoch 40/50 - Train Loss: 0.030222 - Val Loss: 0.045626\n",
      "Epoch 41/50 - Train Loss: 0.029066 - Val Loss: 0.048221\n",
      "Epoch 42/50 - Train Loss: 0.033340 - Val Loss: 0.048806\n",
      "Epoch 43/50 - Train Loss: 0.031006 - Val Loss: 0.048294\n",
      "Epoch 44/50 - Train Loss: 0.030788 - Val Loss: 0.046476\n",
      "Epoch 45/50 - Train Loss: 0.031673 - Val Loss: 0.047855\n",
      "Epoch 46/50 - Train Loss: 0.030836 - Val Loss: 0.045542\n",
      "Epoch 47/50 - Train Loss: 0.029254 - Val Loss: 0.050585\n",
      "Epoch 48/50 - Train Loss: 0.029595 - Val Loss: 0.050656\n",
      "Epoch 49/50 - Train Loss: 0.029205 - Val Loss: 0.047687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:42:44,158] Trial 58 finished with value: 0.04415996621052424 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 147, 'lr': 0.00763024659303532, 'weight_decay': 3.030473380206776e-07, 'batch_size': 8}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031323 - Val Loss: 0.046080\n",
      "Epoch 1/50 - Train Loss: 0.103368 - Val Loss: 0.066750\n",
      "Epoch 2/50 - Train Loss: 0.057621 - Val Loss: 0.107829\n",
      "Epoch 3/50 - Train Loss: 0.047383 - Val Loss: 0.082822\n",
      "Epoch 4/50 - Train Loss: 0.044553 - Val Loss: 0.073617\n",
      "Epoch 5/50 - Train Loss: 0.042236 - Val Loss: 0.082740\n",
      "Epoch 6/50 - Train Loss: 0.039535 - Val Loss: 0.064664\n",
      "Epoch 7/50 - Train Loss: 0.036579 - Val Loss: 0.060237\n",
      "Epoch 8/50 - Train Loss: 0.035130 - Val Loss: 0.060897\n",
      "Epoch 9/50 - Train Loss: 0.036584 - Val Loss: 0.050706\n",
      "Epoch 10/50 - Train Loss: 0.034983 - Val Loss: 0.055724\n",
      "Epoch 11/50 - Train Loss: 0.030726 - Val Loss: 0.047114\n",
      "Epoch 12/50 - Train Loss: 0.032352 - Val Loss: 0.048987\n",
      "Epoch 13/50 - Train Loss: 0.034445 - Val Loss: 0.053399\n",
      "Epoch 14/50 - Train Loss: 0.029462 - Val Loss: 0.047004\n",
      "Epoch 15/50 - Train Loss: 0.031386 - Val Loss: 0.045480\n",
      "Epoch 16/50 - Train Loss: 0.031057 - Val Loss: 0.045614\n",
      "Epoch 17/50 - Train Loss: 0.033680 - Val Loss: 0.045242\n",
      "Epoch 18/50 - Train Loss: 0.032241 - Val Loss: 0.047932\n",
      "Epoch 19/50 - Train Loss: 0.030826 - Val Loss: 0.045603\n",
      "Epoch 20/50 - Train Loss: 0.029158 - Val Loss: 0.044307\n",
      "Epoch 21/50 - Train Loss: 0.034941 - Val Loss: 0.054027\n",
      "Epoch 22/50 - Train Loss: 0.030824 - Val Loss: 0.045425\n",
      "Epoch 23/50 - Train Loss: 0.030727 - Val Loss: 0.044852\n",
      "Epoch 24/50 - Train Loss: 0.029852 - Val Loss: 0.046480\n",
      "Epoch 25/50 - Train Loss: 0.029540 - Val Loss: 0.044150\n",
      "Epoch 26/50 - Train Loss: 0.027349 - Val Loss: 0.045642\n",
      "Epoch 27/50 - Train Loss: 0.035438 - Val Loss: 0.049168\n",
      "Epoch 28/50 - Train Loss: 0.030860 - Val Loss: 0.044920\n",
      "Epoch 29/50 - Train Loss: 0.032715 - Val Loss: 0.045393\n",
      "Epoch 30/50 - Train Loss: 0.033273 - Val Loss: 0.048270\n",
      "Epoch 31/50 - Train Loss: 0.031048 - Val Loss: 0.043860\n",
      "Epoch 32/50 - Train Loss: 0.032945 - Val Loss: 0.047152\n",
      "Epoch 33/50 - Train Loss: 0.030169 - Val Loss: 0.043616\n",
      "Epoch 34/50 - Train Loss: 0.030059 - Val Loss: 0.047157\n",
      "Epoch 35/50 - Train Loss: 0.032110 - Val Loss: 0.045317\n",
      "Epoch 36/50 - Train Loss: 0.028335 - Val Loss: 0.044120\n",
      "Epoch 37/50 - Train Loss: 0.030773 - Val Loss: 0.046992\n",
      "Epoch 38/50 - Train Loss: 0.027410 - Val Loss: 0.044865\n",
      "Epoch 39/50 - Train Loss: 0.027709 - Val Loss: 0.044230\n",
      "Epoch 40/50 - Train Loss: 0.031067 - Val Loss: 0.044593\n",
      "Epoch 41/50 - Train Loss: 0.027295 - Val Loss: 0.044912\n",
      "Epoch 42/50 - Train Loss: 0.029407 - Val Loss: 0.043614\n",
      "Epoch 43/50 - Train Loss: 0.032582 - Val Loss: 0.044012\n",
      "Epoch 44/50 - Train Loss: 0.029730 - Val Loss: 0.051558\n",
      "Epoch 45/50 - Train Loss: 0.031859 - Val Loss: 0.046435\n",
      "Epoch 46/50 - Train Loss: 0.032350 - Val Loss: 0.045641\n",
      "Epoch 47/50 - Train Loss: 0.033066 - Val Loss: 0.045548\n",
      "Epoch 48/50 - Train Loss: 0.025103 - Val Loss: 0.043713\n",
      "Epoch 49/50 - Train Loss: 0.031026 - Val Loss: 0.043699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:43:04,727] Trial 59 finished with value: 0.04361438751220703 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 89, 'lr': 0.0025342824400800294, 'weight_decay': 1.908155957292515e-08, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031918 - Val Loss: 0.045933\n",
      "Epoch 1/50 - Train Loss: 0.094637 - Val Loss: 0.120732\n",
      "Epoch 2/50 - Train Loss: 0.046807 - Val Loss: 0.096458\n",
      "Epoch 3/50 - Train Loss: 0.039840 - Val Loss: 0.072577\n",
      "Epoch 4/50 - Train Loss: 0.039312 - Val Loss: 0.055662\n",
      "Epoch 5/50 - Train Loss: 0.034624 - Val Loss: 0.051721\n",
      "Epoch 6/50 - Train Loss: 0.035519 - Val Loss: 0.071992\n",
      "Epoch 7/50 - Train Loss: 0.034107 - Val Loss: 0.046158\n",
      "Epoch 8/50 - Train Loss: 0.033466 - Val Loss: 0.044641\n",
      "Epoch 9/50 - Train Loss: 0.031734 - Val Loss: 0.046381\n",
      "Epoch 10/50 - Train Loss: 0.030862 - Val Loss: 0.047724\n",
      "Epoch 11/50 - Train Loss: 0.030448 - Val Loss: 0.048362\n",
      "Epoch 12/50 - Train Loss: 0.032837 - Val Loss: 0.048025\n",
      "Epoch 13/50 - Train Loss: 0.031007 - Val Loss: 0.046049\n",
      "Epoch 14/50 - Train Loss: 0.030542 - Val Loss: 0.048473\n",
      "Epoch 15/50 - Train Loss: 0.029737 - Val Loss: 0.045658\n",
      "Epoch 16/50 - Train Loss: 0.032984 - Val Loss: 0.046004\n",
      "Epoch 17/50 - Train Loss: 0.034803 - Val Loss: 0.054831\n",
      "Epoch 18/50 - Train Loss: 0.031157 - Val Loss: 0.047333\n",
      "Epoch 19/50 - Train Loss: 0.032669 - Val Loss: 0.059425\n",
      "Epoch 20/50 - Train Loss: 0.035500 - Val Loss: 0.047003\n",
      "Epoch 21/50 - Train Loss: 0.037120 - Val Loss: 0.055283\n",
      "Epoch 22/50 - Train Loss: 0.034848 - Val Loss: 0.050741\n",
      "Epoch 23/50 - Train Loss: 0.030163 - Val Loss: 0.047793\n",
      "Epoch 24/50 - Train Loss: 0.031907 - Val Loss: 0.047665\n",
      "Epoch 25/50 - Train Loss: 0.030418 - Val Loss: 0.046126\n",
      "Epoch 26/50 - Train Loss: 0.031483 - Val Loss: 0.053266\n",
      "Epoch 27/50 - Train Loss: 0.032199 - Val Loss: 0.058159\n",
      "Epoch 28/50 - Train Loss: 0.029831 - Val Loss: 0.049701\n",
      "Epoch 29/50 - Train Loss: 0.030700 - Val Loss: 0.046086\n",
      "Epoch 30/50 - Train Loss: 0.027786 - Val Loss: 0.051601\n",
      "Epoch 31/50 - Train Loss: 0.031116 - Val Loss: 0.050408\n",
      "Epoch 32/50 - Train Loss: 0.032004 - Val Loss: 0.046321\n",
      "Epoch 33/50 - Train Loss: 0.032010 - Val Loss: 0.045244\n",
      "Epoch 34/50 - Train Loss: 0.031372 - Val Loss: 0.044351\n",
      "Epoch 35/50 - Train Loss: 0.030923 - Val Loss: 0.045171\n",
      "Epoch 36/50 - Train Loss: 0.027833 - Val Loss: 0.044389\n",
      "Epoch 37/50 - Train Loss: 0.026484 - Val Loss: 0.043958\n",
      "Epoch 38/50 - Train Loss: 0.026788 - Val Loss: 0.051081\n",
      "Epoch 39/50 - Train Loss: 0.029366 - Val Loss: 0.047370\n",
      "Epoch 40/50 - Train Loss: 0.029172 - Val Loss: 0.044031\n",
      "Epoch 41/50 - Train Loss: 0.031089 - Val Loss: 0.044313\n",
      "Epoch 42/50 - Train Loss: 0.032596 - Val Loss: 0.045205\n",
      "Epoch 43/50 - Train Loss: 0.027481 - Val Loss: 0.048307\n",
      "Epoch 44/50 - Train Loss: 0.031568 - Val Loss: 0.055411\n",
      "Epoch 45/50 - Train Loss: 0.031980 - Val Loss: 0.047682\n",
      "Epoch 46/50 - Train Loss: 0.030888 - Val Loss: 0.051256\n",
      "Epoch 47/50 - Train Loss: 0.032037 - Val Loss: 0.054161\n",
      "Epoch 48/50 - Train Loss: 0.033649 - Val Loss: 0.047207\n",
      "Epoch 49/50 - Train Loss: 0.032543 - Val Loss: 0.049994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:44:08,177] Trial 60 finished with value: 0.04395781084895134 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 247, 'lr': 0.004060333083718591, 'weight_decay': 1.1051047007202325e-07, 'batch_size': 8}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031092 - Val Loss: 0.048057\n",
      "Epoch 1/50 - Train Loss: 0.096111 - Val Loss: 0.152728\n",
      "Epoch 2/50 - Train Loss: 0.060750 - Val Loss: 0.116529\n",
      "Epoch 3/50 - Train Loss: 0.044153 - Val Loss: 0.066433\n",
      "Epoch 4/50 - Train Loss: 0.045072 - Val Loss: 0.089609\n",
      "Epoch 5/50 - Train Loss: 0.037829 - Val Loss: 0.082836\n",
      "Epoch 6/50 - Train Loss: 0.046428 - Val Loss: 0.069763\n",
      "Epoch 7/50 - Train Loss: 0.033821 - Val Loss: 0.061668\n",
      "Epoch 8/50 - Train Loss: 0.031270 - Val Loss: 0.049594\n",
      "Epoch 9/50 - Train Loss: 0.031368 - Val Loss: 0.046579\n",
      "Epoch 10/50 - Train Loss: 0.032089 - Val Loss: 0.045122\n",
      "Epoch 11/50 - Train Loss: 0.036081 - Val Loss: 0.045522\n",
      "Epoch 12/50 - Train Loss: 0.031420 - Val Loss: 0.045922\n",
      "Epoch 13/50 - Train Loss: 0.032221 - Val Loss: 0.051817\n",
      "Epoch 14/50 - Train Loss: 0.034887 - Val Loss: 0.054015\n",
      "Epoch 15/50 - Train Loss: 0.030921 - Val Loss: 0.045105\n",
      "Epoch 16/50 - Train Loss: 0.034315 - Val Loss: 0.044485\n",
      "Epoch 17/50 - Train Loss: 0.033165 - Val Loss: 0.047171\n",
      "Epoch 18/50 - Train Loss: 0.032614 - Val Loss: 0.044402\n",
      "Epoch 19/50 - Train Loss: 0.030110 - Val Loss: 0.044276\n",
      "Epoch 20/50 - Train Loss: 0.032566 - Val Loss: 0.047547\n",
      "Epoch 21/50 - Train Loss: 0.031780 - Val Loss: 0.047099\n",
      "Epoch 22/50 - Train Loss: 0.030925 - Val Loss: 0.045416\n",
      "Epoch 23/50 - Train Loss: 0.029600 - Val Loss: 0.044920\n",
      "Epoch 24/50 - Train Loss: 0.030220 - Val Loss: 0.044517\n",
      "Epoch 25/50 - Train Loss: 0.032908 - Val Loss: 0.045545\n",
      "Epoch 26/50 - Train Loss: 0.031379 - Val Loss: 0.046751\n",
      "Epoch 27/50 - Train Loss: 0.035471 - Val Loss: 0.046186\n",
      "Epoch 28/50 - Train Loss: 0.033468 - Val Loss: 0.048476\n",
      "Epoch 29/50 - Train Loss: 0.026971 - Val Loss: 0.045873\n",
      "Epoch 30/50 - Train Loss: 0.029481 - Val Loss: 0.045495\n",
      "Epoch 31/50 - Train Loss: 0.031444 - Val Loss: 0.052036\n",
      "Epoch 32/50 - Train Loss: 0.028792 - Val Loss: 0.049553\n",
      "Epoch 33/50 - Train Loss: 0.034354 - Val Loss: 0.045340\n",
      "Epoch 34/50 - Train Loss: 0.029828 - Val Loss: 0.046954\n",
      "Epoch 35/50 - Train Loss: 0.029953 - Val Loss: 0.045036\n",
      "Epoch 36/50 - Train Loss: 0.030392 - Val Loss: 0.045241\n",
      "Epoch 37/50 - Train Loss: 0.033195 - Val Loss: 0.044864\n",
      "Epoch 38/50 - Train Loss: 0.028820 - Val Loss: 0.044733\n",
      "Epoch 39/50 - Train Loss: 0.029167 - Val Loss: 0.044275\n",
      "Epoch 40/50 - Train Loss: 0.032334 - Val Loss: 0.044870\n",
      "Epoch 41/50 - Train Loss: 0.026713 - Val Loss: 0.049797\n",
      "Epoch 42/50 - Train Loss: 0.035287 - Val Loss: 0.051628\n",
      "Epoch 43/50 - Train Loss: 0.032876 - Val Loss: 0.046222\n",
      "Epoch 44/50 - Train Loss: 0.032724 - Val Loss: 0.043983\n",
      "Epoch 45/50 - Train Loss: 0.030754 - Val Loss: 0.053598\n",
      "Epoch 46/50 - Train Loss: 0.026946 - Val Loss: 0.045160\n",
      "Epoch 47/50 - Train Loss: 0.032240 - Val Loss: 0.045640\n",
      "Epoch 48/50 - Train Loss: 0.032174 - Val Loss: 0.046062\n",
      "Epoch 49/50 - Train Loss: 0.031309 - Val Loss: 0.050155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:44:35,445] Trial 61 finished with value: 0.04398341104388237 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 120, 'lr': 0.005531717368754512, 'weight_decay': 3.484017321539848e-08, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.026206 - Val Loss: 0.054704\n",
      "Epoch 1/50 - Train Loss: 0.068118 - Val Loss: 0.100519\n",
      "Epoch 2/50 - Train Loss: 0.043154 - Val Loss: 0.078560\n",
      "Epoch 3/50 - Train Loss: 0.040917 - Val Loss: 0.051576\n",
      "Epoch 4/50 - Train Loss: 0.036673 - Val Loss: 0.048177\n",
      "Epoch 5/50 - Train Loss: 0.037335 - Val Loss: 0.062983\n",
      "Epoch 6/50 - Train Loss: 0.034011 - Val Loss: 0.070715\n",
      "Epoch 7/50 - Train Loss: 0.034022 - Val Loss: 0.051640\n",
      "Epoch 8/50 - Train Loss: 0.032897 - Val Loss: 0.046331\n",
      "Epoch 9/50 - Train Loss: 0.033709 - Val Loss: 0.045979\n",
      "Epoch 10/50 - Train Loss: 0.032803 - Val Loss: 0.045236\n",
      "Epoch 11/50 - Train Loss: 0.031657 - Val Loss: 0.044889\n",
      "Epoch 12/50 - Train Loss: 0.034291 - Val Loss: 0.044931\n",
      "Epoch 13/50 - Train Loss: 0.035071 - Val Loss: 0.045875\n",
      "Epoch 14/50 - Train Loss: 0.034823 - Val Loss: 0.053498\n",
      "Epoch 15/50 - Train Loss: 0.029180 - Val Loss: 0.044629\n",
      "Epoch 16/50 - Train Loss: 0.030532 - Val Loss: 0.051468\n",
      "Epoch 17/50 - Train Loss: 0.032727 - Val Loss: 0.047639\n",
      "Epoch 18/50 - Train Loss: 0.028358 - Val Loss: 0.045804\n",
      "Epoch 19/50 - Train Loss: 0.032789 - Val Loss: 0.048876\n",
      "Epoch 20/50 - Train Loss: 0.032638 - Val Loss: 0.046808\n",
      "Epoch 21/50 - Train Loss: 0.029241 - Val Loss: 0.049837\n",
      "Epoch 22/50 - Train Loss: 0.028576 - Val Loss: 0.052877\n",
      "Epoch 23/50 - Train Loss: 0.030128 - Val Loss: 0.058376\n",
      "Epoch 24/50 - Train Loss: 0.033831 - Val Loss: 0.046231\n",
      "Epoch 25/50 - Train Loss: 0.031159 - Val Loss: 0.044566\n",
      "Epoch 26/50 - Train Loss: 0.032417 - Val Loss: 0.044935\n",
      "Epoch 27/50 - Train Loss: 0.032510 - Val Loss: 0.045928\n",
      "Epoch 28/50 - Train Loss: 0.029115 - Val Loss: 0.048595\n",
      "Epoch 29/50 - Train Loss: 0.033386 - Val Loss: 0.045022\n",
      "Epoch 30/50 - Train Loss: 0.032054 - Val Loss: 0.045077\n",
      "Epoch 31/50 - Train Loss: 0.034820 - Val Loss: 0.056338\n",
      "Epoch 32/50 - Train Loss: 0.030477 - Val Loss: 0.046355\n",
      "Epoch 33/50 - Train Loss: 0.029152 - Val Loss: 0.046216\n",
      "Epoch 34/50 - Train Loss: 0.030323 - Val Loss: 0.045186\n",
      "Epoch 35/50 - Train Loss: 0.032720 - Val Loss: 0.043975\n",
      "Epoch 36/50 - Train Loss: 0.028809 - Val Loss: 0.052098\n",
      "Epoch 37/50 - Train Loss: 0.030551 - Val Loss: 0.045316\n",
      "Epoch 38/50 - Train Loss: 0.028844 - Val Loss: 0.045331\n",
      "Epoch 39/50 - Train Loss: 0.034912 - Val Loss: 0.047060\n",
      "Epoch 40/50 - Train Loss: 0.028319 - Val Loss: 0.045738\n",
      "Epoch 41/50 - Train Loss: 0.032270 - Val Loss: 0.045623\n",
      "Epoch 42/50 - Train Loss: 0.027703 - Val Loss: 0.045976\n",
      "Epoch 43/50 - Train Loss: 0.030584 - Val Loss: 0.046313\n",
      "Epoch 44/50 - Train Loss: 0.029703 - Val Loss: 0.049107\n",
      "Epoch 45/50 - Train Loss: 0.032778 - Val Loss: 0.049037\n",
      "Epoch 46/50 - Train Loss: 0.030137 - Val Loss: 0.047970\n",
      "Epoch 47/50 - Train Loss: 0.032834 - Val Loss: 0.046347\n",
      "Epoch 48/50 - Train Loss: 0.033743 - Val Loss: 0.045227\n",
      "Epoch 49/50 - Train Loss: 0.029326 - Val Loss: 0.044520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:44:56,272] Trial 62 finished with value: 0.04397531785070896 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 85, 'lr': 0.00806255837995577, 'weight_decay': 1.9384039668226548e-08, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.028881 - Val Loss: 0.048014\n",
      "Epoch 1/50 - Train Loss: 0.120000 - Val Loss: 0.097018\n",
      "Epoch 2/50 - Train Loss: 0.047010 - Val Loss: 0.065377\n",
      "Epoch 3/50 - Train Loss: 0.041649 - Val Loss: 0.104651\n",
      "Epoch 4/50 - Train Loss: 0.043506 - Val Loss: 0.073742\n",
      "Epoch 5/50 - Train Loss: 0.041029 - Val Loss: 0.064029\n",
      "Epoch 6/50 - Train Loss: 0.036909 - Val Loss: 0.062706\n",
      "Epoch 7/50 - Train Loss: 0.036368 - Val Loss: 0.059949\n",
      "Epoch 8/50 - Train Loss: 0.034936 - Val Loss: 0.049941\n",
      "Epoch 9/50 - Train Loss: 0.033810 - Val Loss: 0.051680\n",
      "Epoch 10/50 - Train Loss: 0.031064 - Val Loss: 0.045400\n",
      "Epoch 11/50 - Train Loss: 0.032315 - Val Loss: 0.048627\n",
      "Epoch 12/50 - Train Loss: 0.033585 - Val Loss: 0.054624\n",
      "Epoch 13/50 - Train Loss: 0.031601 - Val Loss: 0.046274\n",
      "Epoch 14/50 - Train Loss: 0.028321 - Val Loss: 0.046090\n",
      "Epoch 15/50 - Train Loss: 0.032837 - Val Loss: 0.048459\n",
      "Epoch 16/50 - Train Loss: 0.030036 - Val Loss: 0.049856\n",
      "Epoch 17/50 - Train Loss: 0.030355 - Val Loss: 0.044469\n",
      "Epoch 18/50 - Train Loss: 0.031516 - Val Loss: 0.054393\n",
      "Epoch 19/50 - Train Loss: 0.030971 - Val Loss: 0.044686\n",
      "Epoch 20/50 - Train Loss: 0.030631 - Val Loss: 0.048528\n",
      "Epoch 21/50 - Train Loss: 0.034611 - Val Loss: 0.048203\n",
      "Epoch 22/50 - Train Loss: 0.028019 - Val Loss: 0.045965\n",
      "Epoch 23/50 - Train Loss: 0.031305 - Val Loss: 0.048648\n",
      "Epoch 24/50 - Train Loss: 0.030454 - Val Loss: 0.047957\n",
      "Epoch 25/50 - Train Loss: 0.033948 - Val Loss: 0.045524\n",
      "Epoch 26/50 - Train Loss: 0.031244 - Val Loss: 0.048653\n",
      "Epoch 27/50 - Train Loss: 0.029964 - Val Loss: 0.045711\n",
      "Epoch 28/50 - Train Loss: 0.028262 - Val Loss: 0.046748\n",
      "Epoch 29/50 - Train Loss: 0.028796 - Val Loss: 0.051676\n",
      "Epoch 30/50 - Train Loss: 0.034357 - Val Loss: 0.047757\n",
      "Epoch 31/50 - Train Loss: 0.030369 - Val Loss: 0.050507\n",
      "Epoch 32/50 - Train Loss: 0.031759 - Val Loss: 0.046111\n",
      "Epoch 33/50 - Train Loss: 0.030910 - Val Loss: 0.045117\n",
      "Epoch 34/50 - Train Loss: 0.030302 - Val Loss: 0.051258\n",
      "Epoch 35/50 - Train Loss: 0.029769 - Val Loss: 0.044866\n",
      "Epoch 36/50 - Train Loss: 0.033353 - Val Loss: 0.047708\n",
      "Epoch 37/50 - Train Loss: 0.032329 - Val Loss: 0.045666\n",
      "Epoch 38/50 - Train Loss: 0.032361 - Val Loss: 0.045007\n",
      "Epoch 39/50 - Train Loss: 0.032217 - Val Loss: 0.046385\n",
      "Epoch 40/50 - Train Loss: 0.031879 - Val Loss: 0.046168\n",
      "Epoch 41/50 - Train Loss: 0.027633 - Val Loss: 0.045802\n",
      "Epoch 42/50 - Train Loss: 0.029622 - Val Loss: 0.048589\n",
      "Epoch 43/50 - Train Loss: 0.030484 - Val Loss: 0.046935\n",
      "Epoch 44/50 - Train Loss: 0.028264 - Val Loss: 0.044807\n",
      "Epoch 45/50 - Train Loss: 0.031279 - Val Loss: 0.044193\n",
      "Epoch 46/50 - Train Loss: 0.032923 - Val Loss: 0.046053\n",
      "Epoch 47/50 - Train Loss: 0.031716 - Val Loss: 0.045622\n",
      "Epoch 48/50 - Train Loss: 0.033308 - Val Loss: 0.044007\n",
      "Epoch 49/50 - Train Loss: 0.030622 - Val Loss: 0.045172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:45:15,877] Trial 63 finished with value: 0.04400704428553581 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 62, 'lr': 0.002592641222560621, 'weight_decay': 1.6990456992770513e-08, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.029526 - Val Loss: 0.048148\n",
      "Epoch 1/50 - Train Loss: 0.141184 - Val Loss: 0.268983\n",
      "Epoch 2/50 - Train Loss: 0.117315 - Val Loss: 0.221539\n",
      "Epoch 3/50 - Train Loss: 0.083278 - Val Loss: 0.172003\n",
      "Epoch 4/50 - Train Loss: 0.061931 - Val Loss: 0.127240\n",
      "Epoch 5/50 - Train Loss: 0.049194 - Val Loss: 0.092432\n",
      "Epoch 6/50 - Train Loss: 0.049127 - Val Loss: 0.077481\n",
      "Epoch 7/50 - Train Loss: 0.046012 - Val Loss: 0.073747\n",
      "Epoch 8/50 - Train Loss: 0.042636 - Val Loss: 0.080414\n",
      "Epoch 9/50 - Train Loss: 0.043530 - Val Loss: 0.086527\n",
      "Epoch 10/50 - Train Loss: 0.042371 - Val Loss: 0.085218\n",
      "Epoch 11/50 - Train Loss: 0.039133 - Val Loss: 0.080220\n",
      "Epoch 12/50 - Train Loss: 0.042079 - Val Loss: 0.076328\n",
      "Epoch 13/50 - Train Loss: 0.041068 - Val Loss: 0.076405\n",
      "Epoch 14/50 - Train Loss: 0.042102 - Val Loss: 0.078428\n",
      "Epoch 15/50 - Train Loss: 0.037615 - Val Loss: 0.076455\n",
      "Epoch 16/50 - Train Loss: 0.037242 - Val Loss: 0.074505\n",
      "Epoch 17/50 - Train Loss: 0.040472 - Val Loss: 0.073284\n",
      "Epoch 18/50 - Train Loss: 0.038240 - Val Loss: 0.072951\n",
      "Epoch 19/50 - Train Loss: 0.038561 - Val Loss: 0.069293\n",
      "Epoch 20/50 - Train Loss: 0.038337 - Val Loss: 0.070066\n",
      "Epoch 21/50 - Train Loss: 0.036145 - Val Loss: 0.067450\n",
      "Epoch 22/50 - Train Loss: 0.038441 - Val Loss: 0.067770\n",
      "Epoch 23/50 - Train Loss: 0.034464 - Val Loss: 0.065890\n",
      "Epoch 24/50 - Train Loss: 0.031589 - Val Loss: 0.063231\n",
      "Epoch 25/50 - Train Loss: 0.033544 - Val Loss: 0.060777\n",
      "Epoch 26/50 - Train Loss: 0.034311 - Val Loss: 0.058456\n",
      "Epoch 27/50 - Train Loss: 0.033786 - Val Loss: 0.059771\n",
      "Epoch 28/50 - Train Loss: 0.033316 - Val Loss: 0.055898\n",
      "Epoch 29/50 - Train Loss: 0.034399 - Val Loss: 0.055592\n",
      "Epoch 30/50 - Train Loss: 0.033073 - Val Loss: 0.053561\n",
      "Epoch 31/50 - Train Loss: 0.030303 - Val Loss: 0.052284\n",
      "Epoch 32/50 - Train Loss: 0.034807 - Val Loss: 0.051320\n",
      "Epoch 33/50 - Train Loss: 0.032679 - Val Loss: 0.052417\n",
      "Epoch 34/50 - Train Loss: 0.034461 - Val Loss: 0.049988\n",
      "Epoch 35/50 - Train Loss: 0.034389 - Val Loss: 0.050024\n",
      "Epoch 36/50 - Train Loss: 0.030850 - Val Loss: 0.049947\n",
      "Epoch 37/50 - Train Loss: 0.030879 - Val Loss: 0.048794\n",
      "Epoch 38/50 - Train Loss: 0.033351 - Val Loss: 0.048917\n",
      "Epoch 39/50 - Train Loss: 0.030430 - Val Loss: 0.049058\n",
      "Epoch 40/50 - Train Loss: 0.028708 - Val Loss: 0.048461\n",
      "Epoch 41/50 - Train Loss: 0.031360 - Val Loss: 0.047860\n",
      "Epoch 42/50 - Train Loss: 0.031702 - Val Loss: 0.048603\n",
      "Epoch 43/50 - Train Loss: 0.032492 - Val Loss: 0.047953\n",
      "Epoch 44/50 - Train Loss: 0.031462 - Val Loss: 0.047670\n",
      "Epoch 45/50 - Train Loss: 0.032991 - Val Loss: 0.047550\n",
      "Epoch 46/50 - Train Loss: 0.033550 - Val Loss: 0.047336\n",
      "Epoch 47/50 - Train Loss: 0.034204 - Val Loss: 0.048407\n",
      "Epoch 48/50 - Train Loss: 0.030250 - Val Loss: 0.047124\n",
      "Epoch 49/50 - Train Loss: 0.030305 - Val Loss: 0.048139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:45:33,964] Trial 64 finished with value: 0.046884866431355476 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 73, 'lr': 0.0003078161001605997, 'weight_decay': 8.353259838466038e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031698 - Val Loss: 0.046885\n",
      "Epoch 1/50 - Train Loss: 0.094358 - Val Loss: 0.081018\n",
      "Epoch 2/50 - Train Loss: 0.049203 - Val Loss: 0.088081\n",
      "Epoch 3/50 - Train Loss: 0.046356 - Val Loss: 0.105429\n",
      "Epoch 4/50 - Train Loss: 0.045758 - Val Loss: 0.073938\n",
      "Epoch 5/50 - Train Loss: 0.041705 - Val Loss: 0.071726\n",
      "Epoch 6/50 - Train Loss: 0.041145 - Val Loss: 0.079642\n",
      "Epoch 7/50 - Train Loss: 0.035774 - Val Loss: 0.053512\n",
      "Epoch 8/50 - Train Loss: 0.035455 - Val Loss: 0.059281\n",
      "Epoch 9/50 - Train Loss: 0.034027 - Val Loss: 0.047413\n",
      "Epoch 10/50 - Train Loss: 0.031410 - Val Loss: 0.054465\n",
      "Epoch 11/50 - Train Loss: 0.029369 - Val Loss: 0.046547\n",
      "Epoch 12/50 - Train Loss: 0.033620 - Val Loss: 0.047844\n",
      "Epoch 13/50 - Train Loss: 0.028219 - Val Loss: 0.049946\n",
      "Epoch 14/50 - Train Loss: 0.032386 - Val Loss: 0.045455\n",
      "Epoch 15/50 - Train Loss: 0.030750 - Val Loss: 0.050647\n",
      "Epoch 16/50 - Train Loss: 0.031579 - Val Loss: 0.047200\n",
      "Epoch 17/50 - Train Loss: 0.032834 - Val Loss: 0.044680\n",
      "Epoch 18/50 - Train Loss: 0.033943 - Val Loss: 0.046683\n",
      "Epoch 19/50 - Train Loss: 0.030855 - Val Loss: 0.048552\n",
      "Epoch 20/50 - Train Loss: 0.035425 - Val Loss: 0.047664\n",
      "Epoch 21/50 - Train Loss: 0.029673 - Val Loss: 0.045597\n",
      "Epoch 22/50 - Train Loss: 0.031189 - Val Loss: 0.045328\n",
      "Epoch 23/50 - Train Loss: 0.031611 - Val Loss: 0.047114\n",
      "Epoch 24/50 - Train Loss: 0.033200 - Val Loss: 0.053301\n",
      "Epoch 25/50 - Train Loss: 0.034098 - Val Loss: 0.044903\n",
      "Epoch 26/50 - Train Loss: 0.030398 - Val Loss: 0.046034\n",
      "Epoch 27/50 - Train Loss: 0.030664 - Val Loss: 0.047375\n",
      "Epoch 28/50 - Train Loss: 0.032482 - Val Loss: 0.044163\n",
      "Epoch 29/50 - Train Loss: 0.030489 - Val Loss: 0.047282\n",
      "Epoch 30/50 - Train Loss: 0.029421 - Val Loss: 0.044351\n",
      "Epoch 31/50 - Train Loss: 0.032010 - Val Loss: 0.045396\n",
      "Epoch 32/50 - Train Loss: 0.034607 - Val Loss: 0.044636\n",
      "Epoch 33/50 - Train Loss: 0.032847 - Val Loss: 0.047918\n",
      "Epoch 34/50 - Train Loss: 0.031859 - Val Loss: 0.044705\n",
      "Epoch 35/50 - Train Loss: 0.031656 - Val Loss: 0.045309\n",
      "Epoch 36/50 - Train Loss: 0.030051 - Val Loss: 0.046231\n",
      "Epoch 37/50 - Train Loss: 0.031966 - Val Loss: 0.043887\n",
      "Epoch 38/50 - Train Loss: 0.031726 - Val Loss: 0.051970\n",
      "Epoch 39/50 - Train Loss: 0.033310 - Val Loss: 0.047462\n",
      "Epoch 40/50 - Train Loss: 0.029381 - Val Loss: 0.044238\n",
      "Epoch 41/50 - Train Loss: 0.032793 - Val Loss: 0.045810\n",
      "Epoch 42/50 - Train Loss: 0.028935 - Val Loss: 0.044934\n",
      "Epoch 43/50 - Train Loss: 0.027660 - Val Loss: 0.044387\n",
      "Epoch 44/50 - Train Loss: 0.034216 - Val Loss: 0.051539\n",
      "Epoch 45/50 - Train Loss: 0.029727 - Val Loss: 0.043837\n",
      "Epoch 46/50 - Train Loss: 0.029041 - Val Loss: 0.044364\n",
      "Epoch 47/50 - Train Loss: 0.029410 - Val Loss: 0.046125\n",
      "Epoch 48/50 - Train Loss: 0.033135 - Val Loss: 0.046462\n",
      "Epoch 49/50 - Train Loss: 0.028916 - Val Loss: 0.043797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:46:00,222] Trial 65 finished with value: 0.043797072023153305 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 98, 'lr': 0.0016705243315814106, 'weight_decay': 1.8708958409417404e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030305 - Val Loss: 0.044127\n",
      "Epoch 1/50 - Train Loss: 0.075324 - Val Loss: 0.117765\n",
      "Epoch 2/50 - Train Loss: 0.043244 - Val Loss: 0.075767\n",
      "Epoch 3/50 - Train Loss: 0.034499 - Val Loss: 0.059710\n",
      "Epoch 4/50 - Train Loss: 0.030245 - Val Loss: 0.051620\n",
      "Epoch 5/50 - Train Loss: 0.032448 - Val Loss: 0.046308\n",
      "Epoch 6/50 - Train Loss: 0.033301 - Val Loss: 0.057034\n",
      "Epoch 7/50 - Train Loss: 0.033996 - Val Loss: 0.049519\n",
      "Epoch 8/50 - Train Loss: 0.030901 - Val Loss: 0.047481\n",
      "Epoch 9/50 - Train Loss: 0.032952 - Val Loss: 0.050272\n",
      "Epoch 10/50 - Train Loss: 0.031832 - Val Loss: 0.044233\n",
      "Epoch 11/50 - Train Loss: 0.032138 - Val Loss: 0.050954\n",
      "Epoch 12/50 - Train Loss: 0.031629 - Val Loss: 0.044407\n",
      "Epoch 13/50 - Train Loss: 0.034229 - Val Loss: 0.054263\n",
      "Epoch 14/50 - Train Loss: 0.032430 - Val Loss: 0.044554\n",
      "Epoch 15/50 - Train Loss: 0.033878 - Val Loss: 0.045312\n",
      "Epoch 16/50 - Train Loss: 0.030385 - Val Loss: 0.049815\n",
      "Epoch 17/50 - Train Loss: 0.029862 - Val Loss: 0.044531\n",
      "Epoch 18/50 - Train Loss: 0.032186 - Val Loss: 0.049052\n",
      "Epoch 19/50 - Train Loss: 0.030251 - Val Loss: 0.044764\n",
      "Epoch 20/50 - Train Loss: 0.034605 - Val Loss: 0.064929\n",
      "Epoch 21/50 - Train Loss: 0.032016 - Val Loss: 0.044862\n",
      "Epoch 22/50 - Train Loss: 0.030932 - Val Loss: 0.043838\n",
      "Epoch 23/50 - Train Loss: 0.036266 - Val Loss: 0.060517\n",
      "Epoch 24/50 - Train Loss: 0.033484 - Val Loss: 0.045077\n",
      "Epoch 25/50 - Train Loss: 0.031200 - Val Loss: 0.044109\n",
      "Epoch 26/50 - Train Loss: 0.031401 - Val Loss: 0.052030\n",
      "Epoch 27/50 - Train Loss: 0.030593 - Val Loss: 0.054089\n",
      "Epoch 28/50 - Train Loss: 0.029579 - Val Loss: 0.045457\n",
      "Epoch 29/50 - Train Loss: 0.030794 - Val Loss: 0.043909\n",
      "Epoch 30/50 - Train Loss: 0.029127 - Val Loss: 0.057038\n",
      "Epoch 31/50 - Train Loss: 0.032016 - Val Loss: 0.065508\n",
      "Epoch 32/50 - Train Loss: 0.032029 - Val Loss: 0.053827\n",
      "Epoch 33/50 - Train Loss: 0.028501 - Val Loss: 0.044452\n",
      "Epoch 34/50 - Train Loss: 0.030138 - Val Loss: 0.054148\n",
      "Epoch 35/50 - Train Loss: 0.026500 - Val Loss: 0.045119\n",
      "Epoch 36/50 - Train Loss: 0.027250 - Val Loss: 0.047183\n",
      "Epoch 37/50 - Train Loss: 0.030022 - Val Loss: 0.044288\n",
      "Epoch 38/50 - Train Loss: 0.029803 - Val Loss: 0.045276\n",
      "Epoch 39/50 - Train Loss: 0.029443 - Val Loss: 0.049334\n",
      "Epoch 40/50 - Train Loss: 0.030366 - Val Loss: 0.048718\n",
      "Epoch 41/50 - Train Loss: 0.028941 - Val Loss: 0.044819\n",
      "Epoch 42/50 - Train Loss: 0.030154 - Val Loss: 0.045029\n",
      "Epoch 43/50 - Train Loss: 0.029952 - Val Loss: 0.044636\n",
      "Epoch 44/50 - Train Loss: 0.028433 - Val Loss: 0.044791\n",
      "Epoch 45/50 - Train Loss: 0.028440 - Val Loss: 0.046230\n",
      "Epoch 46/50 - Train Loss: 0.030259 - Val Loss: 0.049399\n",
      "Epoch 47/50 - Train Loss: 0.029404 - Val Loss: 0.054774\n",
      "Epoch 48/50 - Train Loss: 0.030297 - Val Loss: 0.052241\n",
      "Epoch 49/50 - Train Loss: 0.027618 - Val Loss: 0.044141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:46:50,448] Trial 66 finished with value: 0.04383792852361997 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 234, 'lr': 0.0032007179979921204, 'weight_decay': 2.2169738939572308e-07, 'batch_size': 8}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.028403 - Val Loss: 0.055408\n",
      "Epoch 1/50 - Train Loss: 0.092210 - Val Loss: 0.116901\n",
      "Epoch 2/50 - Train Loss: 0.047427 - Val Loss: 0.068814\n",
      "Epoch 3/50 - Train Loss: 0.047721 - Val Loss: 0.092142\n",
      "Epoch 4/50 - Train Loss: 0.045326 - Val Loss: 0.072654\n",
      "Epoch 5/50 - Train Loss: 0.038566 - Val Loss: 0.051342\n",
      "Epoch 6/50 - Train Loss: 0.038930 - Val Loss: 0.051660\n",
      "Epoch 7/50 - Train Loss: 0.039363 - Val Loss: 0.061147\n",
      "Epoch 8/50 - Train Loss: 0.037357 - Val Loss: 0.057780\n",
      "Epoch 9/50 - Train Loss: 0.033224 - Val Loss: 0.047362\n",
      "Epoch 10/50 - Train Loss: 0.036374 - Val Loss: 0.046118\n",
      "Epoch 11/50 - Train Loss: 0.034571 - Val Loss: 0.059756\n",
      "Epoch 12/50 - Train Loss: 0.033959 - Val Loss: 0.050196\n",
      "Epoch 13/50 - Train Loss: 0.030470 - Val Loss: 0.045757\n",
      "Epoch 14/50 - Train Loss: 0.034959 - Val Loss: 0.045771\n",
      "Epoch 15/50 - Train Loss: 0.028765 - Val Loss: 0.047427\n",
      "Epoch 16/50 - Train Loss: 0.030086 - Val Loss: 0.056407\n",
      "Epoch 17/50 - Train Loss: 0.033952 - Val Loss: 0.048064\n",
      "Epoch 18/50 - Train Loss: 0.032546 - Val Loss: 0.044939\n",
      "Epoch 19/50 - Train Loss: 0.030439 - Val Loss: 0.047343\n",
      "Epoch 20/50 - Train Loss: 0.033718 - Val Loss: 0.047185\n",
      "Epoch 21/50 - Train Loss: 0.035175 - Val Loss: 0.046161\n",
      "Epoch 22/50 - Train Loss: 0.028912 - Val Loss: 0.046726\n",
      "Epoch 23/50 - Train Loss: 0.029604 - Val Loss: 0.043587\n",
      "Epoch 24/50 - Train Loss: 0.028257 - Val Loss: 0.044396\n",
      "Epoch 25/50 - Train Loss: 0.035032 - Val Loss: 0.049171\n",
      "Epoch 26/50 - Train Loss: 0.030952 - Val Loss: 0.044078\n",
      "Epoch 27/50 - Train Loss: 0.032754 - Val Loss: 0.045879\n",
      "Epoch 28/50 - Train Loss: 0.032649 - Val Loss: 0.044587\n",
      "Epoch 29/50 - Train Loss: 0.032552 - Val Loss: 0.051244\n",
      "Epoch 30/50 - Train Loss: 0.031450 - Val Loss: 0.064189\n",
      "Epoch 31/50 - Train Loss: 0.030087 - Val Loss: 0.043480\n",
      "Epoch 32/50 - Train Loss: 0.036220 - Val Loss: 0.044715\n",
      "Epoch 33/50 - Train Loss: 0.029989 - Val Loss: 0.046141\n",
      "Epoch 34/50 - Train Loss: 0.030381 - Val Loss: 0.046222\n",
      "Epoch 35/50 - Train Loss: 0.035271 - Val Loss: 0.052167\n",
      "Epoch 36/50 - Train Loss: 0.031768 - Val Loss: 0.047025\n",
      "Epoch 37/50 - Train Loss: 0.027946 - Val Loss: 0.044530\n",
      "Epoch 38/50 - Train Loss: 0.029589 - Val Loss: 0.043653\n",
      "Epoch 39/50 - Train Loss: 0.031771 - Val Loss: 0.049308\n",
      "Epoch 40/50 - Train Loss: 0.031268 - Val Loss: 0.044133\n",
      "Epoch 41/50 - Train Loss: 0.033326 - Val Loss: 0.045799\n",
      "Epoch 42/50 - Train Loss: 0.031019 - Val Loss: 0.045084\n",
      "Epoch 43/50 - Train Loss: 0.027694 - Val Loss: 0.043828\n",
      "Epoch 44/50 - Train Loss: 0.031342 - Val Loss: 0.049136\n",
      "Epoch 45/50 - Train Loss: 0.034771 - Val Loss: 0.044197\n",
      "Epoch 46/50 - Train Loss: 0.033863 - Val Loss: 0.044494\n",
      "Epoch 47/50 - Train Loss: 0.030501 - Val Loss: 0.047245\n",
      "Epoch 48/50 - Train Loss: 0.027641 - Val Loss: 0.043390\n",
      "Epoch 49/50 - Train Loss: 0.029657 - Val Loss: 0.044169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:47:13,448] Trial 67 finished with value: 0.04339006729424 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 86, 'lr': 0.0064111231324617155, 'weight_decay': 7.59622165768459e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.032331 - Val Loss: 0.044586\n",
      "Epoch 1/50 - Train Loss: 0.200304 - Val Loss: 0.140635\n",
      "Epoch 2/50 - Train Loss: 0.137570 - Val Loss: 0.072763\n",
      "Epoch 3/50 - Train Loss: 0.050904 - Val Loss: 0.145339\n",
      "Epoch 4/50 - Train Loss: 0.061228 - Val Loss: 0.157592\n",
      "Epoch 5/50 - Train Loss: 0.063004 - Val Loss: 0.131218\n",
      "Epoch 6/50 - Train Loss: 0.050584 - Val Loss: 0.086010\n",
      "Epoch 7/50 - Train Loss: 0.052589 - Val Loss: 0.070125\n",
      "Epoch 8/50 - Train Loss: 0.053520 - Val Loss: 0.083857\n",
      "Epoch 9/50 - Train Loss: 0.042827 - Val Loss: 0.095011\n",
      "Epoch 10/50 - Train Loss: 0.049609 - Val Loss: 0.089516\n",
      "Epoch 11/50 - Train Loss: 0.049918 - Val Loss: 0.083048\n",
      "Epoch 12/50 - Train Loss: 0.049560 - Val Loss: 0.077728\n",
      "Epoch 13/50 - Train Loss: 0.040679 - Val Loss: 0.073893\n",
      "Epoch 14/50 - Train Loss: 0.045945 - Val Loss: 0.070478\n",
      "Epoch 15/50 - Train Loss: 0.043008 - Val Loss: 0.057792\n",
      "Epoch 16/50 - Train Loss: 0.042910 - Val Loss: 0.060664\n",
      "Epoch 17/50 - Train Loss: 0.041664 - Val Loss: 0.055992\n",
      "Epoch 18/50 - Train Loss: 0.031700 - Val Loss: 0.051795\n",
      "Epoch 19/50 - Train Loss: 0.040567 - Val Loss: 0.060954\n",
      "Epoch 20/50 - Train Loss: 0.033385 - Val Loss: 0.054426\n",
      "Epoch 21/50 - Train Loss: 0.032325 - Val Loss: 0.049305\n",
      "Epoch 22/50 - Train Loss: 0.038751 - Val Loss: 0.051437\n",
      "Epoch 23/50 - Train Loss: 0.037986 - Val Loss: 0.046815\n",
      "Epoch 24/50 - Train Loss: 0.037687 - Val Loss: 0.048978\n",
      "Epoch 25/50 - Train Loss: 0.029353 - Val Loss: 0.049629\n",
      "Epoch 26/50 - Train Loss: 0.036898 - Val Loss: 0.047492\n",
      "Epoch 27/50 - Train Loss: 0.036902 - Val Loss: 0.048119\n",
      "Epoch 28/50 - Train Loss: 0.029343 - Val Loss: 0.047087\n",
      "Epoch 29/50 - Train Loss: 0.029365 - Val Loss: 0.045919\n",
      "Epoch 30/50 - Train Loss: 0.028606 - Val Loss: 0.046874\n",
      "Epoch 31/50 - Train Loss: 0.036602 - Val Loss: 0.046145\n",
      "Epoch 32/50 - Train Loss: 0.028570 - Val Loss: 0.046893\n",
      "Epoch 33/50 - Train Loss: 0.036083 - Val Loss: 0.046861\n",
      "Epoch 34/50 - Train Loss: 0.028714 - Val Loss: 0.046188\n",
      "Epoch 35/50 - Train Loss: 0.028240 - Val Loss: 0.044973\n",
      "Epoch 36/50 - Train Loss: 0.036998 - Val Loss: 0.046449\n",
      "Epoch 37/50 - Train Loss: 0.037507 - Val Loss: 0.045467\n",
      "Epoch 38/50 - Train Loss: 0.037159 - Val Loss: 0.048595\n",
      "Epoch 39/50 - Train Loss: 0.036052 - Val Loss: 0.047523\n",
      "Epoch 40/50 - Train Loss: 0.028795 - Val Loss: 0.044849\n",
      "Epoch 41/50 - Train Loss: 0.028892 - Val Loss: 0.044923\n",
      "Epoch 42/50 - Train Loss: 0.036661 - Val Loss: 0.045633\n",
      "Epoch 43/50 - Train Loss: 0.028126 - Val Loss: 0.045112\n",
      "Epoch 44/50 - Train Loss: 0.036765 - Val Loss: 0.047856\n",
      "Epoch 45/50 - Train Loss: 0.035912 - Val Loss: 0.046077\n",
      "Epoch 46/50 - Train Loss: 0.036212 - Val Loss: 0.045932\n",
      "Epoch 47/50 - Train Loss: 0.029947 - Val Loss: 0.045292\n",
      "Epoch 48/50 - Train Loss: 0.035924 - Val Loss: 0.046940\n",
      "Epoch 49/50 - Train Loss: 0.028195 - Val Loss: 0.045699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:47:30,866] Trial 68 finished with value: 0.04484911262989044 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 109, 'lr': 0.006379283477689055, 'weight_decay': 1.58763373290398e-05, 'batch_size': 64}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.037112 - Val Loss: 0.047021\n",
      "Epoch 1/50 - Train Loss: 0.055794 - Val Loss: 0.083225\n",
      "Epoch 2/50 - Train Loss: 0.048250 - Val Loss: 0.067759\n",
      "Epoch 3/50 - Train Loss: 0.038260 - Val Loss: 0.049039\n",
      "Epoch 4/50 - Train Loss: 0.038536 - Val Loss: 0.058426\n",
      "Epoch 5/50 - Train Loss: 0.034830 - Val Loss: 0.088712\n",
      "Epoch 6/50 - Train Loss: 0.037741 - Val Loss: 0.071540\n",
      "Epoch 7/50 - Train Loss: 0.034941 - Val Loss: 0.051890\n",
      "Epoch 8/50 - Train Loss: 0.033648 - Val Loss: 0.046000\n",
      "Epoch 9/50 - Train Loss: 0.031523 - Val Loss: 0.058681\n",
      "Epoch 10/50 - Train Loss: 0.030734 - Val Loss: 0.053221\n",
      "Epoch 11/50 - Train Loss: 0.033475 - Val Loss: 0.045639\n",
      "Epoch 12/50 - Train Loss: 0.033494 - Val Loss: 0.045968\n",
      "Epoch 13/50 - Train Loss: 0.029686 - Val Loss: 0.044549\n",
      "Epoch 14/50 - Train Loss: 0.033471 - Val Loss: 0.050233\n",
      "Epoch 15/50 - Train Loss: 0.032986 - Val Loss: 0.050013\n",
      "Epoch 16/50 - Train Loss: 0.029936 - Val Loss: 0.044719\n",
      "Epoch 17/50 - Train Loss: 0.030825 - Val Loss: 0.044688\n",
      "Epoch 18/50 - Train Loss: 0.031005 - Val Loss: 0.049432\n",
      "Epoch 19/50 - Train Loss: 0.033411 - Val Loss: 0.062160\n",
      "Epoch 20/50 - Train Loss: 0.035949 - Val Loss: 0.071646\n",
      "Epoch 21/50 - Train Loss: 0.032986 - Val Loss: 0.053092\n",
      "Epoch 22/50 - Train Loss: 0.036019 - Val Loss: 0.067318\n",
      "Epoch 23/50 - Train Loss: 0.033654 - Val Loss: 0.048555\n",
      "Epoch 24/50 - Train Loss: 0.034299 - Val Loss: 0.061262\n",
      "Epoch 25/50 - Train Loss: 0.032695 - Val Loss: 0.053778\n",
      "Epoch 26/50 - Train Loss: 0.033102 - Val Loss: 0.054495\n",
      "Epoch 27/50 - Train Loss: 0.033791 - Val Loss: 0.045237\n",
      "Epoch 28/50 - Train Loss: 0.031486 - Val Loss: 0.044371\n",
      "Epoch 29/50 - Train Loss: 0.033833 - Val Loss: 0.044922\n",
      "Epoch 30/50 - Train Loss: 0.033869 - Val Loss: 0.044912\n",
      "Epoch 31/50 - Train Loss: 0.030302 - Val Loss: 0.044243\n",
      "Epoch 32/50 - Train Loss: 0.031803 - Val Loss: 0.044605\n",
      "Epoch 33/50 - Train Loss: 0.031412 - Val Loss: 0.045956\n",
      "Epoch 34/50 - Train Loss: 0.029817 - Val Loss: 0.047687\n",
      "Epoch 35/50 - Train Loss: 0.031259 - Val Loss: 0.043811\n",
      "Epoch 36/50 - Train Loss: 0.029327 - Val Loss: 0.044877\n",
      "Epoch 37/50 - Train Loss: 0.031238 - Val Loss: 0.047350\n",
      "Epoch 38/50 - Train Loss: 0.031115 - Val Loss: 0.044683\n",
      "Epoch 39/50 - Train Loss: 0.031988 - Val Loss: 0.045093\n",
      "Epoch 40/50 - Train Loss: 0.028837 - Val Loss: 0.045553\n",
      "Epoch 41/50 - Train Loss: 0.031034 - Val Loss: 0.047658\n",
      "Epoch 42/50 - Train Loss: 0.030018 - Val Loss: 0.044987\n",
      "Epoch 43/50 - Train Loss: 0.028865 - Val Loss: 0.046061\n",
      "Epoch 44/50 - Train Loss: 0.030446 - Val Loss: 0.050050\n",
      "Epoch 45/50 - Train Loss: 0.029303 - Val Loss: 0.051096\n",
      "Epoch 46/50 - Train Loss: 0.032666 - Val Loss: 0.048093\n",
      "Epoch 47/50 - Train Loss: 0.027955 - Val Loss: 0.046650\n",
      "Epoch 48/50 - Train Loss: 0.031328 - Val Loss: 0.047983\n",
      "Epoch 49/50 - Train Loss: 0.031887 - Val Loss: 0.058056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:48:30,495] Trial 69 finished with value: 0.04381119211514791 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 171, 'lr': 0.008232051207808103, 'weight_decay': 7.320127839133102e-06, 'batch_size': 8}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.034111 - Val Loss: 0.059035\n",
      "Epoch 1/50 - Train Loss: 0.081529 - Val Loss: 0.143180\n",
      "Epoch 2/50 - Train Loss: 0.048899 - Val Loss: 0.066984\n",
      "Epoch 3/50 - Train Loss: 0.047384 - Val Loss: 0.080691\n",
      "Epoch 4/50 - Train Loss: 0.040055 - Val Loss: 0.052747\n",
      "Epoch 5/50 - Train Loss: 0.035098 - Val Loss: 0.051103\n",
      "Epoch 6/50 - Train Loss: 0.032311 - Val Loss: 0.066930\n",
      "Epoch 7/50 - Train Loss: 0.029822 - Val Loss: 0.056302\n",
      "Epoch 8/50 - Train Loss: 0.031347 - Val Loss: 0.045575\n",
      "Epoch 9/50 - Train Loss: 0.033194 - Val Loss: 0.051201\n",
      "Epoch 10/50 - Train Loss: 0.031552 - Val Loss: 0.045538\n",
      "Epoch 11/50 - Train Loss: 0.031000 - Val Loss: 0.045963\n",
      "Epoch 12/50 - Train Loss: 0.031497 - Val Loss: 0.045131\n",
      "Epoch 13/50 - Train Loss: 0.031498 - Val Loss: 0.048708\n",
      "Epoch 14/50 - Train Loss: 0.031474 - Val Loss: 0.047808\n",
      "Epoch 15/50 - Train Loss: 0.032156 - Val Loss: 0.057247\n",
      "Epoch 16/50 - Train Loss: 0.031335 - Val Loss: 0.050549\n",
      "Epoch 17/50 - Train Loss: 0.036111 - Val Loss: 0.061846\n",
      "Epoch 18/50 - Train Loss: 0.034182 - Val Loss: 0.046628\n",
      "Epoch 19/50 - Train Loss: 0.031075 - Val Loss: 0.057286\n",
      "Epoch 20/50 - Train Loss: 0.033047 - Val Loss: 0.061028\n",
      "Epoch 21/50 - Train Loss: 0.037161 - Val Loss: 0.046075\n",
      "Epoch 22/50 - Train Loss: 0.032002 - Val Loss: 0.045780\n",
      "Epoch 23/50 - Train Loss: 0.033446 - Val Loss: 0.046390\n",
      "Epoch 24/50 - Train Loss: 0.031075 - Val Loss: 0.056792\n",
      "Epoch 25/50 - Train Loss: 0.034526 - Val Loss: 0.050446\n",
      "Epoch 26/50 - Train Loss: 0.035260 - Val Loss: 0.046534\n",
      "Epoch 27/50 - Train Loss: 0.032311 - Val Loss: 0.044422\n",
      "Epoch 28/50 - Train Loss: 0.033272 - Val Loss: 0.045948\n",
      "Epoch 29/50 - Train Loss: 0.027081 - Val Loss: 0.049263\n",
      "Epoch 30/50 - Train Loss: 0.031416 - Val Loss: 0.045878\n",
      "Epoch 31/50 - Train Loss: 0.029948 - Val Loss: 0.044243\n",
      "Epoch 32/50 - Train Loss: 0.033816 - Val Loss: 0.046824\n",
      "Epoch 33/50 - Train Loss: 0.032024 - Val Loss: 0.046309\n",
      "Epoch 34/50 - Train Loss: 0.032994 - Val Loss: 0.045803\n",
      "Epoch 35/50 - Train Loss: 0.029067 - Val Loss: 0.045539\n",
      "Epoch 36/50 - Train Loss: 0.026687 - Val Loss: 0.044362\n",
      "Epoch 37/50 - Train Loss: 0.031236 - Val Loss: 0.045244\n",
      "Epoch 38/50 - Train Loss: 0.034310 - Val Loss: 0.044742\n",
      "Epoch 39/50 - Train Loss: 0.032230 - Val Loss: 0.046797\n",
      "Epoch 40/50 - Train Loss: 0.030633 - Val Loss: 0.051677\n",
      "Epoch 41/50 - Train Loss: 0.030462 - Val Loss: 0.045379\n",
      "Epoch 42/50 - Train Loss: 0.030193 - Val Loss: 0.046224\n",
      "Epoch 43/50 - Train Loss: 0.028457 - Val Loss: 0.044617\n",
      "Epoch 44/50 - Train Loss: 0.032332 - Val Loss: 0.045761\n",
      "Epoch 45/50 - Train Loss: 0.029396 - Val Loss: 0.044238\n",
      "Epoch 46/50 - Train Loss: 0.029603 - Val Loss: 0.049260\n",
      "Epoch 47/50 - Train Loss: 0.028730 - Val Loss: 0.045681\n",
      "Epoch 48/50 - Train Loss: 0.031011 - Val Loss: 0.043968\n",
      "Epoch 49/50 - Train Loss: 0.028458 - Val Loss: 0.044036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:49:19,546] Trial 70 finished with value: 0.04396842420101166 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 216, 'lr': 0.004409122372430353, 'weight_decay': 3.071748504297407e-05, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.028913 - Val Loss: 0.047086\n",
      "Epoch 1/50 - Train Loss: 0.069718 - Val Loss: 0.105042\n",
      "Epoch 2/50 - Train Loss: 0.043094 - Val Loss: 0.073351\n",
      "Epoch 3/50 - Train Loss: 0.042593 - Val Loss: 0.085703\n",
      "Epoch 4/50 - Train Loss: 0.043236 - Val Loss: 0.071849\n",
      "Epoch 5/50 - Train Loss: 0.036294 - Val Loss: 0.057738\n",
      "Epoch 6/50 - Train Loss: 0.034512 - Val Loss: 0.048950\n",
      "Epoch 7/50 - Train Loss: 0.039604 - Val Loss: 0.047652\n",
      "Epoch 8/50 - Train Loss: 0.033162 - Val Loss: 0.052628\n",
      "Epoch 9/50 - Train Loss: 0.033472 - Val Loss: 0.052701\n",
      "Epoch 10/50 - Train Loss: 0.033990 - Val Loss: 0.058143\n",
      "Epoch 11/50 - Train Loss: 0.034668 - Val Loss: 0.053484\n",
      "Epoch 12/50 - Train Loss: 0.033373 - Val Loss: 0.044360\n",
      "Epoch 13/50 - Train Loss: 0.033270 - Val Loss: 0.045591\n",
      "Epoch 14/50 - Train Loss: 0.033355 - Val Loss: 0.049205\n",
      "Epoch 15/50 - Train Loss: 0.030900 - Val Loss: 0.047680\n",
      "Epoch 16/50 - Train Loss: 0.028437 - Val Loss: 0.047374\n",
      "Epoch 17/50 - Train Loss: 0.034936 - Val Loss: 0.055957\n",
      "Epoch 18/50 - Train Loss: 0.031100 - Val Loss: 0.068373\n",
      "Epoch 19/50 - Train Loss: 0.031305 - Val Loss: 0.045635\n",
      "Epoch 20/50 - Train Loss: 0.035799 - Val Loss: 0.045228\n",
      "Epoch 21/50 - Train Loss: 0.029114 - Val Loss: 0.044282\n",
      "Epoch 22/50 - Train Loss: 0.028858 - Val Loss: 0.048750\n",
      "Epoch 23/50 - Train Loss: 0.030146 - Val Loss: 0.045139\n",
      "Epoch 24/50 - Train Loss: 0.033327 - Val Loss: 0.044428\n",
      "Epoch 25/50 - Train Loss: 0.033329 - Val Loss: 0.046759\n",
      "Epoch 26/50 - Train Loss: 0.028096 - Val Loss: 0.052571\n",
      "Epoch 27/50 - Train Loss: 0.032702 - Val Loss: 0.050009\n",
      "Epoch 28/50 - Train Loss: 0.031075 - Val Loss: 0.047982\n",
      "Epoch 29/50 - Train Loss: 0.029974 - Val Loss: 0.044768\n",
      "Epoch 30/50 - Train Loss: 0.033113 - Val Loss: 0.055259\n",
      "Epoch 31/50 - Train Loss: 0.031522 - Val Loss: 0.055301\n",
      "Epoch 32/50 - Train Loss: 0.032982 - Val Loss: 0.044898\n",
      "Epoch 33/50 - Train Loss: 0.031827 - Val Loss: 0.044353\n",
      "Epoch 34/50 - Train Loss: 0.030501 - Val Loss: 0.062059\n",
      "Epoch 35/50 - Train Loss: 0.034815 - Val Loss: 0.050018\n",
      "Epoch 36/50 - Train Loss: 0.031397 - Val Loss: 0.044208\n",
      "Epoch 37/50 - Train Loss: 0.034786 - Val Loss: 0.049467\n",
      "Epoch 38/50 - Train Loss: 0.030864 - Val Loss: 0.058469\n",
      "Epoch 39/50 - Train Loss: 0.031693 - Val Loss: 0.049166\n",
      "Epoch 40/50 - Train Loss: 0.034097 - Val Loss: 0.044355\n",
      "Epoch 41/50 - Train Loss: 0.026744 - Val Loss: 0.045180\n",
      "Epoch 42/50 - Train Loss: 0.031042 - Val Loss: 0.047708\n",
      "Epoch 43/50 - Train Loss: 0.028137 - Val Loss: 0.046526\n",
      "Epoch 44/50 - Train Loss: 0.029720 - Val Loss: 0.049682\n",
      "Epoch 45/50 - Train Loss: 0.031898 - Val Loss: 0.047205\n",
      "Epoch 46/50 - Train Loss: 0.029611 - Val Loss: 0.044824\n",
      "Epoch 47/50 - Train Loss: 0.035033 - Val Loss: 0.047601\n",
      "Epoch 48/50 - Train Loss: 0.034571 - Val Loss: 0.044541\n",
      "Epoch 49/50 - Train Loss: 0.030595 - Val Loss: 0.046627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:49:43,557] Trial 71 finished with value: 0.04420752264559269 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 85, 'lr': 0.006108424309191889, 'weight_decay': 1.0722067119012536e-08, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031514 - Val Loss: 0.049619\n",
      "Epoch 1/50 - Train Loss: 0.112070 - Val Loss: 0.116677\n",
      "Epoch 2/50 - Train Loss: 0.044737 - Val Loss: 0.077358\n",
      "Epoch 3/50 - Train Loss: 0.041146 - Val Loss: 0.076233\n",
      "Epoch 4/50 - Train Loss: 0.043760 - Val Loss: 0.075745\n",
      "Epoch 5/50 - Train Loss: 0.044992 - Val Loss: 0.101222\n",
      "Epoch 6/50 - Train Loss: 0.041378 - Val Loss: 0.057999\n",
      "Epoch 7/50 - Train Loss: 0.038650 - Val Loss: 0.051191\n",
      "Epoch 8/50 - Train Loss: 0.040054 - Val Loss: 0.080626\n",
      "Epoch 9/50 - Train Loss: 0.034640 - Val Loss: 0.048317\n",
      "Epoch 10/50 - Train Loss: 0.034102 - Val Loss: 0.058574\n",
      "Epoch 11/50 - Train Loss: 0.032591 - Val Loss: 0.049401\n",
      "Epoch 12/50 - Train Loss: 0.032918 - Val Loss: 0.046851\n",
      "Epoch 13/50 - Train Loss: 0.031741 - Val Loss: 0.050901\n",
      "Epoch 14/50 - Train Loss: 0.034875 - Val Loss: 0.052236\n",
      "Epoch 15/50 - Train Loss: 0.029328 - Val Loss: 0.044517\n",
      "Epoch 16/50 - Train Loss: 0.031794 - Val Loss: 0.047341\n",
      "Epoch 17/50 - Train Loss: 0.035614 - Val Loss: 0.044764\n",
      "Epoch 18/50 - Train Loss: 0.033624 - Val Loss: 0.077627\n",
      "Epoch 19/50 - Train Loss: 0.034056 - Val Loss: 0.048788\n",
      "Epoch 20/50 - Train Loss: 0.027639 - Val Loss: 0.044259\n",
      "Epoch 21/50 - Train Loss: 0.033137 - Val Loss: 0.049081\n",
      "Epoch 22/50 - Train Loss: 0.030335 - Val Loss: 0.048254\n",
      "Epoch 23/50 - Train Loss: 0.035726 - Val Loss: 0.047152\n",
      "Epoch 24/50 - Train Loss: 0.032037 - Val Loss: 0.045075\n",
      "Epoch 25/50 - Train Loss: 0.030462 - Val Loss: 0.045266\n",
      "Epoch 26/50 - Train Loss: 0.031161 - Val Loss: 0.044596\n",
      "Epoch 27/50 - Train Loss: 0.032831 - Val Loss: 0.046104\n",
      "Epoch 28/50 - Train Loss: 0.028189 - Val Loss: 0.047035\n",
      "Epoch 29/50 - Train Loss: 0.032010 - Val Loss: 0.047825\n",
      "Epoch 30/50 - Train Loss: 0.032173 - Val Loss: 0.044637\n",
      "Epoch 31/50 - Train Loss: 0.030145 - Val Loss: 0.047342\n",
      "Epoch 32/50 - Train Loss: 0.036144 - Val Loss: 0.047175\n",
      "Epoch 33/50 - Train Loss: 0.030286 - Val Loss: 0.044116\n",
      "Epoch 34/50 - Train Loss: 0.035673 - Val Loss: 0.058202\n",
      "Epoch 35/50 - Train Loss: 0.033843 - Val Loss: 0.050465\n",
      "Epoch 36/50 - Train Loss: 0.029611 - Val Loss: 0.046558\n",
      "Epoch 37/50 - Train Loss: 0.033283 - Val Loss: 0.046227\n",
      "Epoch 38/50 - Train Loss: 0.032222 - Val Loss: 0.045839\n",
      "Epoch 39/50 - Train Loss: 0.032800 - Val Loss: 0.044825\n",
      "Epoch 40/50 - Train Loss: 0.031907 - Val Loss: 0.047393\n",
      "Epoch 41/50 - Train Loss: 0.030930 - Val Loss: 0.044139\n",
      "Epoch 42/50 - Train Loss: 0.029966 - Val Loss: 0.044921\n",
      "Epoch 43/50 - Train Loss: 0.033977 - Val Loss: 0.046632\n",
      "Epoch 44/50 - Train Loss: 0.029811 - Val Loss: 0.045415\n",
      "Epoch 45/50 - Train Loss: 0.028976 - Val Loss: 0.053256\n",
      "Epoch 46/50 - Train Loss: 0.033153 - Val Loss: 0.044482\n",
      "Epoch 47/50 - Train Loss: 0.032345 - Val Loss: 0.045414\n",
      "Epoch 48/50 - Train Loss: 0.033010 - Val Loss: 0.047613\n",
      "Epoch 49/50 - Train Loss: 0.032019 - Val Loss: 0.048330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:50:06,545] Trial 72 finished with value: 0.044115785509347916 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 72, 'lr': 0.009997347243131857, 'weight_decay': 1.0082389932253241e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.029388 - Val Loss: 0.050429\n",
      "Epoch 1/50 - Train Loss: 0.120804 - Val Loss: 0.203248\n",
      "Epoch 2/50 - Train Loss: 0.073780 - Val Loss: 0.088332\n",
      "Epoch 3/50 - Train Loss: 0.045833 - Val Loss: 0.104121\n",
      "Epoch 4/50 - Train Loss: 0.046795 - Val Loss: 0.071943\n",
      "Epoch 5/50 - Train Loss: 0.044413 - Val Loss: 0.062935\n",
      "Epoch 6/50 - Train Loss: 0.033708 - Val Loss: 0.049543\n",
      "Epoch 7/50 - Train Loss: 0.035106 - Val Loss: 0.054578\n",
      "Epoch 8/50 - Train Loss: 0.033062 - Val Loss: 0.051994\n",
      "Epoch 9/50 - Train Loss: 0.032220 - Val Loss: 0.048771\n",
      "Epoch 10/50 - Train Loss: 0.037113 - Val Loss: 0.046267\n",
      "Epoch 11/50 - Train Loss: 0.029377 - Val Loss: 0.061962\n",
      "Epoch 12/50 - Train Loss: 0.033958 - Val Loss: 0.046545\n",
      "Epoch 13/50 - Train Loss: 0.032047 - Val Loss: 0.049234\n",
      "Epoch 14/50 - Train Loss: 0.032194 - Val Loss: 0.045216\n",
      "Epoch 15/50 - Train Loss: 0.031536 - Val Loss: 0.044592\n",
      "Epoch 16/50 - Train Loss: 0.033353 - Val Loss: 0.047196\n",
      "Epoch 17/50 - Train Loss: 0.031526 - Val Loss: 0.045574\n",
      "Epoch 18/50 - Train Loss: 0.034708 - Val Loss: 0.044954\n",
      "Epoch 19/50 - Train Loss: 0.030288 - Val Loss: 0.050295\n",
      "Epoch 20/50 - Train Loss: 0.030880 - Val Loss: 0.046878\n",
      "Epoch 21/50 - Train Loss: 0.032909 - Val Loss: 0.044223\n",
      "Epoch 22/50 - Train Loss: 0.035233 - Val Loss: 0.044908\n",
      "Epoch 23/50 - Train Loss: 0.032913 - Val Loss: 0.044547\n",
      "Epoch 24/50 - Train Loss: 0.031079 - Val Loss: 0.045668\n",
      "Epoch 25/50 - Train Loss: 0.031332 - Val Loss: 0.049141\n",
      "Epoch 26/50 - Train Loss: 0.031896 - Val Loss: 0.044554\n",
      "Epoch 27/50 - Train Loss: 0.030792 - Val Loss: 0.048051\n",
      "Epoch 28/50 - Train Loss: 0.031334 - Val Loss: 0.045301\n",
      "Epoch 29/50 - Train Loss: 0.029884 - Val Loss: 0.045556\n",
      "Epoch 30/50 - Train Loss: 0.034165 - Val Loss: 0.045375\n",
      "Epoch 31/50 - Train Loss: 0.033542 - Val Loss: 0.047070\n",
      "Epoch 32/50 - Train Loss: 0.033162 - Val Loss: 0.055746\n",
      "Epoch 33/50 - Train Loss: 0.033444 - Val Loss: 0.047360\n",
      "Epoch 34/50 - Train Loss: 0.032300 - Val Loss: 0.044244\n",
      "Epoch 35/50 - Train Loss: 0.031735 - Val Loss: 0.050777\n",
      "Epoch 36/50 - Train Loss: 0.030163 - Val Loss: 0.044839\n",
      "Epoch 37/50 - Train Loss: 0.029044 - Val Loss: 0.046161\n",
      "Epoch 38/50 - Train Loss: 0.026727 - Val Loss: 0.045458\n",
      "Epoch 39/50 - Train Loss: 0.030975 - Val Loss: 0.045086\n",
      "Epoch 40/50 - Train Loss: 0.034872 - Val Loss: 0.044672\n",
      "Epoch 41/50 - Train Loss: 0.031565 - Val Loss: 0.048481\n",
      "Epoch 42/50 - Train Loss: 0.031161 - Val Loss: 0.053390\n",
      "Epoch 43/50 - Train Loss: 0.029774 - Val Loss: 0.046518\n",
      "Epoch 44/50 - Train Loss: 0.031842 - Val Loss: 0.046330\n",
      "Epoch 45/50 - Train Loss: 0.031541 - Val Loss: 0.048444\n",
      "Epoch 46/50 - Train Loss: 0.029605 - Val Loss: 0.044574\n",
      "Epoch 47/50 - Train Loss: 0.030789 - Val Loss: 0.045632\n",
      "Epoch 48/50 - Train Loss: 0.029690 - Val Loss: 0.046199\n",
      "Epoch 49/50 - Train Loss: 0.028531 - Val Loss: 0.046848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:50:30,856] Trial 73 finished with value: 0.04422259144484997 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 97, 'lr': 0.00807373782698526, 'weight_decay': 8.215428235190086e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.034361 - Val Loss: 0.046413\n",
      "Epoch 1/50 - Train Loss: 0.079164 - Val Loss: 0.098859\n",
      "Epoch 2/50 - Train Loss: 0.040779 - Val Loss: 0.066875\n",
      "Epoch 3/50 - Train Loss: 0.037925 - Val Loss: 0.055470\n",
      "Epoch 4/50 - Train Loss: 0.035287 - Val Loss: 0.047113\n",
      "Epoch 5/50 - Train Loss: 0.031643 - Val Loss: 0.046473\n",
      "Epoch 6/50 - Train Loss: 0.034489 - Val Loss: 0.046891\n",
      "Epoch 7/50 - Train Loss: 0.035313 - Val Loss: 0.047913\n",
      "Epoch 8/50 - Train Loss: 0.035065 - Val Loss: 0.049957\n",
      "Epoch 9/50 - Train Loss: 0.030749 - Val Loss: 0.045127\n",
      "Epoch 10/50 - Train Loss: 0.032419 - Val Loss: 0.055143\n",
      "Epoch 11/50 - Train Loss: 0.035953 - Val Loss: 0.080715\n",
      "Epoch 12/50 - Train Loss: 0.041861 - Val Loss: 0.049163\n",
      "Epoch 13/50 - Train Loss: 0.030340 - Val Loss: 0.044813\n",
      "Epoch 14/50 - Train Loss: 0.034881 - Val Loss: 0.049613\n",
      "Epoch 15/50 - Train Loss: 0.032158 - Val Loss: 0.059710\n",
      "Epoch 16/50 - Train Loss: 0.034763 - Val Loss: 0.044639\n",
      "Epoch 17/50 - Train Loss: 0.032573 - Val Loss: 0.049958\n",
      "Epoch 18/50 - Train Loss: 0.032209 - Val Loss: 0.044818\n",
      "Epoch 19/50 - Train Loss: 0.030334 - Val Loss: 0.048925\n",
      "Epoch 20/50 - Train Loss: 0.032098 - Val Loss: 0.047286\n",
      "Epoch 21/50 - Train Loss: 0.026195 - Val Loss: 0.043856\n",
      "Epoch 22/50 - Train Loss: 0.029209 - Val Loss: 0.046825\n",
      "Epoch 23/50 - Train Loss: 0.030506 - Val Loss: 0.049612\n",
      "Epoch 24/50 - Train Loss: 0.028561 - Val Loss: 0.044052\n",
      "Epoch 25/50 - Train Loss: 0.029876 - Val Loss: 0.044105\n",
      "Epoch 26/50 - Train Loss: 0.029622 - Val Loss: 0.044680\n",
      "Epoch 27/50 - Train Loss: 0.032970 - Val Loss: 0.044770\n",
      "Epoch 28/50 - Train Loss: 0.029436 - Val Loss: 0.049658\n",
      "Epoch 29/50 - Train Loss: 0.030899 - Val Loss: 0.051726\n",
      "Epoch 30/50 - Train Loss: 0.032427 - Val Loss: 0.050295\n",
      "Epoch 31/50 - Train Loss: 0.032268 - Val Loss: 0.045676\n",
      "Epoch 32/50 - Train Loss: 0.035321 - Val Loss: 0.044887\n",
      "Epoch 33/50 - Train Loss: 0.027162 - Val Loss: 0.046171\n",
      "Epoch 34/50 - Train Loss: 0.030753 - Val Loss: 0.044323\n",
      "Epoch 35/50 - Train Loss: 0.031609 - Val Loss: 0.050143\n",
      "Epoch 36/50 - Train Loss: 0.033452 - Val Loss: 0.048156\n",
      "Epoch 37/50 - Train Loss: 0.029307 - Val Loss: 0.043713\n",
      "Epoch 38/50 - Train Loss: 0.030098 - Val Loss: 0.044697\n",
      "Epoch 39/50 - Train Loss: 0.026517 - Val Loss: 0.044733\n",
      "Epoch 40/50 - Train Loss: 0.031335 - Val Loss: 0.043412\n",
      "Epoch 41/50 - Train Loss: 0.031583 - Val Loss: 0.043730\n",
      "Epoch 42/50 - Train Loss: 0.030200 - Val Loss: 0.044898\n",
      "Epoch 43/50 - Train Loss: 0.030234 - Val Loss: 0.043900\n",
      "Epoch 44/50 - Train Loss: 0.030757 - Val Loss: 0.045726\n",
      "Epoch 45/50 - Train Loss: 0.032600 - Val Loss: 0.043597\n",
      "Epoch 46/50 - Train Loss: 0.031667 - Val Loss: 0.049150\n",
      "Epoch 47/50 - Train Loss: 0.031143 - Val Loss: 0.044846\n",
      "Epoch 48/50 - Train Loss: 0.030113 - Val Loss: 0.045438\n",
      "Epoch 49/50 - Train Loss: 0.033784 - Val Loss: 0.044095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:50:49,166] Trial 74 finished with value: 0.04341166093945503 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 87, 'lr': 0.005377360759006228, 'weight_decay': 3.1448437425717934e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.024099 - Val Loss: 0.044006\n",
      "Epoch 1/50 - Train Loss: 0.098371 - Val Loss: 0.096494\n",
      "Epoch 2/50 - Train Loss: 0.044655 - Val Loss: 0.074515\n",
      "Epoch 3/50 - Train Loss: 0.045448 - Val Loss: 0.095808\n",
      "Epoch 4/50 - Train Loss: 0.045593 - Val Loss: 0.095394\n",
      "Epoch 5/50 - Train Loss: 0.044121 - Val Loss: 0.078496\n",
      "Epoch 6/50 - Train Loss: 0.046835 - Val Loss: 0.080691\n",
      "Epoch 7/50 - Train Loss: 0.042478 - Val Loss: 0.093629\n",
      "Epoch 8/50 - Train Loss: 0.046406 - Val Loss: 0.087962\n",
      "Epoch 9/50 - Train Loss: 0.045339 - Val Loss: 0.077499\n",
      "Epoch 10/50 - Train Loss: 0.040474 - Val Loss: 0.076109\n",
      "Epoch 11/50 - Train Loss: 0.046326 - Val Loss: 0.054837\n",
      "Epoch 12/50 - Train Loss: 0.040505 - Val Loss: 0.053271\n",
      "Epoch 13/50 - Train Loss: 0.038763 - Val Loss: 0.057190\n",
      "Epoch 14/50 - Train Loss: 0.038142 - Val Loss: 0.055518\n",
      "Epoch 15/50 - Train Loss: 0.036153 - Val Loss: 0.057567\n",
      "Epoch 16/50 - Train Loss: 0.033625 - Val Loss: 0.048449\n",
      "Epoch 17/50 - Train Loss: 0.038922 - Val Loss: 0.053184\n",
      "Epoch 18/50 - Train Loss: 0.027203 - Val Loss: 0.048200\n",
      "Epoch 19/50 - Train Loss: 0.033077 - Val Loss: 0.052202\n",
      "Epoch 20/50 - Train Loss: 0.030755 - Val Loss: 0.046666\n",
      "Epoch 21/50 - Train Loss: 0.029387 - Val Loss: 0.051209\n",
      "Epoch 22/50 - Train Loss: 0.033453 - Val Loss: 0.050519\n",
      "Epoch 23/50 - Train Loss: 0.036529 - Val Loss: 0.049211\n",
      "Epoch 24/50 - Train Loss: 0.034957 - Val Loss: 0.055179\n",
      "Epoch 25/50 - Train Loss: 0.034968 - Val Loss: 0.047884\n",
      "Epoch 26/50 - Train Loss: 0.027372 - Val Loss: 0.049227\n",
      "Epoch 27/50 - Train Loss: 0.036636 - Val Loss: 0.048456\n",
      "Epoch 28/50 - Train Loss: 0.032215 - Val Loss: 0.050140\n",
      "Epoch 29/50 - Train Loss: 0.035972 - Val Loss: 0.046873\n",
      "Epoch 30/50 - Train Loss: 0.033313 - Val Loss: 0.049356\n",
      "Epoch 31/50 - Train Loss: 0.028823 - Val Loss: 0.048059\n",
      "Epoch 32/50 - Train Loss: 0.031548 - Val Loss: 0.045770\n",
      "Epoch 33/50 - Train Loss: 0.037239 - Val Loss: 0.048190\n",
      "Epoch 34/50 - Train Loss: 0.033732 - Val Loss: 0.048964\n",
      "Epoch 35/50 - Train Loss: 0.028671 - Val Loss: 0.047716\n",
      "Epoch 36/50 - Train Loss: 0.028185 - Val Loss: 0.047390\n",
      "Epoch 37/50 - Train Loss: 0.029339 - Val Loss: 0.045696\n",
      "Epoch 38/50 - Train Loss: 0.029484 - Val Loss: 0.047183\n",
      "Epoch 39/50 - Train Loss: 0.031170 - Val Loss: 0.051125\n",
      "Epoch 40/50 - Train Loss: 0.030653 - Val Loss: 0.047602\n",
      "Epoch 41/50 - Train Loss: 0.028750 - Val Loss: 0.045866\n",
      "Epoch 42/50 - Train Loss: 0.032778 - Val Loss: 0.046426\n",
      "Epoch 43/50 - Train Loss: 0.037627 - Val Loss: 0.046235\n",
      "Epoch 44/50 - Train Loss: 0.027164 - Val Loss: 0.046225\n",
      "Epoch 45/50 - Train Loss: 0.032294 - Val Loss: 0.045446\n",
      "Epoch 46/50 - Train Loss: 0.037802 - Val Loss: 0.045575\n",
      "Epoch 47/50 - Train Loss: 0.028173 - Val Loss: 0.045912\n",
      "Epoch 48/50 - Train Loss: 0.031672 - Val Loss: 0.044734\n",
      "Epoch 49/50 - Train Loss: 0.036179 - Val Loss: 0.048447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:51:02,788] Trial 75 finished with value: 0.04473370313644409 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 57, 'lr': 0.005183843963972096, 'weight_decay': 3.5289461589613148e-06, 'batch_size': 32}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.034714 - Val Loss: 0.045531\n",
      "Epoch 1/50 - Train Loss: 0.116810 - Val Loss: 0.194687\n",
      "Epoch 2/50 - Train Loss: 0.068908 - Val Loss: 0.089544\n",
      "Epoch 3/50 - Train Loss: 0.048208 - Val Loss: 0.097109\n",
      "Epoch 4/50 - Train Loss: 0.043876 - Val Loss: 0.064950\n",
      "Epoch 5/50 - Train Loss: 0.044274 - Val Loss: 0.075656\n",
      "Epoch 6/50 - Train Loss: 0.032505 - Val Loss: 0.049284\n",
      "Epoch 7/50 - Train Loss: 0.035118 - Val Loss: 0.050852\n",
      "Epoch 8/50 - Train Loss: 0.035936 - Val Loss: 0.058343\n",
      "Epoch 9/50 - Train Loss: 0.032294 - Val Loss: 0.047394\n",
      "Epoch 10/50 - Train Loss: 0.032661 - Val Loss: 0.047523\n",
      "Epoch 11/50 - Train Loss: 0.035951 - Val Loss: 0.045337\n",
      "Epoch 12/50 - Train Loss: 0.032523 - Val Loss: 0.052729\n",
      "Epoch 13/50 - Train Loss: 0.033082 - Val Loss: 0.050459\n",
      "Epoch 14/50 - Train Loss: 0.031060 - Val Loss: 0.043910\n",
      "Epoch 15/50 - Train Loss: 0.033027 - Val Loss: 0.045542\n",
      "Epoch 16/50 - Train Loss: 0.030014 - Val Loss: 0.050348\n",
      "Epoch 17/50 - Train Loss: 0.029658 - Val Loss: 0.045031\n",
      "Epoch 18/50 - Train Loss: 0.032355 - Val Loss: 0.044473\n",
      "Epoch 19/50 - Train Loss: 0.034973 - Val Loss: 0.047419\n",
      "Epoch 20/50 - Train Loss: 0.028471 - Val Loss: 0.044984\n",
      "Epoch 21/50 - Train Loss: 0.032511 - Val Loss: 0.044849\n",
      "Epoch 22/50 - Train Loss: 0.031088 - Val Loss: 0.048393\n",
      "Epoch 23/50 - Train Loss: 0.033953 - Val Loss: 0.049073\n",
      "Epoch 24/50 - Train Loss: 0.032196 - Val Loss: 0.053334\n",
      "Epoch 25/50 - Train Loss: 0.031797 - Val Loss: 0.047867\n",
      "Epoch 26/50 - Train Loss: 0.031814 - Val Loss: 0.044356\n",
      "Epoch 27/50 - Train Loss: 0.030383 - Val Loss: 0.046617\n",
      "Epoch 28/50 - Train Loss: 0.028971 - Val Loss: 0.046138\n",
      "Epoch 29/50 - Train Loss: 0.034892 - Val Loss: 0.045343\n",
      "Epoch 30/50 - Train Loss: 0.031229 - Val Loss: 0.044111\n",
      "Epoch 31/50 - Train Loss: 0.027312 - Val Loss: 0.047812\n",
      "Epoch 32/50 - Train Loss: 0.033229 - Val Loss: 0.047454\n",
      "Epoch 33/50 - Train Loss: 0.029984 - Val Loss: 0.046048\n",
      "Epoch 34/50 - Train Loss: 0.029903 - Val Loss: 0.046000\n",
      "Epoch 35/50 - Train Loss: 0.030837 - Val Loss: 0.044482\n",
      "Epoch 36/50 - Train Loss: 0.032249 - Val Loss: 0.045913\n",
      "Epoch 37/50 - Train Loss: 0.031027 - Val Loss: 0.044875\n",
      "Epoch 38/50 - Train Loss: 0.028809 - Val Loss: 0.045236\n",
      "Epoch 39/50 - Train Loss: 0.031174 - Val Loss: 0.044256\n",
      "Epoch 40/50 - Train Loss: 0.031127 - Val Loss: 0.044638\n",
      "Epoch 41/50 - Train Loss: 0.029754 - Val Loss: 0.047781\n",
      "Epoch 42/50 - Train Loss: 0.028777 - Val Loss: 0.044792\n",
      "Epoch 43/50 - Train Loss: 0.030376 - Val Loss: 0.046607\n",
      "Epoch 44/50 - Train Loss: 0.031555 - Val Loss: 0.045608\n",
      "Epoch 45/50 - Train Loss: 0.030614 - Val Loss: 0.045091\n",
      "Epoch 46/50 - Train Loss: 0.030102 - Val Loss: 0.045389\n",
      "Epoch 47/50 - Train Loss: 0.028270 - Val Loss: 0.044199\n",
      "Epoch 48/50 - Train Loss: 0.026773 - Val Loss: 0.044432\n",
      "Epoch 49/50 - Train Loss: 0.030028 - Val Loss: 0.045972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:51:38,342] Trial 76 finished with value: 0.0439101979136467 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 250, 'lr': 0.0034846102920730415, 'weight_decay': 4.249624486061162e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030884 - Val Loss: 0.046325\n",
      "Epoch 1/50 - Train Loss: 0.059345 - Val Loss: 0.078808\n",
      "Epoch 2/50 - Train Loss: 0.041528 - Val Loss: 0.091206\n",
      "Epoch 3/50 - Train Loss: 0.039346 - Val Loss: 0.054288\n",
      "Epoch 4/50 - Train Loss: 0.036532 - Val Loss: 0.057487\n",
      "Epoch 5/50 - Train Loss: 0.031594 - Val Loss: 0.062970\n",
      "Epoch 6/50 - Train Loss: 0.033839 - Val Loss: 0.050486\n",
      "Epoch 7/50 - Train Loss: 0.034308 - Val Loss: 0.052353\n",
      "Epoch 8/50 - Train Loss: 0.033073 - Val Loss: 0.069782\n",
      "Epoch 9/50 - Train Loss: 0.031272 - Val Loss: 0.049850\n",
      "Epoch 10/50 - Train Loss: 0.030901 - Val Loss: 0.047821\n",
      "Epoch 11/50 - Train Loss: 0.033941 - Val Loss: 0.047754\n",
      "Epoch 12/50 - Train Loss: 0.031258 - Val Loss: 0.050337\n",
      "Epoch 13/50 - Train Loss: 0.033041 - Val Loss: 0.048237\n",
      "Epoch 14/50 - Train Loss: 0.032633 - Val Loss: 0.057568\n",
      "Epoch 15/50 - Train Loss: 0.031538 - Val Loss: 0.045620\n",
      "Epoch 16/50 - Train Loss: 0.030371 - Val Loss: 0.046086\n",
      "Epoch 17/50 - Train Loss: 0.032637 - Val Loss: 0.062380\n",
      "Epoch 18/50 - Train Loss: 0.030452 - Val Loss: 0.045468\n",
      "Epoch 19/50 - Train Loss: 0.030975 - Val Loss: 0.045252\n",
      "Epoch 20/50 - Train Loss: 0.030457 - Val Loss: 0.046608\n",
      "Epoch 21/50 - Train Loss: 0.032319 - Val Loss: 0.051312\n",
      "Epoch 22/50 - Train Loss: 0.029492 - Val Loss: 0.046963\n",
      "Epoch 23/50 - Train Loss: 0.033042 - Val Loss: 0.046996\n",
      "Epoch 24/50 - Train Loss: 0.033230 - Val Loss: 0.054514\n",
      "Epoch 25/50 - Train Loss: 0.034322 - Val Loss: 0.045198\n",
      "Epoch 26/50 - Train Loss: 0.032727 - Val Loss: 0.048780\n",
      "Epoch 27/50 - Train Loss: 0.032134 - Val Loss: 0.045820\n",
      "Epoch 28/50 - Train Loss: 0.029023 - Val Loss: 0.046852\n",
      "Epoch 29/50 - Train Loss: 0.030633 - Val Loss: 0.046406\n",
      "Epoch 30/50 - Train Loss: 0.028290 - Val Loss: 0.045937\n",
      "Epoch 31/50 - Train Loss: 0.030550 - Val Loss: 0.048446\n",
      "Epoch 32/50 - Train Loss: 0.030763 - Val Loss: 0.045586\n",
      "Epoch 33/50 - Train Loss: 0.036044 - Val Loss: 0.045947\n",
      "Epoch 34/50 - Train Loss: 0.033079 - Val Loss: 0.050248\n",
      "Epoch 35/50 - Train Loss: 0.030851 - Val Loss: 0.044906\n",
      "Epoch 36/50 - Train Loss: 0.028873 - Val Loss: 0.045254\n",
      "Epoch 37/50 - Train Loss: 0.032153 - Val Loss: 0.046807\n",
      "Epoch 38/50 - Train Loss: 0.033608 - Val Loss: 0.048662\n",
      "Epoch 39/50 - Train Loss: 0.030858 - Val Loss: 0.045752\n",
      "Epoch 40/50 - Train Loss: 0.031947 - Val Loss: 0.050910\n",
      "Epoch 41/50 - Train Loss: 0.032069 - Val Loss: 0.050727\n",
      "Epoch 42/50 - Train Loss: 0.031346 - Val Loss: 0.047411\n",
      "Epoch 43/50 - Train Loss: 0.030432 - Val Loss: 0.046308\n",
      "Epoch 44/50 - Train Loss: 0.031507 - Val Loss: 0.053066\n",
      "Epoch 45/50 - Train Loss: 0.032722 - Val Loss: 0.044910\n",
      "Epoch 46/50 - Train Loss: 0.029368 - Val Loss: 0.046459\n",
      "Epoch 47/50 - Train Loss: 0.028628 - Val Loss: 0.047587\n",
      "Epoch 48/50 - Train Loss: 0.029482 - Val Loss: 0.044798\n",
      "Epoch 49/50 - Train Loss: 0.031709 - Val Loss: 0.048587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:52:22,289] Trial 77 finished with value: 0.04479790727297465 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 127, 'lr': 0.006617372671238094, 'weight_decay': 2.52683536633243e-05, 'batch_size': 8}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030864 - Val Loss: 0.053287\n",
      "Epoch 1/50 - Train Loss: 0.149031 - Val Loss: 0.102469\n",
      "Epoch 2/50 - Train Loss: 0.048780 - Val Loss: 0.095485\n",
      "Epoch 3/50 - Train Loss: 0.041024 - Val Loss: 0.068836\n",
      "Epoch 4/50 - Train Loss: 0.036382 - Val Loss: 0.059568\n",
      "Epoch 5/50 - Train Loss: 0.035490 - Val Loss: 0.046737\n",
      "Epoch 6/50 - Train Loss: 0.035464 - Val Loss: 0.047212\n",
      "Epoch 7/50 - Train Loss: 0.030556 - Val Loss: 0.046482\n",
      "Epoch 8/50 - Train Loss: 0.031266 - Val Loss: 0.046554\n",
      "Epoch 9/50 - Train Loss: 0.030648 - Val Loss: 0.044770\n",
      "Epoch 10/50 - Train Loss: 0.029677 - Val Loss: 0.044860\n",
      "Epoch 11/50 - Train Loss: 0.030889 - Val Loss: 0.049658\n",
      "Epoch 12/50 - Train Loss: 0.032273 - Val Loss: 0.047576\n",
      "Epoch 13/50 - Train Loss: 0.028635 - Val Loss: 0.046327\n",
      "Epoch 14/50 - Train Loss: 0.029450 - Val Loss: 0.046298\n",
      "Epoch 15/50 - Train Loss: 0.030339 - Val Loss: 0.044561\n",
      "Epoch 16/50 - Train Loss: 0.031198 - Val Loss: 0.048137\n",
      "Epoch 17/50 - Train Loss: 0.032086 - Val Loss: 0.044437\n",
      "Epoch 18/50 - Train Loss: 0.033219 - Val Loss: 0.045554\n",
      "Epoch 19/50 - Train Loss: 0.033313 - Val Loss: 0.046414\n",
      "Epoch 20/50 - Train Loss: 0.029961 - Val Loss: 0.047657\n",
      "Epoch 21/50 - Train Loss: 0.033308 - Val Loss: 0.052757\n",
      "Epoch 22/50 - Train Loss: 0.031163 - Val Loss: 0.045950\n",
      "Epoch 23/50 - Train Loss: 0.033868 - Val Loss: 0.045012\n",
      "Epoch 24/50 - Train Loss: 0.029012 - Val Loss: 0.044630\n",
      "Epoch 25/50 - Train Loss: 0.028586 - Val Loss: 0.044448\n",
      "Epoch 26/50 - Train Loss: 0.033726 - Val Loss: 0.045599\n",
      "Epoch 27/50 - Train Loss: 0.028392 - Val Loss: 0.045697\n",
      "Epoch 28/50 - Train Loss: 0.030827 - Val Loss: 0.044671\n",
      "Epoch 29/50 - Train Loss: 0.031876 - Val Loss: 0.048967\n",
      "Epoch 30/50 - Train Loss: 0.032662 - Val Loss: 0.046949\n",
      "Epoch 31/50 - Train Loss: 0.029811 - Val Loss: 0.045054\n",
      "Epoch 32/50 - Train Loss: 0.031495 - Val Loss: 0.045140\n",
      "Epoch 33/50 - Train Loss: 0.029775 - Val Loss: 0.045188\n",
      "Epoch 34/50 - Train Loss: 0.031720 - Val Loss: 0.045216\n",
      "Epoch 35/50 - Train Loss: 0.030667 - Val Loss: 0.045449\n",
      "Epoch 36/50 - Train Loss: 0.031552 - Val Loss: 0.044836\n",
      "Epoch 37/50 - Train Loss: 0.030975 - Val Loss: 0.045069\n",
      "Epoch 38/50 - Train Loss: 0.026411 - Val Loss: 0.044655\n",
      "Epoch 39/50 - Train Loss: 0.027488 - Val Loss: 0.044084\n",
      "Epoch 40/50 - Train Loss: 0.033635 - Val Loss: 0.044398\n",
      "Epoch 41/50 - Train Loss: 0.030095 - Val Loss: 0.046208\n",
      "Epoch 42/50 - Train Loss: 0.033131 - Val Loss: 0.047256\n",
      "Epoch 43/50 - Train Loss: 0.029281 - Val Loss: 0.046131\n",
      "Epoch 44/50 - Train Loss: 0.029237 - Val Loss: 0.049401\n",
      "Epoch 45/50 - Train Loss: 0.032418 - Val Loss: 0.051003\n",
      "Epoch 46/50 - Train Loss: 0.033413 - Val Loss: 0.047427\n",
      "Epoch 47/50 - Train Loss: 0.028373 - Val Loss: 0.044890\n",
      "Epoch 48/50 - Train Loss: 0.032520 - Val Loss: 0.051085\n",
      "Epoch 49/50 - Train Loss: 0.027301 - Val Loss: 0.044357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:52:57,772] Trial 78 finished with value: 0.04408389702439308 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 225, 'lr': 0.00840856022360783, 'weight_decay': 5.968632923828116e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031215 - Val Loss: 0.046040\n",
      "Epoch 1/50 - Train Loss: 0.075264 - Val Loss: 0.089385\n",
      "Epoch 2/50 - Train Loss: 0.040019 - Val Loss: 0.066939\n",
      "Epoch 3/50 - Train Loss: 0.037268 - Val Loss: 0.066745\n",
      "Epoch 4/50 - Train Loss: 0.034972 - Val Loss: 0.051169\n",
      "Epoch 5/50 - Train Loss: 0.037051 - Val Loss: 0.063969\n",
      "Epoch 6/50 - Train Loss: 0.036199 - Val Loss: 0.050541\n",
      "Epoch 7/50 - Train Loss: 0.030984 - Val Loss: 0.050928\n",
      "Epoch 8/50 - Train Loss: 0.033515 - Val Loss: 0.053267\n",
      "Epoch 9/50 - Train Loss: 0.032605 - Val Loss: 0.046880\n",
      "Epoch 10/50 - Train Loss: 0.030897 - Val Loss: 0.044943\n",
      "Epoch 11/50 - Train Loss: 0.031400 - Val Loss: 0.046243\n",
      "Epoch 12/50 - Train Loss: 0.034146 - Val Loss: 0.052309\n",
      "Epoch 13/50 - Train Loss: 0.031364 - Val Loss: 0.046791\n",
      "Epoch 14/50 - Train Loss: 0.032516 - Val Loss: 0.045440\n",
      "Epoch 15/50 - Train Loss: 0.031448 - Val Loss: 0.050537\n",
      "Epoch 16/50 - Train Loss: 0.032673 - Val Loss: 0.052831\n",
      "Epoch 17/50 - Train Loss: 0.028370 - Val Loss: 0.047424\n",
      "Epoch 18/50 - Train Loss: 0.030953 - Val Loss: 0.045575\n",
      "Epoch 19/50 - Train Loss: 0.029319 - Val Loss: 0.045895\n",
      "Epoch 20/50 - Train Loss: 0.028863 - Val Loss: 0.049160\n",
      "Epoch 21/50 - Train Loss: 0.032591 - Val Loss: 0.046476\n",
      "Epoch 22/50 - Train Loss: 0.031836 - Val Loss: 0.048315\n",
      "Epoch 23/50 - Train Loss: 0.028658 - Val Loss: 0.044886\n",
      "Epoch 24/50 - Train Loss: 0.032616 - Val Loss: 0.045506\n",
      "Epoch 25/50 - Train Loss: 0.033908 - Val Loss: 0.048003\n",
      "Epoch 26/50 - Train Loss: 0.030171 - Val Loss: 0.045419\n",
      "Epoch 27/50 - Train Loss: 0.035102 - Val Loss: 0.045868\n",
      "Epoch 28/50 - Train Loss: 0.030990 - Val Loss: 0.051565\n",
      "Epoch 29/50 - Train Loss: 0.032301 - Val Loss: 0.051629\n",
      "Epoch 30/50 - Train Loss: 0.029462 - Val Loss: 0.045094\n",
      "Epoch 31/50 - Train Loss: 0.031091 - Val Loss: 0.048116\n",
      "Epoch 32/50 - Train Loss: 0.030587 - Val Loss: 0.049209\n",
      "Epoch 33/50 - Train Loss: 0.028120 - Val Loss: 0.045379\n",
      "Epoch 34/50 - Train Loss: 0.029280 - Val Loss: 0.044962\n",
      "Epoch 35/50 - Train Loss: 0.030808 - Val Loss: 0.049644\n",
      "Epoch 36/50 - Train Loss: 0.032298 - Val Loss: 0.048887\n",
      "Epoch 37/50 - Train Loss: 0.027211 - Val Loss: 0.044896\n",
      "Epoch 38/50 - Train Loss: 0.031731 - Val Loss: 0.046190\n",
      "Epoch 39/50 - Train Loss: 0.034874 - Val Loss: 0.051004\n",
      "Epoch 40/50 - Train Loss: 0.032981 - Val Loss: 0.050501\n",
      "Epoch 41/50 - Train Loss: 0.033235 - Val Loss: 0.045578\n",
      "Epoch 42/50 - Train Loss: 0.026394 - Val Loss: 0.048771\n",
      "Epoch 43/50 - Train Loss: 0.029122 - Val Loss: 0.045225\n",
      "Epoch 44/50 - Train Loss: 0.029001 - Val Loss: 0.044731\n",
      "Epoch 45/50 - Train Loss: 0.031878 - Val Loss: 0.044937\n",
      "Epoch 46/50 - Train Loss: 0.032103 - Val Loss: 0.047444\n",
      "Epoch 47/50 - Train Loss: 0.028949 - Val Loss: 0.047689\n",
      "Epoch 48/50 - Train Loss: 0.027821 - Val Loss: 0.044917\n",
      "Epoch 49/50 - Train Loss: 0.028944 - Val Loss: 0.044715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:53:14,288] Trial 79 finished with value: 0.04471496306359768 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 79, 'lr': 0.004576468465122268, 'weight_decay': 2.0615205796814413e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030204 - Val Loss: 0.044902\n",
      "Epoch 1/50 - Train Loss: 0.071372 - Val Loss: 0.081222\n",
      "Epoch 2/50 - Train Loss: 0.038185 - Val Loss: 0.049271\n",
      "Epoch 3/50 - Train Loss: 0.033820 - Val Loss: 0.063280\n",
      "Epoch 4/50 - Train Loss: 0.036959 - Val Loss: 0.045846\n",
      "Epoch 5/50 - Train Loss: 0.035657 - Val Loss: 0.045172\n",
      "Epoch 6/50 - Train Loss: 0.037043 - Val Loss: 0.060247\n",
      "Epoch 7/50 - Train Loss: 0.033720 - Val Loss: 0.046076\n",
      "Epoch 8/50 - Train Loss: 0.033882 - Val Loss: 0.055473\n",
      "Epoch 9/50 - Train Loss: 0.032434 - Val Loss: 0.044014\n",
      "Epoch 10/50 - Train Loss: 0.028921 - Val Loss: 0.045836\n",
      "Epoch 11/50 - Train Loss: 0.031296 - Val Loss: 0.050292\n",
      "Epoch 12/50 - Train Loss: 0.034843 - Val Loss: 0.044472\n",
      "Epoch 13/50 - Train Loss: 0.031808 - Val Loss: 0.046334\n",
      "Epoch 14/50 - Train Loss: 0.033004 - Val Loss: 0.052320\n",
      "Epoch 15/50 - Train Loss: 0.030898 - Val Loss: 0.044273\n",
      "Epoch 16/50 - Train Loss: 0.030822 - Val Loss: 0.056631\n",
      "Epoch 17/50 - Train Loss: 0.034483 - Val Loss: 0.043988\n",
      "Epoch 18/50 - Train Loss: 0.028631 - Val Loss: 0.044332\n",
      "Epoch 19/50 - Train Loss: 0.031902 - Val Loss: 0.059672\n",
      "Epoch 20/50 - Train Loss: 0.031913 - Val Loss: 0.046381\n",
      "Epoch 21/50 - Train Loss: 0.030702 - Val Loss: 0.043801\n",
      "Epoch 22/50 - Train Loss: 0.032021 - Val Loss: 0.044396\n",
      "Epoch 23/50 - Train Loss: 0.032279 - Val Loss: 0.045962\n",
      "Epoch 24/50 - Train Loss: 0.030206 - Val Loss: 0.044307\n",
      "Epoch 25/50 - Train Loss: 0.031430 - Val Loss: 0.050702\n",
      "Epoch 26/50 - Train Loss: 0.031274 - Val Loss: 0.047384\n",
      "Epoch 27/50 - Train Loss: 0.028357 - Val Loss: 0.049629\n",
      "Epoch 28/50 - Train Loss: 0.031305 - Val Loss: 0.045005\n",
      "Epoch 29/50 - Train Loss: 0.029790 - Val Loss: 0.046065\n",
      "Epoch 30/50 - Train Loss: 0.034759 - Val Loss: 0.045857\n",
      "Epoch 31/50 - Train Loss: 0.030217 - Val Loss: 0.045097\n",
      "Epoch 32/50 - Train Loss: 0.027328 - Val Loss: 0.053139\n",
      "Epoch 33/50 - Train Loss: 0.030703 - Val Loss: 0.046941\n",
      "Epoch 34/50 - Train Loss: 0.033269 - Val Loss: 0.045997\n",
      "Epoch 35/50 - Train Loss: 0.033491 - Val Loss: 0.047049\n",
      "Epoch 36/50 - Train Loss: 0.034563 - Val Loss: 0.053362\n",
      "Epoch 37/50 - Train Loss: 0.030310 - Val Loss: 0.048591\n",
      "Epoch 38/50 - Train Loss: 0.032235 - Val Loss: 0.049108\n",
      "Epoch 39/50 - Train Loss: 0.031129 - Val Loss: 0.047680\n",
      "Epoch 40/50 - Train Loss: 0.031583 - Val Loss: 0.054489\n",
      "Epoch 41/50 - Train Loss: 0.032040 - Val Loss: 0.045419\n",
      "Epoch 42/50 - Train Loss: 0.029177 - Val Loss: 0.045166\n",
      "Epoch 43/50 - Train Loss: 0.028005 - Val Loss: 0.045548\n",
      "Epoch 44/50 - Train Loss: 0.029583 - Val Loss: 0.046653\n",
      "Epoch 45/50 - Train Loss: 0.030524 - Val Loss: 0.045848\n",
      "Epoch 46/50 - Train Loss: 0.029767 - Val Loss: 0.047183\n",
      "Epoch 47/50 - Train Loss: 0.030255 - Val Loss: 0.050490\n",
      "Epoch 48/50 - Train Loss: 0.029969 - Val Loss: 0.048445\n",
      "Epoch 49/50 - Train Loss: 0.031174 - Val Loss: 0.047919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:53:39,257] Trial 80 finished with value: 0.04380072156588236 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 110, 'lr': 0.006956671189838189, 'weight_decay': 5.769600375714694e-07, 'batch_size': 8}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030174 - Val Loss: 0.047147\n",
      "Epoch 1/50 - Train Loss: 0.074655 - Val Loss: 0.115954\n",
      "Epoch 2/50 - Train Loss: 0.052922 - Val Loss: 0.078515\n",
      "Epoch 3/50 - Train Loss: 0.044125 - Val Loss: 0.076499\n",
      "Epoch 4/50 - Train Loss: 0.041231 - Val Loss: 0.060888\n",
      "Epoch 5/50 - Train Loss: 0.036735 - Val Loss: 0.051276\n",
      "Epoch 6/50 - Train Loss: 0.036141 - Val Loss: 0.050549\n",
      "Epoch 7/50 - Train Loss: 0.034826 - Val Loss: 0.047326\n",
      "Epoch 8/50 - Train Loss: 0.034852 - Val Loss: 0.047506\n",
      "Epoch 9/50 - Train Loss: 0.032854 - Val Loss: 0.046011\n",
      "Epoch 10/50 - Train Loss: 0.032864 - Val Loss: 0.046639\n",
      "Epoch 11/50 - Train Loss: 0.033477 - Val Loss: 0.048176\n",
      "Epoch 12/50 - Train Loss: 0.036416 - Val Loss: 0.052113\n",
      "Epoch 13/50 - Train Loss: 0.033884 - Val Loss: 0.046359\n",
      "Epoch 14/50 - Train Loss: 0.030411 - Val Loss: 0.044131\n",
      "Epoch 15/50 - Train Loss: 0.028104 - Val Loss: 0.045175\n",
      "Epoch 16/50 - Train Loss: 0.031091 - Val Loss: 0.045131\n",
      "Epoch 17/50 - Train Loss: 0.033003 - Val Loss: 0.047946\n",
      "Epoch 18/50 - Train Loss: 0.039521 - Val Loss: 0.060133\n",
      "Epoch 19/50 - Train Loss: 0.035593 - Val Loss: 0.061347\n",
      "Epoch 20/50 - Train Loss: 0.031540 - Val Loss: 0.044673\n",
      "Epoch 21/50 - Train Loss: 0.033033 - Val Loss: 0.054040\n",
      "Epoch 22/50 - Train Loss: 0.033576 - Val Loss: 0.044356\n",
      "Epoch 23/50 - Train Loss: 0.028504 - Val Loss: 0.053458\n",
      "Epoch 24/50 - Train Loss: 0.033319 - Val Loss: 0.044778\n",
      "Epoch 25/50 - Train Loss: 0.031147 - Val Loss: 0.046149\n",
      "Epoch 26/50 - Train Loss: 0.031888 - Val Loss: 0.043639\n",
      "Epoch 27/50 - Train Loss: 0.033883 - Val Loss: 0.045143\n",
      "Epoch 28/50 - Train Loss: 0.033863 - Val Loss: 0.049504\n",
      "Epoch 29/50 - Train Loss: 0.033536 - Val Loss: 0.049047\n",
      "Epoch 30/50 - Train Loss: 0.034767 - Val Loss: 0.048459\n",
      "Epoch 31/50 - Train Loss: 0.028114 - Val Loss: 0.044669\n",
      "Epoch 32/50 - Train Loss: 0.035597 - Val Loss: 0.044479\n",
      "Epoch 33/50 - Train Loss: 0.030647 - Val Loss: 0.046995\n",
      "Epoch 34/50 - Train Loss: 0.029833 - Val Loss: 0.046993\n",
      "Epoch 35/50 - Train Loss: 0.030793 - Val Loss: 0.045865\n",
      "Epoch 36/50 - Train Loss: 0.031824 - Val Loss: 0.045634\n",
      "Epoch 37/50 - Train Loss: 0.031746 - Val Loss: 0.053749\n",
      "Epoch 38/50 - Train Loss: 0.031037 - Val Loss: 0.045462\n",
      "Epoch 39/50 - Train Loss: 0.031381 - Val Loss: 0.047637\n",
      "Epoch 40/50 - Train Loss: 0.029577 - Val Loss: 0.045061\n",
      "Epoch 41/50 - Train Loss: 0.029540 - Val Loss: 0.045187\n",
      "Epoch 42/50 - Train Loss: 0.032964 - Val Loss: 0.047118\n",
      "Epoch 43/50 - Train Loss: 0.028031 - Val Loss: 0.044021\n",
      "Epoch 44/50 - Train Loss: 0.032024 - Val Loss: 0.049020\n",
      "Epoch 45/50 - Train Loss: 0.031819 - Val Loss: 0.045602\n",
      "Epoch 46/50 - Train Loss: 0.030569 - Val Loss: 0.044851\n",
      "Epoch 47/50 - Train Loss: 0.029901 - Val Loss: 0.043607\n",
      "Epoch 48/50 - Train Loss: 0.029244 - Val Loss: 0.049128\n",
      "Epoch 49/50 - Train Loss: 0.035144 - Val Loss: 0.045263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:54:04,810] Trial 81 finished with value: 0.04360653832554817 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 92, 'lr': 0.00564165807535261, 'weight_decay': 1.2249439413924003e-05, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031184 - Val Loss: 0.045099\n",
      "Epoch 1/50 - Train Loss: 0.065478 - Val Loss: 0.089204\n",
      "Epoch 2/50 - Train Loss: 0.042751 - Val Loss: 0.079326\n",
      "Epoch 3/50 - Train Loss: 0.047161 - Val Loss: 0.074522\n",
      "Epoch 4/50 - Train Loss: 0.039299 - Val Loss: 0.065289\n",
      "Epoch 5/50 - Train Loss: 0.034958 - Val Loss: 0.056628\n",
      "Epoch 6/50 - Train Loss: 0.034076 - Val Loss: 0.056561\n",
      "Epoch 7/50 - Train Loss: 0.033811 - Val Loss: 0.048830\n",
      "Epoch 8/50 - Train Loss: 0.028745 - Val Loss: 0.045171\n",
      "Epoch 9/50 - Train Loss: 0.029688 - Val Loss: 0.045110\n",
      "Epoch 10/50 - Train Loss: 0.036209 - Val Loss: 0.047979\n",
      "Epoch 11/50 - Train Loss: 0.031040 - Val Loss: 0.063074\n",
      "Epoch 12/50 - Train Loss: 0.034282 - Val Loss: 0.046908\n",
      "Epoch 13/50 - Train Loss: 0.032918 - Val Loss: 0.046963\n",
      "Epoch 14/50 - Train Loss: 0.031927 - Val Loss: 0.045286\n",
      "Epoch 15/50 - Train Loss: 0.031676 - Val Loss: 0.055359\n",
      "Epoch 16/50 - Train Loss: 0.032651 - Val Loss: 0.053526\n",
      "Epoch 17/50 - Train Loss: 0.032297 - Val Loss: 0.053859\n",
      "Epoch 18/50 - Train Loss: 0.026951 - Val Loss: 0.044011\n",
      "Epoch 19/50 - Train Loss: 0.031165 - Val Loss: 0.044251\n",
      "Epoch 20/50 - Train Loss: 0.033737 - Val Loss: 0.052993\n",
      "Epoch 21/50 - Train Loss: 0.031084 - Val Loss: 0.044175\n",
      "Epoch 22/50 - Train Loss: 0.033838 - Val Loss: 0.047750\n",
      "Epoch 23/50 - Train Loss: 0.031706 - Val Loss: 0.044774\n",
      "Epoch 24/50 - Train Loss: 0.031982 - Val Loss: 0.046398\n",
      "Epoch 25/50 - Train Loss: 0.030163 - Val Loss: 0.046668\n",
      "Epoch 26/50 - Train Loss: 0.029247 - Val Loss: 0.044294\n",
      "Epoch 27/50 - Train Loss: 0.030450 - Val Loss: 0.045866\n",
      "Epoch 28/50 - Train Loss: 0.028945 - Val Loss: 0.047184\n",
      "Epoch 29/50 - Train Loss: 0.033016 - Val Loss: 0.049662\n",
      "Epoch 30/50 - Train Loss: 0.032238 - Val Loss: 0.044282\n",
      "Epoch 31/50 - Train Loss: 0.029410 - Val Loss: 0.045447\n",
      "Epoch 32/50 - Train Loss: 0.032495 - Val Loss: 0.045362\n",
      "Epoch 33/50 - Train Loss: 0.029709 - Val Loss: 0.043750\n",
      "Epoch 34/50 - Train Loss: 0.030443 - Val Loss: 0.045074\n",
      "Epoch 35/50 - Train Loss: 0.032287 - Val Loss: 0.045558\n",
      "Epoch 36/50 - Train Loss: 0.035557 - Val Loss: 0.044311\n",
      "Epoch 37/50 - Train Loss: 0.029350 - Val Loss: 0.047251\n",
      "Epoch 38/50 - Train Loss: 0.028360 - Val Loss: 0.051783\n",
      "Epoch 39/50 - Train Loss: 0.031969 - Val Loss: 0.049396\n",
      "Epoch 40/50 - Train Loss: 0.031018 - Val Loss: 0.046524\n",
      "Epoch 41/50 - Train Loss: 0.031613 - Val Loss: 0.044205\n",
      "Epoch 42/50 - Train Loss: 0.033171 - Val Loss: 0.045878\n",
      "Epoch 43/50 - Train Loss: 0.033204 - Val Loss: 0.049978\n",
      "Epoch 44/50 - Train Loss: 0.034107 - Val Loss: 0.049833\n",
      "Epoch 45/50 - Train Loss: 0.030750 - Val Loss: 0.045107\n",
      "Epoch 46/50 - Train Loss: 0.030551 - Val Loss: 0.044380\n",
      "Epoch 47/50 - Train Loss: 0.029655 - Val Loss: 0.046177\n",
      "Epoch 48/50 - Train Loss: 0.029994 - Val Loss: 0.045076\n",
      "Epoch 49/50 - Train Loss: 0.031828 - Val Loss: 0.044954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:54:27,886] Trial 82 finished with value: 0.043749596923589706 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 98, 'lr': 0.005542137081277171, 'weight_decay': 1.2392184139335159e-05, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031454 - Val Loss: 0.044195\n",
      "Epoch 1/50 - Train Loss: 0.144945 - Val Loss: 0.288700\n",
      "Epoch 2/50 - Train Loss: 0.141022 - Val Loss: 0.267804\n",
      "Epoch 3/50 - Train Loss: 0.116565 - Val Loss: 0.247505\n",
      "Epoch 4/50 - Train Loss: 0.110848 - Val Loss: 0.228012\n",
      "Epoch 5/50 - Train Loss: 0.097657 - Val Loss: 0.208984\n",
      "Epoch 6/50 - Train Loss: 0.089990 - Val Loss: 0.192251\n",
      "Epoch 7/50 - Train Loss: 0.082920 - Val Loss: 0.177201\n",
      "Epoch 8/50 - Train Loss: 0.071895 - Val Loss: 0.162925\n",
      "Epoch 9/50 - Train Loss: 0.065239 - Val Loss: 0.150595\n",
      "Epoch 10/50 - Train Loss: 0.059131 - Val Loss: 0.138410\n",
      "Epoch 11/50 - Train Loss: 0.057357 - Val Loss: 0.125930\n",
      "Epoch 12/50 - Train Loss: 0.049076 - Val Loss: 0.111805\n",
      "Epoch 13/50 - Train Loss: 0.044319 - Val Loss: 0.098419\n",
      "Epoch 14/50 - Train Loss: 0.042868 - Val Loss: 0.089520\n",
      "Epoch 15/50 - Train Loss: 0.041191 - Val Loss: 0.084797\n",
      "Epoch 16/50 - Train Loss: 0.041773 - Val Loss: 0.081536\n",
      "Epoch 17/50 - Train Loss: 0.047151 - Val Loss: 0.082095\n",
      "Epoch 18/50 - Train Loss: 0.042173 - Val Loss: 0.082297\n",
      "Epoch 19/50 - Train Loss: 0.043079 - Val Loss: 0.082604\n",
      "Epoch 20/50 - Train Loss: 0.040899 - Val Loss: 0.082071\n",
      "Epoch 21/50 - Train Loss: 0.043074 - Val Loss: 0.083140\n",
      "Epoch 22/50 - Train Loss: 0.043336 - Val Loss: 0.082193\n",
      "Epoch 23/50 - Train Loss: 0.041333 - Val Loss: 0.080531\n",
      "Epoch 24/50 - Train Loss: 0.040538 - Val Loss: 0.081096\n",
      "Epoch 25/50 - Train Loss: 0.038130 - Val Loss: 0.081080\n",
      "Epoch 26/50 - Train Loss: 0.041549 - Val Loss: 0.078091\n",
      "Epoch 27/50 - Train Loss: 0.040302 - Val Loss: 0.075163\n",
      "Epoch 28/50 - Train Loss: 0.037835 - Val Loss: 0.074003\n",
      "Epoch 29/50 - Train Loss: 0.037282 - Val Loss: 0.074636\n",
      "Epoch 30/50 - Train Loss: 0.038536 - Val Loss: 0.072074\n",
      "Epoch 31/50 - Train Loss: 0.033815 - Val Loss: 0.068453\n",
      "Epoch 32/50 - Train Loss: 0.034807 - Val Loss: 0.065318\n",
      "Epoch 33/50 - Train Loss: 0.034574 - Val Loss: 0.066351\n",
      "Epoch 34/50 - Train Loss: 0.033756 - Val Loss: 0.062635\n",
      "Epoch 35/50 - Train Loss: 0.029023 - Val Loss: 0.059999\n",
      "Epoch 36/50 - Train Loss: 0.034679 - Val Loss: 0.059749\n",
      "Epoch 37/50 - Train Loss: 0.033491 - Val Loss: 0.058437\n",
      "Epoch 38/50 - Train Loss: 0.034014 - Val Loss: 0.056679\n",
      "Epoch 39/50 - Train Loss: 0.035856 - Val Loss: 0.057710\n",
      "Epoch 40/50 - Train Loss: 0.034696 - Val Loss: 0.057829\n",
      "Epoch 41/50 - Train Loss: 0.032637 - Val Loss: 0.054235\n",
      "Epoch 42/50 - Train Loss: 0.032640 - Val Loss: 0.052229\n",
      "Epoch 43/50 - Train Loss: 0.032015 - Val Loss: 0.056144\n",
      "Epoch 44/50 - Train Loss: 0.031322 - Val Loss: 0.056643\n",
      "Epoch 45/50 - Train Loss: 0.034083 - Val Loss: 0.053681\n",
      "Epoch 46/50 - Train Loss: 0.033553 - Val Loss: 0.052674\n",
      "Epoch 47/50 - Train Loss: 0.028280 - Val Loss: 0.053223\n",
      "Epoch 48/50 - Train Loss: 0.029125 - Val Loss: 0.052324\n",
      "Epoch 49/50 - Train Loss: 0.031923 - Val Loss: 0.052004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:54:43,908] Trial 83 finished with value: 0.052004147320985794 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 67, 'lr': 0.00017886629360712962, 'weight_decay': 2.787028671461959e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033413 - Val Loss: 0.052867\n",
      "Epoch 1/50 - Train Loss: 0.057630 - Val Loss: 0.114211\n",
      "Epoch 2/50 - Train Loss: 0.046969 - Val Loss: 0.070566\n",
      "Epoch 3/50 - Train Loss: 0.038026 - Val Loss: 0.062081\n",
      "Epoch 4/50 - Train Loss: 0.040379 - Val Loss: 0.065337\n",
      "Epoch 5/50 - Train Loss: 0.035864 - Val Loss: 0.072413\n",
      "Epoch 6/50 - Train Loss: 0.038803 - Val Loss: 0.047486\n",
      "Epoch 7/50 - Train Loss: 0.033935 - Val Loss: 0.057592\n",
      "Epoch 8/50 - Train Loss: 0.033501 - Val Loss: 0.050948\n",
      "Epoch 9/50 - Train Loss: 0.031179 - Val Loss: 0.045846\n",
      "Epoch 10/50 - Train Loss: 0.028301 - Val Loss: 0.044860\n",
      "Epoch 11/50 - Train Loss: 0.033325 - Val Loss: 0.046385\n",
      "Epoch 12/50 - Train Loss: 0.031886 - Val Loss: 0.045285\n",
      "Epoch 13/50 - Train Loss: 0.033290 - Val Loss: 0.048811\n",
      "Epoch 14/50 - Train Loss: 0.032621 - Val Loss: 0.048680\n",
      "Epoch 15/50 - Train Loss: 0.034028 - Val Loss: 0.045084\n",
      "Epoch 16/50 - Train Loss: 0.029412 - Val Loss: 0.048587\n",
      "Epoch 17/50 - Train Loss: 0.033125 - Val Loss: 0.044691\n",
      "Epoch 18/50 - Train Loss: 0.031157 - Val Loss: 0.045806\n",
      "Epoch 19/50 - Train Loss: 0.030943 - Val Loss: 0.045419\n",
      "Epoch 20/50 - Train Loss: 0.030675 - Val Loss: 0.049072\n",
      "Epoch 21/50 - Train Loss: 0.034365 - Val Loss: 0.059078\n",
      "Epoch 22/50 - Train Loss: 0.031035 - Val Loss: 0.044838\n",
      "Epoch 23/50 - Train Loss: 0.032212 - Val Loss: 0.044977\n",
      "Epoch 24/50 - Train Loss: 0.028196 - Val Loss: 0.044866\n",
      "Epoch 25/50 - Train Loss: 0.033722 - Val Loss: 0.046063\n",
      "Epoch 26/50 - Train Loss: 0.035889 - Val Loss: 0.053742\n",
      "Epoch 27/50 - Train Loss: 0.031272 - Val Loss: 0.045781\n",
      "Epoch 28/50 - Train Loss: 0.030425 - Val Loss: 0.048240\n",
      "Epoch 29/50 - Train Loss: 0.033278 - Val Loss: 0.048742\n",
      "Epoch 30/50 - Train Loss: 0.030571 - Val Loss: 0.045190\n",
      "Epoch 31/50 - Train Loss: 0.034339 - Val Loss: 0.046105\n",
      "Epoch 32/50 - Train Loss: 0.029930 - Val Loss: 0.058077\n",
      "Epoch 33/50 - Train Loss: 0.029820 - Val Loss: 0.044523\n",
      "Epoch 34/50 - Train Loss: 0.038366 - Val Loss: 0.045999\n",
      "Epoch 35/50 - Train Loss: 0.028598 - Val Loss: 0.052938\n",
      "Epoch 36/50 - Train Loss: 0.032761 - Val Loss: 0.051195\n",
      "Epoch 37/50 - Train Loss: 0.031384 - Val Loss: 0.045272\n",
      "Epoch 38/50 - Train Loss: 0.031406 - Val Loss: 0.044428\n",
      "Epoch 39/50 - Train Loss: 0.034169 - Val Loss: 0.047964\n",
      "Epoch 40/50 - Train Loss: 0.033386 - Val Loss: 0.047079\n",
      "Epoch 41/50 - Train Loss: 0.033831 - Val Loss: 0.048771\n",
      "Epoch 42/50 - Train Loss: 0.030325 - Val Loss: 0.045189\n",
      "Epoch 43/50 - Train Loss: 0.030863 - Val Loss: 0.045296\n",
      "Epoch 44/50 - Train Loss: 0.032782 - Val Loss: 0.045948\n",
      "Epoch 45/50 - Train Loss: 0.032137 - Val Loss: 0.046347\n",
      "Epoch 46/50 - Train Loss: 0.034509 - Val Loss: 0.045429\n",
      "Epoch 47/50 - Train Loss: 0.029701 - Val Loss: 0.047016\n",
      "Epoch 48/50 - Train Loss: 0.032210 - Val Loss: 0.044506\n",
      "Epoch 49/50 - Train Loss: 0.030604 - Val Loss: 0.044185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:55:00,187] Trial 84 finished with value: 0.04418467730283737 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 84, 'lr': 0.008579192087934293, 'weight_decay': 5.559185384692868e-05, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033162 - Val Loss: 0.044493\n",
      "Epoch 1/50 - Train Loss: 0.065742 - Val Loss: 0.061922\n",
      "Epoch 2/50 - Train Loss: 0.043787 - Val Loss: 0.099153\n",
      "Epoch 3/50 - Train Loss: 0.042675 - Val Loss: 0.092875\n",
      "Epoch 4/50 - Train Loss: 0.039586 - Val Loss: 0.074391\n",
      "Epoch 5/50 - Train Loss: 0.045280 - Val Loss: 0.085074\n",
      "Epoch 6/50 - Train Loss: 0.042914 - Val Loss: 0.082835\n",
      "Epoch 7/50 - Train Loss: 0.038034 - Val Loss: 0.070282\n",
      "Epoch 8/50 - Train Loss: 0.036021 - Val Loss: 0.050839\n",
      "Epoch 9/50 - Train Loss: 0.036165 - Val Loss: 0.062832\n",
      "Epoch 10/50 - Train Loss: 0.032284 - Val Loss: 0.062060\n",
      "Epoch 11/50 - Train Loss: 0.031073 - Val Loss: 0.050016\n",
      "Epoch 12/50 - Train Loss: 0.028857 - Val Loss: 0.054741\n",
      "Epoch 13/50 - Train Loss: 0.032631 - Val Loss: 0.053126\n",
      "Epoch 14/50 - Train Loss: 0.031372 - Val Loss: 0.049422\n",
      "Epoch 15/50 - Train Loss: 0.028968 - Val Loss: 0.045883\n",
      "Epoch 16/50 - Train Loss: 0.031333 - Val Loss: 0.047359\n",
      "Epoch 17/50 - Train Loss: 0.032001 - Val Loss: 0.059184\n",
      "Epoch 18/50 - Train Loss: 0.035007 - Val Loss: 0.046410\n",
      "Epoch 19/50 - Train Loss: 0.034062 - Val Loss: 0.045267\n",
      "Epoch 20/50 - Train Loss: 0.029269 - Val Loss: 0.050738\n",
      "Epoch 21/50 - Train Loss: 0.030945 - Val Loss: 0.044714\n",
      "Epoch 22/50 - Train Loss: 0.032861 - Val Loss: 0.045782\n",
      "Epoch 23/50 - Train Loss: 0.030606 - Val Loss: 0.049958\n",
      "Epoch 24/50 - Train Loss: 0.031611 - Val Loss: 0.046577\n",
      "Epoch 25/50 - Train Loss: 0.031773 - Val Loss: 0.045126\n",
      "Epoch 26/50 - Train Loss: 0.030490 - Val Loss: 0.047332\n",
      "Epoch 27/50 - Train Loss: 0.032842 - Val Loss: 0.045086\n",
      "Epoch 28/50 - Train Loss: 0.032337 - Val Loss: 0.045218\n",
      "Epoch 29/50 - Train Loss: 0.031590 - Val Loss: 0.045622\n",
      "Epoch 30/50 - Train Loss: 0.030044 - Val Loss: 0.045978\n",
      "Epoch 31/50 - Train Loss: 0.032067 - Val Loss: 0.044606\n",
      "Epoch 32/50 - Train Loss: 0.032401 - Val Loss: 0.044720\n",
      "Epoch 33/50 - Train Loss: 0.031932 - Val Loss: 0.044494\n",
      "Epoch 34/50 - Train Loss: 0.033784 - Val Loss: 0.044672\n",
      "Epoch 35/50 - Train Loss: 0.030124 - Val Loss: 0.046647\n",
      "Epoch 36/50 - Train Loss: 0.031389 - Val Loss: 0.045030\n",
      "Epoch 37/50 - Train Loss: 0.033981 - Val Loss: 0.044740\n",
      "Epoch 38/50 - Train Loss: 0.029852 - Val Loss: 0.047354\n",
      "Epoch 39/50 - Train Loss: 0.032540 - Val Loss: 0.048763\n",
      "Epoch 40/50 - Train Loss: 0.032828 - Val Loss: 0.044933\n",
      "Epoch 41/50 - Train Loss: 0.031254 - Val Loss: 0.045644\n",
      "Epoch 42/50 - Train Loss: 0.033633 - Val Loss: 0.056873\n",
      "Epoch 43/50 - Train Loss: 0.029960 - Val Loss: 0.044636\n",
      "Epoch 44/50 - Train Loss: 0.032108 - Val Loss: 0.044619\n",
      "Epoch 45/50 - Train Loss: 0.032512 - Val Loss: 0.045081\n",
      "Epoch 46/50 - Train Loss: 0.033236 - Val Loss: 0.045395\n",
      "Epoch 47/50 - Train Loss: 0.027681 - Val Loss: 0.044993\n",
      "Epoch 48/50 - Train Loss: 0.033461 - Val Loss: 0.044592\n",
      "Epoch 49/50 - Train Loss: 0.028860 - Val Loss: 0.045136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:55:17,410] Trial 85 finished with value: 0.04449413903057575 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 62, 'lr': 0.004073538291321731, 'weight_decay': 2.0966146120739923e-05, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030503 - Val Loss: 0.044872\n",
      "Epoch 1/50 - Train Loss: 0.104803 - Val Loss: 0.193170\n",
      "Epoch 2/50 - Train Loss: 0.069286 - Val Loss: 0.131580\n",
      "Epoch 3/50 - Train Loss: 0.047037 - Val Loss: 0.078493\n",
      "Epoch 4/50 - Train Loss: 0.048051 - Val Loss: 0.073742\n",
      "Epoch 5/50 - Train Loss: 0.037454 - Val Loss: 0.091521\n",
      "Epoch 6/50 - Train Loss: 0.044140 - Val Loss: 0.090432\n",
      "Epoch 7/50 - Train Loss: 0.043146 - Val Loss: 0.079319\n",
      "Epoch 8/50 - Train Loss: 0.042640 - Val Loss: 0.071814\n",
      "Epoch 9/50 - Train Loss: 0.046130 - Val Loss: 0.073062\n",
      "Epoch 10/50 - Train Loss: 0.040640 - Val Loss: 0.072042\n",
      "Epoch 11/50 - Train Loss: 0.039766 - Val Loss: 0.069367\n",
      "Epoch 12/50 - Train Loss: 0.034251 - Val Loss: 0.056526\n",
      "Epoch 13/50 - Train Loss: 0.036673 - Val Loss: 0.063541\n",
      "Epoch 14/50 - Train Loss: 0.034992 - Val Loss: 0.053920\n",
      "Epoch 15/50 - Train Loss: 0.036215 - Val Loss: 0.054552\n",
      "Epoch 16/50 - Train Loss: 0.035103 - Val Loss: 0.053113\n",
      "Epoch 17/50 - Train Loss: 0.034462 - Val Loss: 0.049959\n",
      "Epoch 18/50 - Train Loss: 0.033011 - Val Loss: 0.051618\n",
      "Epoch 19/50 - Train Loss: 0.034102 - Val Loss: 0.049043\n",
      "Epoch 20/50 - Train Loss: 0.027909 - Val Loss: 0.048842\n",
      "Epoch 21/50 - Train Loss: 0.029458 - Val Loss: 0.048829\n",
      "Epoch 22/50 - Train Loss: 0.033056 - Val Loss: 0.046875\n",
      "Epoch 23/50 - Train Loss: 0.029607 - Val Loss: 0.050094\n",
      "Epoch 24/50 - Train Loss: 0.033308 - Val Loss: 0.049533\n",
      "Epoch 25/50 - Train Loss: 0.031407 - Val Loss: 0.047744\n",
      "Epoch 26/50 - Train Loss: 0.034213 - Val Loss: 0.049997\n",
      "Epoch 27/50 - Train Loss: 0.030059 - Val Loss: 0.046685\n",
      "Epoch 28/50 - Train Loss: 0.032719 - Val Loss: 0.051785\n",
      "Epoch 29/50 - Train Loss: 0.031864 - Val Loss: 0.046843\n",
      "Epoch 30/50 - Train Loss: 0.032959 - Val Loss: 0.050458\n",
      "Epoch 31/50 - Train Loss: 0.029296 - Val Loss: 0.047772\n",
      "Epoch 32/50 - Train Loss: 0.030776 - Val Loss: 0.047960\n",
      "Epoch 33/50 - Train Loss: 0.029570 - Val Loss: 0.048672\n",
      "Epoch 34/50 - Train Loss: 0.031295 - Val Loss: 0.046335\n",
      "Epoch 35/50 - Train Loss: 0.030593 - Val Loss: 0.049319\n",
      "Epoch 36/50 - Train Loss: 0.032848 - Val Loss: 0.047309\n",
      "Epoch 37/50 - Train Loss: 0.032417 - Val Loss: 0.048838\n",
      "Epoch 38/50 - Train Loss: 0.030395 - Val Loss: 0.047456\n",
      "Epoch 39/50 - Train Loss: 0.032722 - Val Loss: 0.048415\n",
      "Epoch 40/50 - Train Loss: 0.034911 - Val Loss: 0.049230\n",
      "Epoch 41/50 - Train Loss: 0.033682 - Val Loss: 0.048625\n",
      "Epoch 42/50 - Train Loss: 0.030036 - Val Loss: 0.047039\n",
      "Epoch 43/50 - Train Loss: 0.030726 - Val Loss: 0.047076\n",
      "Epoch 44/50 - Train Loss: 0.030451 - Val Loss: 0.045226\n",
      "Epoch 45/50 - Train Loss: 0.029287 - Val Loss: 0.045897\n",
      "Epoch 46/50 - Train Loss: 0.031966 - Val Loss: 0.046439\n",
      "Epoch 47/50 - Train Loss: 0.032074 - Val Loss: 0.046517\n",
      "Epoch 48/50 - Train Loss: 0.031098 - Val Loss: 0.047413\n",
      "Epoch 49/50 - Train Loss: 0.027521 - Val Loss: 0.046417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:55:39,321] Trial 86 finished with value: 0.045226406306028366 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 92, 'lr': 0.0005295285184798931, 'weight_decay': 9.042251929067025e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.028253 - Val Loss: 0.045999\n",
      "Epoch 1/50 - Train Loss: 0.090886 - Val Loss: 0.074205\n",
      "Epoch 2/50 - Train Loss: 0.045803 - Val Loss: 0.075769\n",
      "Epoch 3/50 - Train Loss: 0.042823 - Val Loss: 0.089961\n",
      "Epoch 4/50 - Train Loss: 0.042418 - Val Loss: 0.094844\n",
      "Epoch 5/50 - Train Loss: 0.042973 - Val Loss: 0.085696\n",
      "Epoch 6/50 - Train Loss: 0.049821 - Val Loss: 0.080315\n",
      "Epoch 7/50 - Train Loss: 0.048990 - Val Loss: 0.085310\n",
      "Epoch 8/50 - Train Loss: 0.040175 - Val Loss: 0.081379\n",
      "Epoch 9/50 - Train Loss: 0.046428 - Val Loss: 0.069230\n",
      "Epoch 10/50 - Train Loss: 0.042934 - Val Loss: 0.062717\n",
      "Epoch 11/50 - Train Loss: 0.043287 - Val Loss: 0.051637\n",
      "Epoch 12/50 - Train Loss: 0.033965 - Val Loss: 0.050713\n",
      "Epoch 13/50 - Train Loss: 0.040349 - Val Loss: 0.052064\n",
      "Epoch 14/50 - Train Loss: 0.033198 - Val Loss: 0.053593\n",
      "Epoch 15/50 - Train Loss: 0.032863 - Val Loss: 0.061734\n",
      "Epoch 16/50 - Train Loss: 0.039759 - Val Loss: 0.053734\n",
      "Epoch 17/50 - Train Loss: 0.041303 - Val Loss: 0.054590\n",
      "Epoch 18/50 - Train Loss: 0.030866 - Val Loss: 0.057688\n",
      "Epoch 19/50 - Train Loss: 0.039056 - Val Loss: 0.051346\n",
      "Epoch 20/50 - Train Loss: 0.037859 - Val Loss: 0.050717\n",
      "Epoch 21/50 - Train Loss: 0.037640 - Val Loss: 0.052138\n",
      "Epoch 22/50 - Train Loss: 0.029278 - Val Loss: 0.049660\n",
      "Epoch 23/50 - Train Loss: 0.037039 - Val Loss: 0.049551\n",
      "Epoch 24/50 - Train Loss: 0.038308 - Val Loss: 0.049988\n",
      "Epoch 25/50 - Train Loss: 0.038567 - Val Loss: 0.048762\n",
      "Epoch 26/50 - Train Loss: 0.029998 - Val Loss: 0.048731\n",
      "Epoch 27/50 - Train Loss: 0.037209 - Val Loss: 0.047453\n",
      "Epoch 28/50 - Train Loss: 0.028642 - Val Loss: 0.047940\n",
      "Epoch 29/50 - Train Loss: 0.029287 - Val Loss: 0.047336\n",
      "Epoch 30/50 - Train Loss: 0.036425 - Val Loss: 0.046740\n",
      "Epoch 31/50 - Train Loss: 0.029459 - Val Loss: 0.046695\n",
      "Epoch 32/50 - Train Loss: 0.030427 - Val Loss: 0.045989\n",
      "Epoch 33/50 - Train Loss: 0.028867 - Val Loss: 0.047112\n",
      "Epoch 34/50 - Train Loss: 0.029327 - Val Loss: 0.046596\n",
      "Epoch 35/50 - Train Loss: 0.036754 - Val Loss: 0.049339\n",
      "Epoch 36/50 - Train Loss: 0.036784 - Val Loss: 0.049447\n",
      "Epoch 37/50 - Train Loss: 0.035069 - Val Loss: 0.048049\n",
      "Epoch 38/50 - Train Loss: 0.028946 - Val Loss: 0.049410\n",
      "Epoch 39/50 - Train Loss: 0.038114 - Val Loss: 0.047034\n",
      "Epoch 40/50 - Train Loss: 0.028955 - Val Loss: 0.047331\n",
      "Epoch 41/50 - Train Loss: 0.037428 - Val Loss: 0.049545\n",
      "Epoch 42/50 - Train Loss: 0.028978 - Val Loss: 0.046260\n",
      "Epoch 43/50 - Train Loss: 0.028693 - Val Loss: 0.046038\n",
      "Epoch 44/50 - Train Loss: 0.036704 - Val Loss: 0.048527\n",
      "Epoch 45/50 - Train Loss: 0.028634 - Val Loss: 0.046133\n",
      "Epoch 46/50 - Train Loss: 0.036842 - Val Loss: 0.047962\n",
      "Epoch 47/50 - Train Loss: 0.030018 - Val Loss: 0.048068\n",
      "Epoch 48/50 - Train Loss: 0.028968 - Val Loss: 0.046033\n",
      "Epoch 49/50 - Train Loss: 0.027849 - Val Loss: 0.046258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:55:50,085] Trial 87 finished with value: 0.04562097042798996 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 73, 'lr': 0.0069220844540139196, 'weight_decay': 4.867239917418044e-06, 'batch_size': 64}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.029284 - Val Loss: 0.045621\n",
      "Epoch 1/50 - Train Loss: 0.202430 - Val Loss: 0.232126\n",
      "Epoch 2/50 - Train Loss: 0.077776 - Val Loss: 0.099200\n",
      "Epoch 3/50 - Train Loss: 0.058040 - Val Loss: 0.093299\n",
      "Epoch 4/50 - Train Loss: 0.050822 - Val Loss: 0.076268\n",
      "Epoch 5/50 - Train Loss: 0.037924 - Val Loss: 0.079413\n",
      "Epoch 6/50 - Train Loss: 0.045698 - Val Loss: 0.092273\n",
      "Epoch 7/50 - Train Loss: 0.043851 - Val Loss: 0.061030\n",
      "Epoch 8/50 - Train Loss: 0.040720 - Val Loss: 0.067124\n",
      "Epoch 9/50 - Train Loss: 0.037147 - Val Loss: 0.054443\n",
      "Epoch 10/50 - Train Loss: 0.031017 - Val Loss: 0.048892\n",
      "Epoch 11/50 - Train Loss: 0.037669 - Val Loss: 0.047611\n",
      "Epoch 12/50 - Train Loss: 0.034134 - Val Loss: 0.051456\n",
      "Epoch 13/50 - Train Loss: 0.034198 - Val Loss: 0.046130\n",
      "Epoch 14/50 - Train Loss: 0.028128 - Val Loss: 0.046836\n",
      "Epoch 15/50 - Train Loss: 0.031967 - Val Loss: 0.050183\n",
      "Epoch 16/50 - Train Loss: 0.034262 - Val Loss: 0.046199\n",
      "Epoch 17/50 - Train Loss: 0.032213 - Val Loss: 0.049249\n",
      "Epoch 18/50 - Train Loss: 0.034705 - Val Loss: 0.044877\n",
      "Epoch 19/50 - Train Loss: 0.033387 - Val Loss: 0.051167\n",
      "Epoch 20/50 - Train Loss: 0.029115 - Val Loss: 0.044381\n",
      "Epoch 21/50 - Train Loss: 0.033248 - Val Loss: 0.046140\n",
      "Epoch 22/50 - Train Loss: 0.034771 - Val Loss: 0.057747\n",
      "Epoch 23/50 - Train Loss: 0.038971 - Val Loss: 0.046950\n",
      "Epoch 24/50 - Train Loss: 0.036114 - Val Loss: 0.049128\n",
      "Epoch 25/50 - Train Loss: 0.024242 - Val Loss: 0.045163\n",
      "Epoch 26/50 - Train Loss: 0.035792 - Val Loss: 0.052876\n",
      "Epoch 27/50 - Train Loss: 0.031579 - Val Loss: 0.045346\n",
      "Epoch 28/50 - Train Loss: 0.025968 - Val Loss: 0.046942\n",
      "Epoch 29/50 - Train Loss: 0.028213 - Val Loss: 0.044895\n",
      "Epoch 30/50 - Train Loss: 0.028296 - Val Loss: 0.045354\n",
      "Epoch 31/50 - Train Loss: 0.031851 - Val Loss: 0.045856\n",
      "Epoch 32/50 - Train Loss: 0.028821 - Val Loss: 0.045709\n",
      "Epoch 33/50 - Train Loss: 0.030243 - Val Loss: 0.046632\n",
      "Epoch 34/50 - Train Loss: 0.039219 - Val Loss: 0.043955\n",
      "Epoch 35/50 - Train Loss: 0.034206 - Val Loss: 0.044926\n",
      "Epoch 36/50 - Train Loss: 0.041672 - Val Loss: 0.048666\n",
      "Epoch 37/50 - Train Loss: 0.036633 - Val Loss: 0.044578\n",
      "Epoch 38/50 - Train Loss: 0.029359 - Val Loss: 0.053696\n",
      "Epoch 39/50 - Train Loss: 0.030551 - Val Loss: 0.048949\n",
      "Epoch 40/50 - Train Loss: 0.034521 - Val Loss: 0.060142\n",
      "Epoch 41/50 - Train Loss: 0.034269 - Val Loss: 0.044910\n",
      "Epoch 42/50 - Train Loss: 0.031637 - Val Loss: 0.049885\n",
      "Epoch 43/50 - Train Loss: 0.032954 - Val Loss: 0.045079\n",
      "Epoch 44/50 - Train Loss: 0.032247 - Val Loss: 0.052278\n",
      "Epoch 45/50 - Train Loss: 0.033586 - Val Loss: 0.044626\n",
      "Epoch 46/50 - Train Loss: 0.039913 - Val Loss: 0.050822\n",
      "Epoch 47/50 - Train Loss: 0.033778 - Val Loss: 0.045798\n",
      "Epoch 48/50 - Train Loss: 0.033443 - Val Loss: 0.048993\n",
      "Epoch 49/50 - Train Loss: 0.034073 - Val Loss: 0.044279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:56:10,103] Trial 88 finished with value: 0.04395485669374466 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 208, 'lr': 0.008836415457221998, 'weight_decay': 3.9434555760796426e-07, 'batch_size': 32}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030389 - Val Loss: 0.044044\n",
      "Epoch 1/50 - Train Loss: 0.109837 - Val Loss: 0.232078\n",
      "Epoch 2/50 - Train Loss: 0.096550 - Val Loss: 0.230436\n",
      "Epoch 3/50 - Train Loss: 0.103358 - Val Loss: 0.228830\n",
      "Epoch 4/50 - Train Loss: 0.098851 - Val Loss: 0.227195\n",
      "Epoch 5/50 - Train Loss: 0.098558 - Val Loss: 0.225619\n",
      "Epoch 6/50 - Train Loss: 0.093557 - Val Loss: 0.224032\n",
      "Epoch 7/50 - Train Loss: 0.093310 - Val Loss: 0.222429\n",
      "Epoch 8/50 - Train Loss: 0.102198 - Val Loss: 0.220775\n",
      "Epoch 9/50 - Train Loss: 0.092668 - Val Loss: 0.219030\n",
      "Epoch 10/50 - Train Loss: 0.095664 - Val Loss: 0.217272\n",
      "Epoch 11/50 - Train Loss: 0.092212 - Val Loss: 0.215481\n",
      "Epoch 12/50 - Train Loss: 0.089239 - Val Loss: 0.213683\n",
      "Epoch 13/50 - Train Loss: 0.085118 - Val Loss: 0.211886\n",
      "Epoch 14/50 - Train Loss: 0.096026 - Val Loss: 0.210113\n",
      "Epoch 15/50 - Train Loss: 0.089947 - Val Loss: 0.208299\n",
      "Epoch 16/50 - Train Loss: 0.083692 - Val Loss: 0.206426\n",
      "Epoch 17/50 - Train Loss: 0.085498 - Val Loss: 0.204596\n",
      "Epoch 18/50 - Train Loss: 0.080413 - Val Loss: 0.202803\n",
      "Epoch 19/50 - Train Loss: 0.082938 - Val Loss: 0.200980\n",
      "Epoch 20/50 - Train Loss: 0.087597 - Val Loss: 0.199083\n",
      "Epoch 21/50 - Train Loss: 0.092949 - Val Loss: 0.197186\n",
      "Epoch 22/50 - Train Loss: 0.076946 - Val Loss: 0.195247\n",
      "Epoch 23/50 - Train Loss: 0.081252 - Val Loss: 0.193385\n",
      "Epoch 24/50 - Train Loss: 0.080936 - Val Loss: 0.191529\n",
      "Epoch 25/50 - Train Loss: 0.081154 - Val Loss: 0.189601\n",
      "Epoch 26/50 - Train Loss: 0.080182 - Val Loss: 0.187684\n",
      "Epoch 27/50 - Train Loss: 0.077091 - Val Loss: 0.185803\n",
      "Epoch 28/50 - Train Loss: 0.072398 - Val Loss: 0.183918\n",
      "Epoch 29/50 - Train Loss: 0.073827 - Val Loss: 0.182104\n",
      "Epoch 30/50 - Train Loss: 0.071213 - Val Loss: 0.180297\n",
      "Epoch 31/50 - Train Loss: 0.074189 - Val Loss: 0.178439\n",
      "Epoch 32/50 - Train Loss: 0.072535 - Val Loss: 0.176608\n",
      "Epoch 33/50 - Train Loss: 0.074178 - Val Loss: 0.174731\n",
      "Epoch 34/50 - Train Loss: 0.072802 - Val Loss: 0.172863\n",
      "Epoch 35/50 - Train Loss: 0.070145 - Val Loss: 0.170986\n",
      "Epoch 36/50 - Train Loss: 0.068062 - Val Loss: 0.169053\n",
      "Epoch 37/50 - Train Loss: 0.066290 - Val Loss: 0.167212\n",
      "Epoch 38/50 - Train Loss: 0.066236 - Val Loss: 0.165372\n",
      "Epoch 39/50 - Train Loss: 0.063809 - Val Loss: 0.163539\n",
      "Epoch 40/50 - Train Loss: 0.062243 - Val Loss: 0.161718\n",
      "Epoch 41/50 - Train Loss: 0.063627 - Val Loss: 0.159845\n",
      "Epoch 42/50 - Train Loss: 0.062318 - Val Loss: 0.158037\n",
      "Epoch 43/50 - Train Loss: 0.062536 - Val Loss: 0.156199\n",
      "Epoch 44/50 - Train Loss: 0.062109 - Val Loss: 0.154300\n",
      "Epoch 45/50 - Train Loss: 0.064009 - Val Loss: 0.152381\n",
      "Epoch 46/50 - Train Loss: 0.059648 - Val Loss: 0.150596\n",
      "Epoch 47/50 - Train Loss: 0.060679 - Val Loss: 0.148709\n",
      "Epoch 48/50 - Train Loss: 0.062598 - Val Loss: 0.146857\n",
      "Epoch 49/50 - Train Loss: 0.059796 - Val Loss: 0.144982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:56:23,814] Trial 89 finished with value: 0.1431322619318962 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 53, 'lr': 1.9952795762047814e-05, 'weight_decay': 1.518866133531022e-06, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.055979 - Val Loss: 0.143132\n",
      "Epoch 1/50 - Train Loss: 0.183668 - Val Loss: 0.293725\n",
      "Epoch 2/50 - Train Loss: 0.094328 - Val Loss: 0.136316\n",
      "Epoch 3/50 - Train Loss: 0.049290 - Val Loss: 0.075482\n",
      "Epoch 4/50 - Train Loss: 0.046565 - Val Loss: 0.098817\n",
      "Epoch 5/50 - Train Loss: 0.043862 - Val Loss: 0.081315\n",
      "Epoch 6/50 - Train Loss: 0.044321 - Val Loss: 0.085594\n",
      "Epoch 7/50 - Train Loss: 0.043621 - Val Loss: 0.081135\n",
      "Epoch 8/50 - Train Loss: 0.040222 - Val Loss: 0.077137\n",
      "Epoch 9/50 - Train Loss: 0.041086 - Val Loss: 0.074912\n",
      "Epoch 10/50 - Train Loss: 0.040317 - Val Loss: 0.068419\n",
      "Epoch 11/50 - Train Loss: 0.038503 - Val Loss: 0.068150\n",
      "Epoch 12/50 - Train Loss: 0.035673 - Val Loss: 0.055249\n",
      "Epoch 13/50 - Train Loss: 0.033688 - Val Loss: 0.057102\n",
      "Epoch 14/50 - Train Loss: 0.033348 - Val Loss: 0.055245\n",
      "Epoch 15/50 - Train Loss: 0.035158 - Val Loss: 0.053746\n",
      "Epoch 16/50 - Train Loss: 0.032805 - Val Loss: 0.051624\n",
      "Epoch 17/50 - Train Loss: 0.032765 - Val Loss: 0.049137\n",
      "Epoch 18/50 - Train Loss: 0.030796 - Val Loss: 0.050073\n",
      "Epoch 19/50 - Train Loss: 0.030353 - Val Loss: 0.047173\n",
      "Epoch 20/50 - Train Loss: 0.029070 - Val Loss: 0.046831\n",
      "Epoch 21/50 - Train Loss: 0.031760 - Val Loss: 0.046218\n",
      "Epoch 22/50 - Train Loss: 0.030478 - Val Loss: 0.046512\n",
      "Epoch 23/50 - Train Loss: 0.032187 - Val Loss: 0.052712\n",
      "Epoch 24/50 - Train Loss: 0.030901 - Val Loss: 0.046618\n",
      "Epoch 25/50 - Train Loss: 0.029430 - Val Loss: 0.046171\n",
      "Epoch 26/50 - Train Loss: 0.031796 - Val Loss: 0.046511\n",
      "Epoch 27/50 - Train Loss: 0.030673 - Val Loss: 0.046174\n",
      "Epoch 28/50 - Train Loss: 0.030477 - Val Loss: 0.049447\n",
      "Epoch 29/50 - Train Loss: 0.031973 - Val Loss: 0.046746\n",
      "Epoch 30/50 - Train Loss: 0.031123 - Val Loss: 0.045828\n",
      "Epoch 31/50 - Train Loss: 0.032226 - Val Loss: 0.047343\n",
      "Epoch 32/50 - Train Loss: 0.032874 - Val Loss: 0.045599\n",
      "Epoch 33/50 - Train Loss: 0.030169 - Val Loss: 0.047370\n",
      "Epoch 34/50 - Train Loss: 0.032547 - Val Loss: 0.048870\n",
      "Epoch 35/50 - Train Loss: 0.032018 - Val Loss: 0.046609\n",
      "Epoch 36/50 - Train Loss: 0.030434 - Val Loss: 0.047445\n",
      "Epoch 37/50 - Train Loss: 0.029517 - Val Loss: 0.047603\n",
      "Epoch 38/50 - Train Loss: 0.029707 - Val Loss: 0.045318\n",
      "Epoch 39/50 - Train Loss: 0.031471 - Val Loss: 0.045463\n",
      "Epoch 40/50 - Train Loss: 0.029434 - Val Loss: 0.048233\n",
      "Epoch 41/50 - Train Loss: 0.029234 - Val Loss: 0.046754\n",
      "Epoch 42/50 - Train Loss: 0.031179 - Val Loss: 0.044727\n",
      "Epoch 43/50 - Train Loss: 0.030386 - Val Loss: 0.045138\n",
      "Epoch 44/50 - Train Loss: 0.032251 - Val Loss: 0.045540\n",
      "Epoch 45/50 - Train Loss: 0.030681 - Val Loss: 0.045499\n",
      "Epoch 46/50 - Train Loss: 0.030816 - Val Loss: 0.045241\n",
      "Epoch 47/50 - Train Loss: 0.029904 - Val Loss: 0.045251\n",
      "Epoch 48/50 - Train Loss: 0.031829 - Val Loss: 0.048198\n",
      "Epoch 49/50 - Train Loss: 0.028778 - Val Loss: 0.045072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:56:47,678] Trial 90 finished with value: 0.04472662384311358 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 43, 'lr': 0.0009151557807513213, 'weight_decay': 1.5932063675042628e-05, 'batch_size': 8}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.029928 - Val Loss: 0.045306\n",
      "Epoch 1/50 - Train Loss: 0.112016 - Val Loss: 0.091422\n",
      "Epoch 2/50 - Train Loss: 0.058394 - Val Loss: 0.107688\n",
      "Epoch 3/50 - Train Loss: 0.048117 - Val Loss: 0.064983\n",
      "Epoch 4/50 - Train Loss: 0.045389 - Val Loss: 0.090587\n",
      "Epoch 5/50 - Train Loss: 0.041898 - Val Loss: 0.077153\n",
      "Epoch 6/50 - Train Loss: 0.040897 - Val Loss: 0.063787\n",
      "Epoch 7/50 - Train Loss: 0.038805 - Val Loss: 0.077184\n",
      "Epoch 8/50 - Train Loss: 0.038337 - Val Loss: 0.047654\n",
      "Epoch 9/50 - Train Loss: 0.034382 - Val Loss: 0.048905\n",
      "Epoch 10/50 - Train Loss: 0.034439 - Val Loss: 0.056560\n",
      "Epoch 11/50 - Train Loss: 0.031971 - Val Loss: 0.046727\n",
      "Epoch 12/50 - Train Loss: 0.034303 - Val Loss: 0.049253\n",
      "Epoch 13/50 - Train Loss: 0.032472 - Val Loss: 0.049945\n",
      "Epoch 14/50 - Train Loss: 0.029579 - Val Loss: 0.050024\n",
      "Epoch 15/50 - Train Loss: 0.030402 - Val Loss: 0.044837\n",
      "Epoch 16/50 - Train Loss: 0.030513 - Val Loss: 0.052097\n",
      "Epoch 17/50 - Train Loss: 0.031547 - Val Loss: 0.046529\n",
      "Epoch 18/50 - Train Loss: 0.031718 - Val Loss: 0.044578\n",
      "Epoch 19/50 - Train Loss: 0.031773 - Val Loss: 0.047625\n",
      "Epoch 20/50 - Train Loss: 0.032784 - Val Loss: 0.055269\n",
      "Epoch 21/50 - Train Loss: 0.031179 - Val Loss: 0.044642\n",
      "Epoch 22/50 - Train Loss: 0.033611 - Val Loss: 0.045192\n",
      "Epoch 23/50 - Train Loss: 0.030592 - Val Loss: 0.047776\n",
      "Epoch 24/50 - Train Loss: 0.030098 - Val Loss: 0.047794\n",
      "Epoch 25/50 - Train Loss: 0.033356 - Val Loss: 0.051204\n",
      "Epoch 26/50 - Train Loss: 0.030032 - Val Loss: 0.047988\n",
      "Epoch 27/50 - Train Loss: 0.033521 - Val Loss: 0.044971\n",
      "Epoch 28/50 - Train Loss: 0.032900 - Val Loss: 0.044608\n",
      "Epoch 29/50 - Train Loss: 0.027144 - Val Loss: 0.048982\n",
      "Epoch 30/50 - Train Loss: 0.030361 - Val Loss: 0.045346\n",
      "Epoch 31/50 - Train Loss: 0.032552 - Val Loss: 0.044651\n",
      "Epoch 32/50 - Train Loss: 0.030042 - Val Loss: 0.046525\n",
      "Epoch 33/50 - Train Loss: 0.032866 - Val Loss: 0.050929\n",
      "Epoch 34/50 - Train Loss: 0.032277 - Val Loss: 0.046985\n",
      "Epoch 35/50 - Train Loss: 0.030949 - Val Loss: 0.047299\n",
      "Epoch 36/50 - Train Loss: 0.032443 - Val Loss: 0.045612\n",
      "Epoch 37/50 - Train Loss: 0.032156 - Val Loss: 0.045678\n",
      "Epoch 38/50 - Train Loss: 0.026898 - Val Loss: 0.044301\n",
      "Epoch 39/50 - Train Loss: 0.031769 - Val Loss: 0.046797\n",
      "Epoch 40/50 - Train Loss: 0.031362 - Val Loss: 0.045412\n",
      "Epoch 41/50 - Train Loss: 0.034151 - Val Loss: 0.047669\n",
      "Epoch 42/50 - Train Loss: 0.029788 - Val Loss: 0.045413\n",
      "Epoch 43/50 - Train Loss: 0.030059 - Val Loss: 0.045219\n",
      "Epoch 44/50 - Train Loss: 0.034305 - Val Loss: 0.048841\n",
      "Epoch 45/50 - Train Loss: 0.030573 - Val Loss: 0.056304\n",
      "Epoch 46/50 - Train Loss: 0.031677 - Val Loss: 0.050080\n",
      "Epoch 47/50 - Train Loss: 0.030488 - Val Loss: 0.046009\n",
      "Epoch 48/50 - Train Loss: 0.031074 - Val Loss: 0.044548\n",
      "Epoch 49/50 - Train Loss: 0.026880 - Val Loss: 0.047843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:57:04,149] Trial 91 finished with value: 0.044301217421889305 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 86, 'lr': 0.004789470866044876, 'weight_decay': 1.2691399317545744e-07, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.029059 - Val Loss: 0.046277\n",
      "Epoch 1/50 - Train Loss: 0.066256 - Val Loss: 0.081647\n",
      "Epoch 2/50 - Train Loss: 0.040809 - Val Loss: 0.071986\n",
      "Epoch 3/50 - Train Loss: 0.037743 - Val Loss: 0.056765\n",
      "Epoch 4/50 - Train Loss: 0.035537 - Val Loss: 0.047749\n",
      "Epoch 5/50 - Train Loss: 0.032361 - Val Loss: 0.046404\n",
      "Epoch 6/50 - Train Loss: 0.034135 - Val Loss: 0.045540\n",
      "Epoch 7/50 - Train Loss: 0.033266 - Val Loss: 0.047104\n",
      "Epoch 8/50 - Train Loss: 0.031425 - Val Loss: 0.049201\n",
      "Epoch 9/50 - Train Loss: 0.034773 - Val Loss: 0.049713\n",
      "Epoch 10/50 - Train Loss: 0.029292 - Val Loss: 0.044274\n",
      "Epoch 11/50 - Train Loss: 0.030596 - Val Loss: 0.047192\n",
      "Epoch 12/50 - Train Loss: 0.029902 - Val Loss: 0.051241\n",
      "Epoch 13/50 - Train Loss: 0.029755 - Val Loss: 0.053386\n",
      "Epoch 14/50 - Train Loss: 0.032969 - Val Loss: 0.050193\n",
      "Epoch 15/50 - Train Loss: 0.030391 - Val Loss: 0.048142\n",
      "Epoch 16/50 - Train Loss: 0.032203 - Val Loss: 0.044188\n",
      "Epoch 17/50 - Train Loss: 0.033485 - Val Loss: 0.044739\n",
      "Epoch 18/50 - Train Loss: 0.030283 - Val Loss: 0.052684\n",
      "Epoch 19/50 - Train Loss: 0.029502 - Val Loss: 0.045984\n",
      "Epoch 20/50 - Train Loss: 0.034600 - Val Loss: 0.046481\n",
      "Epoch 21/50 - Train Loss: 0.033118 - Val Loss: 0.066805\n",
      "Epoch 22/50 - Train Loss: 0.028875 - Val Loss: 0.049258\n",
      "Epoch 23/50 - Train Loss: 0.035256 - Val Loss: 0.045640\n",
      "Epoch 24/50 - Train Loss: 0.031365 - Val Loss: 0.049595\n",
      "Epoch 25/50 - Train Loss: 0.028348 - Val Loss: 0.046765\n",
      "Epoch 26/50 - Train Loss: 0.033976 - Val Loss: 0.044827\n",
      "Epoch 27/50 - Train Loss: 0.030619 - Val Loss: 0.044265\n",
      "Epoch 28/50 - Train Loss: 0.030178 - Val Loss: 0.046362\n",
      "Epoch 29/50 - Train Loss: 0.033893 - Val Loss: 0.045972\n",
      "Epoch 30/50 - Train Loss: 0.029128 - Val Loss: 0.045150\n",
      "Epoch 31/50 - Train Loss: 0.031876 - Val Loss: 0.046423\n",
      "Epoch 32/50 - Train Loss: 0.029119 - Val Loss: 0.044391\n",
      "Epoch 33/50 - Train Loss: 0.029531 - Val Loss: 0.044300\n",
      "Epoch 34/50 - Train Loss: 0.032420 - Val Loss: 0.046931\n",
      "Epoch 35/50 - Train Loss: 0.031621 - Val Loss: 0.046830\n",
      "Epoch 36/50 - Train Loss: 0.029818 - Val Loss: 0.044319\n",
      "Epoch 37/50 - Train Loss: 0.028776 - Val Loss: 0.044604\n",
      "Epoch 38/50 - Train Loss: 0.029299 - Val Loss: 0.045709\n",
      "Epoch 39/50 - Train Loss: 0.030193 - Val Loss: 0.044247\n",
      "Epoch 40/50 - Train Loss: 0.030075 - Val Loss: 0.044747\n",
      "Epoch 41/50 - Train Loss: 0.032131 - Val Loss: 0.044958\n",
      "Epoch 42/50 - Train Loss: 0.036105 - Val Loss: 0.056376\n",
      "Epoch 43/50 - Train Loss: 0.028598 - Val Loss: 0.045571\n",
      "Epoch 44/50 - Train Loss: 0.029695 - Val Loss: 0.044410\n",
      "Epoch 45/50 - Train Loss: 0.027918 - Val Loss: 0.045663\n",
      "Epoch 46/50 - Train Loss: 0.026820 - Val Loss: 0.044863\n",
      "Epoch 47/50 - Train Loss: 0.029736 - Val Loss: 0.046517\n",
      "Epoch 48/50 - Train Loss: 0.027028 - Val Loss: 0.049423\n",
      "Epoch 49/50 - Train Loss: 0.030080 - Val Loss: 0.047023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:57:26,238] Trial 92 finished with value: 0.044089850038290024 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 105, 'lr': 0.005944984004605689, 'weight_decay': 5.112724246415191e-08, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031870 - Val Loss: 0.044090\n",
      "Epoch 1/50 - Train Loss: 0.143269 - Val Loss: 0.101455\n",
      "Epoch 2/50 - Train Loss: 0.053495 - Val Loss: 0.084453\n",
      "Epoch 3/50 - Train Loss: 0.046401 - Val Loss: 0.114701\n",
      "Epoch 4/50 - Train Loss: 0.041753 - Val Loss: 0.072081\n",
      "Epoch 5/50 - Train Loss: 0.043272 - Val Loss: 0.066637\n",
      "Epoch 6/50 - Train Loss: 0.040231 - Val Loss: 0.083732\n",
      "Epoch 7/50 - Train Loss: 0.037867 - Val Loss: 0.064468\n",
      "Epoch 8/50 - Train Loss: 0.033515 - Val Loss: 0.064892\n",
      "Epoch 9/50 - Train Loss: 0.039498 - Val Loss: 0.059500\n",
      "Epoch 10/50 - Train Loss: 0.033288 - Val Loss: 0.054496\n",
      "Epoch 11/50 - Train Loss: 0.032948 - Val Loss: 0.053993\n",
      "Epoch 12/50 - Train Loss: 0.035020 - Val Loss: 0.048755\n",
      "Epoch 13/50 - Train Loss: 0.033599 - Val Loss: 0.054241\n",
      "Epoch 14/50 - Train Loss: 0.032931 - Val Loss: 0.052255\n",
      "Epoch 15/50 - Train Loss: 0.035976 - Val Loss: 0.048100\n",
      "Epoch 16/50 - Train Loss: 0.032447 - Val Loss: 0.047301\n",
      "Epoch 17/50 - Train Loss: 0.028943 - Val Loss: 0.051108\n",
      "Epoch 18/50 - Train Loss: 0.033188 - Val Loss: 0.049780\n",
      "Epoch 19/50 - Train Loss: 0.031129 - Val Loss: 0.046586\n",
      "Epoch 20/50 - Train Loss: 0.033902 - Val Loss: 0.047509\n",
      "Epoch 21/50 - Train Loss: 0.030111 - Val Loss: 0.046136\n",
      "Epoch 22/50 - Train Loss: 0.035304 - Val Loss: 0.052995\n",
      "Epoch 23/50 - Train Loss: 0.032874 - Val Loss: 0.049532\n",
      "Epoch 24/50 - Train Loss: 0.033859 - Val Loss: 0.049903\n",
      "Epoch 25/50 - Train Loss: 0.033200 - Val Loss: 0.051118\n",
      "Epoch 26/50 - Train Loss: 0.029805 - Val Loss: 0.045559\n",
      "Epoch 27/50 - Train Loss: 0.034564 - Val Loss: 0.048934\n",
      "Epoch 28/50 - Train Loss: 0.032448 - Val Loss: 0.051580\n",
      "Epoch 29/50 - Train Loss: 0.032347 - Val Loss: 0.052515\n",
      "Epoch 30/50 - Train Loss: 0.033497 - Val Loss: 0.049344\n",
      "Epoch 31/50 - Train Loss: 0.033726 - Val Loss: 0.048717\n",
      "Epoch 32/50 - Train Loss: 0.034430 - Val Loss: 0.056452\n",
      "Epoch 33/50 - Train Loss: 0.027399 - Val Loss: 0.045691\n",
      "Epoch 34/50 - Train Loss: 0.029483 - Val Loss: 0.048336\n",
      "Epoch 35/50 - Train Loss: 0.035249 - Val Loss: 0.049672\n",
      "Epoch 36/50 - Train Loss: 0.030956 - Val Loss: 0.047493\n",
      "Epoch 37/50 - Train Loss: 0.035330 - Val Loss: 0.046160\n",
      "Epoch 38/50 - Train Loss: 0.031692 - Val Loss: 0.057166\n",
      "Epoch 39/50 - Train Loss: 0.032713 - Val Loss: 0.054487\n",
      "Epoch 40/50 - Train Loss: 0.034699 - Val Loss: 0.046654\n",
      "Epoch 41/50 - Train Loss: 0.032515 - Val Loss: 0.050115\n",
      "Epoch 42/50 - Train Loss: 0.032403 - Val Loss: 0.051834\n",
      "Epoch 43/50 - Train Loss: 0.032954 - Val Loss: 0.046045\n",
      "Epoch 44/50 - Train Loss: 0.032209 - Val Loss: 0.051164\n",
      "Epoch 45/50 - Train Loss: 0.031365 - Val Loss: 0.055880\n",
      "Epoch 46/50 - Train Loss: 0.035401 - Val Loss: 0.048995\n",
      "Epoch 47/50 - Train Loss: 0.031524 - Val Loss: 0.048643\n",
      "Epoch 48/50 - Train Loss: 0.032384 - Val Loss: 0.049256\n",
      "Epoch 49/50 - Train Loss: 0.030885 - Val Loss: 0.048569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:57:42,655] Trial 93 finished with value: 0.045559078454971313 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 88, 'lr': 0.002333192409867039, 'weight_decay': 0.000993931773209158, 'batch_size': 16}. Best is trial 34 with value: 0.04330885037779808.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033108 - Val Loss: 0.047935\n",
      "Epoch 1/50 - Train Loss: 0.059696 - Val Loss: 0.075170\n",
      "Epoch 2/50 - Train Loss: 0.041831 - Val Loss: 0.088067\n",
      "Epoch 3/50 - Train Loss: 0.038051 - Val Loss: 0.065805\n",
      "Epoch 4/50 - Train Loss: 0.037418 - Val Loss: 0.061030\n",
      "Epoch 5/50 - Train Loss: 0.030624 - Val Loss: 0.066195\n",
      "Epoch 6/50 - Train Loss: 0.033389 - Val Loss: 0.047452\n",
      "Epoch 7/50 - Train Loss: 0.036369 - Val Loss: 0.047942\n",
      "Epoch 8/50 - Train Loss: 0.032115 - Val Loss: 0.049609\n",
      "Epoch 9/50 - Train Loss: 0.031434 - Val Loss: 0.045575\n",
      "Epoch 10/50 - Train Loss: 0.033081 - Val Loss: 0.047532\n",
      "Epoch 11/50 - Train Loss: 0.033062 - Val Loss: 0.045970\n",
      "Epoch 12/50 - Train Loss: 0.033727 - Val Loss: 0.046357\n",
      "Epoch 13/50 - Train Loss: 0.030790 - Val Loss: 0.048433\n",
      "Epoch 14/50 - Train Loss: 0.030355 - Val Loss: 0.047022\n",
      "Epoch 15/50 - Train Loss: 0.033064 - Val Loss: 0.045629\n",
      "Epoch 16/50 - Train Loss: 0.032241 - Val Loss: 0.045772\n",
      "Epoch 17/50 - Train Loss: 0.030681 - Val Loss: 0.049518\n",
      "Epoch 18/50 - Train Loss: 0.030159 - Val Loss: 0.046684\n",
      "Epoch 19/50 - Train Loss: 0.028045 - Val Loss: 0.043939\n",
      "Epoch 20/50 - Train Loss: 0.030688 - Val Loss: 0.045116\n",
      "Epoch 21/50 - Train Loss: 0.030665 - Val Loss: 0.046387\n",
      "Epoch 22/50 - Train Loss: 0.032123 - Val Loss: 0.044960\n",
      "Epoch 23/50 - Train Loss: 0.032724 - Val Loss: 0.044112\n",
      "Epoch 24/50 - Train Loss: 0.027040 - Val Loss: 0.051353\n",
      "Epoch 25/50 - Train Loss: 0.029625 - Val Loss: 0.044444\n",
      "Epoch 26/50 - Train Loss: 0.028628 - Val Loss: 0.043692\n",
      "Epoch 27/50 - Train Loss: 0.033438 - Val Loss: 0.047463\n",
      "Epoch 28/50 - Train Loss: 0.030391 - Val Loss: 0.045283\n",
      "Epoch 29/50 - Train Loss: 0.024726 - Val Loss: 0.044805\n",
      "Epoch 30/50 - Train Loss: 0.031330 - Val Loss: 0.043899\n",
      "Epoch 31/50 - Train Loss: 0.027411 - Val Loss: 0.043889\n",
      "Epoch 32/50 - Train Loss: 0.030819 - Val Loss: 0.043409\n",
      "Epoch 33/50 - Train Loss: 0.030711 - Val Loss: 0.043454\n",
      "Epoch 34/50 - Train Loss: 0.031562 - Val Loss: 0.044018\n",
      "Epoch 35/50 - Train Loss: 0.031465 - Val Loss: 0.047354\n",
      "Epoch 36/50 - Train Loss: 0.030457 - Val Loss: 0.044508\n",
      "Epoch 37/50 - Train Loss: 0.029030 - Val Loss: 0.044003\n",
      "Epoch 38/50 - Train Loss: 0.031914 - Val Loss: 0.045111\n",
      "Epoch 39/50 - Train Loss: 0.031636 - Val Loss: 0.046308\n",
      "Epoch 40/50 - Train Loss: 0.032643 - Val Loss: 0.045827\n",
      "Epoch 41/50 - Train Loss: 0.028939 - Val Loss: 0.043178\n",
      "Epoch 42/50 - Train Loss: 0.029187 - Val Loss: 0.045321\n",
      "Epoch 43/50 - Train Loss: 0.031163 - Val Loss: 0.051644\n",
      "Epoch 44/50 - Train Loss: 0.032650 - Val Loss: 0.046919\n",
      "Epoch 45/50 - Train Loss: 0.031555 - Val Loss: 0.045418\n",
      "Epoch 46/50 - Train Loss: 0.033785 - Val Loss: 0.045425\n",
      "Epoch 47/50 - Train Loss: 0.031273 - Val Loss: 0.044536\n",
      "Epoch 48/50 - Train Loss: 0.027231 - Val Loss: 0.043747\n",
      "Epoch 49/50 - Train Loss: 0.031508 - Val Loss: 0.045060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:58:02,362] Trial 94 finished with value: 0.04317844659090042 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 79, 'lr': 0.0031371929527417553, 'weight_decay': 6.866561490622697e-08, 'batch_size': 16}. Best is trial 94 with value: 0.04317844659090042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.026655 - Val Loss: 0.044517\n",
      "Epoch 1/50 - Train Loss: 0.055224 - Val Loss: 0.074969\n",
      "Epoch 2/50 - Train Loss: 0.043262 - Val Loss: 0.103780\n",
      "Epoch 3/50 - Train Loss: 0.046239 - Val Loss: 0.078873\n",
      "Epoch 4/50 - Train Loss: 0.039144 - Val Loss: 0.049907\n",
      "Epoch 5/50 - Train Loss: 0.031702 - Val Loss: 0.047854\n",
      "Epoch 6/50 - Train Loss: 0.033589 - Val Loss: 0.047746\n",
      "Epoch 7/50 - Train Loss: 0.033464 - Val Loss: 0.048469\n",
      "Epoch 8/50 - Train Loss: 0.034774 - Val Loss: 0.051606\n",
      "Epoch 9/50 - Train Loss: 0.031651 - Val Loss: 0.051613\n",
      "Epoch 10/50 - Train Loss: 0.030792 - Val Loss: 0.060420\n",
      "Epoch 11/50 - Train Loss: 0.031644 - Val Loss: 0.051497\n",
      "Epoch 12/50 - Train Loss: 0.031003 - Val Loss: 0.051044\n",
      "Epoch 13/50 - Train Loss: 0.030831 - Val Loss: 0.050440\n",
      "Epoch 14/50 - Train Loss: 0.032757 - Val Loss: 0.050309\n",
      "Epoch 15/50 - Train Loss: 0.031540 - Val Loss: 0.049057\n",
      "Epoch 16/50 - Train Loss: 0.032043 - Val Loss: 0.045450\n",
      "Epoch 17/50 - Train Loss: 0.030877 - Val Loss: 0.044619\n",
      "Epoch 18/50 - Train Loss: 0.031210 - Val Loss: 0.044537\n",
      "Epoch 19/50 - Train Loss: 0.030584 - Val Loss: 0.045340\n",
      "Epoch 20/50 - Train Loss: 0.031096 - Val Loss: 0.047704\n",
      "Epoch 21/50 - Train Loss: 0.027783 - Val Loss: 0.047585\n",
      "Epoch 22/50 - Train Loss: 0.032995 - Val Loss: 0.049627\n",
      "Epoch 23/50 - Train Loss: 0.033052 - Val Loss: 0.045815\n",
      "Epoch 24/50 - Train Loss: 0.031157 - Val Loss: 0.045682\n",
      "Epoch 25/50 - Train Loss: 0.032984 - Val Loss: 0.044254\n",
      "Epoch 26/50 - Train Loss: 0.033764 - Val Loss: 0.047131\n",
      "Epoch 27/50 - Train Loss: 0.028694 - Val Loss: 0.044397\n",
      "Epoch 28/50 - Train Loss: 0.031039 - Val Loss: 0.048374\n",
      "Epoch 29/50 - Train Loss: 0.031647 - Val Loss: 0.055025\n",
      "Epoch 30/50 - Train Loss: 0.030513 - Val Loss: 0.045361\n",
      "Epoch 31/50 - Train Loss: 0.030105 - Val Loss: 0.044369\n",
      "Epoch 32/50 - Train Loss: 0.031826 - Val Loss: 0.050722\n",
      "Epoch 33/50 - Train Loss: 0.031720 - Val Loss: 0.044660\n",
      "Epoch 34/50 - Train Loss: 0.028443 - Val Loss: 0.046070\n",
      "Epoch 35/50 - Train Loss: 0.030688 - Val Loss: 0.045224\n",
      "Epoch 36/50 - Train Loss: 0.027875 - Val Loss: 0.045647\n",
      "Epoch 37/50 - Train Loss: 0.030048 - Val Loss: 0.048474\n",
      "Epoch 38/50 - Train Loss: 0.035584 - Val Loss: 0.047352\n",
      "Epoch 39/50 - Train Loss: 0.029635 - Val Loss: 0.047433\n",
      "Epoch 40/50 - Train Loss: 0.029451 - Val Loss: 0.044504\n",
      "Epoch 41/50 - Train Loss: 0.030138 - Val Loss: 0.047751\n",
      "Epoch 42/50 - Train Loss: 0.025988 - Val Loss: 0.045400\n",
      "Epoch 43/50 - Train Loss: 0.030177 - Val Loss: 0.048611\n",
      "Epoch 44/50 - Train Loss: 0.031978 - Val Loss: 0.044719\n",
      "Epoch 45/50 - Train Loss: 0.027979 - Val Loss: 0.044912\n",
      "Epoch 46/50 - Train Loss: 0.032190 - Val Loss: 0.045045\n",
      "Epoch 47/50 - Train Loss: 0.030567 - Val Loss: 0.048773\n",
      "Epoch 48/50 - Train Loss: 0.029426 - Val Loss: 0.046104\n",
      "Epoch 49/50 - Train Loss: 0.031230 - Val Loss: 0.045334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:58:38,225] Trial 95 finished with value: 0.044253889471292496 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 79, 'lr': 0.00998510342751918, 'weight_decay': 2.3417769314970325e-07, 'batch_size': 16}. Best is trial 94 with value: 0.04317844659090042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033047 - Val Loss: 0.045399\n",
      "Epoch 1/50 - Train Loss: 0.073055 - Val Loss: 0.114620\n",
      "Epoch 2/50 - Train Loss: 0.047060 - Val Loss: 0.075613\n",
      "Epoch 3/50 - Train Loss: 0.040585 - Val Loss: 0.078687\n",
      "Epoch 4/50 - Train Loss: 0.038908 - Val Loss: 0.056326\n",
      "Epoch 5/50 - Train Loss: 0.036872 - Val Loss: 0.070944\n",
      "Epoch 6/50 - Train Loss: 0.035710 - Val Loss: 0.052938\n",
      "Epoch 7/50 - Train Loss: 0.030398 - Val Loss: 0.044424\n",
      "Epoch 8/50 - Train Loss: 0.036030 - Val Loss: 0.046456\n",
      "Epoch 9/50 - Train Loss: 0.034415 - Val Loss: 0.052481\n",
      "Epoch 10/50 - Train Loss: 0.035225 - Val Loss: 0.046005\n",
      "Epoch 11/50 - Train Loss: 0.031229 - Val Loss: 0.048447\n",
      "Epoch 12/50 - Train Loss: 0.031507 - Val Loss: 0.043702\n",
      "Epoch 13/50 - Train Loss: 0.031472 - Val Loss: 0.046394\n",
      "Epoch 14/50 - Train Loss: 0.033728 - Val Loss: 0.045471\n",
      "Epoch 15/50 - Train Loss: 0.033956 - Val Loss: 0.052671\n",
      "Epoch 16/50 - Train Loss: 0.034216 - Val Loss: 0.045975\n",
      "Epoch 17/50 - Train Loss: 0.034322 - Val Loss: 0.048842\n",
      "Epoch 18/50 - Train Loss: 0.033118 - Val Loss: 0.056441\n",
      "Epoch 19/50 - Train Loss: 0.038343 - Val Loss: 0.046899\n",
      "Epoch 20/50 - Train Loss: 0.031876 - Val Loss: 0.043532\n",
      "Epoch 21/50 - Train Loss: 0.027520 - Val Loss: 0.043089\n",
      "Epoch 22/50 - Train Loss: 0.031783 - Val Loss: 0.048959\n",
      "Epoch 23/50 - Train Loss: 0.032381 - Val Loss: 0.046939\n",
      "Epoch 24/50 - Train Loss: 0.030143 - Val Loss: 0.048050\n",
      "Epoch 25/50 - Train Loss: 0.031729 - Val Loss: 0.044009\n",
      "Epoch 26/50 - Train Loss: 0.029808 - Val Loss: 0.043916\n",
      "Epoch 27/50 - Train Loss: 0.032099 - Val Loss: 0.047117\n",
      "Epoch 28/50 - Train Loss: 0.031717 - Val Loss: 0.044193\n",
      "Epoch 29/50 - Train Loss: 0.032465 - Val Loss: 0.044504\n",
      "Epoch 30/50 - Train Loss: 0.030016 - Val Loss: 0.044413\n",
      "Epoch 31/50 - Train Loss: 0.031293 - Val Loss: 0.047573\n",
      "Epoch 32/50 - Train Loss: 0.031572 - Val Loss: 0.045985\n",
      "Epoch 33/50 - Train Loss: 0.030211 - Val Loss: 0.045169\n",
      "Epoch 34/50 - Train Loss: 0.031158 - Val Loss: 0.044595\n",
      "Epoch 35/50 - Train Loss: 0.030175 - Val Loss: 0.043069\n",
      "Epoch 36/50 - Train Loss: 0.030401 - Val Loss: 0.045758\n",
      "Epoch 37/50 - Train Loss: 0.032537 - Val Loss: 0.044651\n",
      "Epoch 38/50 - Train Loss: 0.028680 - Val Loss: 0.043866\n",
      "Epoch 39/50 - Train Loss: 0.029448 - Val Loss: 0.043471\n",
      "Epoch 40/50 - Train Loss: 0.030227 - Val Loss: 0.047202\n",
      "Epoch 41/50 - Train Loss: 0.035905 - Val Loss: 0.052418\n",
      "Epoch 42/50 - Train Loss: 0.027236 - Val Loss: 0.044242\n",
      "Epoch 43/50 - Train Loss: 0.030580 - Val Loss: 0.043335\n",
      "Epoch 44/50 - Train Loss: 0.031764 - Val Loss: 0.043690\n",
      "Epoch 45/50 - Train Loss: 0.032017 - Val Loss: 0.044648\n",
      "Epoch 46/50 - Train Loss: 0.029669 - Val Loss: 0.044457\n",
      "Epoch 47/50 - Train Loss: 0.032022 - Val Loss: 0.043313\n",
      "Epoch 48/50 - Train Loss: 0.030981 - Val Loss: 0.046245\n",
      "Epoch 49/50 - Train Loss: 0.029274 - Val Loss: 0.044456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:59:38,912] Trial 96 finished with value: 0.04306921176612377 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 241, 'lr': 0.0032448346163709728, 'weight_decay': 7.298354622440359e-08, 'batch_size': 16}. Best is trial 96 with value: 0.04306921176612377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.028988 - Val Loss: 0.044237\n",
      "Epoch 1/50 - Train Loss: 0.069049 - Val Loss: 0.061828\n",
      "Epoch 2/50 - Train Loss: 0.043739 - Val Loss: 0.102499\n",
      "Epoch 3/50 - Train Loss: 0.042876 - Val Loss: 0.078629\n",
      "Epoch 4/50 - Train Loss: 0.044843 - Val Loss: 0.070020\n",
      "Epoch 5/50 - Train Loss: 0.041830 - Val Loss: 0.062338\n",
      "Epoch 6/50 - Train Loss: 0.034995 - Val Loss: 0.058075\n",
      "Epoch 7/50 - Train Loss: 0.035191 - Val Loss: 0.047234\n",
      "Epoch 8/50 - Train Loss: 0.031653 - Val Loss: 0.056621\n",
      "Epoch 9/50 - Train Loss: 0.035637 - Val Loss: 0.048865\n",
      "Epoch 10/50 - Train Loss: 0.033340 - Val Loss: 0.049841\n",
      "Epoch 11/50 - Train Loss: 0.034893 - Val Loss: 0.049763\n",
      "Epoch 12/50 - Train Loss: 0.034265 - Val Loss: 0.050079\n",
      "Epoch 13/50 - Train Loss: 0.033265 - Val Loss: 0.045507\n",
      "Epoch 14/50 - Train Loss: 0.032059 - Val Loss: 0.044234\n",
      "Epoch 15/50 - Train Loss: 0.031487 - Val Loss: 0.047921\n",
      "Epoch 16/50 - Train Loss: 0.035503 - Val Loss: 0.048718\n",
      "Epoch 17/50 - Train Loss: 0.031363 - Val Loss: 0.054468\n",
      "Epoch 18/50 - Train Loss: 0.033236 - Val Loss: 0.051492\n",
      "Epoch 19/50 - Train Loss: 0.036377 - Val Loss: 0.044431\n",
      "Epoch 20/50 - Train Loss: 0.033256 - Val Loss: 0.050153\n",
      "Epoch 21/50 - Train Loss: 0.032761 - Val Loss: 0.044945\n",
      "Epoch 22/50 - Train Loss: 0.033054 - Val Loss: 0.045036\n",
      "Epoch 23/50 - Train Loss: 0.028623 - Val Loss: 0.045369\n",
      "Epoch 24/50 - Train Loss: 0.028018 - Val Loss: 0.043688\n",
      "Epoch 25/50 - Train Loss: 0.032719 - Val Loss: 0.045709\n",
      "Epoch 26/50 - Train Loss: 0.032057 - Val Loss: 0.048523\n",
      "Epoch 27/50 - Train Loss: 0.032840 - Val Loss: 0.045527\n",
      "Epoch 28/50 - Train Loss: 0.034566 - Val Loss: 0.058058\n",
      "Epoch 29/50 - Train Loss: 0.032334 - Val Loss: 0.045782\n",
      "Epoch 30/50 - Train Loss: 0.029769 - Val Loss: 0.045130\n",
      "Epoch 31/50 - Train Loss: 0.034542 - Val Loss: 0.044777\n",
      "Epoch 32/50 - Train Loss: 0.031466 - Val Loss: 0.047086\n",
      "Epoch 33/50 - Train Loss: 0.031238 - Val Loss: 0.045816\n",
      "Epoch 34/50 - Train Loss: 0.029647 - Val Loss: 0.045287\n",
      "Epoch 35/50 - Train Loss: 0.029128 - Val Loss: 0.044733\n",
      "Epoch 36/50 - Train Loss: 0.029775 - Val Loss: 0.047315\n",
      "Epoch 37/50 - Train Loss: 0.033909 - Val Loss: 0.045383\n",
      "Epoch 38/50 - Train Loss: 0.031886 - Val Loss: 0.043946\n",
      "Epoch 39/50 - Train Loss: 0.031887 - Val Loss: 0.047879\n",
      "Epoch 40/50 - Train Loss: 0.028031 - Val Loss: 0.044216\n",
      "Epoch 41/50 - Train Loss: 0.033571 - Val Loss: 0.044470\n",
      "Epoch 42/50 - Train Loss: 0.029814 - Val Loss: 0.049893\n",
      "Epoch 43/50 - Train Loss: 0.028033 - Val Loss: 0.044607\n",
      "Epoch 44/50 - Train Loss: 0.031927 - Val Loss: 0.044147\n",
      "Epoch 45/50 - Train Loss: 0.030442 - Val Loss: 0.044997\n",
      "Epoch 46/50 - Train Loss: 0.034247 - Val Loss: 0.047153\n",
      "Epoch 47/50 - Train Loss: 0.030638 - Val Loss: 0.045117\n",
      "Epoch 48/50 - Train Loss: 0.028753 - Val Loss: 0.044229\n",
      "Epoch 49/50 - Train Loss: 0.032051 - Val Loss: 0.045691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 14:59:56,930] Trial 97 finished with value: 0.043688416481018066 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 70, 'lr': 0.003284777509192802, 'weight_decay': 6.877785361933635e-08, 'batch_size': 16}. Best is trial 96 with value: 0.04306921176612377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.031785 - Val Loss: 0.044693\n",
      "Epoch 1/50 - Train Loss: 0.090379 - Val Loss: 0.092279\n",
      "Epoch 2/50 - Train Loss: 0.045831 - Val Loss: 0.111120\n",
      "Epoch 3/50 - Train Loss: 0.044084 - Val Loss: 0.067566\n",
      "Epoch 4/50 - Train Loss: 0.038453 - Val Loss: 0.057576\n",
      "Epoch 5/50 - Train Loss: 0.035091 - Val Loss: 0.047724\n",
      "Epoch 6/50 - Train Loss: 0.032206 - Val Loss: 0.050438\n",
      "Epoch 7/50 - Train Loss: 0.033862 - Val Loss: 0.050249\n",
      "Epoch 8/50 - Train Loss: 0.031248 - Val Loss: 0.052755\n",
      "Epoch 9/50 - Train Loss: 0.033749 - Val Loss: 0.059251\n",
      "Epoch 10/50 - Train Loss: 0.032275 - Val Loss: 0.055776\n",
      "Epoch 11/50 - Train Loss: 0.031140 - Val Loss: 0.048225\n",
      "Epoch 12/50 - Train Loss: 0.035356 - Val Loss: 0.055367\n",
      "Epoch 13/50 - Train Loss: 0.031838 - Val Loss: 0.056179\n",
      "Epoch 14/50 - Train Loss: 0.030706 - Val Loss: 0.046615\n",
      "Epoch 15/50 - Train Loss: 0.032332 - Val Loss: 0.044591\n",
      "Epoch 16/50 - Train Loss: 0.032696 - Val Loss: 0.049450\n",
      "Epoch 17/50 - Train Loss: 0.031013 - Val Loss: 0.045558\n",
      "Epoch 18/50 - Train Loss: 0.029533 - Val Loss: 0.044351\n",
      "Epoch 19/50 - Train Loss: 0.032854 - Val Loss: 0.049931\n",
      "Epoch 20/50 - Train Loss: 0.032739 - Val Loss: 0.046102\n",
      "Epoch 21/50 - Train Loss: 0.032966 - Val Loss: 0.045313\n",
      "Epoch 22/50 - Train Loss: 0.031117 - Val Loss: 0.045300\n",
      "Epoch 23/50 - Train Loss: 0.028750 - Val Loss: 0.045461\n",
      "Epoch 24/50 - Train Loss: 0.028633 - Val Loss: 0.045171\n",
      "Epoch 25/50 - Train Loss: 0.030902 - Val Loss: 0.045430\n",
      "Epoch 26/50 - Train Loss: 0.028020 - Val Loss: 0.051475\n",
      "Epoch 27/50 - Train Loss: 0.030567 - Val Loss: 0.045793\n",
      "Epoch 28/50 - Train Loss: 0.028714 - Val Loss: 0.047554\n",
      "Epoch 29/50 - Train Loss: 0.031471 - Val Loss: 0.049848\n",
      "Epoch 30/50 - Train Loss: 0.034917 - Val Loss: 0.050642\n",
      "Epoch 31/50 - Train Loss: 0.032143 - Val Loss: 0.052666\n",
      "Epoch 32/50 - Train Loss: 0.032231 - Val Loss: 0.048073\n",
      "Epoch 33/50 - Train Loss: 0.031191 - Val Loss: 0.047044\n",
      "Epoch 34/50 - Train Loss: 0.031007 - Val Loss: 0.047361\n",
      "Epoch 35/50 - Train Loss: 0.029667 - Val Loss: 0.046503\n",
      "Epoch 36/50 - Train Loss: 0.029519 - Val Loss: 0.048602\n",
      "Epoch 37/50 - Train Loss: 0.032804 - Val Loss: 0.045410\n",
      "Epoch 38/50 - Train Loss: 0.031461 - Val Loss: 0.046628\n",
      "Epoch 39/50 - Train Loss: 0.027616 - Val Loss: 0.046346\n",
      "Epoch 40/50 - Train Loss: 0.029736 - Val Loss: 0.044766\n",
      "Epoch 41/50 - Train Loss: 0.031472 - Val Loss: 0.046062\n",
      "Epoch 42/50 - Train Loss: 0.029709 - Val Loss: 0.046434\n",
      "Epoch 43/50 - Train Loss: 0.030305 - Val Loss: 0.048816\n",
      "Epoch 44/50 - Train Loss: 0.029628 - Val Loss: 0.046083\n",
      "Epoch 45/50 - Train Loss: 0.029737 - Val Loss: 0.046941\n",
      "Epoch 46/50 - Train Loss: 0.027495 - Val Loss: 0.045744\n",
      "Epoch 47/50 - Train Loss: 0.028173 - Val Loss: 0.046771\n",
      "Epoch 48/50 - Train Loss: 0.030048 - Val Loss: 0.050635\n",
      "Epoch 49/50 - Train Loss: 0.029162 - Val Loss: 0.046186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 15:00:57,443] Trial 98 finished with value: 0.0443510872622331 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 240, 'lr': 0.007403608012053093, 'weight_decay': 1.0184614416475866e-07, 'batch_size': 8}. Best is trial 96 with value: 0.04306921176612377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.030268 - Val Loss: 0.050036\n",
      "Epoch 1/50 - Train Loss: 0.068460 - Val Loss: 0.126686\n",
      "Epoch 2/50 - Train Loss: 0.045326 - Val Loss: 0.069799\n",
      "Epoch 3/50 - Train Loss: 0.039830 - Val Loss: 0.090883\n",
      "Epoch 4/50 - Train Loss: 0.040007 - Val Loss: 0.061057\n",
      "Epoch 5/50 - Train Loss: 0.037420 - Val Loss: 0.047926\n",
      "Epoch 6/50 - Train Loss: 0.032128 - Val Loss: 0.049503\n",
      "Epoch 7/50 - Train Loss: 0.035094 - Val Loss: 0.055817\n",
      "Epoch 8/50 - Train Loss: 0.033992 - Val Loss: 0.044088\n",
      "Epoch 9/50 - Train Loss: 0.032209 - Val Loss: 0.045811\n",
      "Epoch 10/50 - Train Loss: 0.031644 - Val Loss: 0.045911\n",
      "Epoch 11/50 - Train Loss: 0.036684 - Val Loss: 0.053923\n",
      "Epoch 12/50 - Train Loss: 0.032550 - Val Loss: 0.060298\n",
      "Epoch 13/50 - Train Loss: 0.034207 - Val Loss: 0.047217\n",
      "Epoch 14/50 - Train Loss: 0.034899 - Val Loss: 0.047125\n",
      "Epoch 15/50 - Train Loss: 0.032293 - Val Loss: 0.046909\n",
      "Epoch 16/50 - Train Loss: 0.029318 - Val Loss: 0.044093\n",
      "Epoch 17/50 - Train Loss: 0.031051 - Val Loss: 0.043743\n",
      "Epoch 18/50 - Train Loss: 0.029543 - Val Loss: 0.049532\n",
      "Epoch 19/50 - Train Loss: 0.032882 - Val Loss: 0.048134\n",
      "Epoch 20/50 - Train Loss: 0.032133 - Val Loss: 0.044074\n",
      "Epoch 21/50 - Train Loss: 0.033849 - Val Loss: 0.044448\n",
      "Epoch 22/50 - Train Loss: 0.031543 - Val Loss: 0.045196\n",
      "Epoch 23/50 - Train Loss: 0.030601 - Val Loss: 0.044724\n",
      "Epoch 24/50 - Train Loss: 0.032137 - Val Loss: 0.051024\n",
      "Epoch 25/50 - Train Loss: 0.032757 - Val Loss: 0.049699\n",
      "Epoch 26/50 - Train Loss: 0.032960 - Val Loss: 0.044123\n",
      "Epoch 27/50 - Train Loss: 0.031164 - Val Loss: 0.044646\n",
      "Epoch 28/50 - Train Loss: 0.033574 - Val Loss: 0.044403\n",
      "Epoch 29/50 - Train Loss: 0.033449 - Val Loss: 0.048839\n",
      "Epoch 30/50 - Train Loss: 0.029934 - Val Loss: 0.044675\n",
      "Epoch 31/50 - Train Loss: 0.035115 - Val Loss: 0.045146\n",
      "Epoch 32/50 - Train Loss: 0.027791 - Val Loss: 0.045539\n",
      "Epoch 33/50 - Train Loss: 0.029113 - Val Loss: 0.045099\n",
      "Epoch 34/50 - Train Loss: 0.031716 - Val Loss: 0.045426\n",
      "Epoch 35/50 - Train Loss: 0.032579 - Val Loss: 0.044455\n",
      "Epoch 36/50 - Train Loss: 0.029003 - Val Loss: 0.045754\n",
      "Epoch 37/50 - Train Loss: 0.026373 - Val Loss: 0.044864\n",
      "Epoch 38/50 - Train Loss: 0.028609 - Val Loss: 0.044440\n",
      "Epoch 39/50 - Train Loss: 0.028542 - Val Loss: 0.045105\n",
      "Epoch 40/50 - Train Loss: 0.029093 - Val Loss: 0.045342\n",
      "Epoch 41/50 - Train Loss: 0.030109 - Val Loss: 0.044589\n",
      "Epoch 42/50 - Train Loss: 0.032603 - Val Loss: 0.046527\n",
      "Epoch 43/50 - Train Loss: 0.031049 - Val Loss: 0.046441\n",
      "Epoch 44/50 - Train Loss: 0.030910 - Val Loss: 0.047742\n",
      "Epoch 45/50 - Train Loss: 0.028970 - Val Loss: 0.047712\n",
      "Epoch 46/50 - Train Loss: 0.031067 - Val Loss: 0.050120\n",
      "Epoch 47/50 - Train Loss: 0.027595 - Val Loss: 0.048608\n",
      "Epoch 48/50 - Train Loss: 0.031941 - Val Loss: 0.047653\n",
      "Epoch 49/50 - Train Loss: 0.030127 - Val Loss: 0.047536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-06 15:01:39,607] Trial 99 finished with value: 0.04374323599040508 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 255, 'lr': 0.0030408670921460348, 'weight_decay': 1.553564149970118e-07, 'batch_size': 16}. Best is trial 96 with value: 0.04306921176612377.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.033111 - Val Loss: 0.053726\n",
      "Best Hyperparameters: {'n_hidden_layers': 5, 'n_hidden_units': 241, 'lr': 0.0032448346163709728, 'weight_decay': 7.298354622440359e-08, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to search over\n",
    "    n_hidden_layers = trial.suggest_int(\"n_hidden_layers\", 1, 5)\n",
    "    n_hidden_units = trial.suggest_int(\"n_hidden_units\", 32, 256)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-8, 1e-3)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])  # Match the original hp['batch_sz']\n",
    "\n",
    "    # Create train & validation loaders (following the original code)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize MLP model\n",
    "    model = BasicMLP(\n",
    "        N_INPUT_UNITS=train_dataset.__n_features_in__(),\n",
    "        N_HIDDEN_LAYERS=n_hidden_layers,\n",
    "        N_HIDDEN_UNITS=n_hidden_units,\n",
    "        N_OUTPUT_UNITS=train_dataset.__n_features_out__(),\n",
    "        loss_function=LOSS_FUNC,\n",
    "    )\n",
    "\n",
    "    # Train and return validation loss\n",
    "    val_loss = model.train_model(train_loader, val_loader, epochs=50, lr=lr, weight_decay=weight_decay, device=device)\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"mlp_hyperparameter_optimization_phy_linear\", storage=\"sqlite:///mlp_hyperparameter_optimization_phy.db\", load_if_exists=True)\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_hidden_layers': 5,\n",
       " 'n_hidden_units': 241,\n",
       " 'lr': 0.0032448346163709728,\n",
       " 'weight_decay': 7.298354622440359e-08,\n",
       " 'batch_size': 16}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# best params for the physics model in previous studies\n",
    "# remove if retune\n",
    "# best_params = {'n_hidden_layers': 2, 'n_hidden_units': 237, 'lr': 0.004360166659287016, 'weight_decay': 5.881374833423609e-08, 'batch_size': 16}\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Train Loss: 0.068817 - Val Loss: 0.106901\n",
      "Epoch 2/50 - Train Loss: 0.044666 - Val Loss: 0.066107\n",
      "Epoch 3/50 - Train Loss: 0.042219 - Val Loss: 0.073067\n",
      "Epoch 4/50 - Train Loss: 0.039644 - Val Loss: 0.058859\n",
      "Epoch 5/50 - Train Loss: 0.035606 - Val Loss: 0.060827\n",
      "Epoch 6/50 - Train Loss: 0.034433 - Val Loss: 0.049151\n",
      "Epoch 7/50 - Train Loss: 0.033202 - Val Loss: 0.044977\n",
      "Epoch 8/50 - Train Loss: 0.029490 - Val Loss: 0.045037\n",
      "Epoch 9/50 - Train Loss: 0.029699 - Val Loss: 0.044812\n",
      "Epoch 10/50 - Train Loss: 0.032163 - Val Loss: 0.044630\n",
      "Epoch 11/50 - Train Loss: 0.033037 - Val Loss: 0.057489\n",
      "Epoch 12/50 - Train Loss: 0.034713 - Val Loss: 0.062816\n",
      "Epoch 13/50 - Train Loss: 0.032283 - Val Loss: 0.062205\n",
      "Epoch 14/50 - Train Loss: 0.031676 - Val Loss: 0.045157\n",
      "Epoch 15/50 - Train Loss: 0.032600 - Val Loss: 0.044756\n",
      "Epoch 16/50 - Train Loss: 0.032501 - Val Loss: 0.051851\n",
      "Epoch 17/50 - Train Loss: 0.035073 - Val Loss: 0.046956\n",
      "Epoch 18/50 - Train Loss: 0.034430 - Val Loss: 0.048643\n",
      "Epoch 19/50 - Train Loss: 0.030410 - Val Loss: 0.044479\n",
      "Epoch 20/50 - Train Loss: 0.028985 - Val Loss: 0.043990\n",
      "Epoch 21/50 - Train Loss: 0.034167 - Val Loss: 0.046284\n",
      "Epoch 22/50 - Train Loss: 0.029150 - Val Loss: 0.049480\n",
      "Epoch 23/50 - Train Loss: 0.035177 - Val Loss: 0.062483\n",
      "Epoch 24/50 - Train Loss: 0.032142 - Val Loss: 0.044679\n",
      "Epoch 25/50 - Train Loss: 0.035461 - Val Loss: 0.044073\n",
      "Epoch 26/50 - Train Loss: 0.032588 - Val Loss: 0.045540\n",
      "Epoch 27/50 - Train Loss: 0.031282 - Val Loss: 0.049483\n",
      "Epoch 28/50 - Train Loss: 0.032708 - Val Loss: 0.049277\n",
      "Epoch 29/50 - Train Loss: 0.027225 - Val Loss: 0.045783\n",
      "Epoch 30/50 - Train Loss: 0.033617 - Val Loss: 0.045078\n",
      "Epoch 31/50 - Train Loss: 0.028265 - Val Loss: 0.045165\n",
      "Epoch 32/50 - Train Loss: 0.027021 - Val Loss: 0.056187\n",
      "Epoch 33/50 - Train Loss: 0.033360 - Val Loss: 0.046730\n",
      "Epoch 34/50 - Train Loss: 0.032721 - Val Loss: 0.043996\n",
      "Epoch 35/50 - Train Loss: 0.032380 - Val Loss: 0.048626\n",
      "Epoch 36/50 - Train Loss: 0.036359 - Val Loss: 0.047190\n",
      "Epoch 37/50 - Train Loss: 0.027513 - Val Loss: 0.044762\n",
      "Epoch 38/50 - Train Loss: 0.030808 - Val Loss: 0.043643\n",
      "Epoch 39/50 - Train Loss: 0.028663 - Val Loss: 0.053021\n",
      "Epoch 40/50 - Train Loss: 0.029099 - Val Loss: 0.053489\n",
      "Epoch 41/50 - Train Loss: 0.027748 - Val Loss: 0.043905\n",
      "Epoch 42/50 - Train Loss: 0.028907 - Val Loss: 0.044715\n",
      "Epoch 43/50 - Train Loss: 0.030990 - Val Loss: 0.051623\n",
      "Epoch 44/50 - Train Loss: 0.029226 - Val Loss: 0.045164\n",
      "Epoch 45/50 - Train Loss: 0.031078 - Val Loss: 0.044492\n",
      "Epoch 46/50 - Train Loss: 0.027188 - Val Loss: 0.043964\n",
      "Epoch 47/50 - Train Loss: 0.028897 - Val Loss: 0.044314\n",
      "Epoch 48/50 - Train Loss: 0.030096 - Val Loss: 0.044186\n",
      "Epoch 49/50 - Train Loss: 0.029117 - Val Loss: 0.046152\n",
      "Epoch 50/50 - Train Loss: 0.028856 - Val Loss: 0.043802\n",
      "Model saved as best_mlp_no2.pth in Model folder\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "best_model = BasicMLP(\n",
    "    N_INPUT_UNITS=train_dataset.__n_features_in__(),\n",
    "    N_HIDDEN_LAYERS=best_params[\"n_hidden_layers\"],\n",
    "    N_HIDDEN_UNITS=best_params[\"n_hidden_units\"],\n",
    "    N_OUTPUT_UNITS=train_dataset.__n_features_out__(),\n",
    "    loss_function=LOSS_FUNC,\n",
    ")\n",
    "\n",
    "# Create train & validation loaders with the best batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "# Train the model\n",
    "best_model.train_model(train_loader, val_loader, epochs=50, lr=best_params[\"lr\"], weight_decay=best_params[\"weight_decay\"], device=device)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(best_model.state_dict(), f\"{MODEL_PATH}/best_mlp_no2_linear_test.pth\")\n",
    "print(\"Model saved as best_mlp_no2.pth in Model folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Testing the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO2</td>\n",
       "      <td>1.37</td>\n",
       "      <td>93.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0   min    max\n",
       "0        NO2  1.37  93.95"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_minmax = pd.read_csv(MINMAX_PATH, sep=';')\n",
    "df_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 289.796747\n",
      "Test RMSE Loss: 16.560094\n",
      "Test SMAPE Loss: 41.509572%\n"
     ]
    }
   ],
   "source": [
    "best_model.load_state_dict(torch.load(f\"{MODEL_PATH}/best_mlp_no2_linear_test.pth\"))\n",
    "best_model.eval()\n",
    "\n",
    "# Create the DataLoader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "df_minmax = pd.read_csv(MINMAX_PATH, sep=';')\n",
    "min_value = df_minmax[\"min\"].values\n",
    "max_value = df_minmax[\"max\"].values\n",
    "mse, rmse_val, smape_val = best_model.test_model(test_loader, min_value=min_value, max_value=max_value, device=\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 289.7967472925713, Test RMSE: 16.56009445055203, Test SMAPE: 41.50957178186487\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test MSE: {mse}, Test RMSE: {rmse_val}, Test SMAPE: {smape_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "best_model.eval()\n",
    "\n",
    "y_preds = []\n",
    "y_trues = []\n",
    "\n",
    "# Iterate through the test set and collect predictions & ground truth\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_test, y_true = batch  # Get input and ground truth\n",
    "        x_test = x_test.to(\"cpu\")  # Ensure data is on CPU if needed\n",
    "\n",
    "        # Get predictions\n",
    "        y_pred = best_model(x_test)\n",
    "\n",
    "        # Store results\n",
    "        y_preds.append(y_pred.cpu())\n",
    "        y_trues.append(y_true.cpu())\n",
    "\n",
    "# Convert lists to tensors\n",
    "y_preds = torch.cat(y_preds, dim=0).numpy()\n",
    "y_trues = torch.cat(y_trues, dim=0).numpy()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_trues.flatten(), label=\"Ground Truth (NO)\", linestyle=\"-\", color=\"blue\")\n",
    "plt.scatter(range(len(y_preds.flatten())), y_preds.flatten(), label=\"Predictions\", color=\"black\", s=10)\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"NO Level\")\n",
    "plt.title(\"Predictions vs. Ground Truth\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
