{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Baseline Simple MLP with just MSE**\n",
    "# Only 2017 data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Running the models using the 'modelling' package**\n",
    "\n",
    "A notebook through which different modelling configurations can be ran, using the ``modelling`` package. It follows the steps of:\n",
    "- preparing packages;\n",
    "- setting \"global\" variables;\n",
    "- getting the data;\n",
    "- defining hyperparameters;\n",
    "- running a grid search and/or training a model; and\n",
    "- evaluation.\n",
    "In the modelling package, variations can be made to the models and training functions to experiment. Don't forget to restart the notebook after making changes there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For loading models, go to the ``src/results/models``:\n",
    "- Baseline NO2 2017 with MLP and MSE loss: ``best_mlp_no2_baseline_2017.pth``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting script...\n",
      "\n",
      "Running __init__.py for data pipeline...\n",
      "Modelling package initialized\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting script...\")\n",
    "\n",
    "\n",
    "from modelling.MLP import BasicMLP\n",
    "from modelling import *\n",
    "\n",
    "\n",
    "import optuna\n",
    "import threading\n",
    "import os\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GPU when available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Set \"global\" variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/rachel/forecasting_smog_PEML/src')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/home/rachel/forecasting_smog_PEML/src/config.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import config\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR:  /home/rachel/forecasting_smog_PEML\n",
      "MODEL_PATH:  /home/rachel/forecasting_smog_PEML/src/results/models\n",
      "Results path:  /home/rachel/forecasting_smog_PEML/src/results\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f54c8109fb0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HABROK = bool(0)                  # set to True if using HABROK; it will print\n",
    "                                  # all stdout to a .txt file to log progress\n",
    "\n",
    "\n",
    "print(\"BASE_DIR: \", BASE_DIR)\n",
    "print(\"MODEL_PATH: \", MODEL_PATH)\n",
    "print(\"Results path: \", RESULTS_PATH)\n",
    "\n",
    "torch.manual_seed(34)             # set seed for reproducibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## MODIFY THESE GLOBAL VARIABLES FOR YOUR MODEL SCENARIO\n",
    "## all other variables are defined in config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f54c8109fb0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change this according to the data you want to use\n",
    "# Change this according to the data you want to use\n",
    "YEARS = [2017]\n",
    "TRAIN_YEARS = [2017]\n",
    "VAL_YEARS = [2017]\n",
    "TEST_YEARS = [2017]\n",
    "\n",
    "LOSS_FUNC = \"MSE\" # choose from \"MSE\" and \"Physics_MSE\"\n",
    "NN_TYPE = \"MLP\" # choose from \"MLP\", \"RNN\", \"LSTM\", \"GRU\"\n",
    "torch.random.manual_seed(34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 2017\n",
      "MINMAX_PATH:  /home/rachel/forecasting_smog_PEML/data/data_combined/only_2017/pollutants_minmax_2017.csv\n",
      "DATASET_PATH:  /home/rachel/forecasting_smog_PEML/data/data_combined/only_2017\n",
      "MODEL_PATH_NAME:  best_MLP_no2_MSE_2017.pth\n",
      "RESULTS_METRICS_FILENAME:  results_MLP_no2_MSE_2017.csv\n",
      "BESTPARAMS_FILENAME:  best_params_MLP_no2_MSE_2017.txt\n",
      "PLOT_FILENAME:  plot_MLP_no2_MSE_2017.png\n"
     ]
    }
   ],
   "source": [
    "if YEARS == [2017, 2018, 2020, 2021, 2022, 2023]:\n",
    "    years = \"allyears\"\n",
    "    MINMAX_PATH = MINMAX_PATH_ALLYEARS\n",
    "    DATASET_PATH = DATASET_PATH_ALLYEARS\n",
    "    \n",
    "    print(\"Using all years\")\n",
    "    \n",
    "elif YEARS == [2017]:\n",
    "    years = \"2017\"\n",
    "    MINMAX_PATH = MINMAX_PATH_2017\n",
    "    DATASET_PATH = DATASET_PATH_2017\n",
    "    print(\"Using 2017\")\n",
    "else:\n",
    "    raise ValueError(\"Invalid years selected\")\n",
    "\n",
    "\n",
    "MODEL_PATH_NAME = f'best_{NN_TYPE}_no2_{LOSS_FUNC}_{years}.pth'\n",
    "RESULTS_METRICS_FILENAME = f'results_{NN_TYPE}_no2_{LOSS_FUNC}_{years}.csv'\n",
    "BESTPARAMS_FILENAME = f'best_params_{NN_TYPE}_no2_{LOSS_FUNC}_{years}.txt'\n",
    "PLOT_FILENAME = f'plot_{NN_TYPE}_no2_{LOSS_FUNC}_{years}.png'\n",
    "print(\"MINMAX_PATH: \", MINMAX_PATH)\n",
    "print(\"DATASET_PATH: \", DATASET_PATH)\n",
    "print(\"MODEL_PATH_NAME: \", MODEL_PATH_NAME)\n",
    "print(\"RESULTS_METRICS_FILENAME: \", RESULTS_METRICS_FILENAME)\n",
    "print(\"BESTPARAMS_FILENAME: \", BESTPARAMS_FILENAME)\n",
    "print(\"PLOT_FILENAME: \", PLOT_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load in data and create PyTorch *Datasets***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported train_2017_combined_u.csv\n",
      "Imported train_2017_combined_y.csv\n",
      "Imported val_2017_combined_u.csv\n",
      "Imported val_2017_combined_y.csv\n",
      "Imported test_2017_combined_u.csv\n",
      "Imported test_2017_combined_y.csv\n",
      "Successfully loaded data\n"
     ]
    }
   ],
   "source": [
    "# Load in data and create PyTorch Datasets. To tune\n",
    "# which exact .csv files get extracted, change the\n",
    "# lists in the get_dataframes() definition\n",
    "\n",
    "train_input_frames = get_dataframes('train', 'u', YEARS, DATASET_PATH)\n",
    "train_output_frames = get_dataframes('train', 'y', YEARS, DATASET_PATH)\n",
    "\n",
    "val_input_frames = get_dataframes('val', 'u', YEARS, DATASET_PATH)\n",
    "val_output_frames = get_dataframes('val', 'y', YEARS, DATASET_PATH)\n",
    "\n",
    "test_input_frames = get_dataframes('test', 'u', YEARS, DATASET_PATH)\n",
    "test_output_frames = get_dataframes('test', 'y', YEARS, DATASET_PATH)\n",
    "\n",
    "print(\"Successfully loaded data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                           DD   FF        FH        FX  NO2_BREUKELEN  \\\n",
       " DateTime                                                                \n",
       " 2017-08-01 00:00:00  0.166667  0.1  0.111111  0.000000       0.223698   \n",
       " 2017-08-01 01:00:00  0.000000  0.0  0.111111  0.052632       0.145496   \n",
       " 2017-08-01 02:00:00  0.000000  0.0  0.000000  0.000000       0.275978   \n",
       " 2017-08-01 03:00:00  0.277778  0.1  0.000000  0.000000       0.423742   \n",
       " 2017-08-01 04:00:00  0.805556  0.2  0.111111  0.105263       0.478721   \n",
       " ...                       ...  ...       ...       ...            ...   \n",
       " 2017-11-16 19:00:00  0.750000  0.2  0.333333  0.210526       0.606502   \n",
       " 2017-11-16 20:00:00  0.972222  0.3  0.333333  0.421053       0.456470   \n",
       " 2017-11-16 21:00:00  0.888889  0.1  0.222222  0.263158       0.483258   \n",
       " 2017-11-16 22:00:00  0.944444  0.2  0.111111  0.105263       0.468784   \n",
       " 2017-11-16 23:00:00  0.861111  0.1  0.222222  0.105263       0.473428   \n",
       " \n",
       "                      NO2_TUINDORP         P   SQ         T        TD  \n",
       " DateTime                                                              \n",
       " 2017-08-01 00:00:00      0.242115  0.562982  0.0  0.536667  0.726852  \n",
       " 2017-08-01 01:00:00      0.223158  0.570694  0.0  0.546667  0.740741  \n",
       " 2017-08-01 02:00:00      0.165911  0.560411  0.0  0.506667  0.689815  \n",
       " 2017-08-01 03:00:00      0.142363  0.555270  0.0  0.463333  0.634259  \n",
       " 2017-08-01 04:00:00      0.156297  0.555270  0.0  0.493333  0.662037  \n",
       " ...                           ...       ...  ...       ...       ...  \n",
       " 2017-11-16 19:00:00      0.523871  0.789203  0.0  0.390000  0.513889  \n",
       " 2017-11-16 20:00:00      0.512314  0.814910  0.0  0.353333  0.462963  \n",
       " 2017-11-16 21:00:00      0.232880  0.827763  0.0  0.330000  0.435185  \n",
       " 2017-11-16 22:00:00      0.108123  0.832905  0.0  0.306667  0.407407  \n",
       " 2017-11-16 23:00:00      0.205120  0.845758  0.0  0.250000  0.319444  \n",
       " \n",
       " [2592 rows x 10 columns]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TimeSeriesDataset(\n",
    "    train_input_frames,  # list of input training dataframes\n",
    "    train_output_frames, # list of output training dataframes\n",
    "    len(TRAIN_YEARS),                   # number of dataframes put in for both\n",
    "                         # (basically len(train_input_frames) and\n",
    "                         # len(train_output_frames) must be equal)\n",
    "    N_HOURS_U,           # number of hours of input data\n",
    "    N_HOURS_Y,           # number of hours of output data\n",
    "    N_HOURS_STEP,        # number of hours between each input/output pair\n",
    ")\n",
    "val_dataset = TimeSeriesDataset(\n",
    "    val_input_frames,    # etc.\n",
    "    val_output_frames,\n",
    "    len(VAL_YEARS),\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "test_dataset = TimeSeriesDataset(\n",
    "    test_input_frames,\n",
    "    test_output_frames,\n",
    "    len(TEST_YEARS),\n",
    "    N_HOURS_U,\n",
    "    N_HOURS_Y,\n",
    "    N_HOURS_STEP,\n",
    ")\n",
    "\n",
    "del train_input_frames, train_output_frames\n",
    "del val_input_frames, val_output_frames\n",
    "del test_input_frames, test_output_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                           DD   FF        FH        FX  NO2_BREUKELEN  \\\n",
       " DateTime                                                                \n",
       " 2017-08-01 00:00:00  0.166667  0.1  0.111111  0.000000       0.223698   \n",
       " 2017-08-01 01:00:00  0.000000  0.0  0.111111  0.052632       0.145496   \n",
       " 2017-08-01 02:00:00  0.000000  0.0  0.000000  0.000000       0.275978   \n",
       " 2017-08-01 03:00:00  0.277778  0.1  0.000000  0.000000       0.423742   \n",
       " 2017-08-01 04:00:00  0.805556  0.2  0.111111  0.105263       0.478721   \n",
       " ...                       ...  ...       ...       ...            ...   \n",
       " 2017-11-16 19:00:00  0.750000  0.2  0.333333  0.210526       0.606502   \n",
       " 2017-11-16 20:00:00  0.972222  0.3  0.333333  0.421053       0.456470   \n",
       " 2017-11-16 21:00:00  0.888889  0.1  0.222222  0.263158       0.483258   \n",
       " 2017-11-16 22:00:00  0.944444  0.2  0.111111  0.105263       0.468784   \n",
       " 2017-11-16 23:00:00  0.861111  0.1  0.222222  0.105263       0.473428   \n",
       " \n",
       "                      NO2_TUINDORP         P   SQ         T        TD  \n",
       " DateTime                                                              \n",
       " 2017-08-01 00:00:00      0.242115  0.562982  0.0  0.536667  0.726852  \n",
       " 2017-08-01 01:00:00      0.223158  0.570694  0.0  0.546667  0.740741  \n",
       " 2017-08-01 02:00:00      0.165911  0.560411  0.0  0.506667  0.689815  \n",
       " 2017-08-01 03:00:00      0.142363  0.555270  0.0  0.463333  0.634259  \n",
       " 2017-08-01 04:00:00      0.156297  0.555270  0.0  0.493333  0.662037  \n",
       " ...                           ...       ...  ...       ...       ...  \n",
       " 2017-11-16 19:00:00      0.523871  0.789203  0.0  0.390000  0.513889  \n",
       " 2017-11-16 20:00:00      0.512314  0.814910  0.0  0.353333  0.462963  \n",
       " 2017-11-16 21:00:00      0.232880  0.827763  0.0  0.330000  0.435185  \n",
       " 2017-11-16 22:00:00      0.108123  0.832905  0.0  0.306667  0.407407  \n",
       " 2017-11-16 23:00:00      0.205120  0.845758  0.0  0.250000  0.319444  \n",
       " \n",
       " [2592 rows x 10 columns]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                          NO2\n",
       " DateTime                     \n",
       " 2017-08-01 00:00:00  0.223698\n",
       " 2017-08-01 01:00:00  0.145496\n",
       " 2017-08-01 02:00:00  0.275978\n",
       " 2017-08-01 03:00:00  0.423742\n",
       " 2017-08-01 04:00:00  0.478721\n",
       " ...                       ...\n",
       " 2017-11-16 19:00:00  0.606502\n",
       " 2017-11-16 20:00:00  0.456470\n",
       " 2017-11-16 21:00:00  0.483258\n",
       " 2017-11-16 22:00:00  0.468784\n",
       " 2017-11-16 23:00:00  0.473428\n",
       " \n",
       " [2592 rows x 1 columns]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.pairs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1667, 0.1000, 0.1111, 0.0000, 0.2237, 0.2421, 0.5630, 0.0000, 0.5367,\n",
       "         0.7269],\n",
       "        [0.0000, 0.0000, 0.1111, 0.0526, 0.1455, 0.2232, 0.5707, 0.0000, 0.5467,\n",
       "         0.7407],\n",
       "        [0.0000, 0.0000, 0.0000, 0.0000, 0.2760, 0.1659, 0.5604, 0.0000, 0.5067,\n",
       "         0.6898],\n",
       "        [0.2778, 0.1000, 0.0000, 0.0000, 0.4237, 0.1424, 0.5553, 0.0000, 0.4633,\n",
       "         0.6343],\n",
       "        [0.8056, 0.2000, 0.1111, 0.1053, 0.4787, 0.1563, 0.5553, 0.0000, 0.4933,\n",
       "         0.6620],\n",
       "        [0.0000, 0.0000, 0.1111, 0.1053, 0.4837, 0.3135, 0.5681, 0.3000, 0.6200,\n",
       "         0.7593],\n",
       "        [0.7222, 0.1000, 0.1111, 0.0526, 0.4271, 0.5326, 0.5913, 0.0000, 0.6433,\n",
       "         0.7269],\n",
       "        [0.7500, 0.1000, 0.1111, 0.1053, 0.4223, 0.5367, 0.5938, 0.0000, 0.6500,\n",
       "         0.7037],\n",
       "        [0.7222, 0.2000, 0.2222, 0.1053, 0.3724, 0.5172, 0.5964, 0.0000, 0.6733,\n",
       "         0.6574],\n",
       "        [0.7500, 0.2000, 0.2222, 0.2105, 0.4429, 0.4459, 0.5990, 0.3000, 0.7133,\n",
       "         0.6157],\n",
       "        [0.6111, 0.2000, 0.2222, 0.1579, 0.3622, 0.3129, 0.6041, 0.0000, 0.7167,\n",
       "         0.6019],\n",
       "        [0.6111, 0.2000, 0.2222, 0.1579, 0.2893, 0.3478, 0.6067, 0.0000, 0.7133,\n",
       "         0.5926],\n",
       "        [0.6528, 0.1000, 0.2222, 0.1053, 0.3749, 0.3649, 0.6041, 0.2000, 0.7800,\n",
       "         0.6435],\n",
       "        [0.6944, 0.2000, 0.2222, 0.1053, 0.2847, 0.3019, 0.6015, 0.2000, 0.7867,\n",
       "         0.4861],\n",
       "        [0.7222, 0.2000, 0.2222, 0.2105, 0.3459, 0.2268, 0.5990, 0.4000, 0.7733,\n",
       "         0.5046],\n",
       "        [0.6111, 0.2000, 0.2222, 0.1579, 0.3897, 0.2246, 0.6015, 0.1000, 0.7633,\n",
       "         0.5972],\n",
       "        [0.6944, 0.2000, 0.2222, 0.2105, 0.3676, 0.2855, 0.6041, 0.7000, 0.7700,\n",
       "         0.5880],\n",
       "        [0.5833, 0.2000, 0.2222, 0.1579, 0.3239, 0.2469, 0.6015, 0.2000, 0.7267,\n",
       "         0.6435],\n",
       "        [0.7222, 0.2000, 0.2222, 0.1579, 0.4183, 0.2171, 0.6144, 0.2000, 0.6967,\n",
       "         0.6944],\n",
       "        [0.6944, 0.1000, 0.1111, 0.1053, 0.3872, 0.2834, 0.6298, 0.0000, 0.5933,\n",
       "         0.7130],\n",
       "        [0.4167, 0.1000, 0.1111, 0.0526, 0.4498, 0.3918, 0.6298, 0.0000, 0.5267,\n",
       "         0.6944],\n",
       "        [0.4722, 0.1000, 0.1111, 0.0000, 0.5234, 0.4752, 0.6375, 0.0000, 0.5200,\n",
       "         0.6991],\n",
       "        [0.4722, 0.1000, 0.1111, 0.0526, 0.5909, 0.5745, 0.6298, 0.0000, 0.5067,\n",
       "         0.6852],\n",
       "        [0.5000, 0.1000, 0.1111, 0.1053, 0.6181, 0.5891, 0.6247, 0.0000, 0.5033,\n",
       "         0.6713],\n",
       "        [0.0000, 0.0000, 0.1111, 0.0526, 0.4864, 0.5491, 0.6298, 0.0000, 0.5000,\n",
       "         0.6806],\n",
       "        [0.4444, 0.1000, 0.1111, 0.0526, 0.4299, 0.5092, 0.6221, 0.0000, 0.5300,\n",
       "         0.6944],\n",
       "        [0.4167, 0.2000, 0.1111, 0.0526, 0.3301, 0.3212, 0.6144, 0.0000, 0.5267,\n",
       "         0.6898],\n",
       "        [0.3889, 0.1000, 0.2222, 0.1053, 0.3700, 0.2835, 0.6118, 0.0000, 0.5467,\n",
       "         0.6898],\n",
       "        [0.5000, 0.1000, 0.1111, 0.0526, 0.4474, 0.4099, 0.6144, 0.0000, 0.5533,\n",
       "         0.7083],\n",
       "        [0.5833, 0.2000, 0.2222, 0.1579, 0.5960, 0.4797, 0.6272, 0.0000, 0.6067,\n",
       "         0.7083],\n",
       "        [0.6389, 0.2000, 0.2222, 0.2105, 0.5152, 0.5086, 0.6272, 0.0000, 0.6333,\n",
       "         0.6991],\n",
       "        [0.6667, 0.4000, 0.3333, 0.2632, 0.4485, 0.4155, 0.6375, 0.0000, 0.6567,\n",
       "         0.6574],\n",
       "        [0.6667, 0.4000, 0.4444, 0.3158, 0.3476, 0.3375, 0.6478, 0.1000, 0.6800,\n",
       "         0.6574],\n",
       "        [0.6389, 0.3000, 0.3333, 0.3684, 0.3270, 0.2610, 0.6478, 0.1000, 0.7067,\n",
       "         0.6713],\n",
       "        [0.5556, 0.4000, 0.4444, 0.2632, 0.3436, 0.2420, 0.6555, 0.3000, 0.7300,\n",
       "         0.6296],\n",
       "        [0.5833, 0.4000, 0.4444, 0.3158, 0.3431, 0.2146, 0.6427, 0.2000, 0.7433,\n",
       "         0.5741],\n",
       "        [0.5556, 0.3000, 0.3333, 0.2632, 0.3377, 0.1782, 0.6221, 0.1000, 0.7600,\n",
       "         0.5370],\n",
       "        [0.5000, 0.4000, 0.4444, 0.2632, 0.3841, 0.1985, 0.6195, 0.0000, 0.7533,\n",
       "         0.5556],\n",
       "        [0.5000, 0.5000, 0.4444, 0.3684, 0.3701, 0.2416, 0.5964, 0.0000, 0.7600,\n",
       "         0.6204],\n",
       "        [0.5833, 0.5000, 0.4444, 0.4737, 0.3766, 0.2883, 0.5938, 0.0000, 0.7267,\n",
       "         0.5833],\n",
       "        [0.5833, 0.4000, 0.7778, 0.5789, 0.4383, 0.2718, 0.6093, 0.0000, 0.5933,\n",
       "         0.6806],\n",
       "        [0.5556, 0.2000, 0.3333, 0.3158, 0.2887, 0.1936, 0.5964, 0.0000, 0.5600,\n",
       "         0.7083],\n",
       "        [0.4861, 0.1000, 0.1111, 0.1579, 0.4774, 0.2238, 0.5835, 0.0000, 0.5533,\n",
       "         0.7361],\n",
       "        [0.4167, 0.2000, 0.2222, 0.1579, 0.3391, 0.2430, 0.5656, 0.0000, 0.5533,\n",
       "         0.7269],\n",
       "        [0.3889, 0.2000, 0.2222, 0.1579, 0.1782, 0.3154, 0.5681, 0.0000, 0.5567,\n",
       "         0.7315],\n",
       "        [0.4444, 0.3000, 0.2222, 0.1579, 0.2193, 0.2860, 0.5553, 0.0000, 0.5800,\n",
       "         0.7639],\n",
       "        [0.5000, 0.3000, 0.3333, 0.2632, 0.1981, 0.2077, 0.5373, 0.0000, 0.5967,\n",
       "         0.7778],\n",
       "        [0.5000, 0.2000, 0.2222, 0.2105, 0.1707, 0.1640, 0.5167, 0.0000, 0.6000,\n",
       "         0.7778],\n",
       "        [0.4444, 0.3000, 0.3333, 0.2632, 0.1643, 0.1525, 0.4961, 0.0000, 0.5967,\n",
       "         0.7824],\n",
       "        [0.4722, 0.4000, 0.3333, 0.3158, 0.1965, 0.1328, 0.4730, 0.0000, 0.6000,\n",
       "         0.7824],\n",
       "        [0.5000, 0.4000, 0.4444, 0.3158, 0.1501, 0.1252, 0.4422, 0.0000, 0.6100,\n",
       "         0.7639],\n",
       "        [0.4722, 0.2000, 0.3333, 0.2632, 0.1518, 0.1161, 0.4293, 0.0000, 0.6000,\n",
       "         0.7639],\n",
       "        [0.4722, 0.2000, 0.2222, 0.1579, 0.2622, 0.1766, 0.4165, 0.0000, 0.5967,\n",
       "         0.7731],\n",
       "        [0.5556, 0.4000, 0.3333, 0.3158, 0.5524, 0.2840, 0.4139, 0.0000, 0.6533,\n",
       "         0.8056],\n",
       "        [0.5833, 0.5000, 0.4444, 0.4211, 0.4840, 0.3435, 0.4010, 0.5000, 0.6967,\n",
       "         0.8009],\n",
       "        [0.5833, 0.6000, 0.5556, 0.4737, 0.3544, 0.3057, 0.3985, 0.0000, 0.6867,\n",
       "         0.8194],\n",
       "        [0.5833, 0.6000, 0.5556, 0.4737, 0.2754, 0.2615, 0.4036, 0.0000, 0.6633,\n",
       "         0.8519],\n",
       "        [0.6389, 0.5000, 0.6667, 0.5789, 0.1948, 0.2453, 0.4190, 0.0000, 0.6133,\n",
       "         0.7454],\n",
       "        [0.6389, 0.7000, 0.7778, 0.6316, 0.1734, 0.1434, 0.4216, 0.6000, 0.7067,\n",
       "         0.6806],\n",
       "        [0.6667, 0.9000, 0.8889, 0.7368, 0.1505, 0.1046, 0.4267, 0.7000, 0.7467,\n",
       "         0.6435],\n",
       "        [0.6667, 0.8000, 0.7778, 0.7368, 0.1352, 0.0607, 0.4319, 0.8000, 0.7667,\n",
       "         0.6019],\n",
       "        [0.6667, 0.9000, 1.0000, 0.8947, 0.0778, 0.0700, 0.4319, 1.0000, 0.7867,\n",
       "         0.6065],\n",
       "        [0.6944, 0.8000, 0.8889, 0.7895, 0.1184, 0.0594, 0.4422, 0.4000, 0.7400,\n",
       "         0.6389],\n",
       "        [0.6667, 0.8000, 0.7778, 0.6842, 0.1293, 0.0823, 0.4370, 0.5000, 0.7633,\n",
       "         0.6389],\n",
       "        [0.6667, 0.7000, 0.8889, 0.7368, 0.1238, 0.1016, 0.4473, 1.0000, 0.7467,\n",
       "         0.6944],\n",
       "        [0.6389, 0.9000, 0.8889, 0.8421, 0.1043, 0.1005, 0.4550, 0.5000, 0.7067,\n",
       "         0.5278],\n",
       "        [0.6667, 0.7000, 1.0000, 0.8947, 0.0997, 0.0701, 0.4627, 0.3000, 0.6900,\n",
       "         0.5602],\n",
       "        [0.6389, 1.0000, 0.8889, 0.9474, 0.0812, 0.0572, 0.4653, 0.0000, 0.6800,\n",
       "         0.5648],\n",
       "        [0.6667, 0.9000, 0.8889, 0.8421, 0.0823, 0.0533, 0.4627, 0.0000, 0.6567,\n",
       "         0.5741],\n",
       "        [0.6667, 0.7000, 0.7778, 0.7368, 0.1155, 0.0475, 0.4627, 0.0000, 0.6300,\n",
       "         0.6019],\n",
       "        [0.6389, 0.4000, 0.5556, 0.5789, 0.0837, 0.0376, 0.4576, 0.0000, 0.6100,\n",
       "         0.6204],\n",
       "        [0.6111, 0.5000, 0.4444, 0.4211, 0.0570, 0.0373, 0.4499, 0.0000, 0.5933,\n",
       "         0.6296]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.pairs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1965],\n",
       "        [0.1501],\n",
       "        [0.1518],\n",
       "        [0.2622],\n",
       "        [0.5524],\n",
       "        [0.4840],\n",
       "        [0.3544],\n",
       "        [0.2754],\n",
       "        [0.1948],\n",
       "        [0.1734],\n",
       "        [0.1505],\n",
       "        [0.1352],\n",
       "        [0.0778],\n",
       "        [0.1184],\n",
       "        [0.1293],\n",
       "        [0.1238],\n",
       "        [0.1043],\n",
       "        [0.0997],\n",
       "        [0.0812],\n",
       "        [0.0823],\n",
       "        [0.1155],\n",
       "        [0.0837],\n",
       "        [0.0570],\n",
       "        [0.1006]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.pairs[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No2 tuindorp idx:  5\n",
      "No2 breukelen idx:  4\n",
      "wind dir (dd) idx:  0\n",
      "wind speed (fh) idx:  2\n",
      "Column indices are same as config.py\n"
     ]
    }
   ],
   "source": [
    "# Assuming train_dataset.u[0] is a pandas Index object with column names\n",
    "column_names = list(train_dataset.u[0])  # Convert Index to list\n",
    "\n",
    "\n",
    "print(\"No2 tuindorp idx: \", column_names.index('NO2_TUINDORP'))\n",
    "print(\"No2 breukelen idx: \", column_names.index('NO2_BREUKELEN'))\n",
    "print(\"wind dir (dd) idx: \", column_names.index('DD'))\n",
    "print(\"wind speed (fh) idx: \", column_names.index('FH'))\n",
    "\n",
    "# check if the indices are the same as whats defined in config.py\n",
    "assert column_names.index('NO2_TUINDORP')== NO2_TUINDORP_IDX\n",
    "assert column_names.index('NO2_BREUKELEN') == NO2_BREUKELEN_IDX\n",
    "assert column_names.index('DD') == WIND_DIR_IDX\n",
    "assert column_names.index('FH') == WIND_SPEED_IDX\n",
    "print(\"Column indices are same as config.py\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime\n",
       "2017-08-01 00:00:00    0.242115\n",
       "2017-08-01 01:00:00    0.223158\n",
       "2017-08-01 02:00:00    0.165911\n",
       "2017-08-01 03:00:00    0.142363\n",
       "2017-08-01 04:00:00    0.156297\n",
       "                         ...   \n",
       "2017-11-16 19:00:00    0.523871\n",
       "2017-11-16 20:00:00    0.512314\n",
       "2017-11-16 21:00:00    0.232880\n",
       "2017-11-16 22:00:00    0.108123\n",
       "2017-11-16 23:00:00    0.205120\n",
       "Name: NO2_TUINDORP, Length: 2592, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.u[0].iloc[:,NO2_TUINDORP_IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime\n",
       "2017-08-01 00:00:00    0.223698\n",
       "2017-08-01 01:00:00    0.145496\n",
       "2017-08-01 02:00:00    0.275978\n",
       "2017-08-01 03:00:00    0.423742\n",
       "2017-08-01 04:00:00    0.478721\n",
       "                         ...   \n",
       "2017-11-16 19:00:00    0.606502\n",
       "2017-11-16 20:00:00    0.456470\n",
       "2017-11-16 21:00:00    0.483258\n",
       "2017-11-16 22:00:00    0.468784\n",
       "2017-11-16 23:00:00    0.473428\n",
       "Name: NO2_BREUKELEN, Length: 2592, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.u[0].iloc[:,NO2_BREUKELEN_IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime\n",
       "2017-08-01 00:00:00    0.166667\n",
       "2017-08-01 01:00:00    0.000000\n",
       "2017-08-01 02:00:00    0.000000\n",
       "2017-08-01 03:00:00    0.277778\n",
       "2017-08-01 04:00:00    0.805556\n",
       "                         ...   \n",
       "2017-11-16 19:00:00    0.750000\n",
       "2017-11-16 20:00:00    0.972222\n",
       "2017-11-16 21:00:00    0.888889\n",
       "2017-11-16 22:00:00    0.944444\n",
       "2017-11-16 23:00:00    0.861111\n",
       "Name: DD, Length: 2592, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.u[0].iloc[:,WIND_DIR_IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DateTime\n",
       "2017-08-01 00:00:00    0.111111\n",
       "2017-08-01 01:00:00    0.111111\n",
       "2017-08-01 02:00:00    0.000000\n",
       "2017-08-01 03:00:00    0.000000\n",
       "2017-08-01 04:00:00    0.111111\n",
       "                         ...   \n",
       "2017-11-16 19:00:00    0.333333\n",
       "2017-11-16 20:00:00    0.333333\n",
       "2017-11-16 21:00:00    0.222222\n",
       "2017-11-16 22:00:00    0.111111\n",
       "2017-11-16 23:00:00    0.222222\n",
       "Name: FH, Length: 2592, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.u[0].iloc[:,WIND_SPEED_IDX]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple MSE Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:39:45,769] A new study created in RDB with name: mlp_hyperparameter_optimization_baseline_2017\n",
      "/tmp/ipykernel_9406/3233035118.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
      "/tmp/ipykernel_9406/3233035118.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-8, 1e-3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.084127 - Val Loss (simple RMSE, no physics involved): 0.395761\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.086374 - Val Loss (simple RMSE, no physics involved): 0.394164\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.085680 - Val Loss (simple RMSE, no physics involved): 0.392556\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.088072 - Val Loss (simple RMSE, no physics involved): 0.390947\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.087773 - Val Loss (simple RMSE, no physics involved): 0.389344\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.078638 - Val Loss (simple RMSE, no physics involved): 0.387745\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.078188 - Val Loss (simple RMSE, no physics involved): 0.386174\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.074313 - Val Loss (simple RMSE, no physics involved): 0.384616\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.076305 - Val Loss (simple RMSE, no physics involved): 0.383085\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.076460 - Val Loss (simple RMSE, no physics involved): 0.381552\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.075469 - Val Loss (simple RMSE, no physics involved): 0.380027\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.077808 - Val Loss (simple RMSE, no physics involved): 0.378507\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.073319 - Val Loss (simple RMSE, no physics involved): 0.376974\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.078606 - Val Loss (simple RMSE, no physics involved): 0.375445\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.078915 - Val Loss (simple RMSE, no physics involved): 0.373888\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.079819 - Val Loss (simple RMSE, no physics involved): 0.372324\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.072606 - Val Loss (simple RMSE, no physics involved): 0.370751\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.074730 - Val Loss (simple RMSE, no physics involved): 0.369188\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.066288 - Val Loss (simple RMSE, no physics involved): 0.367630\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.067914 - Val Loss (simple RMSE, no physics involved): 0.366093\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.067461 - Val Loss (simple RMSE, no physics involved): 0.364560\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.069665 - Val Loss (simple RMSE, no physics involved): 0.363030\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.066929 - Val Loss (simple RMSE, no physics involved): 0.361473\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.061356 - Val Loss (simple RMSE, no physics involved): 0.359921\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.071371 - Val Loss (simple RMSE, no physics involved): 0.358378\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.074199 - Val Loss (simple RMSE, no physics involved): 0.356796\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.059700 - Val Loss (simple RMSE, no physics involved): 0.355178\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.064389 - Val Loss (simple RMSE, no physics involved): 0.353584\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.062637 - Val Loss (simple RMSE, no physics involved): 0.351982\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.057265 - Val Loss (simple RMSE, no physics involved): 0.350386\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.067903 - Val Loss (simple RMSE, no physics involved): 0.348795\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.059077 - Val Loss (simple RMSE, no physics involved): 0.347160\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.060283 - Val Loss (simple RMSE, no physics involved): 0.345532\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.060021 - Val Loss (simple RMSE, no physics involved): 0.343885\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.055709 - Val Loss (simple RMSE, no physics involved): 0.342217\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.058246 - Val Loss (simple RMSE, no physics involved): 0.340570\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.053575 - Val Loss (simple RMSE, no physics involved): 0.338902\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.058261 - Val Loss (simple RMSE, no physics involved): 0.337243\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.051487 - Val Loss (simple RMSE, no physics involved): 0.335568\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.058496 - Val Loss (simple RMSE, no physics involved): 0.333891\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.056207 - Val Loss (simple RMSE, no physics involved): 0.332184\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.052791 - Val Loss (simple RMSE, no physics involved): 0.330458\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.048544 - Val Loss (simple RMSE, no physics involved): 0.328728\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.049963 - Val Loss (simple RMSE, no physics involved): 0.327021\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.057277 - Val Loss (simple RMSE, no physics involved): 0.325309\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.050896 - Val Loss (simple RMSE, no physics involved): 0.323525\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.051636 - Val Loss (simple RMSE, no physics involved): 0.321747\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.047586 - Val Loss (simple RMSE, no physics involved): 0.319953\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.046170 - Val Loss (simple RMSE, no physics involved): 0.318171\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.044231 - Val Loss (simple RMSE, no physics involved): 0.316416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:39:57,458] Trial 0 finished with value: 0.3164157271385193 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 149, 'lr': 1.1448234701067847e-05, 'weight_decay': 0.00025696170031068146, 'batch_size': 32}. Best is trial 0 with value: 0.3164157271385193.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.071224 - Val Loss (simple RMSE, no physics involved): 0.233932\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.028903 - Val Loss (simple RMSE, no physics involved): 0.205489\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.024216 - Val Loss (simple RMSE, no physics involved): 0.211837\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.022545 - Val Loss (simple RMSE, no physics involved): 0.167978\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.016374 - Val Loss (simple RMSE, no physics involved): 0.167541\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015852 - Val Loss (simple RMSE, no physics involved): 0.154947\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015257 - Val Loss (simple RMSE, no physics involved): 0.149233\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013961 - Val Loss (simple RMSE, no physics involved): 0.148847\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013326 - Val Loss (simple RMSE, no physics involved): 0.146077\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013638 - Val Loss (simple RMSE, no physics involved): 0.145529\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014197 - Val Loss (simple RMSE, no physics involved): 0.144125\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014843 - Val Loss (simple RMSE, no physics involved): 0.143400\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013075 - Val Loss (simple RMSE, no physics involved): 0.156922\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.014415 - Val Loss (simple RMSE, no physics involved): 0.143728\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013615 - Val Loss (simple RMSE, no physics involved): 0.141862\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012747 - Val Loss (simple RMSE, no physics involved): 0.141636\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012706 - Val Loss (simple RMSE, no physics involved): 0.139733\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013033 - Val Loss (simple RMSE, no physics involved): 0.139272\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012274 - Val Loss (simple RMSE, no physics involved): 0.138916\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013163 - Val Loss (simple RMSE, no physics involved): 0.141568\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013431 - Val Loss (simple RMSE, no physics involved): 0.140234\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012890 - Val Loss (simple RMSE, no physics involved): 0.140641\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012884 - Val Loss (simple RMSE, no physics involved): 0.146279\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012763 - Val Loss (simple RMSE, no physics involved): 0.142946\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013144 - Val Loss (simple RMSE, no physics involved): 0.141249\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013524 - Val Loss (simple RMSE, no physics involved): 0.138934\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013454 - Val Loss (simple RMSE, no physics involved): 0.139686\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012706 - Val Loss (simple RMSE, no physics involved): 0.141239\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012780 - Val Loss (simple RMSE, no physics involved): 0.140037\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012649 - Val Loss (simple RMSE, no physics involved): 0.141747\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012178 - Val Loss (simple RMSE, no physics involved): 0.142034\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012592 - Val Loss (simple RMSE, no physics involved): 0.139746\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012909 - Val Loss (simple RMSE, no physics involved): 0.143215\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012774 - Val Loss (simple RMSE, no physics involved): 0.139005\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012317 - Val Loss (simple RMSE, no physics involved): 0.142609\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.013465 - Val Loss (simple RMSE, no physics involved): 0.141363\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012651 - Val Loss (simple RMSE, no physics involved): 0.144340\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012220 - Val Loss (simple RMSE, no physics involved): 0.141509\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011765 - Val Loss (simple RMSE, no physics involved): 0.143479\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.013451 - Val Loss (simple RMSE, no physics involved): 0.147250\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012954 - Val Loss (simple RMSE, no physics involved): 0.168331\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.014667 - Val Loss (simple RMSE, no physics involved): 0.156946\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013611 - Val Loss (simple RMSE, no physics involved): 0.139576\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012988 - Val Loss (simple RMSE, no physics involved): 0.139676\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.013174 - Val Loss (simple RMSE, no physics involved): 0.139235\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011965 - Val Loss (simple RMSE, no physics involved): 0.141528\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012632 - Val Loss (simple RMSE, no physics involved): 0.140033\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.013154 - Val Loss (simple RMSE, no physics involved): 0.138562\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012296 - Val Loss (simple RMSE, no physics involved): 0.138465\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:40:12,858] Trial 1 finished with value: 0.1382158100605011 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 122, 'lr': 0.006008813639195079, 'weight_decay': 0.00045735623090811437, 'batch_size': 32}. Best is trial 1 with value: 0.1382158100605011.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012685 - Val Loss (simple RMSE, no physics involved): 0.138216\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.065596 - Val Loss (simple RMSE, no physics involved): 0.193846\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.028011 - Val Loss (simple RMSE, no physics involved): 0.194575\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.020432 - Val Loss (simple RMSE, no physics involved): 0.164629\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.016409 - Val Loss (simple RMSE, no physics involved): 0.156331\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.015027 - Val Loss (simple RMSE, no physics involved): 0.150759\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014365 - Val Loss (simple RMSE, no physics involved): 0.145841\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013757 - Val Loss (simple RMSE, no physics involved): 0.143530\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013467 - Val Loss (simple RMSE, no physics involved): 0.138867\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013094 - Val Loss (simple RMSE, no physics involved): 0.136689\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012904 - Val Loss (simple RMSE, no physics involved): 0.137929\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012929 - Val Loss (simple RMSE, no physics involved): 0.135073\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012734 - Val Loss (simple RMSE, no physics involved): 0.134287\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012643 - Val Loss (simple RMSE, no physics involved): 0.133773\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012596 - Val Loss (simple RMSE, no physics involved): 0.134396\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012444 - Val Loss (simple RMSE, no physics involved): 0.134065\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012475 - Val Loss (simple RMSE, no physics involved): 0.133075\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012351 - Val Loss (simple RMSE, no physics involved): 0.134238\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012357 - Val Loss (simple RMSE, no physics involved): 0.133753\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012371 - Val Loss (simple RMSE, no physics involved): 0.133648\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012338 - Val Loss (simple RMSE, no physics involved): 0.134125\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012226 - Val Loss (simple RMSE, no physics involved): 0.133891\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012265 - Val Loss (simple RMSE, no physics involved): 0.133156\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012155 - Val Loss (simple RMSE, no physics involved): 0.133958\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012141 - Val Loss (simple RMSE, no physics involved): 0.133617\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012201 - Val Loss (simple RMSE, no physics involved): 0.134265\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012362 - Val Loss (simple RMSE, no physics involved): 0.133814\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012139 - Val Loss (simple RMSE, no physics involved): 0.136365\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012121 - Val Loss (simple RMSE, no physics involved): 0.134417\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012178 - Val Loss (simple RMSE, no physics involved): 0.134808\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012315 - Val Loss (simple RMSE, no physics involved): 0.134907\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011944 - Val Loss (simple RMSE, no physics involved): 0.135791\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012070 - Val Loss (simple RMSE, no physics involved): 0.135214\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011935 - Val Loss (simple RMSE, no physics involved): 0.134380\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012093 - Val Loss (simple RMSE, no physics involved): 0.134057\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011902 - Val Loss (simple RMSE, no physics involved): 0.133451\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011779 - Val Loss (simple RMSE, no physics involved): 0.134663\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012001 - Val Loss (simple RMSE, no physics involved): 0.134598\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011877 - Val Loss (simple RMSE, no physics involved): 0.134355\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011811 - Val Loss (simple RMSE, no physics involved): 0.133773\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011926 - Val Loss (simple RMSE, no physics involved): 0.135071\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011821 - Val Loss (simple RMSE, no physics involved): 0.135849\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011716 - Val Loss (simple RMSE, no physics involved): 0.135331\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011679 - Val Loss (simple RMSE, no physics involved): 0.135309\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011984 - Val Loss (simple RMSE, no physics involved): 0.136274\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011721 - Val Loss (simple RMSE, no physics involved): 0.137046\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011875 - Val Loss (simple RMSE, no physics involved): 0.136873\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011858 - Val Loss (simple RMSE, no physics involved): 0.136501\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011702 - Val Loss (simple RMSE, no physics involved): 0.134631\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011632 - Val Loss (simple RMSE, no physics involved): 0.135007\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:40:35,811] Trial 2 finished with value: 0.13307538628578186 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 218, 'lr': 0.0004610844820956921, 'weight_decay': 1.4510411727480722e-05, 'batch_size': 8}. Best is trial 2 with value: 0.13307538628578186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011597 - Val Loss (simple RMSE, no physics involved): 0.135314\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.051829 - Val Loss (simple RMSE, no physics involved): 0.199303\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.029757 - Val Loss (simple RMSE, no physics involved): 0.214165\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.026660 - Val Loss (simple RMSE, no physics involved): 0.201931\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.024348 - Val Loss (simple RMSE, no physics involved): 0.166091\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.018646 - Val Loss (simple RMSE, no physics involved): 0.148304\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015675 - Val Loss (simple RMSE, no physics involved): 0.145213\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014296 - Val Loss (simple RMSE, no physics involved): 0.138877\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013524 - Val Loss (simple RMSE, no physics involved): 0.139305\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013462 - Val Loss (simple RMSE, no physics involved): 0.137275\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013204 - Val Loss (simple RMSE, no physics involved): 0.136038\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012898 - Val Loss (simple RMSE, no physics involved): 0.135400\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012979 - Val Loss (simple RMSE, no physics involved): 0.134659\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012899 - Val Loss (simple RMSE, no physics involved): 0.136709\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012636 - Val Loss (simple RMSE, no physics involved): 0.134763\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013327 - Val Loss (simple RMSE, no physics involved): 0.135636\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013192 - Val Loss (simple RMSE, no physics involved): 0.139784\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012590 - Val Loss (simple RMSE, no physics involved): 0.134387\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012535 - Val Loss (simple RMSE, no physics involved): 0.133846\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012562 - Val Loss (simple RMSE, no physics involved): 0.138330\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012650 - Val Loss (simple RMSE, no physics involved): 0.134413\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012466 - Val Loss (simple RMSE, no physics involved): 0.135978\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012657 - Val Loss (simple RMSE, no physics involved): 0.134941\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013103 - Val Loss (simple RMSE, no physics involved): 0.134706\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012797 - Val Loss (simple RMSE, no physics involved): 0.138425\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012517 - Val Loss (simple RMSE, no physics involved): 0.136809\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012267 - Val Loss (simple RMSE, no physics involved): 0.134192\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012228 - Val Loss (simple RMSE, no physics involved): 0.134814\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012193 - Val Loss (simple RMSE, no physics involved): 0.135137\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012268 - Val Loss (simple RMSE, no physics involved): 0.134380\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012085 - Val Loss (simple RMSE, no physics involved): 0.138732\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012444 - Val Loss (simple RMSE, no physics involved): 0.135006\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012022 - Val Loss (simple RMSE, no physics involved): 0.136489\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012002 - Val Loss (simple RMSE, no physics involved): 0.135639\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012083 - Val Loss (simple RMSE, no physics involved): 0.136638\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012092 - Val Loss (simple RMSE, no physics involved): 0.135934\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011994 - Val Loss (simple RMSE, no physics involved): 0.136578\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011938 - Val Loss (simple RMSE, no physics involved): 0.137936\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011804 - Val Loss (simple RMSE, no physics involved): 0.138476\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011802 - Val Loss (simple RMSE, no physics involved): 0.138385\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011793 - Val Loss (simple RMSE, no physics involved): 0.136458\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011695 - Val Loss (simple RMSE, no physics involved): 0.140144\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011752 - Val Loss (simple RMSE, no physics involved): 0.137085\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011845 - Val Loss (simple RMSE, no physics involved): 0.138350\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011755 - Val Loss (simple RMSE, no physics involved): 0.140067\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012057 - Val Loss (simple RMSE, no physics involved): 0.139128\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012198 - Val Loss (simple RMSE, no physics involved): 0.140174\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012001 - Val Loss (simple RMSE, no physics involved): 0.138381\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011749 - Val Loss (simple RMSE, no physics involved): 0.138779\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012280 - Val Loss (simple RMSE, no physics involved): 0.141528\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:41:02,880] Trial 3 finished with value: 0.13384600480397543 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 66, 'lr': 0.0017574459324402921, 'weight_decay': 1.1077830895015586e-08, 'batch_size': 8}. Best is trial 2 with value: 0.13307538628578186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011662 - Val Loss (simple RMSE, no physics involved): 0.139752\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.078046 - Val Loss (simple RMSE, no physics involved): 0.193444\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.025797 - Val Loss (simple RMSE, no physics involved): 0.180875\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.020131 - Val Loss (simple RMSE, no physics involved): 0.164568\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.016215 - Val Loss (simple RMSE, no physics involved): 0.177837\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.017163 - Val Loss (simple RMSE, no physics involved): 0.158623\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.016780 - Val Loss (simple RMSE, no physics involved): 0.155877\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015163 - Val Loss (simple RMSE, no physics involved): 0.151139\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014828 - Val Loss (simple RMSE, no physics involved): 0.148564\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014353 - Val Loss (simple RMSE, no physics involved): 0.147238\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013502 - Val Loss (simple RMSE, no physics involved): 0.145691\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013802 - Val Loss (simple RMSE, no physics involved): 0.148112\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013665 - Val Loss (simple RMSE, no physics involved): 0.142593\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013551 - Val Loss (simple RMSE, no physics involved): 0.142190\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013703 - Val Loss (simple RMSE, no physics involved): 0.143573\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013112 - Val Loss (simple RMSE, no physics involved): 0.140906\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012575 - Val Loss (simple RMSE, no physics involved): 0.144946\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012938 - Val Loss (simple RMSE, no physics involved): 0.140356\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013197 - Val Loss (simple RMSE, no physics involved): 0.144563\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013430 - Val Loss (simple RMSE, no physics involved): 0.141058\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013205 - Val Loss (simple RMSE, no physics involved): 0.141770\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013597 - Val Loss (simple RMSE, no physics involved): 0.142743\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012859 - Val Loss (simple RMSE, no physics involved): 0.140977\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013233 - Val Loss (simple RMSE, no physics involved): 0.144371\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012883 - Val Loss (simple RMSE, no physics involved): 0.141331\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012723 - Val Loss (simple RMSE, no physics involved): 0.144135\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012618 - Val Loss (simple RMSE, no physics involved): 0.141308\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012642 - Val Loss (simple RMSE, no physics involved): 0.142649\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012657 - Val Loss (simple RMSE, no physics involved): 0.141945\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012484 - Val Loss (simple RMSE, no physics involved): 0.141149\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012474 - Val Loss (simple RMSE, no physics involved): 0.140382\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012569 - Val Loss (simple RMSE, no physics involved): 0.139958\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012506 - Val Loss (simple RMSE, no physics involved): 0.141956\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012533 - Val Loss (simple RMSE, no physics involved): 0.140251\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012525 - Val Loss (simple RMSE, no physics involved): 0.140898\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012507 - Val Loss (simple RMSE, no physics involved): 0.141819\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012249 - Val Loss (simple RMSE, no physics involved): 0.139781\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012870 - Val Loss (simple RMSE, no physics involved): 0.142305\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012501 - Val Loss (simple RMSE, no physics involved): 0.140361\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012648 - Val Loss (simple RMSE, no physics involved): 0.143677\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012737 - Val Loss (simple RMSE, no physics involved): 0.141236\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012422 - Val Loss (simple RMSE, no physics involved): 0.140674\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012214 - Val Loss (simple RMSE, no physics involved): 0.143105\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012424 - Val Loss (simple RMSE, no physics involved): 0.140286\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012880 - Val Loss (simple RMSE, no physics involved): 0.143076\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012759 - Val Loss (simple RMSE, no physics involved): 0.140468\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012348 - Val Loss (simple RMSE, no physics involved): 0.143946\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012512 - Val Loss (simple RMSE, no physics involved): 0.140403\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012293 - Val Loss (simple RMSE, no physics involved): 0.143806\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:41:09,276] Trial 4 finished with value: 0.13978062570095062 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 195, 'lr': 0.005047085902530794, 'weight_decay': 0.0006293690046145125, 'batch_size': 64}. Best is trial 2 with value: 0.13307538628578186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Train Loss: 0.012651 - Val Loss (simple RMSE, no physics involved): 0.140697\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.012428 - Val Loss (simple RMSE, no physics involved): 0.145199\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.072065 - Val Loss (simple RMSE, no physics involved): 0.381869\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.077119 - Val Loss (simple RMSE, no physics involved): 0.380833\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.076613 - Val Loss (simple RMSE, no physics involved): 0.379782\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.077408 - Val Loss (simple RMSE, no physics involved): 0.378731\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.079001 - Val Loss (simple RMSE, no physics involved): 0.377678\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.074703 - Val Loss (simple RMSE, no physics involved): 0.376624\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.072505 - Val Loss (simple RMSE, no physics involved): 0.375572\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.072160 - Val Loss (simple RMSE, no physics involved): 0.374523\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.071955 - Val Loss (simple RMSE, no physics involved): 0.373478\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.071850 - Val Loss (simple RMSE, no physics involved): 0.372433\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.078817 - Val Loss (simple RMSE, no physics involved): 0.371382\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.069203 - Val Loss (simple RMSE, no physics involved): 0.370321\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.074304 - Val Loss (simple RMSE, no physics involved): 0.369269\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.066402 - Val Loss (simple RMSE, no physics involved): 0.368213\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.069869 - Val Loss (simple RMSE, no physics involved): 0.367175\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.067982 - Val Loss (simple RMSE, no physics involved): 0.366134\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.064411 - Val Loss (simple RMSE, no physics involved): 0.365100\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.070455 - Val Loss (simple RMSE, no physics involved): 0.364072\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.071235 - Val Loss (simple RMSE, no physics involved): 0.363040\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.077299 - Val Loss (simple RMSE, no physics involved): 0.361990\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.077026 - Val Loss (simple RMSE, no physics involved): 0.360917\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.061137 - Val Loss (simple RMSE, no physics involved): 0.359833\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.072253 - Val Loss (simple RMSE, no physics involved): 0.358770\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.067644 - Val Loss (simple RMSE, no physics involved): 0.357694\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.062092 - Val Loss (simple RMSE, no physics involved): 0.356624\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.070796 - Val Loss (simple RMSE, no physics involved): 0.355562\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.061509 - Val Loss (simple RMSE, no physics involved): 0.354491\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.066438 - Val Loss (simple RMSE, no physics involved): 0.353431\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.061410 - Val Loss (simple RMSE, no physics involved): 0.352357\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.056970 - Val Loss (simple RMSE, no physics involved): 0.351296\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.058969 - Val Loss (simple RMSE, no physics involved): 0.350253\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.062190 - Val Loss (simple RMSE, no physics involved): 0.349202\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.066266 - Val Loss (simple RMSE, no physics involved): 0.348136\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.057773 - Val Loss (simple RMSE, no physics involved): 0.347048\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.059670 - Val Loss (simple RMSE, no physics involved): 0.345957\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.059317 - Val Loss (simple RMSE, no physics involved): 0.344863\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.060076 - Val Loss (simple RMSE, no physics involved): 0.343760\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.062315 - Val Loss (simple RMSE, no physics involved): 0.342651\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.064453 - Val Loss (simple RMSE, no physics involved): 0.341523\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.064882 - Val Loss (simple RMSE, no physics involved): 0.340369\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.058625 - Val Loss (simple RMSE, no physics involved): 0.339188\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.056624 - Val Loss (simple RMSE, no physics involved): 0.338014\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.058329 - Val Loss (simple RMSE, no physics involved): 0.336839\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.059539 - Val Loss (simple RMSE, no physics involved): 0.335666\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.061011 - Val Loss (simple RMSE, no physics involved): 0.334466\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.054731 - Val Loss (simple RMSE, no physics involved): 0.333252\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.056579 - Val Loss (simple RMSE, no physics involved): 0.332045\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.056841 - Val Loss (simple RMSE, no physics involved): 0.330818\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.051859 - Val Loss (simple RMSE, no physics involved): 0.329591\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.053343 - Val Loss (simple RMSE, no physics involved): 0.328376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:41:19,507] Trial 5 finished with value: 0.32837629318237305 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 82, 'lr': 1.468699206317257e-05, 'weight_decay': 0.00024762656299805885, 'batch_size': 32}. Best is trial 2 with value: 0.13307538628578186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.117698 - Val Loss (simple RMSE, no physics involved): 0.433068\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.117375 - Val Loss (simple RMSE, no physics involved): 0.428306\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.109964 - Val Loss (simple RMSE, no physics involved): 0.423542\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.109627 - Val Loss (simple RMSE, no physics involved): 0.418855\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.108810 - Val Loss (simple RMSE, no physics involved): 0.414228\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.103906 - Val Loss (simple RMSE, no physics involved): 0.409595\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.097954 - Val Loss (simple RMSE, no physics involved): 0.404952\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.098500 - Val Loss (simple RMSE, no physics involved): 0.400376\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.093832 - Val Loss (simple RMSE, no physics involved): 0.395773\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.091215 - Val Loss (simple RMSE, no physics involved): 0.391190\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.089343 - Val Loss (simple RMSE, no physics involved): 0.386524\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.088840 - Val Loss (simple RMSE, no physics involved): 0.381797\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.084167 - Val Loss (simple RMSE, no physics involved): 0.376892\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.081628 - Val Loss (simple RMSE, no physics involved): 0.371907\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.079757 - Val Loss (simple RMSE, no physics involved): 0.366937\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.074150 - Val Loss (simple RMSE, no physics involved): 0.361759\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.075581 - Val Loss (simple RMSE, no physics involved): 0.356670\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.072392 - Val Loss (simple RMSE, no physics involved): 0.351406\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.068901 - Val Loss (simple RMSE, no physics involved): 0.346135\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.066254 - Val Loss (simple RMSE, no physics involved): 0.340893\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.062482 - Val Loss (simple RMSE, no physics involved): 0.335595\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.059868 - Val Loss (simple RMSE, no physics involved): 0.330392\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.058762 - Val Loss (simple RMSE, no physics involved): 0.325183\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.057275 - Val Loss (simple RMSE, no physics involved): 0.319964\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.054731 - Val Loss (simple RMSE, no physics involved): 0.314821\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.052333 - Val Loss (simple RMSE, no physics involved): 0.309801\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.049792 - Val Loss (simple RMSE, no physics involved): 0.304743\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.047118 - Val Loss (simple RMSE, no physics involved): 0.299875\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.047175 - Val Loss (simple RMSE, no physics involved): 0.295050\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.047623 - Val Loss (simple RMSE, no physics involved): 0.290248\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.043586 - Val Loss (simple RMSE, no physics involved): 0.285419\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.041740 - Val Loss (simple RMSE, no physics involved): 0.280635\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.040738 - Val Loss (simple RMSE, no physics involved): 0.276162\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.039699 - Val Loss (simple RMSE, no physics involved): 0.271613\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.037742 - Val Loss (simple RMSE, no physics involved): 0.267308\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.039127 - Val Loss (simple RMSE, no physics involved): 0.263067\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.036282 - Val Loss (simple RMSE, no physics involved): 0.258910\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.034378 - Val Loss (simple RMSE, no physics involved): 0.254833\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.033333 - Val Loss (simple RMSE, no physics involved): 0.251038\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.033124 - Val Loss (simple RMSE, no physics involved): 0.247404\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.032683 - Val Loss (simple RMSE, no physics involved): 0.243924\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.031291 - Val Loss (simple RMSE, no physics involved): 0.240536\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.031682 - Val Loss (simple RMSE, no physics involved): 0.237421\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.031219 - Val Loss (simple RMSE, no physics involved): 0.234405\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.030025 - Val Loss (simple RMSE, no physics involved): 0.231689\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.030683 - Val Loss (simple RMSE, no physics involved): 0.229460\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.030490 - Val Loss (simple RMSE, no physics involved): 0.227118\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.029499 - Val Loss (simple RMSE, no physics involved): 0.225108\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.028549 - Val Loss (simple RMSE, no physics involved): 0.223087\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:41:34,987] Trial 6 finished with value: 0.22160954028367996 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 137, 'lr': 1.655612822081493e-05, 'weight_decay': 1.6695879859126077e-08, 'batch_size': 16}. Best is trial 2 with value: 0.13307538628578186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.028110 - Val Loss (simple RMSE, no physics involved): 0.221610\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.141188 - Val Loss (simple RMSE, no physics involved): 0.439986\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.098986 - Val Loss (simple RMSE, no physics involved): 0.384630\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.063096 - Val Loss (simple RMSE, no physics involved): 0.302559\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.035207 - Val Loss (simple RMSE, no physics involved): 0.214026\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.037981 - Val Loss (simple RMSE, no physics involved): 0.204474\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.030877 - Val Loss (simple RMSE, no physics involved): 0.228880\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.025374 - Val Loss (simple RMSE, no physics involved): 0.246699\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.030092 - Val Loss (simple RMSE, no physics involved): 0.238930\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.027089 - Val Loss (simple RMSE, no physics involved): 0.216127\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.024330 - Val Loss (simple RMSE, no physics involved): 0.201137\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.027504 - Val Loss (simple RMSE, no physics involved): 0.201949\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.023895 - Val Loss (simple RMSE, no physics involved): 0.203775\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.022142 - Val Loss (simple RMSE, no physics involved): 0.200932\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.023094 - Val Loss (simple RMSE, no physics involved): 0.191766\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.020103 - Val Loss (simple RMSE, no physics involved): 0.177279\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.019668 - Val Loss (simple RMSE, no physics involved): 0.175744\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.018127 - Val Loss (simple RMSE, no physics involved): 0.173878\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.017721 - Val Loss (simple RMSE, no physics involved): 0.157920\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.015711 - Val Loss (simple RMSE, no physics involved): 0.154668\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.014699 - Val Loss (simple RMSE, no physics involved): 0.152584\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.014426 - Val Loss (simple RMSE, no physics involved): 0.151002\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.014857 - Val Loss (simple RMSE, no physics involved): 0.149653\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.014090 - Val Loss (simple RMSE, no physics involved): 0.147848\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.014442 - Val Loss (simple RMSE, no physics involved): 0.146177\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.015486 - Val Loss (simple RMSE, no physics involved): 0.146345\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.014013 - Val Loss (simple RMSE, no physics involved): 0.144622\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.014667 - Val Loss (simple RMSE, no physics involved): 0.143516\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013050 - Val Loss (simple RMSE, no physics involved): 0.143953\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013376 - Val Loss (simple RMSE, no physics involved): 0.141261\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012390 - Val Loss (simple RMSE, no physics involved): 0.141957\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013719 - Val Loss (simple RMSE, no physics involved): 0.140619\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012825 - Val Loss (simple RMSE, no physics involved): 0.139732\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011863 - Val Loss (simple RMSE, no physics involved): 0.139524\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013290 - Val Loss (simple RMSE, no physics involved): 0.140169\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012616 - Val Loss (simple RMSE, no physics involved): 0.138751\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012450 - Val Loss (simple RMSE, no physics involved): 0.139131\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011912 - Val Loss (simple RMSE, no physics involved): 0.140322\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012426 - Val Loss (simple RMSE, no physics involved): 0.139599\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012384 - Val Loss (simple RMSE, no physics involved): 0.141116\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012070 - Val Loss (simple RMSE, no physics involved): 0.140195\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.013166 - Val Loss (simple RMSE, no physics involved): 0.138070\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012745 - Val Loss (simple RMSE, no physics involved): 0.139666\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013316 - Val Loss (simple RMSE, no physics involved): 0.138218\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011953 - Val Loss (simple RMSE, no physics involved): 0.138630\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.013373 - Val Loss (simple RMSE, no physics involved): 0.139135\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012289 - Val Loss (simple RMSE, no physics involved): 0.140689\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.013305 - Val Loss (simple RMSE, no physics involved): 0.138724\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012335 - Val Loss (simple RMSE, no physics involved): 0.142626\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.013955 - Val Loss (simple RMSE, no physics involved): 0.138516\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:41:57,269] Trial 7 finished with value: 0.13806995749473572 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 196, 'lr': 0.0003826740677043079, 'weight_decay': 2.605378292387279e-07, 'batch_size': 32}. Best is trial 2 with value: 0.13307538628578186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011791 - Val Loss (simple RMSE, no physics involved): 0.140597\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.078099 - Val Loss (simple RMSE, no physics involved): 0.349959\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.051242 - Val Loss (simple RMSE, no physics involved): 0.285337\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.033382 - Val Loss (simple RMSE, no physics involved): 0.224971\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.027837 - Val Loss (simple RMSE, no physics involved): 0.197153\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.029829 - Val Loss (simple RMSE, no physics involved): 0.197533\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.026520 - Val Loss (simple RMSE, no physics involved): 0.210831\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.026359 - Val Loss (simple RMSE, no physics involved): 0.226182\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.026416 - Val Loss (simple RMSE, no physics involved): 0.231877\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.026074 - Val Loss (simple RMSE, no physics involved): 0.223828\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.022523 - Val Loss (simple RMSE, no physics involved): 0.207527\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.023186 - Val Loss (simple RMSE, no physics involved): 0.191608\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.022024 - Val Loss (simple RMSE, no physics involved): 0.182902\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.020521 - Val Loss (simple RMSE, no physics involved): 0.184606\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.020003 - Val Loss (simple RMSE, no physics involved): 0.181940\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.017365 - Val Loss (simple RMSE, no physics involved): 0.175088\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.019518 - Val Loss (simple RMSE, no physics involved): 0.165317\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.015338 - Val Loss (simple RMSE, no physics involved): 0.157781\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.015412 - Val Loss (simple RMSE, no physics involved): 0.155500\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.014455 - Val Loss (simple RMSE, no physics involved): 0.153054\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.015327 - Val Loss (simple RMSE, no physics involved): 0.148800\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.015746 - Val Loss (simple RMSE, no physics involved): 0.147701\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.014910 - Val Loss (simple RMSE, no physics involved): 0.145296\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.014555 - Val Loss (simple RMSE, no physics involved): 0.144686\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013190 - Val Loss (simple RMSE, no physics involved): 0.143557\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.014763 - Val Loss (simple RMSE, no physics involved): 0.142454\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012235 - Val Loss (simple RMSE, no physics involved): 0.142693\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013156 - Val Loss (simple RMSE, no physics involved): 0.141823\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013338 - Val Loss (simple RMSE, no physics involved): 0.141315\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013731 - Val Loss (simple RMSE, no physics involved): 0.142622\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012336 - Val Loss (simple RMSE, no physics involved): 0.143103\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012846 - Val Loss (simple RMSE, no physics involved): 0.142872\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013121 - Val Loss (simple RMSE, no physics involved): 0.142299\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011509 - Val Loss (simple RMSE, no physics involved): 0.141760\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012660 - Val Loss (simple RMSE, no physics involved): 0.141840\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012453 - Val Loss (simple RMSE, no physics involved): 0.141034\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011924 - Val Loss (simple RMSE, no physics involved): 0.142090\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012719 - Val Loss (simple RMSE, no physics involved): 0.141354\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011819 - Val Loss (simple RMSE, no physics involved): 0.143639\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012309 - Val Loss (simple RMSE, no physics involved): 0.140847\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.013279 - Val Loss (simple RMSE, no physics involved): 0.141704\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012123 - Val Loss (simple RMSE, no physics involved): 0.142249\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011990 - Val Loss (simple RMSE, no physics involved): 0.141179\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011722 - Val Loss (simple RMSE, no physics involved): 0.142191\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013408 - Val Loss (simple RMSE, no physics involved): 0.140314\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012923 - Val Loss (simple RMSE, no physics involved): 0.141677\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012631 - Val Loss (simple RMSE, no physics involved): 0.142364\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012234 - Val Loss (simple RMSE, no physics involved): 0.140348\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012180 - Val Loss (simple RMSE, no physics involved): 0.141376\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:42:04,163] Trial 8 finished with value: 0.1403137594461441 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 41, 'lr': 0.0017337787958767628, 'weight_decay': 4.2332537494415276e-08, 'batch_size': 32}. Best is trial 2 with value: 0.13307538628578186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Train Loss: 0.013119 - Val Loss (simple RMSE, no physics involved): 0.140594\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.013287 - Val Loss (simple RMSE, no physics involved): 0.141131\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.079721 - Val Loss (simple RMSE, no physics involved): 0.260594\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.037905 - Val Loss (simple RMSE, no physics involved): 0.198221\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.031792 - Val Loss (simple RMSE, no physics involved): 0.232979\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025142 - Val Loss (simple RMSE, no physics involved): 0.215079\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.024573 - Val Loss (simple RMSE, no physics involved): 0.177092\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.019753 - Val Loss (simple RMSE, no physics involved): 0.168783\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.018511 - Val Loss (simple RMSE, no physics involved): 0.155557\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.016520 - Val Loss (simple RMSE, no physics involved): 0.148410\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014259 - Val Loss (simple RMSE, no physics involved): 0.148082\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.016107 - Val Loss (simple RMSE, no physics involved): 0.145748\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013587 - Val Loss (simple RMSE, no physics involved): 0.147124\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014718 - Val Loss (simple RMSE, no physics involved): 0.144530\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.015979 - Val Loss (simple RMSE, no physics involved): 0.144794\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.014691 - Val Loss (simple RMSE, no physics involved): 0.142600\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013786 - Val Loss (simple RMSE, no physics involved): 0.141990\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.014361 - Val Loss (simple RMSE, no physics involved): 0.140720\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.014511 - Val Loss (simple RMSE, no physics involved): 0.140612\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013101 - Val Loss (simple RMSE, no physics involved): 0.142641\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013529 - Val Loss (simple RMSE, no physics involved): 0.140478\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012838 - Val Loss (simple RMSE, no physics involved): 0.141815\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012421 - Val Loss (simple RMSE, no physics involved): 0.142384\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013136 - Val Loss (simple RMSE, no physics involved): 0.139505\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012531 - Val Loss (simple RMSE, no physics involved): 0.140536\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012353 - Val Loss (simple RMSE, no physics involved): 0.139182\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011841 - Val Loss (simple RMSE, no physics involved): 0.142346\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012153 - Val Loss (simple RMSE, no physics involved): 0.140029\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012745 - Val Loss (simple RMSE, no physics involved): 0.139894\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012325 - Val Loss (simple RMSE, no physics involved): 0.139696\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012785 - Val Loss (simple RMSE, no physics involved): 0.143349\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013423 - Val Loss (simple RMSE, no physics involved): 0.140017\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013592 - Val Loss (simple RMSE, no physics involved): 0.156159\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013812 - Val Loss (simple RMSE, no physics involved): 0.139298\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012787 - Val Loss (simple RMSE, no physics involved): 0.147469\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013317 - Val Loss (simple RMSE, no physics involved): 0.140103\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012713 - Val Loss (simple RMSE, no physics involved): 0.146374\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012897 - Val Loss (simple RMSE, no physics involved): 0.139890\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013086 - Val Loss (simple RMSE, no physics involved): 0.146571\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012693 - Val Loss (simple RMSE, no physics involved): 0.140888\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012406 - Val Loss (simple RMSE, no physics involved): 0.140275\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012784 - Val Loss (simple RMSE, no physics involved): 0.143511\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012246 - Val Loss (simple RMSE, no physics involved): 0.139617\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012917 - Val Loss (simple RMSE, no physics involved): 0.141612\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012543 - Val Loss (simple RMSE, no physics involved): 0.139854\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011579 - Val Loss (simple RMSE, no physics involved): 0.143473\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012892 - Val Loss (simple RMSE, no physics involved): 0.139356\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.014547 - Val Loss (simple RMSE, no physics involved): 0.141302\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012278 - Val Loss (simple RMSE, no physics involved): 0.143837\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012087 - Val Loss (simple RMSE, no physics involved): 0.140071\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012587 - Val Loss (simple RMSE, no physics involved): 0.149283\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.012171 - Val Loss (simple RMSE, no physics involved): 0.140595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:42:14,762] Trial 9 finished with value: 0.13918189704418182 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 68, 'lr': 0.003397773199113435, 'weight_decay': 7.587614102447341e-08, 'batch_size': 32}. Best is trial 2 with value: 0.13307538628578186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.109674 - Val Loss (simple RMSE, no physics involved): 0.332759\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.046155 - Val Loss (simple RMSE, no physics involved): 0.230860\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.030456 - Val Loss (simple RMSE, no physics involved): 0.202627\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.027840 - Val Loss (simple RMSE, no physics involved): 0.196708\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.024565 - Val Loss (simple RMSE, no physics involved): 0.190667\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.022030 - Val Loss (simple RMSE, no physics involved): 0.179776\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.019928 - Val Loss (simple RMSE, no physics involved): 0.172791\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.018293 - Val Loss (simple RMSE, no physics involved): 0.163977\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.017107 - Val Loss (simple RMSE, no physics involved): 0.156000\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.015909 - Val Loss (simple RMSE, no physics involved): 0.152234\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.015270 - Val Loss (simple RMSE, no physics involved): 0.147802\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014556 - Val Loss (simple RMSE, no physics involved): 0.144742\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.014215 - Val Loss (simple RMSE, no physics involved): 0.142890\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013820 - Val Loss (simple RMSE, no physics involved): 0.141021\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013603 - Val Loss (simple RMSE, no physics involved): 0.139797\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013499 - Val Loss (simple RMSE, no physics involved): 0.138622\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013374 - Val Loss (simple RMSE, no physics involved): 0.137769\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013135 - Val Loss (simple RMSE, no physics involved): 0.136912\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013026 - Val Loss (simple RMSE, no physics involved): 0.136197\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012938 - Val Loss (simple RMSE, no physics involved): 0.135716\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012850 - Val Loss (simple RMSE, no physics involved): 0.135225\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012786 - Val Loss (simple RMSE, no physics involved): 0.134787\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012737 - Val Loss (simple RMSE, no physics involved): 0.134378\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012693 - Val Loss (simple RMSE, no physics involved): 0.133908\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012651 - Val Loss (simple RMSE, no physics involved): 0.133775\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012620 - Val Loss (simple RMSE, no physics involved): 0.133507\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012580 - Val Loss (simple RMSE, no physics involved): 0.133270\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012594 - Val Loss (simple RMSE, no physics involved): 0.133381\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012640 - Val Loss (simple RMSE, no physics involved): 0.133171\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012494 - Val Loss (simple RMSE, no physics involved): 0.133210\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012527 - Val Loss (simple RMSE, no physics involved): 0.133156\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012473 - Val Loss (simple RMSE, no physics involved): 0.132970\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012462 - Val Loss (simple RMSE, no physics involved): 0.133292\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012400 - Val Loss (simple RMSE, no physics involved): 0.132929\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012387 - Val Loss (simple RMSE, no physics involved): 0.132947\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012370 - Val Loss (simple RMSE, no physics involved): 0.133448\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012346 - Val Loss (simple RMSE, no physics involved): 0.133029\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012340 - Val Loss (simple RMSE, no physics involved): 0.133074\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012315 - Val Loss (simple RMSE, no physics involved): 0.133057\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012274 - Val Loss (simple RMSE, no physics involved): 0.133257\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012268 - Val Loss (simple RMSE, no physics involved): 0.133272\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012258 - Val Loss (simple RMSE, no physics involved): 0.133203\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012250 - Val Loss (simple RMSE, no physics involved): 0.133838\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012233 - Val Loss (simple RMSE, no physics involved): 0.133523\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012238 - Val Loss (simple RMSE, no physics involved): 0.133603\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012179 - Val Loss (simple RMSE, no physics involved): 0.133470\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012185 - Val Loss (simple RMSE, no physics involved): 0.133669\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012159 - Val Loss (simple RMSE, no physics involved): 0.133824\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012174 - Val Loss (simple RMSE, no physics involved): 0.133953\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:42:37,696] Trial 10 finished with value: 0.13292881846427917 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 235, 'lr': 0.00010611010714835097, 'weight_decay': 9.02968717956186e-06, 'batch_size': 8}. Best is trial 10 with value: 0.13292881846427917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012131 - Val Loss (simple RMSE, no physics involved): 0.133919\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.050369 - Val Loss (simple RMSE, no physics involved): 0.248902\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.027936 - Val Loss (simple RMSE, no physics involved): 0.202876\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.024937 - Val Loss (simple RMSE, no physics involved): 0.193694\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.021150 - Val Loss (simple RMSE, no physics involved): 0.188038\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.018672 - Val Loss (simple RMSE, no physics involved): 0.172345\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.016979 - Val Loss (simple RMSE, no physics involved): 0.161904\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015569 - Val Loss (simple RMSE, no physics involved): 0.158715\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015025 - Val Loss (simple RMSE, no physics involved): 0.152514\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014503 - Val Loss (simple RMSE, no physics involved): 0.149828\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014314 - Val Loss (simple RMSE, no physics involved): 0.147685\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013878 - Val Loss (simple RMSE, no physics involved): 0.145895\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013636 - Val Loss (simple RMSE, no physics involved): 0.144336\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013642 - Val Loss (simple RMSE, no physics involved): 0.143260\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013425 - Val Loss (simple RMSE, no physics involved): 0.142044\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013263 - Val Loss (simple RMSE, no physics involved): 0.141148\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013205 - Val Loss (simple RMSE, no physics involved): 0.140424\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013089 - Val Loss (simple RMSE, no physics involved): 0.140001\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013059 - Val Loss (simple RMSE, no physics involved): 0.139217\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013030 - Val Loss (simple RMSE, no physics involved): 0.139281\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012937 - Val Loss (simple RMSE, no physics involved): 0.138493\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013007 - Val Loss (simple RMSE, no physics involved): 0.138088\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012851 - Val Loss (simple RMSE, no physics involved): 0.138036\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012869 - Val Loss (simple RMSE, no physics involved): 0.137637\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012751 - Val Loss (simple RMSE, no physics involved): 0.137957\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012756 - Val Loss (simple RMSE, no physics involved): 0.137372\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012925 - Val Loss (simple RMSE, no physics involved): 0.137635\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012674 - Val Loss (simple RMSE, no physics involved): 0.137245\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012617 - Val Loss (simple RMSE, no physics involved): 0.137236\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012637 - Val Loss (simple RMSE, no physics involved): 0.136614\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012564 - Val Loss (simple RMSE, no physics involved): 0.136572\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012517 - Val Loss (simple RMSE, no physics involved): 0.136451\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012500 - Val Loss (simple RMSE, no physics involved): 0.136492\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012482 - Val Loss (simple RMSE, no physics involved): 0.137050\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012452 - Val Loss (simple RMSE, no physics involved): 0.136105\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012409 - Val Loss (simple RMSE, no physics involved): 0.136711\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012394 - Val Loss (simple RMSE, no physics involved): 0.136078\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012418 - Val Loss (simple RMSE, no physics involved): 0.136854\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012369 - Val Loss (simple RMSE, no physics involved): 0.136361\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012360 - Val Loss (simple RMSE, no physics involved): 0.135910\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012365 - Val Loss (simple RMSE, no physics involved): 0.136182\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012290 - Val Loss (simple RMSE, no physics involved): 0.136197\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012243 - Val Loss (simple RMSE, no physics involved): 0.136097\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012249 - Val Loss (simple RMSE, no physics involved): 0.136604\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012224 - Val Loss (simple RMSE, no physics involved): 0.136476\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012430 - Val Loss (simple RMSE, no physics involved): 0.136113\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012347 - Val Loss (simple RMSE, no physics involved): 0.136958\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012266 - Val Loss (simple RMSE, no physics involved): 0.136852\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012157 - Val Loss (simple RMSE, no physics involved): 0.136064\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012150 - Val Loss (simple RMSE, no physics involved): 0.136158\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:43:01,796] Trial 11 finished with value: 0.13591016083955765 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 250, 'lr': 0.00010743916147418155, 'weight_decay': 7.156001309145776e-06, 'batch_size': 8}. Best is trial 10 with value: 0.13292881846427917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012126 - Val Loss (simple RMSE, no physics involved): 0.135964\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.054799 - Val Loss (simple RMSE, no physics involved): 0.204326\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.028290 - Val Loss (simple RMSE, no physics involved): 0.185340\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.020957 - Val Loss (simple RMSE, no physics involved): 0.183989\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.018010 - Val Loss (simple RMSE, no physics involved): 0.164597\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.015830 - Val Loss (simple RMSE, no physics involved): 0.152837\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014833 - Val Loss (simple RMSE, no physics involved): 0.148615\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014110 - Val Loss (simple RMSE, no physics involved): 0.143791\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013774 - Val Loss (simple RMSE, no physics involved): 0.142004\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013555 - Val Loss (simple RMSE, no physics involved): 0.139522\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013414 - Val Loss (simple RMSE, no physics involved): 0.140311\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013502 - Val Loss (simple RMSE, no physics involved): 0.137428\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013151 - Val Loss (simple RMSE, no physics involved): 0.137115\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013011 - Val Loss (simple RMSE, no physics involved): 0.136120\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012932 - Val Loss (simple RMSE, no physics involved): 0.135862\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012894 - Val Loss (simple RMSE, no physics involved): 0.135240\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012867 - Val Loss (simple RMSE, no physics involved): 0.137963\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012894 - Val Loss (simple RMSE, no physics involved): 0.134534\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012682 - Val Loss (simple RMSE, no physics involved): 0.134182\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012617 - Val Loss (simple RMSE, no physics involved): 0.134149\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012547 - Val Loss (simple RMSE, no physics involved): 0.134283\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012507 - Val Loss (simple RMSE, no physics involved): 0.136232\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012727 - Val Loss (simple RMSE, no physics involved): 0.135312\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012596 - Val Loss (simple RMSE, no physics involved): 0.134495\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012484 - Val Loss (simple RMSE, no physics involved): 0.134176\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012432 - Val Loss (simple RMSE, no physics involved): 0.134731\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012326 - Val Loss (simple RMSE, no physics involved): 0.134719\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012327 - Val Loss (simple RMSE, no physics involved): 0.133833\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012415 - Val Loss (simple RMSE, no physics involved): 0.134478\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012297 - Val Loss (simple RMSE, no physics involved): 0.134585\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012212 - Val Loss (simple RMSE, no physics involved): 0.134641\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012190 - Val Loss (simple RMSE, no physics involved): 0.134832\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012229 - Val Loss (simple RMSE, no physics involved): 0.134798\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012142 - Val Loss (simple RMSE, no physics involved): 0.134604\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012308 - Val Loss (simple RMSE, no physics involved): 0.134545\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012111 - Val Loss (simple RMSE, no physics involved): 0.134256\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012147 - Val Loss (simple RMSE, no physics involved): 0.134590\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012123 - Val Loss (simple RMSE, no physics involved): 0.134897\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012056 - Val Loss (simple RMSE, no physics involved): 0.134963\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012021 - Val Loss (simple RMSE, no physics involved): 0.134936\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012133 - Val Loss (simple RMSE, no physics involved): 0.135462\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012175 - Val Loss (simple RMSE, no physics involved): 0.136771\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012026 - Val Loss (simple RMSE, no physics involved): 0.135343\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011980 - Val Loss (simple RMSE, no physics involved): 0.136084\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012150 - Val Loss (simple RMSE, no physics involved): 0.135580\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012104 - Val Loss (simple RMSE, no physics involved): 0.135581\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011907 - Val Loss (simple RMSE, no physics involved): 0.135853\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011959 - Val Loss (simple RMSE, no physics involved): 0.135549\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011974 - Val Loss (simple RMSE, no physics involved): 0.136329\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012330 - Val Loss (simple RMSE, no physics involved): 0.137873\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:43:25,997] Trial 12 finished with value: 0.13383328666289648 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 245, 'lr': 0.00017238564702681296, 'weight_decay': 1.3734744480973449e-05, 'batch_size': 8}. Best is trial 10 with value: 0.13292881846427917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011933 - Val Loss (simple RMSE, no physics involved): 0.137322\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.043816 - Val Loss (simple RMSE, no physics involved): 0.174826\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.024369 - Val Loss (simple RMSE, no physics involved): 0.190240\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.016868 - Val Loss (simple RMSE, no physics involved): 0.154077\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.014538 - Val Loss (simple RMSE, no physics involved): 0.145453\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.013783 - Val Loss (simple RMSE, no physics involved): 0.142628\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.013476 - Val Loss (simple RMSE, no physics involved): 0.139155\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013312 - Val Loss (simple RMSE, no physics involved): 0.135839\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013274 - Val Loss (simple RMSE, no physics involved): 0.135276\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.012938 - Val Loss (simple RMSE, no physics involved): 0.134630\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013027 - Val Loss (simple RMSE, no physics involved): 0.135454\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012769 - Val Loss (simple RMSE, no physics involved): 0.134715\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012667 - Val Loss (simple RMSE, no physics involved): 0.134651\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012726 - Val Loss (simple RMSE, no physics involved): 0.133649\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012786 - Val Loss (simple RMSE, no physics involved): 0.133018\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012503 - Val Loss (simple RMSE, no physics involved): 0.134869\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012929 - Val Loss (simple RMSE, no physics involved): 0.135398\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012609 - Val Loss (simple RMSE, no physics involved): 0.133563\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012358 - Val Loss (simple RMSE, no physics involved): 0.134795\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012361 - Val Loss (simple RMSE, no physics involved): 0.139295\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012674 - Val Loss (simple RMSE, no physics involved): 0.141720\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012806 - Val Loss (simple RMSE, no physics involved): 0.137627\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012372 - Val Loss (simple RMSE, no physics involved): 0.135449\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012152 - Val Loss (simple RMSE, no physics involved): 0.135864\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012035 - Val Loss (simple RMSE, no physics involved): 0.136554\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012029 - Val Loss (simple RMSE, no physics involved): 0.136093\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012005 - Val Loss (simple RMSE, no physics involved): 0.137052\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011921 - Val Loss (simple RMSE, no physics involved): 0.137205\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011959 - Val Loss (simple RMSE, no physics involved): 0.137903\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011966 - Val Loss (simple RMSE, no physics involved): 0.136671\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012165 - Val Loss (simple RMSE, no physics involved): 0.139266\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012378 - Val Loss (simple RMSE, no physics involved): 0.141196\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012160 - Val Loss (simple RMSE, no physics involved): 0.142458\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012126 - Val Loss (simple RMSE, no physics involved): 0.141086\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011764 - Val Loss (simple RMSE, no physics involved): 0.139431\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011705 - Val Loss (simple RMSE, no physics involved): 0.138777\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011732 - Val Loss (simple RMSE, no physics involved): 0.138709\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011628 - Val Loss (simple RMSE, no physics involved): 0.141314\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011677 - Val Loss (simple RMSE, no physics involved): 0.139788\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011653 - Val Loss (simple RMSE, no physics involved): 0.138610\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011679 - Val Loss (simple RMSE, no physics involved): 0.138674\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011503 - Val Loss (simple RMSE, no physics involved): 0.140820\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011659 - Val Loss (simple RMSE, no physics involved): 0.142160\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011623 - Val Loss (simple RMSE, no physics involved): 0.140551\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011484 - Val Loss (simple RMSE, no physics involved): 0.144625\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011500 - Val Loss (simple RMSE, no physics involved): 0.140359\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011467 - Val Loss (simple RMSE, no physics involved): 0.144360\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011786 - Val Loss (simple RMSE, no physics involved): 0.147454\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011782 - Val Loss (simple RMSE, no physics involved): 0.141549\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011581 - Val Loss (simple RMSE, no physics involved): 0.140035\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:43:48,424] Trial 13 finished with value: 0.1330178901553154 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 208, 'lr': 0.0004960963349706197, 'weight_decay': 1.3414870095545872e-06, 'batch_size': 8}. Best is trial 10 with value: 0.13292881846427917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011434 - Val Loss (simple RMSE, no physics involved): 0.139858\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.088895 - Val Loss (simple RMSE, no physics involved): 0.364572\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.059128 - Val Loss (simple RMSE, no physics involved): 0.308599\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.041265 - Val Loss (simple RMSE, no physics involved): 0.266890\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.033058 - Val Loss (simple RMSE, no physics involved): 0.240574\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.030355 - Val Loss (simple RMSE, no physics involved): 0.224640\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.028331 - Val Loss (simple RMSE, no physics involved): 0.219398\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.026716 - Val Loss (simple RMSE, no physics involved): 0.214198\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.025075 - Val Loss (simple RMSE, no physics involved): 0.209767\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.023742 - Val Loss (simple RMSE, no physics involved): 0.206498\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.022425 - Val Loss (simple RMSE, no physics involved): 0.200626\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.021476 - Val Loss (simple RMSE, no physics involved): 0.193730\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.020610 - Val Loss (simple RMSE, no physics involved): 0.191347\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.019842 - Val Loss (simple RMSE, no physics involved): 0.187205\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.019217 - Val Loss (simple RMSE, no physics involved): 0.181599\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.018607 - Val Loss (simple RMSE, no physics involved): 0.178933\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.018049 - Val Loss (simple RMSE, no physics involved): 0.175822\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.017555 - Val Loss (simple RMSE, no physics involved): 0.172129\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.017137 - Val Loss (simple RMSE, no physics involved): 0.169639\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.016761 - Val Loss (simple RMSE, no physics involved): 0.165324\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.016350 - Val Loss (simple RMSE, no physics involved): 0.164124\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.016120 - Val Loss (simple RMSE, no physics involved): 0.162262\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.015678 - Val Loss (simple RMSE, no physics involved): 0.158984\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.015522 - Val Loss (simple RMSE, no physics involved): 0.157212\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.015113 - Val Loss (simple RMSE, no physics involved): 0.156317\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.014913 - Val Loss (simple RMSE, no physics involved): 0.153685\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.014732 - Val Loss (simple RMSE, no physics involved): 0.151937\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.014493 - Val Loss (simple RMSE, no physics involved): 0.151041\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.014280 - Val Loss (simple RMSE, no physics involved): 0.148893\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.014133 - Val Loss (simple RMSE, no physics involved): 0.147622\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013933 - Val Loss (simple RMSE, no physics involved): 0.146601\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013878 - Val Loss (simple RMSE, no physics involved): 0.145330\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013700 - Val Loss (simple RMSE, no physics involved): 0.144221\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.013584 - Val Loss (simple RMSE, no physics involved): 0.143267\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013514 - Val Loss (simple RMSE, no physics involved): 0.142497\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.013393 - Val Loss (simple RMSE, no physics involved): 0.141427\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.013316 - Val Loss (simple RMSE, no physics involved): 0.140730\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013294 - Val Loss (simple RMSE, no physics involved): 0.140184\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.013141 - Val Loss (simple RMSE, no physics involved): 0.139505\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013095 - Val Loss (simple RMSE, no physics involved): 0.139109\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.013056 - Val Loss (simple RMSE, no physics involved): 0.138536\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012961 - Val Loss (simple RMSE, no physics involved): 0.138303\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012916 - Val Loss (simple RMSE, no physics involved): 0.137809\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012879 - Val Loss (simple RMSE, no physics involved): 0.137491\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012851 - Val Loss (simple RMSE, no physics involved): 0.137221\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012871 - Val Loss (simple RMSE, no physics involved): 0.136885\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012807 - Val Loss (simple RMSE, no physics involved): 0.136751\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012762 - Val Loss (simple RMSE, no physics involved): 0.136469\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012866 - Val Loss (simple RMSE, no physics involved): 0.136253\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012665 - Val Loss (simple RMSE, no physics involved): 0.135967\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:44:10,761] Trial 14 finished with value: 0.1359674111008644 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 177, 'lr': 5.827191773759865e-05, 'weight_decay': 7.434246273352563e-07, 'batch_size': 8}. Best is trial 10 with value: 0.13292881846427917.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012751 - Val Loss (simple RMSE, no physics involved): 0.135999\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.065361 - Val Loss (simple RMSE, no physics involved): 0.189326\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.034179 - Val Loss (simple RMSE, no physics involved): 0.220308\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.026297 - Val Loss (simple RMSE, no physics involved): 0.187546\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.021525 - Val Loss (simple RMSE, no physics involved): 0.158360\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.018055 - Val Loss (simple RMSE, no physics involved): 0.152754\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015411 - Val Loss (simple RMSE, no physics involved): 0.142212\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014391 - Val Loss (simple RMSE, no physics involved): 0.140852\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014212 - Val Loss (simple RMSE, no physics involved): 0.137296\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013155 - Val Loss (simple RMSE, no physics involved): 0.137313\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013000 - Val Loss (simple RMSE, no physics involved): 0.133589\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012914 - Val Loss (simple RMSE, no physics involved): 0.132991\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012684 - Val Loss (simple RMSE, no physics involved): 0.132795\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012417 - Val Loss (simple RMSE, no physics involved): 0.131529\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012884 - Val Loss (simple RMSE, no physics involved): 0.133136\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012356 - Val Loss (simple RMSE, no physics involved): 0.131997\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012257 - Val Loss (simple RMSE, no physics involved): 0.130452\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012620 - Val Loss (simple RMSE, no physics involved): 0.129883\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012318 - Val Loss (simple RMSE, no physics involved): 0.129871\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012182 - Val Loss (simple RMSE, no physics involved): 0.129885\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012004 - Val Loss (simple RMSE, no physics involved): 0.130497\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012315 - Val Loss (simple RMSE, no physics involved): 0.130701\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012374 - Val Loss (simple RMSE, no physics involved): 0.130565\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012006 - Val Loss (simple RMSE, no physics involved): 0.130991\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.011708 - Val Loss (simple RMSE, no physics involved): 0.131437\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011569 - Val Loss (simple RMSE, no physics involved): 0.131124\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011621 - Val Loss (simple RMSE, no physics involved): 0.131272\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011765 - Val Loss (simple RMSE, no physics involved): 0.130855\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011794 - Val Loss (simple RMSE, no physics involved): 0.131590\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011788 - Val Loss (simple RMSE, no physics involved): 0.131893\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011652 - Val Loss (simple RMSE, no physics involved): 0.131154\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011512 - Val Loss (simple RMSE, no physics involved): 0.133185\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011353 - Val Loss (simple RMSE, no physics involved): 0.135172\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011627 - Val Loss (simple RMSE, no physics involved): 0.137807\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011895 - Val Loss (simple RMSE, no physics involved): 0.134618\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011506 - Val Loss (simple RMSE, no physics involved): 0.132470\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011425 - Val Loss (simple RMSE, no physics involved): 0.133489\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011702 - Val Loss (simple RMSE, no physics involved): 0.131461\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011487 - Val Loss (simple RMSE, no physics involved): 0.132802\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011663 - Val Loss (simple RMSE, no physics involved): 0.133479\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011129 - Val Loss (simple RMSE, no physics involved): 0.135796\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011240 - Val Loss (simple RMSE, no physics involved): 0.135760\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011410 - Val Loss (simple RMSE, no physics involved): 0.134131\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011308 - Val Loss (simple RMSE, no physics involved): 0.135494\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.010877 - Val Loss (simple RMSE, no physics involved): 0.133515\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011753 - Val Loss (simple RMSE, no physics involved): 0.136293\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011772 - Val Loss (simple RMSE, no physics involved): 0.136867\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011449 - Val Loss (simple RMSE, no physics involved): 0.140730\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.010904 - Val Loss (simple RMSE, no physics involved): 0.137059\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012114 - Val Loss (simple RMSE, no physics involved): 0.135618\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:44:35,506] Trial 15 finished with value: 0.12987105175852776 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 224, 'lr': 0.000726421369199765, 'weight_decay': 2.4297340342993167e-06, 'batch_size': 16}. Best is trial 15 with value: 0.12987105175852776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011325 - Val Loss (simple RMSE, no physics involved): 0.136788\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.132380 - Val Loss (simple RMSE, no physics involved): 0.446882\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.122731 - Val Loss (simple RMSE, no physics involved): 0.424906\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.103399 - Val Loss (simple RMSE, no physics involved): 0.402762\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.089268 - Val Loss (simple RMSE, no physics involved): 0.380044\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.076920 - Val Loss (simple RMSE, no physics involved): 0.355068\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.066431 - Val Loss (simple RMSE, no physics involved): 0.327559\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.053731 - Val Loss (simple RMSE, no physics involved): 0.298104\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.042390 - Val Loss (simple RMSE, no physics involved): 0.268535\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.035251 - Val Loss (simple RMSE, no physics involved): 0.241203\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.029446 - Val Loss (simple RMSE, no physics involved): 0.219459\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.027694 - Val Loss (simple RMSE, no physics involved): 0.205497\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.027044 - Val Loss (simple RMSE, no physics involved): 0.200630\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.026540 - Val Loss (simple RMSE, no physics involved): 0.198156\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.026322 - Val Loss (simple RMSE, no physics involved): 0.199190\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.025784 - Val Loss (simple RMSE, no physics involved): 0.198586\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.025511 - Val Loss (simple RMSE, no physics involved): 0.196898\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.023777 - Val Loss (simple RMSE, no physics involved): 0.193091\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.023795 - Val Loss (simple RMSE, no physics involved): 0.190337\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.022420 - Val Loss (simple RMSE, no physics involved): 0.187090\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.021648 - Val Loss (simple RMSE, no physics involved): 0.183430\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.021746 - Val Loss (simple RMSE, no physics involved): 0.179414\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.020683 - Val Loss (simple RMSE, no physics involved): 0.176216\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.019757 - Val Loss (simple RMSE, no physics involved): 0.172662\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.018613 - Val Loss (simple RMSE, no physics involved): 0.169886\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.018202 - Val Loss (simple RMSE, no physics involved): 0.165766\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.018103 - Val Loss (simple RMSE, no physics involved): 0.164186\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.017341 - Val Loss (simple RMSE, no physics involved): 0.160228\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.016735 - Val Loss (simple RMSE, no physics involved): 0.155278\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.015766 - Val Loss (simple RMSE, no physics involved): 0.153644\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.015176 - Val Loss (simple RMSE, no physics involved): 0.151879\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.015385 - Val Loss (simple RMSE, no physics involved): 0.148671\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.015049 - Val Loss (simple RMSE, no physics involved): 0.146730\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.014417 - Val Loss (simple RMSE, no physics involved): 0.144451\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.014721 - Val Loss (simple RMSE, no physics involved): 0.143697\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.014570 - Val Loss (simple RMSE, no physics involved): 0.141867\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.014003 - Val Loss (simple RMSE, no physics involved): 0.140675\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013760 - Val Loss (simple RMSE, no physics involved): 0.140145\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.013775 - Val Loss (simple RMSE, no physics involved): 0.139210\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013403 - Val Loss (simple RMSE, no physics involved): 0.138486\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.013299 - Val Loss (simple RMSE, no physics involved): 0.138210\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.013591 - Val Loss (simple RMSE, no physics involved): 0.137450\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013220 - Val Loss (simple RMSE, no physics involved): 0.136996\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013305 - Val Loss (simple RMSE, no physics involved): 0.136656\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013030 - Val Loss (simple RMSE, no physics involved): 0.136395\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.013116 - Val Loss (simple RMSE, no physics involved): 0.136104\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.013162 - Val Loss (simple RMSE, no physics involved): 0.135846\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.013143 - Val Loss (simple RMSE, no physics involved): 0.135626\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.013290 - Val Loss (simple RMSE, no physics involved): 0.135378\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.013192 - Val Loss (simple RMSE, no physics involved): 0.135133\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:45:01,667] Trial 16 finished with value: 0.13511385768651962 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 236, 'lr': 4.354673684917861e-05, 'weight_decay': 6.050354234723067e-05, 'batch_size': 16}. Best is trial 15 with value: 0.12987105175852776.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012987 - Val Loss (simple RMSE, no physics involved): 0.135114\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.096709 - Val Loss (simple RMSE, no physics involved): 0.248401\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.035944 - Val Loss (simple RMSE, no physics involved): 0.204659\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.027619 - Val Loss (simple RMSE, no physics involved): 0.229819\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.026809 - Val Loss (simple RMSE, no physics involved): 0.178271\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.023287 - Val Loss (simple RMSE, no physics involved): 0.176794\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.020989 - Val Loss (simple RMSE, no physics involved): 0.155529\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.017879 - Val Loss (simple RMSE, no physics involved): 0.148768\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.016312 - Val Loss (simple RMSE, no physics involved): 0.153944\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014492 - Val Loss (simple RMSE, no physics involved): 0.138328\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013926 - Val Loss (simple RMSE, no physics involved): 0.140298\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013748 - Val Loss (simple RMSE, no physics involved): 0.134476\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013105 - Val Loss (simple RMSE, no physics involved): 0.132618\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013000 - Val Loss (simple RMSE, no physics involved): 0.132129\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012901 - Val Loss (simple RMSE, no physics involved): 0.131247\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013125 - Val Loss (simple RMSE, no physics involved): 0.131027\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012427 - Val Loss (simple RMSE, no physics involved): 0.131187\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013026 - Val Loss (simple RMSE, no physics involved): 0.130418\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012519 - Val Loss (simple RMSE, no physics involved): 0.129962\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012503 - Val Loss (simple RMSE, no physics involved): 0.129982\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012640 - Val Loss (simple RMSE, no physics involved): 0.129820\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012350 - Val Loss (simple RMSE, no physics involved): 0.131490\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012608 - Val Loss (simple RMSE, no physics involved): 0.129648\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.011984 - Val Loss (simple RMSE, no physics involved): 0.130009\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012617 - Val Loss (simple RMSE, no physics involved): 0.130142\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012283 - Val Loss (simple RMSE, no physics involved): 0.131017\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011999 - Val Loss (simple RMSE, no physics involved): 0.130309\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012455 - Val Loss (simple RMSE, no physics involved): 0.130197\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012411 - Val Loss (simple RMSE, no physics involved): 0.130121\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012314 - Val Loss (simple RMSE, no physics involved): 0.130628\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012623 - Val Loss (simple RMSE, no physics involved): 0.132442\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012118 - Val Loss (simple RMSE, no physics involved): 0.132765\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012228 - Val Loss (simple RMSE, no physics involved): 0.131775\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012070 - Val Loss (simple RMSE, no physics involved): 0.132294\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011983 - Val Loss (simple RMSE, no physics involved): 0.132605\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012061 - Val Loss (simple RMSE, no physics involved): 0.136976\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012364 - Val Loss (simple RMSE, no physics involved): 0.134475\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012286 - Val Loss (simple RMSE, no physics involved): 0.134616\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012152 - Val Loss (simple RMSE, no physics involved): 0.133811\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011723 - Val Loss (simple RMSE, no physics involved): 0.134564\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011930 - Val Loss (simple RMSE, no physics involved): 0.133065\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012461 - Val Loss (simple RMSE, no physics involved): 0.133895\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011801 - Val Loss (simple RMSE, no physics involved): 0.133697\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011673 - Val Loss (simple RMSE, no physics involved): 0.133452\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011706 - Val Loss (simple RMSE, no physics involved): 0.132743\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011587 - Val Loss (simple RMSE, no physics involved): 0.135017\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012121 - Val Loss (simple RMSE, no physics involved): 0.135711\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012575 - Val Loss (simple RMSE, no physics involved): 0.135179\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012130 - Val Loss (simple RMSE, no physics involved): 0.137535\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012402 - Val Loss (simple RMSE, no physics involved): 0.138628\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:45:33,383] Trial 17 finished with value: 0.12964755669236183 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 167, 'lr': 0.0009750757050264334, 'weight_decay': 2.9053102110337503e-06, 'batch_size': 16}. Best is trial 17 with value: 0.12964755669236183.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012257 - Val Loss (simple RMSE, no physics involved): 0.132445\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.126077 - Val Loss (simple RMSE, no physics involved): 0.284106\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.039764 - Val Loss (simple RMSE, no physics involved): 0.223818\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.033396 - Val Loss (simple RMSE, no physics involved): 0.235495\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.028198 - Val Loss (simple RMSE, no physics involved): 0.176373\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.023714 - Val Loss (simple RMSE, no physics involved): 0.207730\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.021898 - Val Loss (simple RMSE, no physics involved): 0.162044\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.018249 - Val Loss (simple RMSE, no physics involved): 0.161127\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.016368 - Val Loss (simple RMSE, no physics involved): 0.142781\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.015056 - Val Loss (simple RMSE, no physics involved): 0.140545\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014667 - Val Loss (simple RMSE, no physics involved): 0.136925\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014189 - Val Loss (simple RMSE, no physics involved): 0.137390\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013614 - Val Loss (simple RMSE, no physics involved): 0.134095\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013234 - Val Loss (simple RMSE, no physics involved): 0.134045\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013451 - Val Loss (simple RMSE, no physics involved): 0.132864\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013124 - Val Loss (simple RMSE, no physics involved): 0.132427\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012654 - Val Loss (simple RMSE, no physics involved): 0.131930\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012949 - Val Loss (simple RMSE, no physics involved): 0.132467\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013171 - Val Loss (simple RMSE, no physics involved): 0.131329\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012679 - Val Loss (simple RMSE, no physics involved): 0.131123\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012296 - Val Loss (simple RMSE, no physics involved): 0.130483\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012249 - Val Loss (simple RMSE, no physics involved): 0.138233\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013001 - Val Loss (simple RMSE, no physics involved): 0.130045\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012621 - Val Loss (simple RMSE, no physics involved): 0.130617\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012541 - Val Loss (simple RMSE, no physics involved): 0.129953\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012922 - Val Loss (simple RMSE, no physics involved): 0.128688\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012536 - Val Loss (simple RMSE, no physics involved): 0.129496\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012186 - Val Loss (simple RMSE, no physics involved): 0.129553\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012355 - Val Loss (simple RMSE, no physics involved): 0.129139\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012266 - Val Loss (simple RMSE, no physics involved): 0.129018\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012091 - Val Loss (simple RMSE, no physics involved): 0.129220\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011900 - Val Loss (simple RMSE, no physics involved): 0.131350\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012121 - Val Loss (simple RMSE, no physics involved): 0.128839\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012076 - Val Loss (simple RMSE, no physics involved): 0.137095\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012948 - Val Loss (simple RMSE, no physics involved): 0.132091\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012191 - Val Loss (simple RMSE, no physics involved): 0.131133\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012392 - Val Loss (simple RMSE, no physics involved): 0.129548\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012062 - Val Loss (simple RMSE, no physics involved): 0.129014\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012039 - Val Loss (simple RMSE, no physics involved): 0.131513\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012120 - Val Loss (simple RMSE, no physics involved): 0.130316\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012228 - Val Loss (simple RMSE, no physics involved): 0.129629\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012313 - Val Loss (simple RMSE, no physics involved): 0.129092\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012624 - Val Loss (simple RMSE, no physics involved): 0.129645\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012593 - Val Loss (simple RMSE, no physics involved): 0.128231\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012310 - Val Loss (simple RMSE, no physics involved): 0.131602\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012180 - Val Loss (simple RMSE, no physics involved): 0.131568\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012063 - Val Loss (simple RMSE, no physics involved): 0.129586\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012142 - Val Loss (simple RMSE, no physics involved): 0.131647\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012173 - Val Loss (simple RMSE, no physics involved): 0.130602\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012289 - Val Loss (simple RMSE, no physics involved): 0.131423\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:46:05,514] Trial 18 finished with value: 0.12823061645030975 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 167, 'lr': 0.0010718891119475718, 'weight_decay': 1.8657508806403555e-06, 'batch_size': 16}. Best is trial 18 with value: 0.12823061645030975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012012 - Val Loss (simple RMSE, no physics involved): 0.128308\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.068441 - Val Loss (simple RMSE, no physics involved): 0.214867\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.031051 - Val Loss (simple RMSE, no physics involved): 0.222019\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028817 - Val Loss (simple RMSE, no physics involved): 0.215852\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.026573 - Val Loss (simple RMSE, no physics involved): 0.187200\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.024330 - Val Loss (simple RMSE, no physics involved): 0.185520\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.021283 - Val Loss (simple RMSE, no physics involved): 0.166053\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.017192 - Val Loss (simple RMSE, no physics involved): 0.155959\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015877 - Val Loss (simple RMSE, no physics involved): 0.151788\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.015123 - Val Loss (simple RMSE, no physics involved): 0.146987\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013964 - Val Loss (simple RMSE, no physics involved): 0.146367\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013994 - Val Loss (simple RMSE, no physics involved): 0.141683\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013260 - Val Loss (simple RMSE, no physics involved): 0.135233\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013377 - Val Loss (simple RMSE, no physics involved): 0.131131\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012791 - Val Loss (simple RMSE, no physics involved): 0.131065\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012480 - Val Loss (simple RMSE, no physics involved): 0.131497\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013086 - Val Loss (simple RMSE, no physics involved): 0.131255\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013341 - Val Loss (simple RMSE, no physics involved): 0.133068\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012901 - Val Loss (simple RMSE, no physics involved): 0.131494\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012475 - Val Loss (simple RMSE, no physics involved): 0.130907\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012122 - Val Loss (simple RMSE, no physics involved): 0.131328\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012352 - Val Loss (simple RMSE, no physics involved): 0.130758\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012034 - Val Loss (simple RMSE, no physics involved): 0.130682\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012083 - Val Loss (simple RMSE, no physics involved): 0.133085\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013217 - Val Loss (simple RMSE, no physics involved): 0.132011\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012392 - Val Loss (simple RMSE, no physics involved): 0.134137\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012524 - Val Loss (simple RMSE, no physics involved): 0.133142\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012746 - Val Loss (simple RMSE, no physics involved): 0.133486\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012132 - Val Loss (simple RMSE, no physics involved): 0.132022\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012403 - Val Loss (simple RMSE, no physics involved): 0.132384\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012367 - Val Loss (simple RMSE, no physics involved): 0.130962\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011919 - Val Loss (simple RMSE, no physics involved): 0.131884\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012125 - Val Loss (simple RMSE, no physics involved): 0.132308\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011774 - Val Loss (simple RMSE, no physics involved): 0.131254\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012788 - Val Loss (simple RMSE, no physics involved): 0.132468\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012151 - Val Loss (simple RMSE, no physics involved): 0.131426\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011923 - Val Loss (simple RMSE, no physics involved): 0.130894\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012157 - Val Loss (simple RMSE, no physics involved): 0.130918\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011738 - Val Loss (simple RMSE, no physics involved): 0.132241\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012045 - Val Loss (simple RMSE, no physics involved): 0.133212\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011628 - Val Loss (simple RMSE, no physics involved): 0.131968\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012154 - Val Loss (simple RMSE, no physics involved): 0.131764\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011795 - Val Loss (simple RMSE, no physics involved): 0.132910\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012169 - Val Loss (simple RMSE, no physics involved): 0.135052\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011635 - Val Loss (simple RMSE, no physics involved): 0.130715\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011854 - Val Loss (simple RMSE, no physics involved): 0.131795\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011618 - Val Loss (simple RMSE, no physics involved): 0.138369\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011939 - Val Loss (simple RMSE, no physics involved): 0.137461\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011933 - Val Loss (simple RMSE, no physics involved): 0.133168\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011693 - Val Loss (simple RMSE, no physics involved): 0.132246\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:46:36,327] Trial 19 finished with value: 0.13068150356411934 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 156, 'lr': 0.00109301607409027, 'weight_decay': 2.9695779676828777e-07, 'batch_size': 16}. Best is trial 18 with value: 0.12823061645030975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011468 - Val Loss (simple RMSE, no physics involved): 0.131110\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.121658 - Val Loss (simple RMSE, no physics involved): 0.376704\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.052234 - Val Loss (simple RMSE, no physics involved): 0.188511\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.027034 - Val Loss (simple RMSE, no physics involved): 0.220633\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025265 - Val Loss (simple RMSE, no physics involved): 0.176789\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019461 - Val Loss (simple RMSE, no physics involved): 0.166265\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.017358 - Val Loss (simple RMSE, no physics involved): 0.157047\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.017333 - Val Loss (simple RMSE, no physics involved): 0.154828\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.017350 - Val Loss (simple RMSE, no physics involved): 0.145433\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014760 - Val Loss (simple RMSE, no physics involved): 0.140051\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013790 - Val Loss (simple RMSE, no physics involved): 0.137044\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013789 - Val Loss (simple RMSE, no physics involved): 0.133900\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013999 - Val Loss (simple RMSE, no physics involved): 0.136168\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013081 - Val Loss (simple RMSE, no physics involved): 0.136168\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013174 - Val Loss (simple RMSE, no physics involved): 0.136260\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013355 - Val Loss (simple RMSE, no physics involved): 0.133355\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012936 - Val Loss (simple RMSE, no physics involved): 0.133765\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012597 - Val Loss (simple RMSE, no physics involved): 0.133546\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013187 - Val Loss (simple RMSE, no physics involved): 0.132076\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012994 - Val Loss (simple RMSE, no physics involved): 0.132393\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013389 - Val Loss (simple RMSE, no physics involved): 0.131687\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012929 - Val Loss (simple RMSE, no physics involved): 0.130887\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012362 - Val Loss (simple RMSE, no physics involved): 0.130843\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012622 - Val Loss (simple RMSE, no physics involved): 0.132351\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012520 - Val Loss (simple RMSE, no physics involved): 0.131026\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012551 - Val Loss (simple RMSE, no physics involved): 0.131511\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012350 - Val Loss (simple RMSE, no physics involved): 0.135246\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013065 - Val Loss (simple RMSE, no physics involved): 0.131317\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012786 - Val Loss (simple RMSE, no physics involved): 0.131875\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012470 - Val Loss (simple RMSE, no physics involved): 0.132606\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012459 - Val Loss (simple RMSE, no physics involved): 0.138515\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012760 - Val Loss (simple RMSE, no physics involved): 0.139355\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013259 - Val Loss (simple RMSE, no physics involved): 0.159215\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.015728 - Val Loss (simple RMSE, no physics involved): 0.163393\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.015248 - Val Loss (simple RMSE, no physics involved): 0.149980\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.014256 - Val Loss (simple RMSE, no physics involved): 0.136775\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012899 - Val Loss (simple RMSE, no physics involved): 0.134828\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012146 - Val Loss (simple RMSE, no physics involved): 0.136611\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012529 - Val Loss (simple RMSE, no physics involved): 0.144206\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012453 - Val Loss (simple RMSE, no physics involved): 0.133547\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012442 - Val Loss (simple RMSE, no physics involved): 0.134248\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012967 - Val Loss (simple RMSE, no physics involved): 0.135120\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012639 - Val Loss (simple RMSE, no physics involved): 0.132790\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012261 - Val Loss (simple RMSE, no physics involved): 0.139569\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012448 - Val Loss (simple RMSE, no physics involved): 0.136946\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012009 - Val Loss (simple RMSE, no physics involved): 0.136833\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012067 - Val Loss (simple RMSE, no physics involved): 0.131730\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011738 - Val Loss (simple RMSE, no physics involved): 0.132565\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011799 - Val Loss (simple RMSE, no physics involved): 0.131742\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012370 - Val Loss (simple RMSE, no physics involved): 0.134017\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:46:58,845] Trial 20 finished with value: 0.13084281608462334 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 108, 'lr': 0.009522008239249367, 'weight_decay': 4.9483667624278e-05, 'batch_size': 16}. Best is trial 18 with value: 0.12823061645030975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012370 - Val Loss (simple RMSE, no physics involved): 0.131600\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.061077 - Val Loss (simple RMSE, no physics involved): 0.217789\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.032834 - Val Loss (simple RMSE, no physics involved): 0.204623\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028465 - Val Loss (simple RMSE, no physics involved): 0.231218\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.029081 - Val Loss (simple RMSE, no physics involved): 0.196037\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.026099 - Val Loss (simple RMSE, no physics involved): 0.180152\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.022048 - Val Loss (simple RMSE, no physics involved): 0.175502\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.018974 - Val Loss (simple RMSE, no physics involved): 0.145736\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015501 - Val Loss (simple RMSE, no physics involved): 0.144723\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.015975 - Val Loss (simple RMSE, no physics involved): 0.141720\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.015010 - Val Loss (simple RMSE, no physics involved): 0.144296\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014167 - Val Loss (simple RMSE, no physics involved): 0.136778\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014064 - Val Loss (simple RMSE, no physics involved): 0.140309\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013738 - Val Loss (simple RMSE, no physics involved): 0.134003\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013202 - Val Loss (simple RMSE, no physics involved): 0.136303\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013007 - Val Loss (simple RMSE, no physics involved): 0.135605\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013096 - Val Loss (simple RMSE, no physics involved): 0.132131\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012655 - Val Loss (simple RMSE, no physics involved): 0.132645\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012826 - Val Loss (simple RMSE, no physics involved): 0.132331\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012583 - Val Loss (simple RMSE, no physics involved): 0.134609\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012670 - Val Loss (simple RMSE, no physics involved): 0.132216\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012044 - Val Loss (simple RMSE, no physics involved): 0.133886\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012693 - Val Loss (simple RMSE, no physics involved): 0.131947\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012384 - Val Loss (simple RMSE, no physics involved): 0.133630\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012468 - Val Loss (simple RMSE, no physics involved): 0.132490\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012300 - Val Loss (simple RMSE, no physics involved): 0.132268\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012065 - Val Loss (simple RMSE, no physics involved): 0.131622\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012799 - Val Loss (simple RMSE, no physics involved): 0.135032\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012428 - Val Loss (simple RMSE, no physics involved): 0.131084\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012087 - Val Loss (simple RMSE, no physics involved): 0.135564\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012825 - Val Loss (simple RMSE, no physics involved): 0.131829\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012411 - Val Loss (simple RMSE, no physics involved): 0.134164\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012227 - Val Loss (simple RMSE, no physics involved): 0.135191\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011956 - Val Loss (simple RMSE, no physics involved): 0.133711\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011920 - Val Loss (simple RMSE, no physics involved): 0.134833\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012320 - Val Loss (simple RMSE, no physics involved): 0.132316\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012078 - Val Loss (simple RMSE, no physics involved): 0.134030\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011766 - Val Loss (simple RMSE, no physics involved): 0.133456\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012110 - Val Loss (simple RMSE, no physics involved): 0.132790\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012331 - Val Loss (simple RMSE, no physics involved): 0.136180\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011524 - Val Loss (simple RMSE, no physics involved): 0.135530\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012030 - Val Loss (simple RMSE, no physics involved): 0.136186\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011793 - Val Loss (simple RMSE, no physics involved): 0.134513\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012101 - Val Loss (simple RMSE, no physics involved): 0.135292\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011987 - Val Loss (simple RMSE, no physics involved): 0.133674\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011979 - Val Loss (simple RMSE, no physics involved): 0.133066\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011708 - Val Loss (simple RMSE, no physics involved): 0.135434\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012165 - Val Loss (simple RMSE, no physics involved): 0.134951\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012316 - Val Loss (simple RMSE, no physics involved): 0.132939\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011442 - Val Loss (simple RMSE, no physics involved): 0.133346\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:47:31,147] Trial 21 finished with value: 0.13108419254422188 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 179, 'lr': 0.0008756423349522832, 'weight_decay': 2.7440286191478734e-06, 'batch_size': 16}. Best is trial 18 with value: 0.12823061645030975.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011777 - Val Loss (simple RMSE, no physics involved): 0.137673\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.084784 - Val Loss (simple RMSE, no physics involved): 0.210054\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.031885 - Val Loss (simple RMSE, no physics involved): 0.208621\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.025739 - Val Loss (simple RMSE, no physics involved): 0.197453\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.023403 - Val Loss (simple RMSE, no physics involved): 0.178929\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019334 - Val Loss (simple RMSE, no physics involved): 0.161728\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.016158 - Val Loss (simple RMSE, no physics involved): 0.144153\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015378 - Val Loss (simple RMSE, no physics involved): 0.142265\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015670 - Val Loss (simple RMSE, no physics involved): 0.136010\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014450 - Val Loss (simple RMSE, no physics involved): 0.138956\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014213 - Val Loss (simple RMSE, no physics involved): 0.133040\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013177 - Val Loss (simple RMSE, no physics involved): 0.131759\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013061 - Val Loss (simple RMSE, no physics involved): 0.132035\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012994 - Val Loss (simple RMSE, no physics involved): 0.130490\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012869 - Val Loss (simple RMSE, no physics involved): 0.130400\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013100 - Val Loss (simple RMSE, no physics involved): 0.133347\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013781 - Val Loss (simple RMSE, no physics involved): 0.130446\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013873 - Val Loss (simple RMSE, no physics involved): 0.133003\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012393 - Val Loss (simple RMSE, no physics involved): 0.136618\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013159 - Val Loss (simple RMSE, no physics involved): 0.129530\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012479 - Val Loss (simple RMSE, no physics involved): 0.128746\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012437 - Val Loss (simple RMSE, no physics involved): 0.129113\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012430 - Val Loss (simple RMSE, no physics involved): 0.131504\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012223 - Val Loss (simple RMSE, no physics involved): 0.131119\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012817 - Val Loss (simple RMSE, no physics involved): 0.128567\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012533 - Val Loss (simple RMSE, no physics involved): 0.129344\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012303 - Val Loss (simple RMSE, no physics involved): 0.127764\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012786 - Val Loss (simple RMSE, no physics involved): 0.128446\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012872 - Val Loss (simple RMSE, no physics involved): 0.131450\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012423 - Val Loss (simple RMSE, no physics involved): 0.128082\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012581 - Val Loss (simple RMSE, no physics involved): 0.128302\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012910 - Val Loss (simple RMSE, no physics involved): 0.128179\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012235 - Val Loss (simple RMSE, no physics involved): 0.131134\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012663 - Val Loss (simple RMSE, no physics involved): 0.130042\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012057 - Val Loss (simple RMSE, no physics involved): 0.128619\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011736 - Val Loss (simple RMSE, no physics involved): 0.128298\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011623 - Val Loss (simple RMSE, no physics involved): 0.127521\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011747 - Val Loss (simple RMSE, no physics involved): 0.129357\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011961 - Val Loss (simple RMSE, no physics involved): 0.128401\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012020 - Val Loss (simple RMSE, no physics involved): 0.127761\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011608 - Val Loss (simple RMSE, no physics involved): 0.128585\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012718 - Val Loss (simple RMSE, no physics involved): 0.129646\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011801 - Val Loss (simple RMSE, no physics involved): 0.129096\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012048 - Val Loss (simple RMSE, no physics involved): 0.129094\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012370 - Val Loss (simple RMSE, no physics involved): 0.130076\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011676 - Val Loss (simple RMSE, no physics involved): 0.130430\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012027 - Val Loss (simple RMSE, no physics involved): 0.127402\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011910 - Val Loss (simple RMSE, no physics involved): 0.128228\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011584 - Val Loss (simple RMSE, no physics involved): 0.130567\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011721 - Val Loss (simple RMSE, no physics involved): 0.128156\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:48:02,704] Trial 22 finished with value: 0.12740245088934898 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 174, 'lr': 0.0008364469986651901, 'weight_decay': 2.32244353634307e-06, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011218 - Val Loss (simple RMSE, no physics involved): 0.130927\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.060176 - Val Loss (simple RMSE, no physics involved): 0.225647\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.028995 - Val Loss (simple RMSE, no physics involved): 0.176952\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.024900 - Val Loss (simple RMSE, no physics involved): 0.180710\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.019435 - Val Loss (simple RMSE, no physics involved): 0.149450\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.016193 - Val Loss (simple RMSE, no physics involved): 0.148470\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015512 - Val Loss (simple RMSE, no physics involved): 0.141670\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013516 - Val Loss (simple RMSE, no physics involved): 0.136256\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013041 - Val Loss (simple RMSE, no physics involved): 0.133220\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013307 - Val Loss (simple RMSE, no physics involved): 0.133149\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012809 - Val Loss (simple RMSE, no physics involved): 0.133161\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013079 - Val Loss (simple RMSE, no physics involved): 0.132276\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012628 - Val Loss (simple RMSE, no physics involved): 0.130329\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012558 - Val Loss (simple RMSE, no physics involved): 0.130942\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012322 - Val Loss (simple RMSE, no physics involved): 0.131445\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012995 - Val Loss (simple RMSE, no physics involved): 0.132100\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013075 - Val Loss (simple RMSE, no physics involved): 0.130733\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012462 - Val Loss (simple RMSE, no physics involved): 0.131660\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012523 - Val Loss (simple RMSE, no physics involved): 0.131319\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012847 - Val Loss (simple RMSE, no physics involved): 0.130687\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012121 - Val Loss (simple RMSE, no physics involved): 0.131043\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.011920 - Val Loss (simple RMSE, no physics involved): 0.130753\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012584 - Val Loss (simple RMSE, no physics involved): 0.133853\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012266 - Val Loss (simple RMSE, no physics involved): 0.138880\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012808 - Val Loss (simple RMSE, no physics involved): 0.133011\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012106 - Val Loss (simple RMSE, no physics involved): 0.130712\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011868 - Val Loss (simple RMSE, no physics involved): 0.132053\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012127 - Val Loss (simple RMSE, no physics involved): 0.135569\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011967 - Val Loss (simple RMSE, no physics involved): 0.135107\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012027 - Val Loss (simple RMSE, no physics involved): 0.132638\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011544 - Val Loss (simple RMSE, no physics involved): 0.135164\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011701 - Val Loss (simple RMSE, no physics involved): 0.132335\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011896 - Val Loss (simple RMSE, no physics involved): 0.132452\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011512 - Val Loss (simple RMSE, no physics involved): 0.132862\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011749 - Val Loss (simple RMSE, no physics involved): 0.132606\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011779 - Val Loss (simple RMSE, no physics involved): 0.135619\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011569 - Val Loss (simple RMSE, no physics involved): 0.135284\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011670 - Val Loss (simple RMSE, no physics involved): 0.133638\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011492 - Val Loss (simple RMSE, no physics involved): 0.133804\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011113 - Val Loss (simple RMSE, no physics involved): 0.136655\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011238 - Val Loss (simple RMSE, no physics involved): 0.136077\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011887 - Val Loss (simple RMSE, no physics involved): 0.139210\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011734 - Val Loss (simple RMSE, no physics involved): 0.140710\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011311 - Val Loss (simple RMSE, no physics involved): 0.135869\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011218 - Val Loss (simple RMSE, no physics involved): 0.135809\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011301 - Val Loss (simple RMSE, no physics involved): 0.143062\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011393 - Val Loss (simple RMSE, no physics involved): 0.138745\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011083 - Val Loss (simple RMSE, no physics involved): 0.136755\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011186 - Val Loss (simple RMSE, no physics involved): 0.136273\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011838 - Val Loss (simple RMSE, no physics involved): 0.135700\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:48:28,335] Trial 23 finished with value: 0.1303294226527214 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 170, 'lr': 0.00238860613732165, 'weight_decay': 5.597824843471828e-07, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011339 - Val Loss (simple RMSE, no physics involved): 0.136270\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.065981 - Val Loss (simple RMSE, no physics involved): 0.350796\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.063128 - Val Loss (simple RMSE, no physics involved): 0.342832\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.057808 - Val Loss (simple RMSE, no physics involved): 0.335098\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.056912 - Val Loss (simple RMSE, no physics involved): 0.327597\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.052054 - Val Loss (simple RMSE, no physics involved): 0.320264\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.050625 - Val Loss (simple RMSE, no physics involved): 0.312801\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.047823 - Val Loss (simple RMSE, no physics involved): 0.305172\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.045793 - Val Loss (simple RMSE, no physics involved): 0.297233\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.039940 - Val Loss (simple RMSE, no physics involved): 0.288901\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.038434 - Val Loss (simple RMSE, no physics involved): 0.280220\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.036675 - Val Loss (simple RMSE, no physics involved): 0.271118\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.035149 - Val Loss (simple RMSE, no physics involved): 0.261507\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.032779 - Val Loss (simple RMSE, no physics involved): 0.251429\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.029537 - Val Loss (simple RMSE, no physics involved): 0.241054\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.029749 - Val Loss (simple RMSE, no physics involved): 0.231266\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.028244 - Val Loss (simple RMSE, no physics involved): 0.222334\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.027742 - Val Loss (simple RMSE, no physics involved): 0.214897\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.027868 - Val Loss (simple RMSE, no physics involved): 0.209614\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.027541 - Val Loss (simple RMSE, no physics involved): 0.206689\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.028332 - Val Loss (simple RMSE, no physics involved): 0.205461\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.027701 - Val Loss (simple RMSE, no physics involved): 0.206117\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.027597 - Val Loss (simple RMSE, no physics involved): 0.207753\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.026870 - Val Loss (simple RMSE, no physics involved): 0.210272\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.025843 - Val Loss (simple RMSE, no physics involved): 0.212593\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.025721 - Val Loss (simple RMSE, no physics involved): 0.214724\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.026616 - Val Loss (simple RMSE, no physics involved): 0.216184\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.026450 - Val Loss (simple RMSE, no physics involved): 0.215832\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.026168 - Val Loss (simple RMSE, no physics involved): 0.214349\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.025235 - Val Loss (simple RMSE, no physics involved): 0.211616\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.024759 - Val Loss (simple RMSE, no physics involved): 0.208505\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.024861 - Val Loss (simple RMSE, no physics involved): 0.205176\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.024908 - Val Loss (simple RMSE, no physics involved): 0.201921\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.023138 - Val Loss (simple RMSE, no physics involved): 0.198854\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.023418 - Val Loss (simple RMSE, no physics involved): 0.196467\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.022478 - Val Loss (simple RMSE, no physics involved): 0.194539\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.022588 - Val Loss (simple RMSE, no physics involved): 0.192632\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.022680 - Val Loss (simple RMSE, no physics involved): 0.190780\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.020303 - Val Loss (simple RMSE, no physics involved): 0.188224\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.020459 - Val Loss (simple RMSE, no physics involved): 0.185914\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.020115 - Val Loss (simple RMSE, no physics involved): 0.182899\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.019816 - Val Loss (simple RMSE, no physics involved): 0.179588\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.019852 - Val Loss (simple RMSE, no physics involved): 0.175466\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.018660 - Val Loss (simple RMSE, no physics involved): 0.171098\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.018589 - Val Loss (simple RMSE, no physics involved): 0.167581\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.017834 - Val Loss (simple RMSE, no physics involved): 0.165313\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.017395 - Val Loss (simple RMSE, no physics involved): 0.163188\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.016758 - Val Loss (simple RMSE, no physics involved): 0.161635\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.016252 - Val Loss (simple RMSE, no physics involved): 0.159476\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.015775 - Val Loss (simple RMSE, no physics involved): 0.157091\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.015485 - Val Loss (simple RMSE, no physics involved): 0.155485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:48:37,507] Trial 24 finished with value: 0.15548484027385712 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 123, 'lr': 0.00019912525032537374, 'weight_decay': 5.29278373896761e-06, 'batch_size': 64}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.095269 - Val Loss (simple RMSE, no physics involved): 0.223844\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.034006 - Val Loss (simple RMSE, no physics involved): 0.226113\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028128 - Val Loss (simple RMSE, no physics involved): 0.203636\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025226 - Val Loss (simple RMSE, no physics involved): 0.176580\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.020520 - Val Loss (simple RMSE, no physics involved): 0.170472\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.017883 - Val Loss (simple RMSE, no physics involved): 0.141812\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015101 - Val Loss (simple RMSE, no physics involved): 0.136809\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014618 - Val Loss (simple RMSE, no physics involved): 0.136202\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013564 - Val Loss (simple RMSE, no physics involved): 0.135931\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013769 - Val Loss (simple RMSE, no physics involved): 0.134060\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013003 - Val Loss (simple RMSE, no physics involved): 0.132987\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012909 - Val Loss (simple RMSE, no physics involved): 0.131500\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012693 - Val Loss (simple RMSE, no physics involved): 0.132555\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013135 - Val Loss (simple RMSE, no physics involved): 0.131993\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012769 - Val Loss (simple RMSE, no physics involved): 0.133098\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012974 - Val Loss (simple RMSE, no physics involved): 0.135750\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013193 - Val Loss (simple RMSE, no physics involved): 0.138555\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013564 - Val Loss (simple RMSE, no physics involved): 0.130502\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013420 - Val Loss (simple RMSE, no physics involved): 0.131347\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012604 - Val Loss (simple RMSE, no physics involved): 0.135585\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013345 - Val Loss (simple RMSE, no physics involved): 0.131550\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012879 - Val Loss (simple RMSE, no physics involved): 0.131524\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012295 - Val Loss (simple RMSE, no physics involved): 0.131771\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012891 - Val Loss (simple RMSE, no physics involved): 0.133636\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012219 - Val Loss (simple RMSE, no physics involved): 0.130691\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012453 - Val Loss (simple RMSE, no physics involved): 0.131151\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012644 - Val Loss (simple RMSE, no physics involved): 0.130699\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012215 - Val Loss (simple RMSE, no physics involved): 0.131480\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012394 - Val Loss (simple RMSE, no physics involved): 0.130615\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012644 - Val Loss (simple RMSE, no physics involved): 0.130767\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012191 - Val Loss (simple RMSE, no physics involved): 0.131252\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012161 - Val Loss (simple RMSE, no physics involved): 0.130283\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011949 - Val Loss (simple RMSE, no physics involved): 0.132965\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012678 - Val Loss (simple RMSE, no physics involved): 0.133610\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012115 - Val Loss (simple RMSE, no physics involved): 0.131211\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012619 - Val Loss (simple RMSE, no physics involved): 0.133214\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011872 - Val Loss (simple RMSE, no physics involved): 0.133824\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012157 - Val Loss (simple RMSE, no physics involved): 0.130977\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011943 - Val Loss (simple RMSE, no physics involved): 0.131351\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012406 - Val Loss (simple RMSE, no physics involved): 0.136775\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012199 - Val Loss (simple RMSE, no physics involved): 0.138980\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012023 - Val Loss (simple RMSE, no physics involved): 0.137859\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012095 - Val Loss (simple RMSE, no physics involved): 0.136352\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012367 - Val Loss (simple RMSE, no physics involved): 0.132775\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012318 - Val Loss (simple RMSE, no physics involved): 0.132919\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011537 - Val Loss (simple RMSE, no physics involved): 0.133267\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011738 - Val Loss (simple RMSE, no physics involved): 0.134679\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012201 - Val Loss (simple RMSE, no physics involved): 0.132939\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011785 - Val Loss (simple RMSE, no physics involved): 0.133217\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:49:05,354] Trial 25 finished with value: 0.13028307259082794 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 162, 'lr': 0.0011890875372657069, 'weight_decay': 3.0742219867555516e-05, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011972 - Val Loss (simple RMSE, no physics involved): 0.137126\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.067577 - Val Loss (simple RMSE, no physics involved): 0.307247\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.041088 - Val Loss (simple RMSE, no physics involved): 0.229109\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029377 - Val Loss (simple RMSE, no physics involved): 0.190157\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.029474 - Val Loss (simple RMSE, no physics involved): 0.202848\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.026165 - Val Loss (simple RMSE, no physics involved): 0.205716\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.026307 - Val Loss (simple RMSE, no physics involved): 0.189865\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.023368 - Val Loss (simple RMSE, no physics involved): 0.175952\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.020451 - Val Loss (simple RMSE, no physics involved): 0.167216\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.017466 - Val Loss (simple RMSE, no physics involved): 0.153267\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.016398 - Val Loss (simple RMSE, no physics involved): 0.146312\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.015736 - Val Loss (simple RMSE, no physics involved): 0.140990\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.015084 - Val Loss (simple RMSE, no physics involved): 0.138571\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.014131 - Val Loss (simple RMSE, no physics involved): 0.135377\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013804 - Val Loss (simple RMSE, no physics involved): 0.134143\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013950 - Val Loss (simple RMSE, no physics involved): 0.133374\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013538 - Val Loss (simple RMSE, no physics involved): 0.132958\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013811 - Val Loss (simple RMSE, no physics involved): 0.131130\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013184 - Val Loss (simple RMSE, no physics involved): 0.131104\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013386 - Val Loss (simple RMSE, no physics involved): 0.130514\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013211 - Val Loss (simple RMSE, no physics involved): 0.133354\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012874 - Val Loss (simple RMSE, no physics involved): 0.131042\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013080 - Val Loss (simple RMSE, no physics involved): 0.129784\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012714 - Val Loss (simple RMSE, no physics involved): 0.129900\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012567 - Val Loss (simple RMSE, no physics involved): 0.129940\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013095 - Val Loss (simple RMSE, no physics involved): 0.129818\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012980 - Val Loss (simple RMSE, no physics involved): 0.129528\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012670 - Val Loss (simple RMSE, no physics involved): 0.129262\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012438 - Val Loss (simple RMSE, no physics involved): 0.129729\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012522 - Val Loss (simple RMSE, no physics involved): 0.129776\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012526 - Val Loss (simple RMSE, no physics involved): 0.129576\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012370 - Val Loss (simple RMSE, no physics involved): 0.129856\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012485 - Val Loss (simple RMSE, no physics involved): 0.129507\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012424 - Val Loss (simple RMSE, no physics involved): 0.129088\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012178 - Val Loss (simple RMSE, no physics involved): 0.129213\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012646 - Val Loss (simple RMSE, no physics involved): 0.132478\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012221 - Val Loss (simple RMSE, no physics involved): 0.129981\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012459 - Val Loss (simple RMSE, no physics involved): 0.130248\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012136 - Val Loss (simple RMSE, no physics involved): 0.130699\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011966 - Val Loss (simple RMSE, no physics involved): 0.131899\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012243 - Val Loss (simple RMSE, no physics involved): 0.129710\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012311 - Val Loss (simple RMSE, no physics involved): 0.129882\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011991 - Val Loss (simple RMSE, no physics involved): 0.132690\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012188 - Val Loss (simple RMSE, no physics involved): 0.131755\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012641 - Val Loss (simple RMSE, no physics involved): 0.129833\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012419 - Val Loss (simple RMSE, no physics involved): 0.129681\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012179 - Val Loss (simple RMSE, no physics involved): 0.129869\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011920 - Val Loss (simple RMSE, no physics involved): 0.135007\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012049 - Val Loss (simple RMSE, no physics involved): 0.130250\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011997 - Val Loss (simple RMSE, no physics involved): 0.129961\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:49:30,125] Trial 26 finished with value: 0.1290881559252739 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 196, 'lr': 0.00026372328284587036, 'weight_decay': 1.3643319247186788e-06, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012328 - Val Loss (simple RMSE, no physics involved): 0.130903\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.149551 - Val Loss (simple RMSE, no physics involved): 0.443917\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.103966 - Val Loss (simple RMSE, no physics involved): 0.375569\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.063867 - Val Loss (simple RMSE, no physics involved): 0.278609\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.032384 - Val Loss (simple RMSE, no physics involved): 0.187008\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.032408 - Val Loss (simple RMSE, no physics involved): 0.190236\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.026091 - Val Loss (simple RMSE, no physics involved): 0.211184\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.025629 - Val Loss (simple RMSE, no physics involved): 0.200355\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.022982 - Val Loss (simple RMSE, no physics involved): 0.177306\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.021738 - Val Loss (simple RMSE, no physics involved): 0.171397\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.020674 - Val Loss (simple RMSE, no physics involved): 0.171385\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.018423 - Val Loss (simple RMSE, no physics involved): 0.157533\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.016901 - Val Loss (simple RMSE, no physics involved): 0.151358\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.015856 - Val Loss (simple RMSE, no physics involved): 0.147411\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.014992 - Val Loss (simple RMSE, no physics involved): 0.143555\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.014688 - Val Loss (simple RMSE, no physics involved): 0.141554\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.014065 - Val Loss (simple RMSE, no physics involved): 0.139959\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.014213 - Val Loss (simple RMSE, no physics involved): 0.138929\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.014104 - Val Loss (simple RMSE, no physics involved): 0.137096\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013604 - Val Loss (simple RMSE, no physics involved): 0.137447\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013559 - Val Loss (simple RMSE, no physics involved): 0.135212\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013089 - Val Loss (simple RMSE, no physics involved): 0.135319\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013165 - Val Loss (simple RMSE, no physics involved): 0.134026\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012671 - Val Loss (simple RMSE, no physics involved): 0.134181\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013369 - Val Loss (simple RMSE, no physics involved): 0.133313\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012727 - Val Loss (simple RMSE, no physics involved): 0.132937\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012944 - Val Loss (simple RMSE, no physics involved): 0.134157\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013004 - Val Loss (simple RMSE, no physics involved): 0.132264\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012751 - Val Loss (simple RMSE, no physics involved): 0.133586\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012592 - Val Loss (simple RMSE, no physics involved): 0.132053\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013197 - Val Loss (simple RMSE, no physics involved): 0.132646\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012583 - Val Loss (simple RMSE, no physics involved): 0.132098\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012414 - Val Loss (simple RMSE, no physics involved): 0.131742\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012614 - Val Loss (simple RMSE, no physics involved): 0.132563\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012238 - Val Loss (simple RMSE, no physics involved): 0.131459\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012195 - Val Loss (simple RMSE, no physics involved): 0.131739\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012466 - Val Loss (simple RMSE, no physics involved): 0.133661\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012623 - Val Loss (simple RMSE, no physics involved): 0.131673\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012254 - Val Loss (simple RMSE, no physics involved): 0.134664\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012189 - Val Loss (simple RMSE, no physics involved): 0.131378\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012296 - Val Loss (simple RMSE, no physics involved): 0.132522\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012110 - Val Loss (simple RMSE, no physics involved): 0.132309\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012120 - Val Loss (simple RMSE, no physics involved): 0.132149\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012146 - Val Loss (simple RMSE, no physics involved): 0.131519\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012689 - Val Loss (simple RMSE, no physics involved): 0.133386\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012069 - Val Loss (simple RMSE, no physics involved): 0.131642\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012122 - Val Loss (simple RMSE, no physics involved): 0.133245\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011887 - Val Loss (simple RMSE, no physics involved): 0.133683\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011853 - Val Loss (simple RMSE, no physics involved): 0.131554\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011972 - Val Loss (simple RMSE, no physics involved): 0.131853\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:49:52,785] Trial 27 finished with value: 0.13137773424386978 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 192, 'lr': 0.00024621784367239536, 'weight_decay': 1.40495283443899e-07, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012187 - Val Loss (simple RMSE, no physics involved): 0.133644\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.104965 - Val Loss (simple RMSE, no physics involved): 0.402929\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.085210 - Val Loss (simple RMSE, no physics involved): 0.367552\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.066802 - Val Loss (simple RMSE, no physics involved): 0.330081\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.049261 - Val Loss (simple RMSE, no physics involved): 0.290207\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.036363 - Val Loss (simple RMSE, no physics involved): 0.248222\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.028028 - Val Loss (simple RMSE, no physics involved): 0.212535\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.029615 - Val Loss (simple RMSE, no physics involved): 0.198666\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.034250 - Val Loss (simple RMSE, no physics involved): 0.196578\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.031662 - Val Loss (simple RMSE, no physics involved): 0.199276\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.027626 - Val Loss (simple RMSE, no physics involved): 0.208052\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.025801 - Val Loss (simple RMSE, no physics involved): 0.219239\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.026881 - Val Loss (simple RMSE, no physics involved): 0.227532\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.025842 - Val Loss (simple RMSE, no physics involved): 0.229578\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.025681 - Val Loss (simple RMSE, no physics involved): 0.225764\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.025803 - Val Loss (simple RMSE, no physics involved): 0.217081\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.024778 - Val Loss (simple RMSE, no physics involved): 0.205685\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.022425 - Val Loss (simple RMSE, no physics involved): 0.193641\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.022205 - Val Loss (simple RMSE, no physics involved): 0.184452\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.021815 - Val Loss (simple RMSE, no physics involved): 0.178709\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.021565 - Val Loss (simple RMSE, no physics involved): 0.177175\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.020950 - Val Loss (simple RMSE, no physics involved): 0.178565\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.019344 - Val Loss (simple RMSE, no physics involved): 0.179535\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.018066 - Val Loss (simple RMSE, no physics involved): 0.177712\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.018744 - Val Loss (simple RMSE, no physics involved): 0.172487\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.017028 - Val Loss (simple RMSE, no physics involved): 0.163540\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.016978 - Val Loss (simple RMSE, no physics involved): 0.156887\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.016264 - Val Loss (simple RMSE, no physics involved): 0.153498\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.015662 - Val Loss (simple RMSE, no physics involved): 0.152056\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.015485 - Val Loss (simple RMSE, no physics involved): 0.152169\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.014835 - Val Loss (simple RMSE, no physics involved): 0.152003\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.014959 - Val Loss (simple RMSE, no physics involved): 0.149566\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.014904 - Val Loss (simple RMSE, no physics involved): 0.147485\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.014279 - Val Loss (simple RMSE, no physics involved): 0.146717\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013726 - Val Loss (simple RMSE, no physics involved): 0.145906\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.014096 - Val Loss (simple RMSE, no physics involved): 0.145783\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.013811 - Val Loss (simple RMSE, no physics involved): 0.144655\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013336 - Val Loss (simple RMSE, no physics involved): 0.144067\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.013873 - Val Loss (simple RMSE, no physics involved): 0.143635\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013265 - Val Loss (simple RMSE, no physics involved): 0.143404\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.013143 - Val Loss (simple RMSE, no physics involved): 0.143467\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.013662 - Val Loss (simple RMSE, no physics involved): 0.142802\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013476 - Val Loss (simple RMSE, no physics involved): 0.142571\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013268 - Val Loss (simple RMSE, no physics involved): 0.142343\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013109 - Val Loss (simple RMSE, no physics involved): 0.141922\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012893 - Val Loss (simple RMSE, no physics involved): 0.141877\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012848 - Val Loss (simple RMSE, no physics involved): 0.141445\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.013054 - Val Loss (simple RMSE, no physics involved): 0.141322\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012707 - Val Loss (simple RMSE, no physics involved): 0.141572\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012566 - Val Loss (simple RMSE, no physics involved): 0.141791\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:50:00,792] Trial 28 finished with value: 0.14122752845287323 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 134, 'lr': 0.0005756713205479646, 'weight_decay': 9.357138551247629e-07, 'batch_size': 64}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.013209 - Val Loss (simple RMSE, no physics involved): 0.141228\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.072456 - Val Loss (simple RMSE, no physics involved): 0.321120\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.044891 - Val Loss (simple RMSE, no physics involved): 0.252122\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.031522 - Val Loss (simple RMSE, no physics involved): 0.198158\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.029257 - Val Loss (simple RMSE, no physics involved): 0.191997\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.026915 - Val Loss (simple RMSE, no physics involved): 0.207502\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.025989 - Val Loss (simple RMSE, no physics involved): 0.205967\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.025257 - Val Loss (simple RMSE, no physics involved): 0.190377\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.023144 - Val Loss (simple RMSE, no physics involved): 0.177463\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.020347 - Val Loss (simple RMSE, no physics involved): 0.180888\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.018869 - Val Loss (simple RMSE, no physics involved): 0.165336\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.016494 - Val Loss (simple RMSE, no physics involved): 0.155242\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.015736 - Val Loss (simple RMSE, no physics involved): 0.148935\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.015064 - Val Loss (simple RMSE, no physics involved): 0.143305\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.014368 - Val Loss (simple RMSE, no physics involved): 0.141608\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.014241 - Val Loss (simple RMSE, no physics involved): 0.140105\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013767 - Val Loss (simple RMSE, no physics involved): 0.139046\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.014103 - Val Loss (simple RMSE, no physics involved): 0.137461\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013666 - Val Loss (simple RMSE, no physics involved): 0.136621\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013298 - Val Loss (simple RMSE, no physics involved): 0.136464\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012999 - Val Loss (simple RMSE, no physics involved): 0.135275\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012970 - Val Loss (simple RMSE, no physics involved): 0.135295\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013333 - Val Loss (simple RMSE, no physics involved): 0.133671\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012941 - Val Loss (simple RMSE, no physics involved): 0.133281\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012630 - Val Loss (simple RMSE, no physics involved): 0.133044\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012877 - Val Loss (simple RMSE, no physics involved): 0.132726\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012855 - Val Loss (simple RMSE, no physics involved): 0.132633\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012454 - Val Loss (simple RMSE, no physics involved): 0.132548\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012718 - Val Loss (simple RMSE, no physics involved): 0.131753\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012345 - Val Loss (simple RMSE, no physics involved): 0.132288\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012646 - Val Loss (simple RMSE, no physics involved): 0.131208\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012198 - Val Loss (simple RMSE, no physics involved): 0.132536\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012873 - Val Loss (simple RMSE, no physics involved): 0.131598\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012159 - Val Loss (simple RMSE, no physics involved): 0.132018\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012247 - Val Loss (simple RMSE, no physics involved): 0.131471\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012403 - Val Loss (simple RMSE, no physics involved): 0.131821\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012226 - Val Loss (simple RMSE, no physics involved): 0.132942\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012586 - Val Loss (simple RMSE, no physics involved): 0.131783\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012467 - Val Loss (simple RMSE, no physics involved): 0.133166\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012439 - Val Loss (simple RMSE, no physics involved): 0.131914\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012467 - Val Loss (simple RMSE, no physics involved): 0.130796\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012322 - Val Loss (simple RMSE, no physics involved): 0.131563\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012200 - Val Loss (simple RMSE, no physics involved): 0.131736\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012209 - Val Loss (simple RMSE, no physics involved): 0.131764\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012324 - Val Loss (simple RMSE, no physics involved): 0.133469\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012148 - Val Loss (simple RMSE, no physics involved): 0.131745\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011987 - Val Loss (simple RMSE, no physics involved): 0.132773\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012132 - Val Loss (simple RMSE, no physics involved): 0.133509\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012373 - Val Loss (simple RMSE, no physics involved): 0.134594\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012424 - Val Loss (simple RMSE, no physics involved): 0.133161\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:50:22,455] Trial 29 finished with value: 0.13079619407653809 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 150, 'lr': 0.00030606184989871276, 'weight_decay': 3.530813362670497e-07, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012686 - Val Loss (simple RMSE, no physics involved): 0.138964\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.104767 - Val Loss (simple RMSE, no physics involved): 0.392306\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.083386 - Val Loss (simple RMSE, no physics involved): 0.355806\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.063877 - Val Loss (simple RMSE, no physics involved): 0.314317\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.046412 - Val Loss (simple RMSE, no physics involved): 0.267411\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.032942 - Val Loss (simple RMSE, no physics involved): 0.219511\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.028813 - Val Loss (simple RMSE, no physics involved): 0.194052\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.028063 - Val Loss (simple RMSE, no physics involved): 0.193470\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.026008 - Val Loss (simple RMSE, no physics involved): 0.198391\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.025258 - Val Loss (simple RMSE, no physics involved): 0.199163\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.024402 - Val Loss (simple RMSE, no physics involved): 0.192750\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.022941 - Val Loss (simple RMSE, no physics involved): 0.181787\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.022204 - Val Loss (simple RMSE, no physics involved): 0.176670\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.020180 - Val Loss (simple RMSE, no physics involved): 0.171161\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.019060 - Val Loss (simple RMSE, no physics involved): 0.165661\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.017531 - Val Loss (simple RMSE, no physics involved): 0.157034\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.017105 - Val Loss (simple RMSE, no physics involved): 0.152868\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.015497 - Val Loss (simple RMSE, no physics involved): 0.149455\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.015563 - Val Loss (simple RMSE, no physics involved): 0.147461\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.014798 - Val Loss (simple RMSE, no physics involved): 0.144830\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.014428 - Val Loss (simple RMSE, no physics involved): 0.143065\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.014331 - Val Loss (simple RMSE, no physics involved): 0.141416\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.014180 - Val Loss (simple RMSE, no physics involved): 0.139828\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013498 - Val Loss (simple RMSE, no physics involved): 0.138523\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.014042 - Val Loss (simple RMSE, no physics involved): 0.136966\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013494 - Val Loss (simple RMSE, no physics involved): 0.135917\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013301 - Val Loss (simple RMSE, no physics involved): 0.134724\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013489 - Val Loss (simple RMSE, no physics involved): 0.133910\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013081 - Val Loss (simple RMSE, no physics involved): 0.133178\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013365 - Val Loss (simple RMSE, no physics involved): 0.132749\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013613 - Val Loss (simple RMSE, no physics involved): 0.132517\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012931 - Val Loss (simple RMSE, no physics involved): 0.131443\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012940 - Val Loss (simple RMSE, no physics involved): 0.131195\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012612 - Val Loss (simple RMSE, no physics involved): 0.131136\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012630 - Val Loss (simple RMSE, no physics involved): 0.130584\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012582 - Val Loss (simple RMSE, no physics involved): 0.130995\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012841 - Val Loss (simple RMSE, no physics involved): 0.130136\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012518 - Val Loss (simple RMSE, no physics involved): 0.131016\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012603 - Val Loss (simple RMSE, no physics involved): 0.129709\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012327 - Val Loss (simple RMSE, no physics involved): 0.129645\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012601 - Val Loss (simple RMSE, no physics involved): 0.129861\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012805 - Val Loss (simple RMSE, no physics involved): 0.129460\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012656 - Val Loss (simple RMSE, no physics involved): 0.129374\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012478 - Val Loss (simple RMSE, no physics involved): 0.129408\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012064 - Val Loss (simple RMSE, no physics involved): 0.129083\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012369 - Val Loss (simple RMSE, no physics involved): 0.129240\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012231 - Val Loss (simple RMSE, no physics involved): 0.128731\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012279 - Val Loss (simple RMSE, no physics involved): 0.131084\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012777 - Val Loss (simple RMSE, no physics involved): 0.129884\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012152 - Val Loss (simple RMSE, no physics involved): 0.131359\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:50:46,346] Trial 30 finished with value: 0.1287313848733902 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 206, 'lr': 0.00011806530726244462, 'weight_decay': 1.7712997673305546e-06, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012273 - Val Loss (simple RMSE, no physics involved): 0.129121\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.111838 - Val Loss (simple RMSE, no physics involved): 0.410769\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.096199 - Val Loss (simple RMSE, no physics involved): 0.385508\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.081758 - Val Loss (simple RMSE, no physics involved): 0.358293\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.066833 - Val Loss (simple RMSE, no physics involved): 0.323758\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.049572 - Val Loss (simple RMSE, no physics involved): 0.275339\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.033576 - Val Loss (simple RMSE, no physics involved): 0.220212\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.028163 - Val Loss (simple RMSE, no physics involved): 0.191752\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.028912 - Val Loss (simple RMSE, no physics involved): 0.193475\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.026864 - Val Loss (simple RMSE, no physics involved): 0.206582\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.025702 - Val Loss (simple RMSE, no physics involved): 0.204690\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.024631 - Val Loss (simple RMSE, no physics involved): 0.195449\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.023366 - Val Loss (simple RMSE, no physics involved): 0.187682\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.022446 - Val Loss (simple RMSE, no physics involved): 0.185269\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.021166 - Val Loss (simple RMSE, no physics involved): 0.182703\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.021227 - Val Loss (simple RMSE, no physics involved): 0.175569\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.019317 - Val Loss (simple RMSE, no physics involved): 0.167622\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.017757 - Val Loss (simple RMSE, no physics involved): 0.163068\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.016260 - Val Loss (simple RMSE, no physics involved): 0.155959\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.015168 - Val Loss (simple RMSE, no physics involved): 0.151971\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.015015 - Val Loss (simple RMSE, no physics involved): 0.148061\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.014692 - Val Loss (simple RMSE, no physics involved): 0.144032\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.014944 - Val Loss (simple RMSE, no physics involved): 0.142876\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013870 - Val Loss (simple RMSE, no physics involved): 0.140597\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013971 - Val Loss (simple RMSE, no physics involved): 0.140146\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013685 - Val Loss (simple RMSE, no physics involved): 0.138328\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013734 - Val Loss (simple RMSE, no physics involved): 0.137965\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013604 - Val Loss (simple RMSE, no physics involved): 0.136478\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013216 - Val Loss (simple RMSE, no physics involved): 0.136459\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013211 - Val Loss (simple RMSE, no physics involved): 0.134916\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013107 - Val Loss (simple RMSE, no physics involved): 0.135634\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013237 - Val Loss (simple RMSE, no physics involved): 0.133766\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012874 - Val Loss (simple RMSE, no physics involved): 0.135231\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.013487 - Val Loss (simple RMSE, no physics involved): 0.133062\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012927 - Val Loss (simple RMSE, no physics involved): 0.134139\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012816 - Val Loss (simple RMSE, no physics involved): 0.132438\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012664 - Val Loss (simple RMSE, no physics involved): 0.132473\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013299 - Val Loss (simple RMSE, no physics involved): 0.131983\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.013163 - Val Loss (simple RMSE, no physics involved): 0.131396\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012946 - Val Loss (simple RMSE, no physics involved): 0.132556\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012757 - Val Loss (simple RMSE, no physics involved): 0.131240\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012529 - Val Loss (simple RMSE, no physics involved): 0.132398\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013036 - Val Loss (simple RMSE, no physics involved): 0.131177\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012551 - Val Loss (simple RMSE, no physics involved): 0.132407\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012926 - Val Loss (simple RMSE, no physics involved): 0.130662\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.013007 - Val Loss (simple RMSE, no physics involved): 0.131672\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012971 - Val Loss (simple RMSE, no physics involved): 0.130533\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012370 - Val Loss (simple RMSE, no physics involved): 0.131866\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012618 - Val Loss (simple RMSE, no physics involved): 0.130262\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012848 - Val Loss (simple RMSE, no physics involved): 0.131417\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:51:10,780] Trial 31 finished with value: 0.13018960878252983 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 206, 'lr': 0.00011389563164908752, 'weight_decay': 1.4779201104365483e-06, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012724 - Val Loss (simple RMSE, no physics involved): 0.130190\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.089948 - Val Loss (simple RMSE, no physics involved): 0.386074\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.082718 - Val Loss (simple RMSE, no physics involved): 0.375510\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.081874 - Val Loss (simple RMSE, no physics involved): 0.364989\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.075311 - Val Loss (simple RMSE, no physics involved): 0.354416\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.067189 - Val Loss (simple RMSE, no physics involved): 0.343544\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.063739 - Val Loss (simple RMSE, no physics involved): 0.332467\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.060147 - Val Loss (simple RMSE, no physics involved): 0.320425\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.054689 - Val Loss (simple RMSE, no physics involved): 0.307452\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.048172 - Val Loss (simple RMSE, no physics involved): 0.293152\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.043865 - Val Loss (simple RMSE, no physics involved): 0.276941\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.036911 - Val Loss (simple RMSE, no physics involved): 0.259915\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.033555 - Val Loss (simple RMSE, no physics involved): 0.242370\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.030864 - Val Loss (simple RMSE, no physics involved): 0.226870\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.027967 - Val Loss (simple RMSE, no physics involved): 0.213642\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.027298 - Val Loss (simple RMSE, no physics involved): 0.204148\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.026181 - Val Loss (simple RMSE, no physics involved): 0.198240\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.026287 - Val Loss (simple RMSE, no physics involved): 0.197419\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.025796 - Val Loss (simple RMSE, no physics involved): 0.196445\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.024899 - Val Loss (simple RMSE, no physics involved): 0.195098\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.023647 - Val Loss (simple RMSE, no physics involved): 0.191491\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.022849 - Val Loss (simple RMSE, no physics involved): 0.188589\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.022152 - Val Loss (simple RMSE, no physics involved): 0.185153\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.020991 - Val Loss (simple RMSE, no physics involved): 0.182763\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.022061 - Val Loss (simple RMSE, no physics involved): 0.179244\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.020044 - Val Loss (simple RMSE, no physics involved): 0.172819\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.019001 - Val Loss (simple RMSE, no physics involved): 0.169344\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.018208 - Val Loss (simple RMSE, no physics involved): 0.165791\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.017403 - Val Loss (simple RMSE, no physics involved): 0.161784\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.016788 - Val Loss (simple RMSE, no physics involved): 0.158031\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.016270 - Val Loss (simple RMSE, no physics involved): 0.154661\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.016083 - Val Loss (simple RMSE, no physics involved): 0.152414\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.015441 - Val Loss (simple RMSE, no physics involved): 0.150114\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.015309 - Val Loss (simple RMSE, no physics involved): 0.147900\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.015175 - Val Loss (simple RMSE, no physics involved): 0.146238\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.014620 - Val Loss (simple RMSE, no physics involved): 0.145086\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.014920 - Val Loss (simple RMSE, no physics involved): 0.144247\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.015190 - Val Loss (simple RMSE, no physics involved): 0.143239\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.014807 - Val Loss (simple RMSE, no physics involved): 0.142663\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.014591 - Val Loss (simple RMSE, no physics involved): 0.141820\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.014614 - Val Loss (simple RMSE, no physics involved): 0.141399\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.013979 - Val Loss (simple RMSE, no physics involved): 0.141260\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013864 - Val Loss (simple RMSE, no physics involved): 0.140123\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013975 - Val Loss (simple RMSE, no physics involved): 0.139773\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013742 - Val Loss (simple RMSE, no physics involved): 0.140200\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.014203 - Val Loss (simple RMSE, no physics involved): 0.139292\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.013924 - Val Loss (simple RMSE, no physics involved): 0.138737\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.013797 - Val Loss (simple RMSE, no physics involved): 0.139249\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.013785 - Val Loss (simple RMSE, no physics involved): 0.138313\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.014011 - Val Loss (simple RMSE, no physics involved): 0.138447\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:51:33,144] Trial 32 finished with value: 0.13831250369548798 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 183, 'lr': 4.67408733994052e-05, 'weight_decay': 4.525938219531061e-06, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.013160 - Val Loss (simple RMSE, no physics involved): 0.138393\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.149194 - Val Loss (simple RMSE, no physics involved): 0.463060\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.125464 - Val Loss (simple RMSE, no physics involved): 0.431031\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.104378 - Val Loss (simple RMSE, no physics involved): 0.390273\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.077513 - Val Loss (simple RMSE, no physics involved): 0.330215\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.045448 - Val Loss (simple RMSE, no physics involved): 0.236956\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.031764 - Val Loss (simple RMSE, no physics involved): 0.189907\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.030239 - Val Loss (simple RMSE, no physics involved): 0.199742\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.025813 - Val Loss (simple RMSE, no physics involved): 0.212606\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.026286 - Val Loss (simple RMSE, no physics involved): 0.200556\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.023712 - Val Loss (simple RMSE, no physics involved): 0.179181\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.022009 - Val Loss (simple RMSE, no physics involved): 0.177973\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.020133 - Val Loss (simple RMSE, no physics involved): 0.176507\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.018587 - Val Loss (simple RMSE, no physics involved): 0.162926\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.017339 - Val Loss (simple RMSE, no physics involved): 0.155420\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.015717 - Val Loss (simple RMSE, no physics involved): 0.151155\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.014962 - Val Loss (simple RMSE, no physics involved): 0.147417\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.014927 - Val Loss (simple RMSE, no physics involved): 0.145617\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.014555 - Val Loss (simple RMSE, no physics involved): 0.144456\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.014865 - Val Loss (simple RMSE, no physics involved): 0.142808\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.014646 - Val Loss (simple RMSE, no physics involved): 0.142078\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013649 - Val Loss (simple RMSE, no physics involved): 0.141164\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013890 - Val Loss (simple RMSE, no physics involved): 0.140631\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013489 - Val Loss (simple RMSE, no physics involved): 0.139111\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013221 - Val Loss (simple RMSE, no physics involved): 0.138615\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013194 - Val Loss (simple RMSE, no physics involved): 0.137580\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013276 - Val Loss (simple RMSE, no physics involved): 0.137423\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013264 - Val Loss (simple RMSE, no physics involved): 0.136512\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013000 - Val Loss (simple RMSE, no physics involved): 0.136335\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013329 - Val Loss (simple RMSE, no physics involved): 0.135405\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013125 - Val Loss (simple RMSE, no physics involved): 0.135606\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013065 - Val Loss (simple RMSE, no physics involved): 0.134745\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012951 - Val Loss (simple RMSE, no physics involved): 0.135147\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012832 - Val Loss (simple RMSE, no physics involved): 0.134197\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012990 - Val Loss (simple RMSE, no physics involved): 0.134669\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012989 - Val Loss (simple RMSE, no physics involved): 0.133703\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012588 - Val Loss (simple RMSE, no physics involved): 0.133532\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012624 - Val Loss (simple RMSE, no physics involved): 0.133450\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012560 - Val Loss (simple RMSE, no physics involved): 0.133237\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013076 - Val Loss (simple RMSE, no physics involved): 0.132955\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012360 - Val Loss (simple RMSE, no physics involved): 0.132678\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012633 - Val Loss (simple RMSE, no physics involved): 0.133057\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012534 - Val Loss (simple RMSE, no physics involved): 0.132973\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012545 - Val Loss (simple RMSE, no physics involved): 0.133487\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012920 - Val Loss (simple RMSE, no physics involved): 0.133657\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012242 - Val Loss (simple RMSE, no physics involved): 0.133012\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012597 - Val Loss (simple RMSE, no physics involved): 0.132863\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012495 - Val Loss (simple RMSE, no physics involved): 0.132760\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012699 - Val Loss (simple RMSE, no physics involved): 0.133041\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012299 - Val Loss (simple RMSE, no physics involved): 0.132828\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:52:02,263] Trial 33 finished with value: 0.13267828151583672 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 217, 'lr': 0.00014782242514283734, 'weight_decay': 2.2618288013261927e-06, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012341 - Val Loss (simple RMSE, no physics involved): 0.133402\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.108573 - Val Loss (simple RMSE, no physics involved): 0.410450\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.095076 - Val Loss (simple RMSE, no physics involved): 0.388968\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.085436 - Val Loss (simple RMSE, no physics involved): 0.365964\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.072769 - Val Loss (simple RMSE, no physics involved): 0.340443\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.060338 - Val Loss (simple RMSE, no physics involved): 0.311727\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.049522 - Val Loss (simple RMSE, no physics involved): 0.280217\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.036897 - Val Loss (simple RMSE, no physics involved): 0.248456\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.030027 - Val Loss (simple RMSE, no physics involved): 0.221881\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.027666 - Val Loss (simple RMSE, no physics involved): 0.203063\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.026407 - Val Loss (simple RMSE, no physics involved): 0.195541\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.025545 - Val Loss (simple RMSE, no physics involved): 0.193504\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.025499 - Val Loss (simple RMSE, no physics involved): 0.193103\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.023922 - Val Loss (simple RMSE, no physics involved): 0.190316\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.023118 - Val Loss (simple RMSE, no physics involved): 0.189399\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.022635 - Val Loss (simple RMSE, no physics involved): 0.183712\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.021440 - Val Loss (simple RMSE, no physics involved): 0.178572\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.020296 - Val Loss (simple RMSE, no physics involved): 0.172441\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.018768 - Val Loss (simple RMSE, no physics involved): 0.165689\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.017717 - Val Loss (simple RMSE, no physics involved): 0.162585\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.016964 - Val Loss (simple RMSE, no physics involved): 0.157399\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.016147 - Val Loss (simple RMSE, no physics involved): 0.152507\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.015647 - Val Loss (simple RMSE, no physics involved): 0.148918\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.015866 - Val Loss (simple RMSE, no physics involved): 0.146680\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.014985 - Val Loss (simple RMSE, no physics involved): 0.144642\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.014489 - Val Loss (simple RMSE, no physics involved): 0.142983\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.015036 - Val Loss (simple RMSE, no physics involved): 0.141507\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.014132 - Val Loss (simple RMSE, no physics involved): 0.140380\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013893 - Val Loss (simple RMSE, no physics involved): 0.139315\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013674 - Val Loss (simple RMSE, no physics involved): 0.138773\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013570 - Val Loss (simple RMSE, no physics involved): 0.137699\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.014059 - Val Loss (simple RMSE, no physics involved): 0.137204\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013940 - Val Loss (simple RMSE, no physics involved): 0.136211\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.013998 - Val Loss (simple RMSE, no physics involved): 0.135733\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013671 - Val Loss (simple RMSE, no physics involved): 0.135212\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.013782 - Val Loss (simple RMSE, no physics involved): 0.134533\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.013322 - Val Loss (simple RMSE, no physics involved): 0.134430\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013194 - Val Loss (simple RMSE, no physics involved): 0.133717\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.013655 - Val Loss (simple RMSE, no physics involved): 0.133349\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013494 - Val Loss (simple RMSE, no physics involved): 0.133024\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.013412 - Val Loss (simple RMSE, no physics involved): 0.133045\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012974 - Val Loss (simple RMSE, no physics involved): 0.132444\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013101 - Val Loss (simple RMSE, no physics involved): 0.132181\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013313 - Val Loss (simple RMSE, no physics involved): 0.132045\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013182 - Val Loss (simple RMSE, no physics involved): 0.132039\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012853 - Val Loss (simple RMSE, no physics involved): 0.132010\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012723 - Val Loss (simple RMSE, no physics involved): 0.131920\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012985 - Val Loss (simple RMSE, no physics involved): 0.131942\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012714 - Val Loss (simple RMSE, no physics involved): 0.131650\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.013026 - Val Loss (simple RMSE, no physics involved): 0.131551\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:52:22,222] Trial 34 finished with value: 0.13132233545184135 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 203, 'lr': 6.943623528263012e-05, 'weight_decay': 1.7960703144412264e-05, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012851 - Val Loss (simple RMSE, no physics involved): 0.131322\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.110480 - Val Loss (simple RMSE, no physics involved): 0.419987\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.106938 - Val Loss (simple RMSE, no physics involved): 0.412680\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.101588 - Val Loss (simple RMSE, no physics involved): 0.405774\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.095736 - Val Loss (simple RMSE, no physics involved): 0.399083\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.093008 - Val Loss (simple RMSE, no physics involved): 0.392364\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.089174 - Val Loss (simple RMSE, no physics involved): 0.385285\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.084958 - Val Loss (simple RMSE, no physics involved): 0.377801\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.079370 - Val Loss (simple RMSE, no physics involved): 0.370089\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.075791 - Val Loss (simple RMSE, no physics involved): 0.362209\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.071122 - Val Loss (simple RMSE, no physics involved): 0.354338\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.070613 - Val Loss (simple RMSE, no physics involved): 0.346320\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.065354 - Val Loss (simple RMSE, no physics involved): 0.338006\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.063115 - Val Loss (simple RMSE, no physics involved): 0.329350\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.056678 - Val Loss (simple RMSE, no physics involved): 0.319937\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.052714 - Val Loss (simple RMSE, no physics involved): 0.309531\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.047282 - Val Loss (simple RMSE, no physics involved): 0.297275\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.043892 - Val Loss (simple RMSE, no physics involved): 0.284104\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.040707 - Val Loss (simple RMSE, no physics involved): 0.270410\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.036496 - Val Loss (simple RMSE, no physics involved): 0.256017\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.031866 - Val Loss (simple RMSE, no physics involved): 0.241915\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.029784 - Val Loss (simple RMSE, no physics involved): 0.228602\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.028501 - Val Loss (simple RMSE, no physics involved): 0.218230\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.026277 - Val Loss (simple RMSE, no physics involved): 0.210742\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.026353 - Val Loss (simple RMSE, no physics involved): 0.205593\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.026652 - Val Loss (simple RMSE, no physics involved): 0.201880\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.026671 - Val Loss (simple RMSE, no physics involved): 0.200080\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.025947 - Val Loss (simple RMSE, no physics involved): 0.198754\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.025623 - Val Loss (simple RMSE, no physics involved): 0.197925\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.024628 - Val Loss (simple RMSE, no physics involved): 0.196134\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.024380 - Val Loss (simple RMSE, no physics involved): 0.194567\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.024627 - Val Loss (simple RMSE, no physics involved): 0.193359\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.023232 - Val Loss (simple RMSE, no physics involved): 0.191570\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.023193 - Val Loss (simple RMSE, no physics involved): 0.189832\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.023741 - Val Loss (simple RMSE, no physics involved): 0.187214\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.021427 - Val Loss (simple RMSE, no physics involved): 0.185100\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.021922 - Val Loss (simple RMSE, no physics involved): 0.183859\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.021666 - Val Loss (simple RMSE, no physics involved): 0.182125\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.020976 - Val Loss (simple RMSE, no physics involved): 0.178895\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.020090 - Val Loss (simple RMSE, no physics involved): 0.176105\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.020288 - Val Loss (simple RMSE, no physics involved): 0.174368\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.019607 - Val Loss (simple RMSE, no physics involved): 0.171070\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.018694 - Val Loss (simple RMSE, no physics involved): 0.167588\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.018431 - Val Loss (simple RMSE, no physics involved): 0.165614\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.018149 - Val Loss (simple RMSE, no physics involved): 0.164963\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.017533 - Val Loss (simple RMSE, no physics involved): 0.161203\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.016626 - Val Loss (simple RMSE, no physics involved): 0.158354\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.017086 - Val Loss (simple RMSE, no physics involved): 0.156235\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.016619 - Val Loss (simple RMSE, no physics involved): 0.154670\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.015918 - Val Loss (simple RMSE, no physics involved): 0.152318\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:52:47,214] Trial 35 finished with value: 0.15092537552118301 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 223, 'lr': 2.5379403088224673e-05, 'weight_decay': 6.390283688821347e-07, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.016820 - Val Loss (simple RMSE, no physics involved): 0.150925\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.118872 - Val Loss (simple RMSE, no physics involved): 0.376120\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.063848 - Val Loss (simple RMSE, no physics involved): 0.251454\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.035274 - Val Loss (simple RMSE, no physics involved): 0.200308\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.036744 - Val Loss (simple RMSE, no physics involved): 0.218012\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.028057 - Val Loss (simple RMSE, no physics involved): 0.249630\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.030211 - Val Loss (simple RMSE, no physics involved): 0.252132\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.030991 - Val Loss (simple RMSE, no physics involved): 0.236309\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.027196 - Val Loss (simple RMSE, no physics involved): 0.210374\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.025885 - Val Loss (simple RMSE, no physics involved): 0.189909\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.026366 - Val Loss (simple RMSE, no physics involved): 0.183833\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.025094 - Val Loss (simple RMSE, no physics involved): 0.188821\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.022610 - Val Loss (simple RMSE, no physics involved): 0.194333\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.022547 - Val Loss (simple RMSE, no physics involved): 0.187330\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.020996 - Val Loss (simple RMSE, no physics involved): 0.167202\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.019062 - Val Loss (simple RMSE, no physics involved): 0.156566\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.018128 - Val Loss (simple RMSE, no physics involved): 0.153794\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.016939 - Val Loss (simple RMSE, no physics involved): 0.156678\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.016732 - Val Loss (simple RMSE, no physics involved): 0.151503\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.015562 - Val Loss (simple RMSE, no physics involved): 0.154651\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.015368 - Val Loss (simple RMSE, no physics involved): 0.148500\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.014390 - Val Loss (simple RMSE, no physics involved): 0.146740\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.014104 - Val Loss (simple RMSE, no physics involved): 0.145043\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013917 - Val Loss (simple RMSE, no physics involved): 0.144163\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013714 - Val Loss (simple RMSE, no physics involved): 0.144553\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013792 - Val Loss (simple RMSE, no physics involved): 0.142829\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013195 - Val Loss (simple RMSE, no physics involved): 0.142232\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013030 - Val Loss (simple RMSE, no physics involved): 0.141863\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012891 - Val Loss (simple RMSE, no physics involved): 0.141854\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013390 - Val Loss (simple RMSE, no physics involved): 0.141649\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013074 - Val Loss (simple RMSE, no physics involved): 0.141873\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013037 - Val Loss (simple RMSE, no physics involved): 0.140616\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012831 - Val Loss (simple RMSE, no physics involved): 0.142645\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012584 - Val Loss (simple RMSE, no physics involved): 0.140552\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012913 - Val Loss (simple RMSE, no physics involved): 0.140826\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012503 - Val Loss (simple RMSE, no physics involved): 0.139863\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012626 - Val Loss (simple RMSE, no physics involved): 0.140609\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012327 - Val Loss (simple RMSE, no physics involved): 0.139750\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012085 - Val Loss (simple RMSE, no physics involved): 0.139203\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012455 - Val Loss (simple RMSE, no physics involved): 0.140962\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012198 - Val Loss (simple RMSE, no physics involved): 0.139343\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012416 - Val Loss (simple RMSE, no physics involved): 0.141230\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012384 - Val Loss (simple RMSE, no physics involved): 0.140681\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012454 - Val Loss (simple RMSE, no physics involved): 0.140062\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012020 - Val Loss (simple RMSE, no physics involved): 0.141195\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012226 - Val Loss (simple RMSE, no physics involved): 0.140813\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012209 - Val Loss (simple RMSE, no physics involved): 0.141356\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011790 - Val Loss (simple RMSE, no physics involved): 0.140651\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011958 - Val Loss (simple RMSE, no physics involved): 0.141482\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012005 - Val Loss (simple RMSE, no physics involved): 0.141078\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:52:58,784] Trial 36 finished with value: 0.13920292258262634 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 188, 'lr': 0.0015740177908455544, 'weight_decay': 1.222774883672225e-07, 'batch_size': 64}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011750 - Val Loss (simple RMSE, no physics involved): 0.140551\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.085706 - Val Loss (simple RMSE, no physics involved): 0.360241\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.065721 - Val Loss (simple RMSE, no physics involved): 0.318940\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.047125 - Val Loss (simple RMSE, no physics involved): 0.265694\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.032717 - Val Loss (simple RMSE, no physics involved): 0.210434\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.030133 - Val Loss (simple RMSE, no physics involved): 0.197220\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.028454 - Val Loss (simple RMSE, no physics involved): 0.209609\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.027516 - Val Loss (simple RMSE, no physics involved): 0.212644\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.026596 - Val Loss (simple RMSE, no physics involved): 0.200842\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.025489 - Val Loss (simple RMSE, no physics involved): 0.193414\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.023416 - Val Loss (simple RMSE, no physics involved): 0.187651\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.022431 - Val Loss (simple RMSE, no physics involved): 0.182487\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.020268 - Val Loss (simple RMSE, no physics involved): 0.169675\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.018331 - Val Loss (simple RMSE, no physics involved): 0.155032\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.016251 - Val Loss (simple RMSE, no physics involved): 0.146700\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.015035 - Val Loss (simple RMSE, no physics involved): 0.138862\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.014455 - Val Loss (simple RMSE, no physics involved): 0.136170\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013745 - Val Loss (simple RMSE, no physics involved): 0.137073\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013685 - Val Loss (simple RMSE, no physics involved): 0.134418\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013912 - Val Loss (simple RMSE, no physics involved): 0.136675\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013390 - Val Loss (simple RMSE, no physics involved): 0.132844\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013215 - Val Loss (simple RMSE, no physics involved): 0.132381\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013100 - Val Loss (simple RMSE, no physics involved): 0.131793\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013075 - Val Loss (simple RMSE, no physics involved): 0.131834\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012910 - Val Loss (simple RMSE, no physics involved): 0.131892\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012741 - Val Loss (simple RMSE, no physics involved): 0.131834\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012790 - Val Loss (simple RMSE, no physics involved): 0.131481\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012950 - Val Loss (simple RMSE, no physics involved): 0.132465\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012567 - Val Loss (simple RMSE, no physics involved): 0.131291\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013011 - Val Loss (simple RMSE, no physics involved): 0.131953\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012524 - Val Loss (simple RMSE, no physics involved): 0.130927\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012877 - Val Loss (simple RMSE, no physics involved): 0.130667\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012652 - Val Loss (simple RMSE, no physics involved): 0.131944\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012610 - Val Loss (simple RMSE, no physics involved): 0.130470\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012842 - Val Loss (simple RMSE, no physics involved): 0.131029\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012483 - Val Loss (simple RMSE, no physics involved): 0.131426\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012678 - Val Loss (simple RMSE, no physics involved): 0.130326\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012678 - Val Loss (simple RMSE, no physics involved): 0.132357\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012761 - Val Loss (simple RMSE, no physics involved): 0.130300\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012208 - Val Loss (simple RMSE, no physics involved): 0.130582\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012365 - Val Loss (simple RMSE, no physics involved): 0.130980\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012923 - Val Loss (simple RMSE, no physics involved): 0.133405\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012791 - Val Loss (simple RMSE, no physics involved): 0.130546\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013033 - Val Loss (simple RMSE, no physics involved): 0.130860\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012538 - Val Loss (simple RMSE, no physics involved): 0.132607\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012649 - Val Loss (simple RMSE, no physics involved): 0.130630\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012481 - Val Loss (simple RMSE, no physics involved): 0.130405\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012310 - Val Loss (simple RMSE, no physics involved): 0.131053\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012238 - Val Loss (simple RMSE, no physics involved): 0.130467\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011990 - Val Loss (simple RMSE, no physics involved): 0.131736\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:53:19,960] Trial 37 finished with value: 0.130300372838974 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 146, 'lr': 0.000260064912476376, 'weight_decay': 0.00015235438549578454, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012284 - Val Loss (simple RMSE, no physics involved): 0.130830\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.054174 - Val Loss (simple RMSE, no physics involved): 0.266184\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.030603 - Val Loss (simple RMSE, no physics involved): 0.197266\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.030286 - Val Loss (simple RMSE, no physics involved): 0.204610\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.026939 - Val Loss (simple RMSE, no physics involved): 0.213439\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.025858 - Val Loss (simple RMSE, no physics involved): 0.197446\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.024000 - Val Loss (simple RMSE, no physics involved): 0.177680\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.021475 - Val Loss (simple RMSE, no physics involved): 0.172541\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.018050 - Val Loss (simple RMSE, no physics involved): 0.152370\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.015462 - Val Loss (simple RMSE, no physics involved): 0.144196\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014808 - Val Loss (simple RMSE, no physics involved): 0.140555\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014058 - Val Loss (simple RMSE, no physics involved): 0.139383\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014195 - Val Loss (simple RMSE, no physics involved): 0.137300\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013547 - Val Loss (simple RMSE, no physics involved): 0.136495\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013033 - Val Loss (simple RMSE, no physics involved): 0.134710\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013213 - Val Loss (simple RMSE, no physics involved): 0.135272\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012963 - Val Loss (simple RMSE, no physics involved): 0.134517\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013015 - Val Loss (simple RMSE, no physics involved): 0.133767\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012623 - Val Loss (simple RMSE, no physics involved): 0.134851\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012807 - Val Loss (simple RMSE, no physics involved): 0.134489\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012516 - Val Loss (simple RMSE, no physics involved): 0.134179\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013123 - Val Loss (simple RMSE, no physics involved): 0.133087\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012607 - Val Loss (simple RMSE, no physics involved): 0.134429\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012643 - Val Loss (simple RMSE, no physics involved): 0.133931\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012417 - Val Loss (simple RMSE, no physics involved): 0.134017\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012495 - Val Loss (simple RMSE, no physics involved): 0.133474\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012556 - Val Loss (simple RMSE, no physics involved): 0.134007\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012104 - Val Loss (simple RMSE, no physics involved): 0.132874\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012683 - Val Loss (simple RMSE, no physics involved): 0.132848\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012101 - Val Loss (simple RMSE, no physics involved): 0.132306\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012247 - Val Loss (simple RMSE, no physics involved): 0.134613\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012361 - Val Loss (simple RMSE, no physics involved): 0.133226\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012322 - Val Loss (simple RMSE, no physics involved): 0.133406\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012094 - Val Loss (simple RMSE, no physics involved): 0.133731\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011912 - Val Loss (simple RMSE, no physics involved): 0.133678\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012045 - Val Loss (simple RMSE, no physics involved): 0.133642\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012089 - Val Loss (simple RMSE, no physics involved): 0.134487\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012102 - Val Loss (simple RMSE, no physics involved): 0.134530\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011929 - Val Loss (simple RMSE, no physics involved): 0.134723\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012078 - Val Loss (simple RMSE, no physics involved): 0.134168\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011938 - Val Loss (simple RMSE, no physics involved): 0.133336\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012060 - Val Loss (simple RMSE, no physics involved): 0.132920\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011680 - Val Loss (simple RMSE, no physics involved): 0.134939\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011661 - Val Loss (simple RMSE, no physics involved): 0.134224\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011752 - Val Loss (simple RMSE, no physics involved): 0.133050\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011968 - Val Loss (simple RMSE, no physics involved): 0.133377\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011449 - Val Loss (simple RMSE, no physics involved): 0.137849\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011704 - Val Loss (simple RMSE, no physics involved): 0.135826\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011711 - Val Loss (simple RMSE, no physics involved): 0.138526\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012121 - Val Loss (simple RMSE, no physics involved): 0.135575\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:53:40,161] Trial 38 finished with value: 0.13230595365166664 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 100, 'lr': 0.0005853127928362614, 'weight_decay': 1.4990881325942331e-06, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012054 - Val Loss (simple RMSE, no physics involved): 0.136914\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.068567 - Val Loss (simple RMSE, no physics involved): 0.288431\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.033931 - Val Loss (simple RMSE, no physics involved): 0.196691\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.031120 - Val Loss (simple RMSE, no physics involved): 0.186755\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025512 - Val Loss (simple RMSE, no physics involved): 0.200040\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.023452 - Val Loss (simple RMSE, no physics involved): 0.187108\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.020312 - Val Loss (simple RMSE, no physics involved): 0.166513\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.018017 - Val Loss (simple RMSE, no physics involved): 0.157627\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015962 - Val Loss (simple RMSE, no physics involved): 0.148883\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.015379 - Val Loss (simple RMSE, no physics involved): 0.143990\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.015245 - Val Loss (simple RMSE, no physics involved): 0.140439\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014538 - Val Loss (simple RMSE, no physics involved): 0.139895\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014241 - Val Loss (simple RMSE, no physics involved): 0.137091\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013127 - Val Loss (simple RMSE, no physics involved): 0.137172\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013464 - Val Loss (simple RMSE, no physics involved): 0.135324\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013114 - Val Loss (simple RMSE, no physics involved): 0.134585\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012803 - Val Loss (simple RMSE, no physics involved): 0.133832\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012642 - Val Loss (simple RMSE, no physics involved): 0.133561\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012593 - Val Loss (simple RMSE, no physics involved): 0.132777\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012928 - Val Loss (simple RMSE, no physics involved): 0.133246\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012420 - Val Loss (simple RMSE, no physics involved): 0.132354\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012657 - Val Loss (simple RMSE, no physics involved): 0.132495\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012543 - Val Loss (simple RMSE, no physics involved): 0.132053\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012693 - Val Loss (simple RMSE, no physics involved): 0.132271\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012585 - Val Loss (simple RMSE, no physics involved): 0.131521\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012415 - Val Loss (simple RMSE, no physics involved): 0.131972\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012310 - Val Loss (simple RMSE, no physics involved): 0.131035\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012586 - Val Loss (simple RMSE, no physics involved): 0.131508\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012347 - Val Loss (simple RMSE, no physics involved): 0.132258\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012073 - Val Loss (simple RMSE, no physics involved): 0.131832\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012225 - Val Loss (simple RMSE, no physics involved): 0.131396\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012066 - Val Loss (simple RMSE, no physics involved): 0.131266\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012394 - Val Loss (simple RMSE, no physics involved): 0.130938\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012092 - Val Loss (simple RMSE, no physics involved): 0.132010\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012668 - Val Loss (simple RMSE, no physics involved): 0.131612\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012155 - Val Loss (simple RMSE, no physics involved): 0.132234\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012328 - Val Loss (simple RMSE, no physics involved): 0.131795\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012141 - Val Loss (simple RMSE, no physics involved): 0.133148\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012368 - Val Loss (simple RMSE, no physics involved): 0.131345\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012186 - Val Loss (simple RMSE, no physics involved): 0.131908\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011781 - Val Loss (simple RMSE, no physics involved): 0.134324\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012128 - Val Loss (simple RMSE, no physics involved): 0.133195\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011882 - Val Loss (simple RMSE, no physics involved): 0.132310\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011794 - Val Loss (simple RMSE, no physics involved): 0.132301\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011813 - Val Loss (simple RMSE, no physics involved): 0.132607\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011906 - Val Loss (simple RMSE, no physics involved): 0.132446\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011848 - Val Loss (simple RMSE, no physics involved): 0.132051\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011871 - Val Loss (simple RMSE, no physics involved): 0.132023\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012058 - Val Loss (simple RMSE, no physics involved): 0.131862\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011716 - Val Loss (simple RMSE, no physics involved): 0.132552\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:53:58,906] Trial 39 finished with value: 0.1309375986456871 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 168, 'lr': 0.00036776277185743267, 'weight_decay': 4.8363152623842974e-06, 'batch_size': 16}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011500 - Val Loss (simple RMSE, no physics involved): 0.132545\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.069947 - Val Loss (simple RMSE, no physics involved): 0.198670\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.034456 - Val Loss (simple RMSE, no physics involved): 0.248590\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.025218 - Val Loss (simple RMSE, no physics involved): 0.166690\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.021866 - Val Loss (simple RMSE, no physics involved): 0.165396\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019969 - Val Loss (simple RMSE, no physics involved): 0.168474\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.016834 - Val Loss (simple RMSE, no physics involved): 0.160905\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015770 - Val Loss (simple RMSE, no physics involved): 0.155220\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015638 - Val Loss (simple RMSE, no physics involved): 0.147831\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.016361 - Val Loss (simple RMSE, no physics involved): 0.145873\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014386 - Val Loss (simple RMSE, no physics involved): 0.147596\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014416 - Val Loss (simple RMSE, no physics involved): 0.143793\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014462 - Val Loss (simple RMSE, no physics involved): 0.142800\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.014322 - Val Loss (simple RMSE, no physics involved): 0.140949\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.014157 - Val Loss (simple RMSE, no physics involved): 0.140066\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012950 - Val Loss (simple RMSE, no physics involved): 0.143380\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013465 - Val Loss (simple RMSE, no physics involved): 0.140434\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013096 - Val Loss (simple RMSE, no physics involved): 0.148530\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013000 - Val Loss (simple RMSE, no physics involved): 0.139683\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.014533 - Val Loss (simple RMSE, no physics involved): 0.140821\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012986 - Val Loss (simple RMSE, no physics involved): 0.140331\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012850 - Val Loss (simple RMSE, no physics involved): 0.139663\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012608 - Val Loss (simple RMSE, no physics involved): 0.143065\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.011810 - Val Loss (simple RMSE, no physics involved): 0.139753\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012736 - Val Loss (simple RMSE, no physics involved): 0.141171\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012446 - Val Loss (simple RMSE, no physics involved): 0.139179\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012100 - Val Loss (simple RMSE, no physics involved): 0.140771\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012257 - Val Loss (simple RMSE, no physics involved): 0.139176\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012618 - Val Loss (simple RMSE, no physics involved): 0.140247\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011854 - Val Loss (simple RMSE, no physics involved): 0.139991\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012139 - Val Loss (simple RMSE, no physics involved): 0.139102\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011996 - Val Loss (simple RMSE, no physics involved): 0.142893\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011656 - Val Loss (simple RMSE, no physics involved): 0.139494\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012462 - Val Loss (simple RMSE, no physics involved): 0.140864\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012284 - Val Loss (simple RMSE, no physics involved): 0.139357\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011904 - Val Loss (simple RMSE, no physics involved): 0.140042\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011265 - Val Loss (simple RMSE, no physics involved): 0.141478\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012376 - Val Loss (simple RMSE, no physics involved): 0.140199\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011943 - Val Loss (simple RMSE, no physics involved): 0.145307\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012322 - Val Loss (simple RMSE, no physics involved): 0.140747\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011922 - Val Loss (simple RMSE, no physics involved): 0.140326\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011981 - Val Loss (simple RMSE, no physics involved): 0.140250\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012785 - Val Loss (simple RMSE, no physics involved): 0.141196\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012015 - Val Loss (simple RMSE, no physics involved): 0.151927\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013015 - Val Loss (simple RMSE, no physics involved): 0.142131\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.013836 - Val Loss (simple RMSE, no physics involved): 0.146416\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011800 - Val Loss (simple RMSE, no physics involved): 0.143465\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011622 - Val Loss (simple RMSE, no physics involved): 0.145262\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012038 - Val Loss (simple RMSE, no physics involved): 0.141848\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011869 - Val Loss (simple RMSE, no physics involved): 0.142308\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.011657 - Val Loss (simple RMSE, no physics involved): 0.140715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:54:09,288] Trial 40 finished with value: 0.13910230994224548 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 214, 'lr': 0.00211344796925464, 'weight_decay': 4.872976302821584e-07, 'batch_size': 32}. Best is trial 22 with value: 0.12740245088934898.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.056599 - Val Loss (simple RMSE, no physics involved): 0.255883\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.034698 - Val Loss (simple RMSE, no physics involved): 0.232736\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028583 - Val Loss (simple RMSE, no physics involved): 0.192999\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.028739 - Val Loss (simple RMSE, no physics involved): 0.190389\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019956 - Val Loss (simple RMSE, no physics involved): 0.142541\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015426 - Val Loss (simple RMSE, no physics involved): 0.141593\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014660 - Val Loss (simple RMSE, no physics involved): 0.136480\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013245 - Val Loss (simple RMSE, no physics involved): 0.137582\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013571 - Val Loss (simple RMSE, no physics involved): 0.131303\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013606 - Val Loss (simple RMSE, no physics involved): 0.131003\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013009 - Val Loss (simple RMSE, no physics involved): 0.129395\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013218 - Val Loss (simple RMSE, no physics involved): 0.130646\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013329 - Val Loss (simple RMSE, no physics involved): 0.130137\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012661 - Val Loss (simple RMSE, no physics involved): 0.130777\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012722 - Val Loss (simple RMSE, no physics involved): 0.126733\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012440 - Val Loss (simple RMSE, no physics involved): 0.132260\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012412 - Val Loss (simple RMSE, no physics involved): 0.130358\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012466 - Val Loss (simple RMSE, no physics involved): 0.128960\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012310 - Val Loss (simple RMSE, no physics involved): 0.128196\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012448 - Val Loss (simple RMSE, no physics involved): 0.127370\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013335 - Val Loss (simple RMSE, no physics involved): 0.133899\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012611 - Val Loss (simple RMSE, no physics involved): 0.138421\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012398 - Val Loss (simple RMSE, no physics involved): 0.128276\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012131 - Val Loss (simple RMSE, no physics involved): 0.134168\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012174 - Val Loss (simple RMSE, no physics involved): 0.134014\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013165 - Val Loss (simple RMSE, no physics involved): 0.132071\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012259 - Val Loss (simple RMSE, no physics involved): 0.129691\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012244 - Val Loss (simple RMSE, no physics involved): 0.130141\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012058 - Val Loss (simple RMSE, no physics involved): 0.131782\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011835 - Val Loss (simple RMSE, no physics involved): 0.142003\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012661 - Val Loss (simple RMSE, no physics involved): 0.135787\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013237 - Val Loss (simple RMSE, no physics involved): 0.133180\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012993 - Val Loss (simple RMSE, no physics involved): 0.133071\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012849 - Val Loss (simple RMSE, no physics involved): 0.130264\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012553 - Val Loss (simple RMSE, no physics involved): 0.131768\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011916 - Val Loss (simple RMSE, no physics involved): 0.135694\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011868 - Val Loss (simple RMSE, no physics involved): 0.131916\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011743 - Val Loss (simple RMSE, no physics involved): 0.132325\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011916 - Val Loss (simple RMSE, no physics involved): 0.129167\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011871 - Val Loss (simple RMSE, no physics involved): 0.133617\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011875 - Val Loss (simple RMSE, no physics involved): 0.132436\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011845 - Val Loss (simple RMSE, no physics involved): 0.137189\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011825 - Val Loss (simple RMSE, no physics involved): 0.131225\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011123 - Val Loss (simple RMSE, no physics involved): 0.133943\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011322 - Val Loss (simple RMSE, no physics involved): 0.131281\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011434 - Val Loss (simple RMSE, no physics involved): 0.132635\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011444 - Val Loss (simple RMSE, no physics involved): 0.132872\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011377 - Val Loss (simple RMSE, no physics involved): 0.142498\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012035 - Val Loss (simple RMSE, no physics involved): 0.131857\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:54:34,522] Trial 41 finished with value: 0.12673278152942657 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 163, 'lr': 0.0031656932205590947, 'weight_decay': 3.408518000104593e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011772 - Val Loss (simple RMSE, no physics involved): 0.135388\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.070713 - Val Loss (simple RMSE, no physics involved): 0.290028\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.039610 - Val Loss (simple RMSE, no physics involved): 0.212278\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029905 - Val Loss (simple RMSE, no physics involved): 0.208976\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.026312 - Val Loss (simple RMSE, no physics involved): 0.180100\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.020089 - Val Loss (simple RMSE, no physics involved): 0.147685\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015711 - Val Loss (simple RMSE, no physics involved): 0.141789\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015437 - Val Loss (simple RMSE, no physics involved): 0.136719\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013525 - Val Loss (simple RMSE, no physics involved): 0.132104\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013498 - Val Loss (simple RMSE, no physics involved): 0.132191\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012774 - Val Loss (simple RMSE, no physics involved): 0.138706\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013259 - Val Loss (simple RMSE, no physics involved): 0.133994\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012586 - Val Loss (simple RMSE, no physics involved): 0.130381\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013016 - Val Loss (simple RMSE, no physics involved): 0.128911\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012565 - Val Loss (simple RMSE, no physics involved): 0.128841\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012591 - Val Loss (simple RMSE, no physics involved): 0.129665\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012988 - Val Loss (simple RMSE, no physics involved): 0.128130\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013019 - Val Loss (simple RMSE, no physics involved): 0.129802\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012509 - Val Loss (simple RMSE, no physics involved): 0.136687\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012944 - Val Loss (simple RMSE, no physics involved): 0.129835\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012958 - Val Loss (simple RMSE, no physics involved): 0.133076\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012352 - Val Loss (simple RMSE, no physics involved): 0.131665\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012243 - Val Loss (simple RMSE, no physics involved): 0.133336\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013270 - Val Loss (simple RMSE, no physics involved): 0.128683\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013010 - Val Loss (simple RMSE, no physics involved): 0.136211\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013847 - Val Loss (simple RMSE, no physics involved): 0.131088\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013291 - Val Loss (simple RMSE, no physics involved): 0.132294\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012124 - Val Loss (simple RMSE, no physics involved): 0.130524\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012423 - Val Loss (simple RMSE, no physics involved): 0.130544\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011631 - Val Loss (simple RMSE, no physics involved): 0.131132\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012105 - Val Loss (simple RMSE, no physics involved): 0.132331\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012081 - Val Loss (simple RMSE, no physics involved): 0.132455\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011622 - Val Loss (simple RMSE, no physics involved): 0.134620\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011510 - Val Loss (simple RMSE, no physics involved): 0.134730\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012078 - Val Loss (simple RMSE, no physics involved): 0.135020\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012125 - Val Loss (simple RMSE, no physics involved): 0.135994\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011822 - Val Loss (simple RMSE, no physics involved): 0.133096\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011674 - Val Loss (simple RMSE, no physics involved): 0.134283\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011477 - Val Loss (simple RMSE, no physics involved): 0.137324\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011498 - Val Loss (simple RMSE, no physics involved): 0.147968\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011752 - Val Loss (simple RMSE, no physics involved): 0.134994\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011725 - Val Loss (simple RMSE, no physics involved): 0.134971\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011480 - Val Loss (simple RMSE, no physics involved): 0.142475\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012057 - Val Loss (simple RMSE, no physics involved): 0.138933\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011698 - Val Loss (simple RMSE, no physics involved): 0.136878\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012046 - Val Loss (simple RMSE, no physics involved): 0.140999\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011712 - Val Loss (simple RMSE, no physics involved): 0.153533\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012179 - Val Loss (simple RMSE, no physics involved): 0.145028\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011469 - Val Loss (simple RMSE, no physics involved): 0.152974\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011082 - Val Loss (simple RMSE, no physics involved): 0.137765\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:54:57,964] Trial 42 finished with value: 0.12812994047999382 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 137, 'lr': 0.004072362806632007, 'weight_decay': 1.2184408160830023e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011464 - Val Loss (simple RMSE, no physics involved): 0.138677\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.039086 - Val Loss (simple RMSE, no physics involved): 0.232376\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.029623 - Val Loss (simple RMSE, no physics involved): 0.217331\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.026627 - Val Loss (simple RMSE, no physics involved): 0.174784\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.021474 - Val Loss (simple RMSE, no physics involved): 0.166564\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019954 - Val Loss (simple RMSE, no physics involved): 0.143824\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015062 - Val Loss (simple RMSE, no physics involved): 0.155439\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015016 - Val Loss (simple RMSE, no physics involved): 0.141328\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013443 - Val Loss (simple RMSE, no physics involved): 0.136621\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013249 - Val Loss (simple RMSE, no physics involved): 0.133797\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013275 - Val Loss (simple RMSE, no physics involved): 0.133059\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012804 - Val Loss (simple RMSE, no physics involved): 0.134658\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013213 - Val Loss (simple RMSE, no physics involved): 0.131460\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012728 - Val Loss (simple RMSE, no physics involved): 0.131527\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012608 - Val Loss (simple RMSE, no physics involved): 0.133315\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012389 - Val Loss (simple RMSE, no physics involved): 0.134938\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012508 - Val Loss (simple RMSE, no physics involved): 0.132517\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012270 - Val Loss (simple RMSE, no physics involved): 0.132974\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012195 - Val Loss (simple RMSE, no physics involved): 0.131682\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012437 - Val Loss (simple RMSE, no physics involved): 0.130604\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012033 - Val Loss (simple RMSE, no physics involved): 0.131747\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012469 - Val Loss (simple RMSE, no physics involved): 0.136977\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012641 - Val Loss (simple RMSE, no physics involved): 0.135156\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012750 - Val Loss (simple RMSE, no physics involved): 0.130638\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012351 - Val Loss (simple RMSE, no physics involved): 0.135169\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012007 - Val Loss (simple RMSE, no physics involved): 0.134225\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011761 - Val Loss (simple RMSE, no physics involved): 0.133330\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012128 - Val Loss (simple RMSE, no physics involved): 0.134093\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011753 - Val Loss (simple RMSE, no physics involved): 0.136595\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011828 - Val Loss (simple RMSE, no physics involved): 0.135201\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012195 - Val Loss (simple RMSE, no physics involved): 0.147938\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011929 - Val Loss (simple RMSE, no physics involved): 0.136970\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012680 - Val Loss (simple RMSE, no physics involved): 0.154636\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011817 - Val Loss (simple RMSE, no physics involved): 0.136370\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011889 - Val Loss (simple RMSE, no physics involved): 0.133341\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012018 - Val Loss (simple RMSE, no physics involved): 0.135329\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012102 - Val Loss (simple RMSE, no physics involved): 0.138830\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012048 - Val Loss (simple RMSE, no physics involved): 0.143073\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012112 - Val Loss (simple RMSE, no physics involved): 0.137978\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011785 - Val Loss (simple RMSE, no physics involved): 0.140580\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011982 - Val Loss (simple RMSE, no physics involved): 0.152465\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011771 - Val Loss (simple RMSE, no physics involved): 0.136145\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011461 - Val Loss (simple RMSE, no physics involved): 0.144980\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011301 - Val Loss (simple RMSE, no physics involved): 0.132984\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011498 - Val Loss (simple RMSE, no physics involved): 0.134495\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.010928 - Val Loss (simple RMSE, no physics involved): 0.133813\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011480 - Val Loss (simple RMSE, no physics involved): 0.134599\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011933 - Val Loss (simple RMSE, no physics involved): 0.137538\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012309 - Val Loss (simple RMSE, no physics involved): 0.131375\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011862 - Val Loss (simple RMSE, no physics involved): 0.130205\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:55:21,919] Trial 43 finished with value: 0.13020538911223412 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 125, 'lr': 0.0034307821394226504, 'weight_decay': 9.28074493609684e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011062 - Val Loss (simple RMSE, no physics involved): 0.137435\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.050244 - Val Loss (simple RMSE, no physics involved): 0.189845\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.030992 - Val Loss (simple RMSE, no physics involved): 0.233572\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.023909 - Val Loss (simple RMSE, no physics involved): 0.163471\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.018694 - Val Loss (simple RMSE, no physics involved): 0.213692\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.016917 - Val Loss (simple RMSE, no physics involved): 0.140605\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014380 - Val Loss (simple RMSE, no physics involved): 0.138329\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013560 - Val Loss (simple RMSE, no physics involved): 0.135928\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013366 - Val Loss (simple RMSE, no physics involved): 0.144819\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014885 - Val Loss (simple RMSE, no physics involved): 0.142085\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013464 - Val Loss (simple RMSE, no physics involved): 0.144705\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013091 - Val Loss (simple RMSE, no physics involved): 0.150220\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014754 - Val Loss (simple RMSE, no physics involved): 0.158912\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.015397 - Val Loss (simple RMSE, no physics involved): 0.137903\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013627 - Val Loss (simple RMSE, no physics involved): 0.150852\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013894 - Val Loss (simple RMSE, no physics involved): 0.142815\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013091 - Val Loss (simple RMSE, no physics involved): 0.146405\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012989 - Val Loss (simple RMSE, no physics involved): 0.131660\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013277 - Val Loss (simple RMSE, no physics involved): 0.133114\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013678 - Val Loss (simple RMSE, no physics involved): 0.131628\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013350 - Val Loss (simple RMSE, no physics involved): 0.142541\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012914 - Val Loss (simple RMSE, no physics involved): 0.144316\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013222 - Val Loss (simple RMSE, no physics involved): 0.134879\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012637 - Val Loss (simple RMSE, no physics involved): 0.131485\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012186 - Val Loss (simple RMSE, no physics involved): 0.134710\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012396 - Val Loss (simple RMSE, no physics involved): 0.135504\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012154 - Val Loss (simple RMSE, no physics involved): 0.136080\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011982 - Val Loss (simple RMSE, no physics involved): 0.141920\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012171 - Val Loss (simple RMSE, no physics involved): 0.135661\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011947 - Val Loss (simple RMSE, no physics involved): 0.133366\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012000 - Val Loss (simple RMSE, no physics involved): 0.146745\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012552 - Val Loss (simple RMSE, no physics involved): 0.133593\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013293 - Val Loss (simple RMSE, no physics involved): 0.138871\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012441 - Val Loss (simple RMSE, no physics involved): 0.141674\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012158 - Val Loss (simple RMSE, no physics involved): 0.136696\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011939 - Val Loss (simple RMSE, no physics involved): 0.135322\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011247 - Val Loss (simple RMSE, no physics involved): 0.136517\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011874 - Val Loss (simple RMSE, no physics involved): 0.135578\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011180 - Val Loss (simple RMSE, no physics involved): 0.136130\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011791 - Val Loss (simple RMSE, no physics involved): 0.137652\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011450 - Val Loss (simple RMSE, no physics involved): 0.140931\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011188 - Val Loss (simple RMSE, no physics involved): 0.145391\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011712 - Val Loss (simple RMSE, no physics involved): 0.140391\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011820 - Val Loss (simple RMSE, no physics involved): 0.144859\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011684 - Val Loss (simple RMSE, no physics involved): 0.141335\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011781 - Val Loss (simple RMSE, no physics involved): 0.139006\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012286 - Val Loss (simple RMSE, no physics involved): 0.145942\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011953 - Val Loss (simple RMSE, no physics involved): 0.144899\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012228 - Val Loss (simple RMSE, no physics involved): 0.148606\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011592 - Val Loss (simple RMSE, no physics involved): 0.139009\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:55:46,245] Trial 44 finished with value: 0.13148494064807892 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 155, 'lr': 0.00505092843860366, 'weight_decay': 2.0428098496606013e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011192 - Val Loss (simple RMSE, no physics involved): 0.138657\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.626171 - Val Loss (simple RMSE, no physics involved): 0.379983\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.101534 - Val Loss (simple RMSE, no physics involved): 0.444080\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.086749 - Val Loss (simple RMSE, no physics involved): 0.200249\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.045480 - Val Loss (simple RMSE, no physics involved): 0.273309\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.030968 - Val Loss (simple RMSE, no physics involved): 0.190236\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.026687 - Val Loss (simple RMSE, no physics involved): 0.238525\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.028250 - Val Loss (simple RMSE, no physics involved): 0.175722\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.024003 - Val Loss (simple RMSE, no physics involved): 0.198610\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.022369 - Val Loss (simple RMSE, no physics involved): 0.162213\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.018239 - Val Loss (simple RMSE, no physics involved): 0.150810\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.018036 - Val Loss (simple RMSE, no physics involved): 0.154811\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.016203 - Val Loss (simple RMSE, no physics involved): 0.148709\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.015192 - Val Loss (simple RMSE, no physics involved): 0.146789\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.014387 - Val Loss (simple RMSE, no physics involved): 0.147896\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.014541 - Val Loss (simple RMSE, no physics involved): 0.144620\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013103 - Val Loss (simple RMSE, no physics involved): 0.146570\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.014247 - Val Loss (simple RMSE, no physics involved): 0.142561\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.014086 - Val Loss (simple RMSE, no physics involved): 0.142606\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013015 - Val Loss (simple RMSE, no physics involved): 0.145732\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.014194 - Val Loss (simple RMSE, no physics involved): 0.142427\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012656 - Val Loss (simple RMSE, no physics involved): 0.140479\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012546 - Val Loss (simple RMSE, no physics involved): 0.141623\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013705 - Val Loss (simple RMSE, no physics involved): 0.140164\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012370 - Val Loss (simple RMSE, no physics involved): 0.143894\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012673 - Val Loss (simple RMSE, no physics involved): 0.147910\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.014014 - Val Loss (simple RMSE, no physics involved): 0.142069\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012589 - Val Loss (simple RMSE, no physics involved): 0.142228\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012055 - Val Loss (simple RMSE, no physics involved): 0.140702\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012877 - Val Loss (simple RMSE, no physics involved): 0.151773\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013465 - Val Loss (simple RMSE, no physics involved): 0.145438\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.014284 - Val Loss (simple RMSE, no physics involved): 0.140653\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012915 - Val Loss (simple RMSE, no physics involved): 0.142778\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.013770 - Val Loss (simple RMSE, no physics involved): 0.145659\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013823 - Val Loss (simple RMSE, no physics involved): 0.144991\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.013154 - Val Loss (simple RMSE, no physics involved): 0.139775\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012217 - Val Loss (simple RMSE, no physics involved): 0.140850\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012190 - Val Loss (simple RMSE, no physics involved): 0.141055\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012261 - Val Loss (simple RMSE, no physics involved): 0.141632\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011587 - Val Loss (simple RMSE, no physics involved): 0.140821\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011328 - Val Loss (simple RMSE, no physics involved): 0.141140\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.013143 - Val Loss (simple RMSE, no physics involved): 0.140828\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013624 - Val Loss (simple RMSE, no physics involved): 0.143194\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012240 - Val Loss (simple RMSE, no physics involved): 0.151365\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013566 - Val Loss (simple RMSE, no physics involved): 0.151621\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012499 - Val Loss (simple RMSE, no physics involved): 0.142786\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012286 - Val Loss (simple RMSE, no physics involved): 0.140589\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011577 - Val Loss (simple RMSE, no physics involved): 0.145669\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012268 - Val Loss (simple RMSE, no physics involved): 0.150049\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012231 - Val Loss (simple RMSE, no physics involved): 0.141607\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:56:01,015] Trial 45 finished with value: 0.13977515697479248 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 141, 'lr': 0.009961350529410645, 'weight_decay': 3.791160000881104e-06, 'batch_size': 32}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012686 - Val Loss (simple RMSE, no physics involved): 0.149648\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.153018 - Val Loss (simple RMSE, no physics involved): 0.389475\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.062729 - Val Loss (simple RMSE, no physics involved): 0.208411\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.044254 - Val Loss (simple RMSE, no physics involved): 0.195406\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.037654 - Val Loss (simple RMSE, no physics involved): 0.232719\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.029991 - Val Loss (simple RMSE, no physics involved): 0.265171\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.032589 - Val Loss (simple RMSE, no physics involved): 0.263953\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.032160 - Val Loss (simple RMSE, no physics involved): 0.244989\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.028769 - Val Loss (simple RMSE, no physics involved): 0.218170\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.027209 - Val Loss (simple RMSE, no physics involved): 0.197960\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.028752 - Val Loss (simple RMSE, no physics involved): 0.192738\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.028028 - Val Loss (simple RMSE, no physics involved): 0.197806\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.025001 - Val Loss (simple RMSE, no physics involved): 0.209302\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.024950 - Val Loss (simple RMSE, no physics involved): 0.211864\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.024094 - Val Loss (simple RMSE, no physics involved): 0.198787\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.021613 - Val Loss (simple RMSE, no physics involved): 0.177577\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.019567 - Val Loss (simple RMSE, no physics involved): 0.162878\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.017579 - Val Loss (simple RMSE, no physics involved): 0.154072\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.015795 - Val Loss (simple RMSE, no physics involved): 0.147715\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.015815 - Val Loss (simple RMSE, no physics involved): 0.148837\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.015826 - Val Loss (simple RMSE, no physics involved): 0.146913\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.014780 - Val Loss (simple RMSE, no physics involved): 0.144627\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.014504 - Val Loss (simple RMSE, no physics involved): 0.145797\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013869 - Val Loss (simple RMSE, no physics involved): 0.145827\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013710 - Val Loss (simple RMSE, no physics involved): 0.146245\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013938 - Val Loss (simple RMSE, no physics involved): 0.143194\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013727 - Val Loss (simple RMSE, no physics involved): 0.141605\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013606 - Val Loss (simple RMSE, no physics involved): 0.141501\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013534 - Val Loss (simple RMSE, no physics involved): 0.142615\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013149 - Val Loss (simple RMSE, no physics involved): 0.141385\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013424 - Val Loss (simple RMSE, no physics involved): 0.144045\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013713 - Val Loss (simple RMSE, no physics involved): 0.144278\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013349 - Val Loss (simple RMSE, no physics involved): 0.140975\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.013609 - Val Loss (simple RMSE, no physics involved): 0.142652\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013262 - Val Loss (simple RMSE, no physics involved): 0.139872\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012861 - Val Loss (simple RMSE, no physics involved): 0.139469\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012733 - Val Loss (simple RMSE, no physics involved): 0.141138\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012699 - Val Loss (simple RMSE, no physics involved): 0.138714\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012672 - Val Loss (simple RMSE, no physics involved): 0.139160\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012815 - Val Loss (simple RMSE, no physics involved): 0.139767\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.013014 - Val Loss (simple RMSE, no physics involved): 0.138961\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012851 - Val Loss (simple RMSE, no physics involved): 0.138681\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012622 - Val Loss (simple RMSE, no physics involved): 0.138337\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012673 - Val Loss (simple RMSE, no physics involved): 0.137879\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012909 - Val Loss (simple RMSE, no physics involved): 0.139464\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012676 - Val Loss (simple RMSE, no physics involved): 0.138219\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012576 - Val Loss (simple RMSE, no physics involved): 0.138631\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012717 - Val Loss (simple RMSE, no physics involved): 0.139169\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012402 - Val Loss (simple RMSE, no physics involved): 0.138117\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:56:09,209] Trial 46 finished with value: 0.1378789097070694 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 109, 'lr': 0.00288275559115255, 'weight_decay': 1.6602119007074768e-05, 'batch_size': 64}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Train Loss: 0.012264 - Val Loss (simple RMSE, no physics involved): 0.139818\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.013150 - Val Loss (simple RMSE, no physics involved): 0.138049\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.069059 - Val Loss (simple RMSE, no physics involved): 0.251861\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.028808 - Val Loss (simple RMSE, no physics involved): 0.176788\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.024498 - Val Loss (simple RMSE, no physics involved): 0.175688\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.018224 - Val Loss (simple RMSE, no physics involved): 0.157337\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.016545 - Val Loss (simple RMSE, no physics involved): 0.141928\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015011 - Val Loss (simple RMSE, no physics involved): 0.141999\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013910 - Val Loss (simple RMSE, no physics involved): 0.148458\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014454 - Val Loss (simple RMSE, no physics involved): 0.148570\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014192 - Val Loss (simple RMSE, no physics involved): 0.140543\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013236 - Val Loss (simple RMSE, no physics involved): 0.130266\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013146 - Val Loss (simple RMSE, no physics involved): 0.135028\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013832 - Val Loss (simple RMSE, no physics involved): 0.131029\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013048 - Val Loss (simple RMSE, no physics involved): 0.131735\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012655 - Val Loss (simple RMSE, no physics involved): 0.131463\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013293 - Val Loss (simple RMSE, no physics involved): 0.130401\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013742 - Val Loss (simple RMSE, no physics involved): 0.131624\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012726 - Val Loss (simple RMSE, no physics involved): 0.129698\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012575 - Val Loss (simple RMSE, no physics involved): 0.130140\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013215 - Val Loss (simple RMSE, no physics involved): 0.128277\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013132 - Val Loss (simple RMSE, no physics involved): 0.131019\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012744 - Val Loss (simple RMSE, no physics involved): 0.137433\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012842 - Val Loss (simple RMSE, no physics involved): 0.132548\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013100 - Val Loss (simple RMSE, no physics involved): 0.130427\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012077 - Val Loss (simple RMSE, no physics involved): 0.129961\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012316 - Val Loss (simple RMSE, no physics involved): 0.131310\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012909 - Val Loss (simple RMSE, no physics involved): 0.137539\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012234 - Val Loss (simple RMSE, no physics involved): 0.145843\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.014996 - Val Loss (simple RMSE, no physics involved): 0.130874\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012627 - Val Loss (simple RMSE, no physics involved): 0.132721\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013099 - Val Loss (simple RMSE, no physics involved): 0.131943\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.014414 - Val Loss (simple RMSE, no physics involved): 0.136843\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013512 - Val Loss (simple RMSE, no physics involved): 0.139412\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.013129 - Val Loss (simple RMSE, no physics involved): 0.145263\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012950 - Val Loss (simple RMSE, no physics involved): 0.145270\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012687 - Val Loss (simple RMSE, no physics involved): 0.138498\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012275 - Val Loss (simple RMSE, no physics involved): 0.138061\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012340 - Val Loss (simple RMSE, no physics involved): 0.133643\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012223 - Val Loss (simple RMSE, no physics involved): 0.152503\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013248 - Val Loss (simple RMSE, no physics involved): 0.136342\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012631 - Val Loss (simple RMSE, no physics involved): 0.144435\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012870 - Val Loss (simple RMSE, no physics involved): 0.137651\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013159 - Val Loss (simple RMSE, no physics involved): 0.151423\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013752 - Val Loss (simple RMSE, no physics involved): 0.145273\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013406 - Val Loss (simple RMSE, no physics involved): 0.141081\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012208 - Val Loss (simple RMSE, no physics involved): 0.133063\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011523 - Val Loss (simple RMSE, no physics involved): 0.130824\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011506 - Val Loss (simple RMSE, no physics involved): 0.131488\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012266 - Val Loss (simple RMSE, no physics involved): 0.133065\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011771 - Val Loss (simple RMSE, no physics involved): 0.133365\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:56:33,698] Trial 47 finished with value: 0.1282770037651062 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 134, 'lr': 0.003953288339994724, 'weight_decay': 8.599943757062414e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012068 - Val Loss (simple RMSE, no physics involved): 0.133207\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.057011 - Val Loss (simple RMSE, no physics involved): 0.268857\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.034838 - Val Loss (simple RMSE, no physics involved): 0.193487\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028848 - Val Loss (simple RMSE, no physics involved): 0.220054\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025873 - Val Loss (simple RMSE, no physics involved): 0.165053\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019680 - Val Loss (simple RMSE, no physics involved): 0.144470\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015414 - Val Loss (simple RMSE, no physics involved): 0.140340\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014331 - Val Loss (simple RMSE, no physics involved): 0.143198\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014090 - Val Loss (simple RMSE, no physics involved): 0.130950\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014013 - Val Loss (simple RMSE, no physics involved): 0.143598\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014427 - Val Loss (simple RMSE, no physics involved): 0.134431\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013202 - Val Loss (simple RMSE, no physics involved): 0.130461\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012396 - Val Loss (simple RMSE, no physics involved): 0.137025\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012849 - Val Loss (simple RMSE, no physics involved): 0.146492\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013341 - Val Loss (simple RMSE, no physics involved): 0.129368\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012681 - Val Loss (simple RMSE, no physics involved): 0.127961\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012420 - Val Loss (simple RMSE, no physics involved): 0.127136\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012325 - Val Loss (simple RMSE, no physics involved): 0.131911\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013313 - Val Loss (simple RMSE, no physics involved): 0.128381\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012758 - Val Loss (simple RMSE, no physics involved): 0.131112\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013510 - Val Loss (simple RMSE, no physics involved): 0.136349\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012941 - Val Loss (simple RMSE, no physics involved): 0.132689\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012190 - Val Loss (simple RMSE, no physics involved): 0.127779\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012685 - Val Loss (simple RMSE, no physics involved): 0.131895\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012283 - Val Loss (simple RMSE, no physics involved): 0.139793\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013656 - Val Loss (simple RMSE, no physics involved): 0.128155\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012072 - Val Loss (simple RMSE, no physics involved): 0.133832\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012182 - Val Loss (simple RMSE, no physics involved): 0.136687\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011956 - Val Loss (simple RMSE, no physics involved): 0.138386\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012406 - Val Loss (simple RMSE, no physics involved): 0.141321\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013410 - Val Loss (simple RMSE, no physics involved): 0.139654\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012141 - Val Loss (simple RMSE, no physics involved): 0.136688\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012957 - Val Loss (simple RMSE, no physics involved): 0.133371\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012019 - Val Loss (simple RMSE, no physics involved): 0.131551\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011708 - Val Loss (simple RMSE, no physics involved): 0.130327\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011791 - Val Loss (simple RMSE, no physics involved): 0.130187\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011910 - Val Loss (simple RMSE, no physics involved): 0.129434\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011714 - Val Loss (simple RMSE, no physics involved): 0.128762\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012160 - Val Loss (simple RMSE, no physics involved): 0.132831\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011392 - Val Loss (simple RMSE, no physics involved): 0.131463\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011551 - Val Loss (simple RMSE, no physics involved): 0.130248\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011583 - Val Loss (simple RMSE, no physics involved): 0.130362\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011266 - Val Loss (simple RMSE, no physics involved): 0.132278\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011393 - Val Loss (simple RMSE, no physics involved): 0.132524\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011511 - Val Loss (simple RMSE, no physics involved): 0.135606\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011561 - Val Loss (simple RMSE, no physics involved): 0.143513\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012502 - Val Loss (simple RMSE, no physics involved): 0.133173\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011878 - Val Loss (simple RMSE, no physics involved): 0.136372\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011354 - Val Loss (simple RMSE, no physics involved): 0.134717\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011314 - Val Loss (simple RMSE, no physics involved): 0.139555\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:56:59,807] Trial 48 finished with value: 0.12713630869984627 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 131, 'lr': 0.006192361540848148, 'weight_decay': 3.970490653939271e-08, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011515 - Val Loss (simple RMSE, no physics involved): 0.140578\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.059355 - Val Loss (simple RMSE, no physics involved): 0.257607\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.028720 - Val Loss (simple RMSE, no physics involved): 0.204108\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.026650 - Val Loss (simple RMSE, no physics involved): 0.183477\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.017901 - Val Loss (simple RMSE, no physics involved): 0.147339\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.016079 - Val Loss (simple RMSE, no physics involved): 0.144165\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014288 - Val Loss (simple RMSE, no physics involved): 0.139830\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013842 - Val Loss (simple RMSE, no physics involved): 0.136368\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013133 - Val Loss (simple RMSE, no physics involved): 0.141634\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013005 - Val Loss (simple RMSE, no physics involved): 0.135300\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013137 - Val Loss (simple RMSE, no physics involved): 0.132740\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012816 - Val Loss (simple RMSE, no physics involved): 0.137550\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013055 - Val Loss (simple RMSE, no physics involved): 0.134282\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.014611 - Val Loss (simple RMSE, no physics involved): 0.137006\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013446 - Val Loss (simple RMSE, no physics involved): 0.136630\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012910 - Val Loss (simple RMSE, no physics involved): 0.136730\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012628 - Val Loss (simple RMSE, no physics involved): 0.135797\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012710 - Val Loss (simple RMSE, no physics involved): 0.132552\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012450 - Val Loss (simple RMSE, no physics involved): 0.143810\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012994 - Val Loss (simple RMSE, no physics involved): 0.138081\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012885 - Val Loss (simple RMSE, no physics involved): 0.134836\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012304 - Val Loss (simple RMSE, no physics involved): 0.136758\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012440 - Val Loss (simple RMSE, no physics involved): 0.140643\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012983 - Val Loss (simple RMSE, no physics involved): 0.138946\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012865 - Val Loss (simple RMSE, no physics involved): 0.135727\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012561 - Val Loss (simple RMSE, no physics involved): 0.138359\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012418 - Val Loss (simple RMSE, no physics involved): 0.140007\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012384 - Val Loss (simple RMSE, no physics involved): 0.139187\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012549 - Val Loss (simple RMSE, no physics involved): 0.139152\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012421 - Val Loss (simple RMSE, no physics involved): 0.143496\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012779 - Val Loss (simple RMSE, no physics involved): 0.143502\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012446 - Val Loss (simple RMSE, no physics involved): 0.139333\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012161 - Val Loss (simple RMSE, no physics involved): 0.144277\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012064 - Val Loss (simple RMSE, no physics involved): 0.146527\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011907 - Val Loss (simple RMSE, no physics involved): 0.141807\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011746 - Val Loss (simple RMSE, no physics involved): 0.144789\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011542 - Val Loss (simple RMSE, no physics involved): 0.142302\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011646 - Val Loss (simple RMSE, no physics involved): 0.155730\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011707 - Val Loss (simple RMSE, no physics involved): 0.140121\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011762 - Val Loss (simple RMSE, no physics involved): 0.145492\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012020 - Val Loss (simple RMSE, no physics involved): 0.143767\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012102 - Val Loss (simple RMSE, no physics involved): 0.146277\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012567 - Val Loss (simple RMSE, no physics involved): 0.152220\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011747 - Val Loss (simple RMSE, no physics involved): 0.139160\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011440 - Val Loss (simple RMSE, no physics involved): 0.142249\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011791 - Val Loss (simple RMSE, no physics involved): 0.140428\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011515 - Val Loss (simple RMSE, no physics involved): 0.142219\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011467 - Val Loss (simple RMSE, no physics involved): 0.155872\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011472 - Val Loss (simple RMSE, no physics involved): 0.143862\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011088 - Val Loss (simple RMSE, no physics involved): 0.145856\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:57:31,370] Trial 49 finished with value: 0.13255162288745245 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 97, 'lr': 0.006966874244219716, 'weight_decay': 3.4448033868001565e-08, 'batch_size': 8}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011313 - Val Loss (simple RMSE, no physics involved): 0.140835\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.071976 - Val Loss (simple RMSE, no physics involved): 0.204143\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.028723 - Val Loss (simple RMSE, no physics involved): 0.262797\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.032731 - Val Loss (simple RMSE, no physics involved): 0.233022\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.029215 - Val Loss (simple RMSE, no physics involved): 0.203203\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.029443 - Val Loss (simple RMSE, no physics involved): 0.206372\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.026454 - Val Loss (simple RMSE, no physics involved): 0.206207\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.024248 - Val Loss (simple RMSE, no physics involved): 0.165900\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.017936 - Val Loss (simple RMSE, no physics involved): 0.157563\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.018051 - Val Loss (simple RMSE, no physics involved): 0.152551\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014164 - Val Loss (simple RMSE, no physics involved): 0.152850\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014157 - Val Loss (simple RMSE, no physics involved): 0.151965\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014644 - Val Loss (simple RMSE, no physics involved): 0.144404\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013618 - Val Loss (simple RMSE, no physics involved): 0.151800\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013506 - Val Loss (simple RMSE, no physics involved): 0.144104\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013671 - Val Loss (simple RMSE, no physics involved): 0.144712\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012831 - Val Loss (simple RMSE, no physics involved): 0.143937\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012297 - Val Loss (simple RMSE, no physics involved): 0.144133\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013764 - Val Loss (simple RMSE, no physics involved): 0.142717\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013012 - Val Loss (simple RMSE, no physics involved): 0.141508\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013577 - Val Loss (simple RMSE, no physics involved): 0.142331\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013645 - Val Loss (simple RMSE, no physics involved): 0.144168\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012595 - Val Loss (simple RMSE, no physics involved): 0.142452\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012768 - Val Loss (simple RMSE, no physics involved): 0.141945\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012913 - Val Loss (simple RMSE, no physics involved): 0.141846\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013335 - Val Loss (simple RMSE, no physics involved): 0.143781\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013759 - Val Loss (simple RMSE, no physics involved): 0.143622\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012717 - Val Loss (simple RMSE, no physics involved): 0.141776\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012903 - Val Loss (simple RMSE, no physics involved): 0.143493\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012630 - Val Loss (simple RMSE, no physics involved): 0.142984\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013538 - Val Loss (simple RMSE, no physics involved): 0.141485\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013396 - Val Loss (simple RMSE, no physics involved): 0.141663\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012336 - Val Loss (simple RMSE, no physics involved): 0.153746\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012720 - Val Loss (simple RMSE, no physics involved): 0.140757\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012598 - Val Loss (simple RMSE, no physics involved): 0.143708\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012221 - Val Loss (simple RMSE, no physics involved): 0.148932\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012353 - Val Loss (simple RMSE, no physics involved): 0.142831\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012909 - Val Loss (simple RMSE, no physics involved): 0.142289\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.013004 - Val Loss (simple RMSE, no physics involved): 0.145520\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012307 - Val Loss (simple RMSE, no physics involved): 0.142269\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011932 - Val Loss (simple RMSE, no physics involved): 0.141584\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.013656 - Val Loss (simple RMSE, no physics involved): 0.142367\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011863 - Val Loss (simple RMSE, no physics involved): 0.159267\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013625 - Val Loss (simple RMSE, no physics involved): 0.142167\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012630 - Val Loss (simple RMSE, no physics involved): 0.142214\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012220 - Val Loss (simple RMSE, no physics involved): 0.142349\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011266 - Val Loss (simple RMSE, no physics involved): 0.145822\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012089 - Val Loss (simple RMSE, no physics involved): 0.140893\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011992 - Val Loss (simple RMSE, no physics involved): 0.141542\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011972 - Val Loss (simple RMSE, no physics involved): 0.142168\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:57:46,128] Trial 50 finished with value: 0.14075690507888794 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 82, 'lr': 0.006634287477713881, 'weight_decay': 1.1012109697083568e-08, 'batch_size': 32}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.013443 - Val Loss (simple RMSE, no physics involved): 0.142168\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.084424 - Val Loss (simple RMSE, no physics involved): 0.251866\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.035369 - Val Loss (simple RMSE, no physics involved): 0.193223\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028435 - Val Loss (simple RMSE, no physics involved): 0.213457\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025698 - Val Loss (simple RMSE, no physics involved): 0.161731\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019846 - Val Loss (simple RMSE, no physics involved): 0.151922\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.016501 - Val Loss (simple RMSE, no physics involved): 0.143750\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015144 - Val Loss (simple RMSE, no physics involved): 0.138677\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014140 - Val Loss (simple RMSE, no physics involved): 0.142870\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013794 - Val Loss (simple RMSE, no physics involved): 0.133311\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013454 - Val Loss (simple RMSE, no physics involved): 0.132843\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013651 - Val Loss (simple RMSE, no physics involved): 0.139664\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014059 - Val Loss (simple RMSE, no physics involved): 0.131995\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013362 - Val Loss (simple RMSE, no physics involved): 0.130951\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012526 - Val Loss (simple RMSE, no physics involved): 0.130512\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012914 - Val Loss (simple RMSE, no physics involved): 0.131236\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013223 - Val Loss (simple RMSE, no physics involved): 0.130965\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012772 - Val Loss (simple RMSE, no physics involved): 0.134998\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013260 - Val Loss (simple RMSE, no physics involved): 0.133976\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013491 - Val Loss (simple RMSE, no physics involved): 0.130828\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012883 - Val Loss (simple RMSE, no physics involved): 0.130602\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012566 - Val Loss (simple RMSE, no physics involved): 0.130099\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012037 - Val Loss (simple RMSE, no physics involved): 0.131413\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012307 - Val Loss (simple RMSE, no physics involved): 0.129372\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012910 - Val Loss (simple RMSE, no physics involved): 0.129987\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013120 - Val Loss (simple RMSE, no physics involved): 0.137266\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013404 - Val Loss (simple RMSE, no physics involved): 0.134958\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012612 - Val Loss (simple RMSE, no physics involved): 0.139740\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013008 - Val Loss (simple RMSE, no physics involved): 0.139803\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013033 - Val Loss (simple RMSE, no physics involved): 0.141328\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012904 - Val Loss (simple RMSE, no physics involved): 0.142161\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013427 - Val Loss (simple RMSE, no physics involved): 0.134637\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012713 - Val Loss (simple RMSE, no physics involved): 0.136512\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012643 - Val Loss (simple RMSE, no physics involved): 0.137006\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013128 - Val Loss (simple RMSE, no physics involved): 0.137369\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012265 - Val Loss (simple RMSE, no physics involved): 0.142659\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.013817 - Val Loss (simple RMSE, no physics involved): 0.146804\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013166 - Val Loss (simple RMSE, no physics involved): 0.131594\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012312 - Val Loss (simple RMSE, no physics involved): 0.134948\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012441 - Val Loss (simple RMSE, no physics involved): 0.141132\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012133 - Val Loss (simple RMSE, no physics involved): 0.134677\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012023 - Val Loss (simple RMSE, no physics involved): 0.134411\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012041 - Val Loss (simple RMSE, no physics involved): 0.135224\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012303 - Val Loss (simple RMSE, no physics involved): 0.135174\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011837 - Val Loss (simple RMSE, no physics involved): 0.134318\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011558 - Val Loss (simple RMSE, no physics involved): 0.132604\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011538 - Val Loss (simple RMSE, no physics involved): 0.134309\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012547 - Val Loss (simple RMSE, no physics involved): 0.135940\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011797 - Val Loss (simple RMSE, no physics involved): 0.136102\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011639 - Val Loss (simple RMSE, no physics involved): 0.134535\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:58:09,456] Trial 51 finished with value: 0.129372276365757 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 131, 'lr': 0.003755796437885033, 'weight_decay': 2.2047295829096446e-08, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011768 - Val Loss (simple RMSE, no physics involved): 0.135404\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.047663 - Val Loss (simple RMSE, no physics involved): 0.216715\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.029369 - Val Loss (simple RMSE, no physics involved): 0.210973\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029032 - Val Loss (simple RMSE, no physics involved): 0.205223\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025980 - Val Loss (simple RMSE, no physics involved): 0.171992\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019125 - Val Loss (simple RMSE, no physics involved): 0.141703\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.017443 - Val Loss (simple RMSE, no physics involved): 0.150240\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014290 - Val Loss (simple RMSE, no physics involved): 0.144484\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013868 - Val Loss (simple RMSE, no physics involved): 0.137190\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013687 - Val Loss (simple RMSE, no physics involved): 0.133548\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012958 - Val Loss (simple RMSE, no physics involved): 0.132507\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013118 - Val Loss (simple RMSE, no physics involved): 0.133389\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013422 - Val Loss (simple RMSE, no physics involved): 0.134358\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013472 - Val Loss (simple RMSE, no physics involved): 0.137610\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013698 - Val Loss (simple RMSE, no physics involved): 0.137000\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012625 - Val Loss (simple RMSE, no physics involved): 0.138623\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012814 - Val Loss (simple RMSE, no physics involved): 0.132296\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012042 - Val Loss (simple RMSE, no physics involved): 0.130864\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012463 - Val Loss (simple RMSE, no physics involved): 0.132163\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012771 - Val Loss (simple RMSE, no physics involved): 0.130873\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012711 - Val Loss (simple RMSE, no physics involved): 0.131648\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012556 - Val Loss (simple RMSE, no physics involved): 0.130680\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.011971 - Val Loss (simple RMSE, no physics involved): 0.133138\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012129 - Val Loss (simple RMSE, no physics involved): 0.132160\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012140 - Val Loss (simple RMSE, no physics involved): 0.143854\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013278 - Val Loss (simple RMSE, no physics involved): 0.136909\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012674 - Val Loss (simple RMSE, no physics involved): 0.135896\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012794 - Val Loss (simple RMSE, no physics involved): 0.143973\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012622 - Val Loss (simple RMSE, no physics involved): 0.143698\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012788 - Val Loss (simple RMSE, no physics involved): 0.140942\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012697 - Val Loss (simple RMSE, no physics involved): 0.138904\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012326 - Val Loss (simple RMSE, no physics involved): 0.134812\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012065 - Val Loss (simple RMSE, no physics involved): 0.134899\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012087 - Val Loss (simple RMSE, no physics involved): 0.132956\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011623 - Val Loss (simple RMSE, no physics involved): 0.132418\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011409 - Val Loss (simple RMSE, no physics involved): 0.134467\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012354 - Val Loss (simple RMSE, no physics involved): 0.133504\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011545 - Val Loss (simple RMSE, no physics involved): 0.136944\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012302 - Val Loss (simple RMSE, no physics involved): 0.133563\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012646 - Val Loss (simple RMSE, no physics involved): 0.137829\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011765 - Val Loss (simple RMSE, no physics involved): 0.136667\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011575 - Val Loss (simple RMSE, no physics involved): 0.136581\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012156 - Val Loss (simple RMSE, no physics involved): 0.134211\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011369 - Val Loss (simple RMSE, no physics involved): 0.135325\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011396 - Val Loss (simple RMSE, no physics involved): 0.138653\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011969 - Val Loss (simple RMSE, no physics involved): 0.137209\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011391 - Val Loss (simple RMSE, no physics involved): 0.136235\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011272 - Val Loss (simple RMSE, no physics involved): 0.140409\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012093 - Val Loss (simple RMSE, no physics involved): 0.144372\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011617 - Val Loss (simple RMSE, no physics involved): 0.140735\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:58:31,927] Trial 52 finished with value: 0.13067961484193802 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 112, 'lr': 0.00419330559419202, 'weight_decay': 9.470164047067497e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011554 - Val Loss (simple RMSE, no physics involved): 0.135975\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.062904 - Val Loss (simple RMSE, no physics involved): 0.196023\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.033694 - Val Loss (simple RMSE, no physics involved): 0.237037\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029919 - Val Loss (simple RMSE, no physics involved): 0.202404\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.027042 - Val Loss (simple RMSE, no physics involved): 0.181965\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.022359 - Val Loss (simple RMSE, no physics involved): 0.177056\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.018147 - Val Loss (simple RMSE, no physics involved): 0.146544\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015170 - Val Loss (simple RMSE, no physics involved): 0.138323\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014373 - Val Loss (simple RMSE, no physics involved): 0.137448\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013688 - Val Loss (simple RMSE, no physics involved): 0.135459\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013498 - Val Loss (simple RMSE, no physics involved): 0.134154\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013279 - Val Loss (simple RMSE, no physics involved): 0.136151\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013668 - Val Loss (simple RMSE, no physics involved): 0.133604\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013038 - Val Loss (simple RMSE, no physics involved): 0.136533\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013348 - Val Loss (simple RMSE, no physics involved): 0.138067\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013441 - Val Loss (simple RMSE, no physics involved): 0.133745\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013056 - Val Loss (simple RMSE, no physics involved): 0.135527\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013101 - Val Loss (simple RMSE, no physics involved): 0.131984\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012759 - Val Loss (simple RMSE, no physics involved): 0.130460\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012494 - Val Loss (simple RMSE, no physics involved): 0.130770\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012351 - Val Loss (simple RMSE, no physics involved): 0.131264\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012583 - Val Loss (simple RMSE, no physics involved): 0.132413\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012347 - Val Loss (simple RMSE, no physics involved): 0.131428\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012324 - Val Loss (simple RMSE, no physics involved): 0.131464\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012359 - Val Loss (simple RMSE, no physics involved): 0.132243\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012442 - Val Loss (simple RMSE, no physics involved): 0.131819\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012243 - Val Loss (simple RMSE, no physics involved): 0.131849\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012164 - Val Loss (simple RMSE, no physics involved): 0.131779\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012479 - Val Loss (simple RMSE, no physics involved): 0.132234\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011903 - Val Loss (simple RMSE, no physics involved): 0.131752\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012261 - Val Loss (simple RMSE, no physics involved): 0.131604\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012388 - Val Loss (simple RMSE, no physics involved): 0.132334\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011853 - Val Loss (simple RMSE, no physics involved): 0.131899\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012142 - Val Loss (simple RMSE, no physics involved): 0.133894\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012086 - Val Loss (simple RMSE, no physics involved): 0.132568\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011956 - Val Loss (simple RMSE, no physics involved): 0.143169\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.013432 - Val Loss (simple RMSE, no physics involved): 0.134134\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012283 - Val Loss (simple RMSE, no physics involved): 0.132277\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011765 - Val Loss (simple RMSE, no physics involved): 0.133031\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011979 - Val Loss (simple RMSE, no physics involved): 0.133684\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.013025 - Val Loss (simple RMSE, no physics involved): 0.134324\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012278 - Val Loss (simple RMSE, no physics involved): 0.134973\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012727 - Val Loss (simple RMSE, no physics involved): 0.135278\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012524 - Val Loss (simple RMSE, no physics involved): 0.135310\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012229 - Val Loss (simple RMSE, no physics involved): 0.135106\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012441 - Val Loss (simple RMSE, no physics involved): 0.134779\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012152 - Val Loss (simple RMSE, no physics involved): 0.133852\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011947 - Val Loss (simple RMSE, no physics involved): 0.133932\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012403 - Val Loss (simple RMSE, no physics involved): 0.133187\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012236 - Val Loss (simple RMSE, no physics involved): 0.132493\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:58:55,973] Trial 53 finished with value: 0.13045980408787727 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 141, 'lr': 0.0016473338071695594, 'weight_decay': 5.148633202172506e-08, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011731 - Val Loss (simple RMSE, no physics involved): 0.132808\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.044565 - Val Loss (simple RMSE, no physics involved): 0.205597\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.027198 - Val Loss (simple RMSE, no physics involved): 0.211214\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.024889 - Val Loss (simple RMSE, no physics involved): 0.171432\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.018210 - Val Loss (simple RMSE, no physics involved): 0.147132\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.014939 - Val Loss (simple RMSE, no physics involved): 0.141569\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014355 - Val Loss (simple RMSE, no physics involved): 0.133196\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013752 - Val Loss (simple RMSE, no physics involved): 0.135262\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013244 - Val Loss (simple RMSE, no physics involved): 0.134450\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013347 - Val Loss (simple RMSE, no physics involved): 0.132715\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012905 - Val Loss (simple RMSE, no physics involved): 0.134744\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012740 - Val Loss (simple RMSE, no physics involved): 0.130468\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012612 - Val Loss (simple RMSE, no physics involved): 0.131916\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012588 - Val Loss (simple RMSE, no physics involved): 0.130347\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012748 - Val Loss (simple RMSE, no physics involved): 0.130189\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012322 - Val Loss (simple RMSE, no physics involved): 0.130805\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012588 - Val Loss (simple RMSE, no physics involved): 0.129994\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012284 - Val Loss (simple RMSE, no physics involved): 0.130058\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013149 - Val Loss (simple RMSE, no physics involved): 0.131454\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013119 - Val Loss (simple RMSE, no physics involved): 0.138557\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013390 - Val Loss (simple RMSE, no physics involved): 0.140100\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013061 - Val Loss (simple RMSE, no physics involved): 0.132996\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012684 - Val Loss (simple RMSE, no physics involved): 0.133448\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012715 - Val Loss (simple RMSE, no physics involved): 0.133516\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012399 - Val Loss (simple RMSE, no physics involved): 0.130622\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012138 - Val Loss (simple RMSE, no physics involved): 0.131287\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011955 - Val Loss (simple RMSE, no physics involved): 0.131363\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012225 - Val Loss (simple RMSE, no physics involved): 0.131510\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011767 - Val Loss (simple RMSE, no physics involved): 0.131455\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012097 - Val Loss (simple RMSE, no physics involved): 0.132901\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012142 - Val Loss (simple RMSE, no physics involved): 0.138053\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012236 - Val Loss (simple RMSE, no physics involved): 0.131449\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011996 - Val Loss (simple RMSE, no physics involved): 0.140347\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.013016 - Val Loss (simple RMSE, no physics involved): 0.139036\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012891 - Val Loss (simple RMSE, no physics involved): 0.135295\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012351 - Val Loss (simple RMSE, no physics involved): 0.134440\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012050 - Val Loss (simple RMSE, no physics involved): 0.143022\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013277 - Val Loss (simple RMSE, no physics involved): 0.139868\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012352 - Val Loss (simple RMSE, no physics involved): 0.139948\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012232 - Val Loss (simple RMSE, no physics involved): 0.133929\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011609 - Val Loss (simple RMSE, no physics involved): 0.135234\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011930 - Val Loss (simple RMSE, no physics involved): 0.132819\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011471 - Val Loss (simple RMSE, no physics involved): 0.134139\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011543 - Val Loss (simple RMSE, no physics involved): 0.133269\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011409 - Val Loss (simple RMSE, no physics involved): 0.133527\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012000 - Val Loss (simple RMSE, no physics involved): 0.137253\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012288 - Val Loss (simple RMSE, no physics involved): 0.132999\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011553 - Val Loss (simple RMSE, no physics involved): 0.135324\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011841 - Val Loss (simple RMSE, no physics involved): 0.133023\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011693 - Val Loss (simple RMSE, no physics involved): 0.139539\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:59:20,002] Trial 54 finished with value: 0.12999393045902252 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 150, 'lr': 0.002430824426936809, 'weight_decay': 7.590054964421446e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.013255 - Val Loss (simple RMSE, no physics involved): 0.134821\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.076983 - Val Loss (simple RMSE, no physics involved): 0.308040\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.035970 - Val Loss (simple RMSE, no physics involved): 0.190385\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.030300 - Val Loss (simple RMSE, no physics involved): 0.240628\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.028475 - Val Loss (simple RMSE, no physics involved): 0.178447\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.023844 - Val Loss (simple RMSE, no physics involved): 0.152723\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.017436 - Val Loss (simple RMSE, no physics involved): 0.146010\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015476 - Val Loss (simple RMSE, no physics involved): 0.138294\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015285 - Val Loss (simple RMSE, no physics involved): 0.137011\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.015157 - Val Loss (simple RMSE, no physics involved): 0.135236\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013677 - Val Loss (simple RMSE, no physics involved): 0.136276\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013272 - Val Loss (simple RMSE, no physics involved): 0.135045\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013203 - Val Loss (simple RMSE, no physics involved): 0.134323\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013202 - Val Loss (simple RMSE, no physics involved): 0.132658\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012651 - Val Loss (simple RMSE, no physics involved): 0.131984\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012590 - Val Loss (simple RMSE, no physics involved): 0.132956\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012455 - Val Loss (simple RMSE, no physics involved): 0.134971\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012700 - Val Loss (simple RMSE, no physics involved): 0.130889\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013254 - Val Loss (simple RMSE, no physics involved): 0.133522\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013200 - Val Loss (simple RMSE, no physics involved): 0.132261\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013059 - Val Loss (simple RMSE, no physics involved): 0.132957\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012361 - Val Loss (simple RMSE, no physics involved): 0.133553\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.011994 - Val Loss (simple RMSE, no physics involved): 0.133281\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012477 - Val Loss (simple RMSE, no physics involved): 0.130624\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012242 - Val Loss (simple RMSE, no physics involved): 0.137522\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012311 - Val Loss (simple RMSE, no physics involved): 0.140222\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012519 - Val Loss (simple RMSE, no physics involved): 0.136633\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012181 - Val Loss (simple RMSE, no physics involved): 0.139999\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012298 - Val Loss (simple RMSE, no physics involved): 0.135929\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012186 - Val Loss (simple RMSE, no physics involved): 0.135568\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013230 - Val Loss (simple RMSE, no physics involved): 0.133227\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013097 - Val Loss (simple RMSE, no physics involved): 0.145935\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012157 - Val Loss (simple RMSE, no physics involved): 0.137797\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012008 - Val Loss (simple RMSE, no physics involved): 0.139641\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011740 - Val Loss (simple RMSE, no physics involved): 0.139419\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011733 - Val Loss (simple RMSE, no physics involved): 0.137534\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012121 - Val Loss (simple RMSE, no physics involved): 0.138115\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011499 - Val Loss (simple RMSE, no physics involved): 0.139529\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012705 - Val Loss (simple RMSE, no physics involved): 0.135429\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012690 - Val Loss (simple RMSE, no physics involved): 0.136994\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011641 - Val Loss (simple RMSE, no physics involved): 0.136702\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011759 - Val Loss (simple RMSE, no physics involved): 0.139156\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011679 - Val Loss (simple RMSE, no physics involved): 0.141034\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011555 - Val Loss (simple RMSE, no physics involved): 0.136391\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011582 - Val Loss (simple RMSE, no physics involved): 0.140179\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011720 - Val Loss (simple RMSE, no physics involved): 0.143052\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011612 - Val Loss (simple RMSE, no physics involved): 0.152868\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012199 - Val Loss (simple RMSE, no physics involved): 0.140871\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012406 - Val Loss (simple RMSE, no physics involved): 0.141707\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011938 - Val Loss (simple RMSE, no physics involved): 0.136733\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 17:59:44,817] Trial 55 finished with value: 0.1306237280368805 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 161, 'lr': 0.005212074306118367, 'weight_decay': 4.227809332731655e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012275 - Val Loss (simple RMSE, no physics involved): 0.138450\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.078128 - Val Loss (simple RMSE, no physics involved): 0.193263\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.029710 - Val Loss (simple RMSE, no physics involved): 0.235254\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.026860 - Val Loss (simple RMSE, no physics involved): 0.176685\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.023383 - Val Loss (simple RMSE, no physics involved): 0.172112\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.018392 - Val Loss (simple RMSE, no physics involved): 0.148367\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.016447 - Val Loss (simple RMSE, no physics involved): 0.142652\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014848 - Val Loss (simple RMSE, no physics involved): 0.142159\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013706 - Val Loss (simple RMSE, no physics involved): 0.138416\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013434 - Val Loss (simple RMSE, no physics involved): 0.135647\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013141 - Val Loss (simple RMSE, no physics involved): 0.134309\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012770 - Val Loss (simple RMSE, no physics involved): 0.133612\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013163 - Val Loss (simple RMSE, no physics involved): 0.131778\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012698 - Val Loss (simple RMSE, no physics involved): 0.131299\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012833 - Val Loss (simple RMSE, no physics involved): 0.130667\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012414 - Val Loss (simple RMSE, no physics involved): 0.130363\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013023 - Val Loss (simple RMSE, no physics involved): 0.132065\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012286 - Val Loss (simple RMSE, no physics involved): 0.129540\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012101 - Val Loss (simple RMSE, no physics involved): 0.129694\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012360 - Val Loss (simple RMSE, no physics involved): 0.132277\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012504 - Val Loss (simple RMSE, no physics involved): 0.130360\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012470 - Val Loss (simple RMSE, no physics involved): 0.132728\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012010 - Val Loss (simple RMSE, no physics involved): 0.134024\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012543 - Val Loss (simple RMSE, no physics involved): 0.132624\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012329 - Val Loss (simple RMSE, no physics involved): 0.130417\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011800 - Val Loss (simple RMSE, no physics involved): 0.129935\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012017 - Val Loss (simple RMSE, no physics involved): 0.130078\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011865 - Val Loss (simple RMSE, no physics involved): 0.130677\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012007 - Val Loss (simple RMSE, no physics involved): 0.134535\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012154 - Val Loss (simple RMSE, no physics involved): 0.132832\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012139 - Val Loss (simple RMSE, no physics involved): 0.132661\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011985 - Val Loss (simple RMSE, no physics involved): 0.131030\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011989 - Val Loss (simple RMSE, no physics involved): 0.138538\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012145 - Val Loss (simple RMSE, no physics involved): 0.131700\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012054 - Val Loss (simple RMSE, no physics involved): 0.132865\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011978 - Val Loss (simple RMSE, no physics involved): 0.130704\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011483 - Val Loss (simple RMSE, no physics involved): 0.133368\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011758 - Val Loss (simple RMSE, no physics involved): 0.131383\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011384 - Val Loss (simple RMSE, no physics involved): 0.135518\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011499 - Val Loss (simple RMSE, no physics involved): 0.133121\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011978 - Val Loss (simple RMSE, no physics involved): 0.132600\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011952 - Val Loss (simple RMSE, no physics involved): 0.133194\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011641 - Val Loss (simple RMSE, no physics involved): 0.133698\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011412 - Val Loss (simple RMSE, no physics involved): 0.132869\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011647 - Val Loss (simple RMSE, no physics involved): 0.130306\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011421 - Val Loss (simple RMSE, no physics involved): 0.134001\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011640 - Val Loss (simple RMSE, no physics involved): 0.132801\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011181 - Val Loss (simple RMSE, no physics involved): 0.137165\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011672 - Val Loss (simple RMSE, no physics involved): 0.132026\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011556 - Val Loss (simple RMSE, no physics involved): 0.132188\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:00:10,316] Trial 56 finished with value: 0.1295403689146042 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 176, 'lr': 0.0014173258140852873, 'weight_decay': 1.023905987284993e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011659 - Val Loss (simple RMSE, no physics involved): 0.141031\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.053422 - Val Loss (simple RMSE, no physics involved): 0.211390\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.029212 - Val Loss (simple RMSE, no physics involved): 0.200535\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.020141 - Val Loss (simple RMSE, no physics involved): 0.149559\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.015116 - Val Loss (simple RMSE, no physics involved): 0.140790\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.014483 - Val Loss (simple RMSE, no physics involved): 0.146464\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014622 - Val Loss (simple RMSE, no physics involved): 0.141629\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013328 - Val Loss (simple RMSE, no physics involved): 0.140651\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.012959 - Val Loss (simple RMSE, no physics involved): 0.133320\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.012904 - Val Loss (simple RMSE, no physics involved): 0.151042\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013678 - Val Loss (simple RMSE, no physics involved): 0.140740\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012712 - Val Loss (simple RMSE, no physics involved): 0.135576\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012414 - Val Loss (simple RMSE, no physics involved): 0.134765\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013758 - Val Loss (simple RMSE, no physics involved): 0.137954\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012732 - Val Loss (simple RMSE, no physics involved): 0.138567\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012682 - Val Loss (simple RMSE, no physics involved): 0.133315\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012074 - Val Loss (simple RMSE, no physics involved): 0.135540\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012492 - Val Loss (simple RMSE, no physics involved): 0.139906\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013133 - Val Loss (simple RMSE, no physics involved): 0.148227\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013272 - Val Loss (simple RMSE, no physics involved): 0.136706\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012456 - Val Loss (simple RMSE, no physics involved): 0.136135\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012264 - Val Loss (simple RMSE, no physics involved): 0.140592\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012486 - Val Loss (simple RMSE, no physics involved): 0.138649\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.011733 - Val Loss (simple RMSE, no physics involved): 0.136030\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.011725 - Val Loss (simple RMSE, no physics involved): 0.141558\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011913 - Val Loss (simple RMSE, no physics involved): 0.141652\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012181 - Val Loss (simple RMSE, no physics involved): 0.136821\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012120 - Val Loss (simple RMSE, no physics involved): 0.138870\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012259 - Val Loss (simple RMSE, no physics involved): 0.145233\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011787 - Val Loss (simple RMSE, no physics involved): 0.136825\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012217 - Val Loss (simple RMSE, no physics involved): 0.148985\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012643 - Val Loss (simple RMSE, no physics involved): 0.138091\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011411 - Val Loss (simple RMSE, no physics involved): 0.140847\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011394 - Val Loss (simple RMSE, no physics involved): 0.139610\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011201 - Val Loss (simple RMSE, no physics involved): 0.143076\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011220 - Val Loss (simple RMSE, no physics involved): 0.144072\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011196 - Val Loss (simple RMSE, no physics involved): 0.148062\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011970 - Val Loss (simple RMSE, no physics involved): 0.150222\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011261 - Val Loss (simple RMSE, no physics involved): 0.142842\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011697 - Val Loss (simple RMSE, no physics involved): 0.145988\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011319 - Val Loss (simple RMSE, no physics involved): 0.139237\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011357 - Val Loss (simple RMSE, no physics involved): 0.157652\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011529 - Val Loss (simple RMSE, no physics involved): 0.148750\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011093 - Val Loss (simple RMSE, no physics involved): 0.139649\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011289 - Val Loss (simple RMSE, no physics involved): 0.140912\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011428 - Val Loss (simple RMSE, no physics involved): 0.144589\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011660 - Val Loss (simple RMSE, no physics involved): 0.146327\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011485 - Val Loss (simple RMSE, no physics involved): 0.152541\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011896 - Val Loss (simple RMSE, no physics involved): 0.147776\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011265 - Val Loss (simple RMSE, no physics involved): 0.156387\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:00:50,124] Trial 57 finished with value: 0.13331461946169534 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 130, 'lr': 0.007177424223729633, 'weight_decay': 1.7477349500116342e-07, 'batch_size': 8}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011647 - Val Loss (simple RMSE, no physics involved): 0.144027\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.053679 - Val Loss (simple RMSE, no physics involved): 0.195214\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.028244 - Val Loss (simple RMSE, no physics involved): 0.192489\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.024011 - Val Loss (simple RMSE, no physics involved): 0.157106\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.019664 - Val Loss (simple RMSE, no physics involved): 0.146618\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.016235 - Val Loss (simple RMSE, no physics involved): 0.144298\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014581 - Val Loss (simple RMSE, no physics involved): 0.143958\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014327 - Val Loss (simple RMSE, no physics involved): 0.142689\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014859 - Val Loss (simple RMSE, no physics involved): 0.134907\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013061 - Val Loss (simple RMSE, no physics involved): 0.133830\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013152 - Val Loss (simple RMSE, no physics involved): 0.131754\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012614 - Val Loss (simple RMSE, no physics involved): 0.131307\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012958 - Val Loss (simple RMSE, no physics involved): 0.131940\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013273 - Val Loss (simple RMSE, no physics involved): 0.136441\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012578 - Val Loss (simple RMSE, no physics involved): 0.142569\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013417 - Val Loss (simple RMSE, no physics involved): 0.136625\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013147 - Val Loss (simple RMSE, no physics involved): 0.132226\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012100 - Val Loss (simple RMSE, no physics involved): 0.139740\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012637 - Val Loss (simple RMSE, no physics involved): 0.133604\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012971 - Val Loss (simple RMSE, no physics involved): 0.131906\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012849 - Val Loss (simple RMSE, no physics involved): 0.132659\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012159 - Val Loss (simple RMSE, no physics involved): 0.134805\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012898 - Val Loss (simple RMSE, no physics involved): 0.137221\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012312 - Val Loss (simple RMSE, no physics involved): 0.134819\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012735 - Val Loss (simple RMSE, no physics involved): 0.135495\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012373 - Val Loss (simple RMSE, no physics involved): 0.134300\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011452 - Val Loss (simple RMSE, no physics involved): 0.135881\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011680 - Val Loss (simple RMSE, no physics involved): 0.137612\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011699 - Val Loss (simple RMSE, no physics involved): 0.134696\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012163 - Val Loss (simple RMSE, no physics involved): 0.136707\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011820 - Val Loss (simple RMSE, no physics involved): 0.134834\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011983 - Val Loss (simple RMSE, no physics involved): 0.135227\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012095 - Val Loss (simple RMSE, no physics involved): 0.133756\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011693 - Val Loss (simple RMSE, no physics involved): 0.134889\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011603 - Val Loss (simple RMSE, no physics involved): 0.137307\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011813 - Val Loss (simple RMSE, no physics involved): 0.137558\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012404 - Val Loss (simple RMSE, no physics involved): 0.133626\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011784 - Val Loss (simple RMSE, no physics involved): 0.133040\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011688 - Val Loss (simple RMSE, no physics involved): 0.134023\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011588 - Val Loss (simple RMSE, no physics involved): 0.131648\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011806 - Val Loss (simple RMSE, no physics involved): 0.131864\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012746 - Val Loss (simple RMSE, no physics involved): 0.133203\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011808 - Val Loss (simple RMSE, no physics involved): 0.132559\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011712 - Val Loss (simple RMSE, no physics involved): 0.131519\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011479 - Val Loss (simple RMSE, no physics involved): 0.134352\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012154 - Val Loss (simple RMSE, no physics involved): 0.143523\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011650 - Val Loss (simple RMSE, no physics involved): 0.134896\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011081 - Val Loss (simple RMSE, no physics involved): 0.131305\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011470 - Val Loss (simple RMSE, no physics involved): 0.131557\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011281 - Val Loss (simple RMSE, no physics involved): 0.134262\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:01:14,422] Trial 58 finished with value: 0.13130497187376022 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 122, 'lr': 0.002964296789360894, 'weight_decay': 8.47251607724235e-08, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.010909 - Val Loss (simple RMSE, no physics involved): 0.138235\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.085213 - Val Loss (simple RMSE, no physics involved): 0.193066\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.033589 - Val Loss (simple RMSE, no physics involved): 0.236642\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029543 - Val Loss (simple RMSE, no physics involved): 0.212442\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.026609 - Val Loss (simple RMSE, no physics involved): 0.183181\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.022136 - Val Loss (simple RMSE, no physics involved): 0.169562\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.016788 - Val Loss (simple RMSE, no physics involved): 0.139995\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014988 - Val Loss (simple RMSE, no physics involved): 0.135203\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013887 - Val Loss (simple RMSE, no physics involved): 0.140620\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013682 - Val Loss (simple RMSE, no physics involved): 0.133333\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013179 - Val Loss (simple RMSE, no physics involved): 0.131906\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013141 - Val Loss (simple RMSE, no physics involved): 0.135847\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013654 - Val Loss (simple RMSE, no physics involved): 0.135361\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.014224 - Val Loss (simple RMSE, no physics involved): 0.131631\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012842 - Val Loss (simple RMSE, no physics involved): 0.134110\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012917 - Val Loss (simple RMSE, no physics involved): 0.131172\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012536 - Val Loss (simple RMSE, no physics involved): 0.130847\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012881 - Val Loss (simple RMSE, no physics involved): 0.130723\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013126 - Val Loss (simple RMSE, no physics involved): 0.133403\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012973 - Val Loss (simple RMSE, no physics involved): 0.132560\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012545 - Val Loss (simple RMSE, no physics involved): 0.130731\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012653 - Val Loss (simple RMSE, no physics involved): 0.131179\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012423 - Val Loss (simple RMSE, no physics involved): 0.131372\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012386 - Val Loss (simple RMSE, no physics involved): 0.136328\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013048 - Val Loss (simple RMSE, no physics involved): 0.139502\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013049 - Val Loss (simple RMSE, no physics involved): 0.132108\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012564 - Val Loss (simple RMSE, no physics involved): 0.130871\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012229 - Val Loss (simple RMSE, no physics involved): 0.133751\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012457 - Val Loss (simple RMSE, no physics involved): 0.133411\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012039 - Val Loss (simple RMSE, no physics involved): 0.131462\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012684 - Val Loss (simple RMSE, no physics involved): 0.132060\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012487 - Val Loss (simple RMSE, no physics involved): 0.132423\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011811 - Val Loss (simple RMSE, no physics involved): 0.133587\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012144 - Val Loss (simple RMSE, no physics involved): 0.134358\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012007 - Val Loss (simple RMSE, no physics involved): 0.136993\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012820 - Val Loss (simple RMSE, no physics involved): 0.138273\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011906 - Val Loss (simple RMSE, no physics involved): 0.133576\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011940 - Val Loss (simple RMSE, no physics involved): 0.133068\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012003 - Val Loss (simple RMSE, no physics involved): 0.133669\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012022 - Val Loss (simple RMSE, no physics involved): 0.133363\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012208 - Val Loss (simple RMSE, no physics involved): 0.135828\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011900 - Val Loss (simple RMSE, no physics involved): 0.139958\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011894 - Val Loss (simple RMSE, no physics involved): 0.135901\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012106 - Val Loss (simple RMSE, no physics involved): 0.139555\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011708 - Val Loss (simple RMSE, no physics involved): 0.136937\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012031 - Val Loss (simple RMSE, no physics involved): 0.140480\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011764 - Val Loss (simple RMSE, no physics involved): 0.135640\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011651 - Val Loss (simple RMSE, no physics involved): 0.137750\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011554 - Val Loss (simple RMSE, no physics involved): 0.140048\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011377 - Val Loss (simple RMSE, no physics involved): 0.135556\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:01:37,466] Trial 59 finished with value: 0.13072344660758972 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 116, 'lr': 0.001963675196887278, 'weight_decay': 2.922613924151005e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011739 - Val Loss (simple RMSE, no physics involved): 0.137273\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.066047 - Val Loss (simple RMSE, no physics involved): 0.346306\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.058827 - Val Loss (simple RMSE, no physics involved): 0.334426\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.054346 - Val Loss (simple RMSE, no physics involved): 0.322719\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.050928 - Val Loss (simple RMSE, no physics involved): 0.311213\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.046937 - Val Loss (simple RMSE, no physics involved): 0.299694\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.040847 - Val Loss (simple RMSE, no physics involved): 0.288146\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.038956 - Val Loss (simple RMSE, no physics involved): 0.276744\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.036818 - Val Loss (simple RMSE, no physics involved): 0.265528\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.032807 - Val Loss (simple RMSE, no physics involved): 0.254733\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.031140 - Val Loss (simple RMSE, no physics involved): 0.244792\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.029305 - Val Loss (simple RMSE, no physics involved): 0.235570\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.029869 - Val Loss (simple RMSE, no physics involved): 0.227766\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.028377 - Val Loss (simple RMSE, no physics involved): 0.221321\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.028329 - Val Loss (simple RMSE, no physics involved): 0.216675\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.029234 - Val Loss (simple RMSE, no physics involved): 0.213801\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.029399 - Val Loss (simple RMSE, no physics involved): 0.212639\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.029502 - Val Loss (simple RMSE, no physics involved): 0.212860\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.029290 - Val Loss (simple RMSE, no physics involved): 0.213882\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.028233 - Val Loss (simple RMSE, no physics involved): 0.215579\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.028171 - Val Loss (simple RMSE, no physics involved): 0.217705\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.028483 - Val Loss (simple RMSE, no physics involved): 0.219983\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.027730 - Val Loss (simple RMSE, no physics involved): 0.221939\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.028513 - Val Loss (simple RMSE, no physics involved): 0.223325\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.027667 - Val Loss (simple RMSE, no physics involved): 0.223670\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.027415 - Val Loss (simple RMSE, no physics involved): 0.223025\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.028125 - Val Loss (simple RMSE, no physics involved): 0.221871\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.026292 - Val Loss (simple RMSE, no physics involved): 0.219749\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.027063 - Val Loss (simple RMSE, no physics involved): 0.217803\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.025990 - Val Loss (simple RMSE, no physics involved): 0.215225\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.026802 - Val Loss (simple RMSE, no physics involved): 0.212536\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.026509 - Val Loss (simple RMSE, no physics involved): 0.209905\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.026177 - Val Loss (simple RMSE, no physics involved): 0.206897\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.025809 - Val Loss (simple RMSE, no physics involved): 0.203750\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.024235 - Val Loss (simple RMSE, no physics involved): 0.200636\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.023858 - Val Loss (simple RMSE, no physics involved): 0.197578\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.023223 - Val Loss (simple RMSE, no physics involved): 0.194141\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.023118 - Val Loss (simple RMSE, no physics involved): 0.190611\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.022343 - Val Loss (simple RMSE, no physics involved): 0.186191\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.021310 - Val Loss (simple RMSE, no physics involved): 0.181211\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.020054 - Val Loss (simple RMSE, no physics involved): 0.175210\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.019546 - Val Loss (simple RMSE, no physics involved): 0.169363\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.019462 - Val Loss (simple RMSE, no physics involved): 0.163834\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.018591 - Val Loss (simple RMSE, no physics involved): 0.158361\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.017848 - Val Loss (simple RMSE, no physics involved): 0.153798\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.016796 - Val Loss (simple RMSE, no physics involved): 0.151081\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.016380 - Val Loss (simple RMSE, no physics involved): 0.149674\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.016196 - Val Loss (simple RMSE, no physics involved): 0.148938\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.015565 - Val Loss (simple RMSE, no physics involved): 0.147941\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.015390 - Val Loss (simple RMSE, no physics involved): 0.146956\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:01:43,373] Trial 60 finished with value: 0.146240234375 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 40, 'lr': 0.000822819381387762, 'weight_decay': 6.239874706654236e-06, 'batch_size': 64}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.014963 - Val Loss (simple RMSE, no physics involved): 0.146240\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.045144 - Val Loss (simple RMSE, no physics involved): 0.203368\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.021163 - Val Loss (simple RMSE, no physics involved): 0.177056\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.018489 - Val Loss (simple RMSE, no physics involved): 0.164684\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.015841 - Val Loss (simple RMSE, no physics involved): 0.138595\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.014421 - Val Loss (simple RMSE, no physics involved): 0.142494\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015225 - Val Loss (simple RMSE, no physics involved): 0.138737\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014932 - Val Loss (simple RMSE, no physics involved): 0.133912\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013447 - Val Loss (simple RMSE, no physics involved): 0.138608\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013007 - Val Loss (simple RMSE, no physics involved): 0.134375\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012711 - Val Loss (simple RMSE, no physics involved): 0.135427\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013084 - Val Loss (simple RMSE, no physics involved): 0.134791\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012576 - Val Loss (simple RMSE, no physics involved): 0.134366\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013008 - Val Loss (simple RMSE, no physics involved): 0.135058\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012687 - Val Loss (simple RMSE, no physics involved): 0.137077\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012880 - Val Loss (simple RMSE, no physics involved): 0.134314\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012403 - Val Loss (simple RMSE, no physics involved): 0.134582\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012590 - Val Loss (simple RMSE, no physics involved): 0.132062\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012180 - Val Loss (simple RMSE, no physics involved): 0.132728\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012370 - Val Loss (simple RMSE, no physics involved): 0.132894\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.011826 - Val Loss (simple RMSE, no physics involved): 0.133291\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012090 - Val Loss (simple RMSE, no physics involved): 0.133476\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.011846 - Val Loss (simple RMSE, no physics involved): 0.132178\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012271 - Val Loss (simple RMSE, no physics involved): 0.134370\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012044 - Val Loss (simple RMSE, no physics involved): 0.135378\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012847 - Val Loss (simple RMSE, no physics involved): 0.136215\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012357 - Val Loss (simple RMSE, no physics involved): 0.135415\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012343 - Val Loss (simple RMSE, no physics involved): 0.143000\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013162 - Val Loss (simple RMSE, no physics involved): 0.134610\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.014092 - Val Loss (simple RMSE, no physics involved): 0.138532\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012951 - Val Loss (simple RMSE, no physics involved): 0.135024\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011795 - Val Loss (simple RMSE, no physics involved): 0.133658\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011620 - Val Loss (simple RMSE, no physics involved): 0.136054\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012194 - Val Loss (simple RMSE, no physics involved): 0.141571\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012077 - Val Loss (simple RMSE, no physics involved): 0.135542\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011993 - Val Loss (simple RMSE, no physics involved): 0.133153\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011525 - Val Loss (simple RMSE, no physics involved): 0.134388\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011656 - Val Loss (simple RMSE, no physics involved): 0.135891\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011223 - Val Loss (simple RMSE, no physics involved): 0.142496\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012527 - Val Loss (simple RMSE, no physics involved): 0.137190\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011316 - Val Loss (simple RMSE, no physics involved): 0.138967\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011350 - Val Loss (simple RMSE, no physics involved): 0.138067\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011278 - Val Loss (simple RMSE, no physics involved): 0.148610\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012101 - Val Loss (simple RMSE, no physics involved): 0.137972\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013038 - Val Loss (simple RMSE, no physics involved): 0.139547\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012157 - Val Loss (simple RMSE, no physics involved): 0.135705\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011989 - Val Loss (simple RMSE, no physics involved): 0.133087\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011312 - Val Loss (simple RMSE, no physics involved): 0.133821\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011348 - Val Loss (simple RMSE, no physics involved): 0.136329\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012580 - Val Loss (simple RMSE, no physics involved): 0.132004\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:02:04,912] Trial 61 finished with value: 0.13200395926833153 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 158, 'lr': 0.004017685197121229, 'weight_decay': 2.174864664810679e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012054 - Val Loss (simple RMSE, no physics involved): 0.142941\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.047141 - Val Loss (simple RMSE, no physics involved): 0.167673\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.019634 - Val Loss (simple RMSE, no physics involved): 0.150104\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.014690 - Val Loss (simple RMSE, no physics involved): 0.143701\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.013946 - Val Loss (simple RMSE, no physics involved): 0.136776\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.013505 - Val Loss (simple RMSE, no physics involved): 0.137704\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.013388 - Val Loss (simple RMSE, no physics involved): 0.148981\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013097 - Val Loss (simple RMSE, no physics involved): 0.136978\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.012815 - Val Loss (simple RMSE, no physics involved): 0.132948\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013314 - Val Loss (simple RMSE, no physics involved): 0.130649\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012532 - Val Loss (simple RMSE, no physics involved): 0.132072\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012469 - Val Loss (simple RMSE, no physics involved): 0.130982\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013101 - Val Loss (simple RMSE, no physics involved): 0.131085\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012200 - Val Loss (simple RMSE, no physics involved): 0.135655\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012472 - Val Loss (simple RMSE, no physics involved): 0.132559\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012695 - Val Loss (simple RMSE, no physics involved): 0.136322\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.014203 - Val Loss (simple RMSE, no physics involved): 0.130349\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.014388 - Val Loss (simple RMSE, no physics involved): 0.134819\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013079 - Val Loss (simple RMSE, no physics involved): 0.160115\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.014789 - Val Loss (simple RMSE, no physics involved): 0.148125\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.014518 - Val Loss (simple RMSE, no physics involved): 0.143775\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013941 - Val Loss (simple RMSE, no physics involved): 0.134533\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012873 - Val Loss (simple RMSE, no physics involved): 0.140293\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012837 - Val Loss (simple RMSE, no physics involved): 0.140855\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012346 - Val Loss (simple RMSE, no physics involved): 0.142472\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013245 - Val Loss (simple RMSE, no physics involved): 0.140792\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013085 - Val Loss (simple RMSE, no physics involved): 0.135241\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012175 - Val Loss (simple RMSE, no physics involved): 0.132648\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011954 - Val Loss (simple RMSE, no physics involved): 0.131640\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012104 - Val Loss (simple RMSE, no physics involved): 0.131058\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011695 - Val Loss (simple RMSE, no physics involved): 0.132080\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011685 - Val Loss (simple RMSE, no physics involved): 0.131100\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011777 - Val Loss (simple RMSE, no physics involved): 0.132287\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011192 - Val Loss (simple RMSE, no physics involved): 0.132930\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012294 - Val Loss (simple RMSE, no physics involved): 0.131978\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012059 - Val Loss (simple RMSE, no physics involved): 0.133238\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011672 - Val Loss (simple RMSE, no physics involved): 0.137221\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011784 - Val Loss (simple RMSE, no physics involved): 0.137487\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011916 - Val Loss (simple RMSE, no physics involved): 0.135459\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011959 - Val Loss (simple RMSE, no physics involved): 0.131647\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012741 - Val Loss (simple RMSE, no physics involved): 0.132628\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011942 - Val Loss (simple RMSE, no physics involved): 0.130808\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011666 - Val Loss (simple RMSE, no physics involved): 0.133680\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012125 - Val Loss (simple RMSE, no physics involved): 0.129101\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012016 - Val Loss (simple RMSE, no physics involved): 0.136642\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011834 - Val Loss (simple RMSE, no physics involved): 0.142351\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011279 - Val Loss (simple RMSE, no physics involved): 0.131894\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011593 - Val Loss (simple RMSE, no physics involved): 0.131960\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011357 - Val Loss (simple RMSE, no physics involved): 0.132803\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011257 - Val Loss (simple RMSE, no physics involved): 0.132283\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:02:20,143] Trial 62 finished with value: 0.12910090386867523 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 172, 'lr': 0.00572354046989252, 'weight_decay': 9.95939243359168e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011427 - Val Loss (simple RMSE, no physics involved): 0.135254\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.096956 - Val Loss (simple RMSE, no physics involved): 0.207005\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.041408 - Val Loss (simple RMSE, no physics involved): 0.197711\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029165 - Val Loss (simple RMSE, no physics involved): 0.209382\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.023243 - Val Loss (simple RMSE, no physics involved): 0.165629\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019559 - Val Loss (simple RMSE, no physics involved): 0.164887\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.017273 - Val Loss (simple RMSE, no physics involved): 0.154765\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015083 - Val Loss (simple RMSE, no physics involved): 0.146649\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014865 - Val Loss (simple RMSE, no physics involved): 0.149487\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014158 - Val Loss (simple RMSE, no physics involved): 0.140326\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013492 - Val Loss (simple RMSE, no physics involved): 0.137294\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013603 - Val Loss (simple RMSE, no physics involved): 0.140225\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013270 - Val Loss (simple RMSE, no physics involved): 0.134432\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013447 - Val Loss (simple RMSE, no physics involved): 0.133977\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012669 - Val Loss (simple RMSE, no physics involved): 0.133583\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012279 - Val Loss (simple RMSE, no physics involved): 0.133535\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012617 - Val Loss (simple RMSE, no physics involved): 0.133641\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012402 - Val Loss (simple RMSE, no physics involved): 0.134102\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012150 - Val Loss (simple RMSE, no physics involved): 0.132259\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012317 - Val Loss (simple RMSE, no physics involved): 0.132905\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012622 - Val Loss (simple RMSE, no physics involved): 0.133203\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012262 - Val Loss (simple RMSE, no physics involved): 0.134181\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012073 - Val Loss (simple RMSE, no physics involved): 0.132680\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012159 - Val Loss (simple RMSE, no physics involved): 0.135632\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012461 - Val Loss (simple RMSE, no physics involved): 0.132616\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012312 - Val Loss (simple RMSE, no physics involved): 0.133805\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012608 - Val Loss (simple RMSE, no physics involved): 0.132542\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012556 - Val Loss (simple RMSE, no physics involved): 0.136259\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012349 - Val Loss (simple RMSE, no physics involved): 0.132677\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012063 - Val Loss (simple RMSE, no physics involved): 0.133186\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011915 - Val Loss (simple RMSE, no physics involved): 0.133689\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012057 - Val Loss (simple RMSE, no physics involved): 0.132479\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011735 - Val Loss (simple RMSE, no physics involved): 0.131983\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012039 - Val Loss (simple RMSE, no physics involved): 0.132114\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012148 - Val Loss (simple RMSE, no physics involved): 0.134198\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011678 - Val Loss (simple RMSE, no physics involved): 0.130388\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011847 - Val Loss (simple RMSE, no physics involved): 0.130272\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011554 - Val Loss (simple RMSE, no physics involved): 0.132831\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011416 - Val Loss (simple RMSE, no physics involved): 0.131424\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011751 - Val Loss (simple RMSE, no physics involved): 0.131990\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012259 - Val Loss (simple RMSE, no physics involved): 0.133326\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011717 - Val Loss (simple RMSE, no physics involved): 0.133035\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011870 - Val Loss (simple RMSE, no physics involved): 0.134556\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011395 - Val Loss (simple RMSE, no physics involved): 0.133086\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011703 - Val Loss (simple RMSE, no physics involved): 0.132834\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011750 - Val Loss (simple RMSE, no physics involved): 0.133635\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012257 - Val Loss (simple RMSE, no physics involved): 0.138341\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012146 - Val Loss (simple RMSE, no physics involved): 0.130918\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011795 - Val Loss (simple RMSE, no physics involved): 0.131754\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011635 - Val Loss (simple RMSE, no physics involved): 0.131543\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:02:38,043] Trial 63 finished with value: 0.1302715763449669 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 141, 'lr': 0.001208104268321251, 'weight_decay': 1.8431740499030915e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011344 - Val Loss (simple RMSE, no physics involved): 0.132239\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.075847 - Val Loss (simple RMSE, no physics involved): 0.300667\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.040862 - Val Loss (simple RMSE, no physics involved): 0.188357\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.025520 - Val Loss (simple RMSE, no physics involved): 0.185825\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.019856 - Val Loss (simple RMSE, no physics involved): 0.152018\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.016657 - Val Loss (simple RMSE, no physics involved): 0.141433\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014780 - Val Loss (simple RMSE, no physics involved): 0.141641\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013567 - Val Loss (simple RMSE, no physics involved): 0.137806\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013243 - Val Loss (simple RMSE, no physics involved): 0.135454\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.012994 - Val Loss (simple RMSE, no physics involved): 0.137212\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012751 - Val Loss (simple RMSE, no physics involved): 0.133809\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012738 - Val Loss (simple RMSE, no physics involved): 0.140444\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013334 - Val Loss (simple RMSE, no physics involved): 0.144195\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013925 - Val Loss (simple RMSE, no physics involved): 0.136285\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013349 - Val Loss (simple RMSE, no physics involved): 0.137403\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013364 - Val Loss (simple RMSE, no physics involved): 0.134983\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012826 - Val Loss (simple RMSE, no physics involved): 0.147994\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013132 - Val Loss (simple RMSE, no physics involved): 0.138302\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012666 - Val Loss (simple RMSE, no physics involved): 0.134906\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012687 - Val Loss (simple RMSE, no physics involved): 0.134411\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012607 - Val Loss (simple RMSE, no physics involved): 0.134100\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012189 - Val Loss (simple RMSE, no physics involved): 0.136982\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.011979 - Val Loss (simple RMSE, no physics involved): 0.140117\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012055 - Val Loss (simple RMSE, no physics involved): 0.140273\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012170 - Val Loss (simple RMSE, no physics involved): 0.136747\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011742 - Val Loss (simple RMSE, no physics involved): 0.137684\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012072 - Val Loss (simple RMSE, no physics involved): 0.138707\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011603 - Val Loss (simple RMSE, no physics involved): 0.135406\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011374 - Val Loss (simple RMSE, no physics involved): 0.137211\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012656 - Val Loss (simple RMSE, no physics involved): 0.135479\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011752 - Val Loss (simple RMSE, no physics involved): 0.136216\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012360 - Val Loss (simple RMSE, no physics involved): 0.136986\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012345 - Val Loss (simple RMSE, no physics involved): 0.138396\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012285 - Val Loss (simple RMSE, no physics involved): 0.148677\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011397 - Val Loss (simple RMSE, no physics involved): 0.145209\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012095 - Val Loss (simple RMSE, no physics involved): 0.146141\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012612 - Val Loss (simple RMSE, no physics involved): 0.154177\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011712 - Val Loss (simple RMSE, no physics involved): 0.157462\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012099 - Val Loss (simple RMSE, no physics involved): 0.137788\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011472 - Val Loss (simple RMSE, no physics involved): 0.139086\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011587 - Val Loss (simple RMSE, no physics involved): 0.141469\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011774 - Val Loss (simple RMSE, no physics involved): 0.137043\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011858 - Val Loss (simple RMSE, no physics involved): 0.140498\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011341 - Val Loss (simple RMSE, no physics involved): 0.135208\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011208 - Val Loss (simple RMSE, no physics involved): 0.140195\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011237 - Val Loss (simple RMSE, no physics involved): 0.136049\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.010973 - Val Loss (simple RMSE, no physics involved): 0.137604\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011323 - Val Loss (simple RMSE, no physics involved): 0.149175\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011016 - Val Loss (simple RMSE, no physics involved): 0.143714\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011346 - Val Loss (simple RMSE, no physics involved): 0.139078\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:03:00,696] Trial 64 finished with value: 0.13380882143974304 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 184, 'lr': 0.002848626466479077, 'weight_decay': 3.578328713068162e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.010883 - Val Loss (simple RMSE, no physics involved): 0.140217\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.161064 - Val Loss (simple RMSE, no physics involved): 0.392123\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.067032 - Val Loss (simple RMSE, no physics involved): 0.188791\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.033660 - Val Loss (simple RMSE, no physics involved): 0.213181\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.026753 - Val Loss (simple RMSE, no physics involved): 0.209423\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.024464 - Val Loss (simple RMSE, no physics involved): 0.159080\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.019164 - Val Loss (simple RMSE, no physics involved): 0.149332\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.016563 - Val Loss (simple RMSE, no physics involved): 0.146793\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014443 - Val Loss (simple RMSE, no physics involved): 0.146480\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014548 - Val Loss (simple RMSE, no physics involved): 0.142656\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013602 - Val Loss (simple RMSE, no physics involved): 0.133975\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014002 - Val Loss (simple RMSE, no physics involved): 0.135118\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013973 - Val Loss (simple RMSE, no physics involved): 0.135495\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013023 - Val Loss (simple RMSE, no physics involved): 0.135247\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013272 - Val Loss (simple RMSE, no physics involved): 0.132758\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012678 - Val Loss (simple RMSE, no physics involved): 0.132692\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012908 - Val Loss (simple RMSE, no physics involved): 0.132115\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012866 - Val Loss (simple RMSE, no physics involved): 0.131143\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012267 - Val Loss (simple RMSE, no physics involved): 0.131608\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.011976 - Val Loss (simple RMSE, no physics involved): 0.134163\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012725 - Val Loss (simple RMSE, no physics involved): 0.133297\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012551 - Val Loss (simple RMSE, no physics involved): 0.134080\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012510 - Val Loss (simple RMSE, no physics involved): 0.132263\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012204 - Val Loss (simple RMSE, no physics involved): 0.133342\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012334 - Val Loss (simple RMSE, no physics involved): 0.131906\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012055 - Val Loss (simple RMSE, no physics involved): 0.134239\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012252 - Val Loss (simple RMSE, no physics involved): 0.136206\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011798 - Val Loss (simple RMSE, no physics involved): 0.138391\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011532 - Val Loss (simple RMSE, no physics involved): 0.137927\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011941 - Val Loss (simple RMSE, no physics involved): 0.136058\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012218 - Val Loss (simple RMSE, no physics involved): 0.137852\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012328 - Val Loss (simple RMSE, no physics involved): 0.144242\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012049 - Val Loss (simple RMSE, no physics involved): 0.136795\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011546 - Val Loss (simple RMSE, no physics involved): 0.136837\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011421 - Val Loss (simple RMSE, no physics involved): 0.135082\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011747 - Val Loss (simple RMSE, no physics involved): 0.137008\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011674 - Val Loss (simple RMSE, no physics involved): 0.137080\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011403 - Val Loss (simple RMSE, no physics involved): 0.136698\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011425 - Val Loss (simple RMSE, no physics involved): 0.135017\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011626 - Val Loss (simple RMSE, no physics involved): 0.136299\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011700 - Val Loss (simple RMSE, no physics involved): 0.133884\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011415 - Val Loss (simple RMSE, no physics involved): 0.139347\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011300 - Val Loss (simple RMSE, no physics involved): 0.138876\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011305 - Val Loss (simple RMSE, no physics involved): 0.141741\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011350 - Val Loss (simple RMSE, no physics involved): 0.141108\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011842 - Val Loss (simple RMSE, no physics involved): 0.137442\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011139 - Val Loss (simple RMSE, no physics involved): 0.143140\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011282 - Val Loss (simple RMSE, no physics involved): 0.151188\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011940 - Val Loss (simple RMSE, no physics involved): 0.140477\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.013358 - Val Loss (simple RMSE, no physics involved): 0.144161\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:03:22,561] Trial 65 finished with value: 0.13114338740706444 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 153, 'lr': 0.007748241083046387, 'weight_decay': 7.341901214031017e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012807 - Val Loss (simple RMSE, no physics involved): 0.138280\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.072931 - Val Loss (simple RMSE, no physics involved): 0.283608\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.035676 - Val Loss (simple RMSE, no physics involved): 0.185642\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028389 - Val Loss (simple RMSE, no physics involved): 0.221167\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.027380 - Val Loss (simple RMSE, no physics involved): 0.196478\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.024955 - Val Loss (simple RMSE, no physics involved): 0.179536\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.022692 - Val Loss (simple RMSE, no physics involved): 0.180756\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.019843 - Val Loss (simple RMSE, no physics involved): 0.155420\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.016735 - Val Loss (simple RMSE, no physics involved): 0.148875\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.015293 - Val Loss (simple RMSE, no physics involved): 0.151249\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.015064 - Val Loss (simple RMSE, no physics involved): 0.141065\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013492 - Val Loss (simple RMSE, no physics involved): 0.138644\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014152 - Val Loss (simple RMSE, no physics involved): 0.139100\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013326 - Val Loss (simple RMSE, no physics involved): 0.139944\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.014448 - Val Loss (simple RMSE, no physics involved): 0.135598\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013049 - Val Loss (simple RMSE, no physics involved): 0.137201\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013297 - Val Loss (simple RMSE, no physics involved): 0.134877\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012994 - Val Loss (simple RMSE, no physics involved): 0.133385\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012835 - Val Loss (simple RMSE, no physics involved): 0.133490\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012673 - Val Loss (simple RMSE, no physics involved): 0.132336\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013010 - Val Loss (simple RMSE, no physics involved): 0.132310\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013286 - Val Loss (simple RMSE, no physics involved): 0.132407\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012498 - Val Loss (simple RMSE, no physics involved): 0.133795\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012495 - Val Loss (simple RMSE, no physics involved): 0.132532\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012908 - Val Loss (simple RMSE, no physics involved): 0.133735\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012542 - Val Loss (simple RMSE, no physics involved): 0.131917\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012570 - Val Loss (simple RMSE, no physics involved): 0.134051\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012260 - Val Loss (simple RMSE, no physics involved): 0.131825\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012367 - Val Loss (simple RMSE, no physics involved): 0.132112\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012515 - Val Loss (simple RMSE, no physics involved): 0.131900\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012429 - Val Loss (simple RMSE, no physics involved): 0.132169\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012629 - Val Loss (simple RMSE, no physics involved): 0.132393\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012734 - Val Loss (simple RMSE, no physics involved): 0.133185\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012179 - Val Loss (simple RMSE, no physics involved): 0.132531\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012140 - Val Loss (simple RMSE, no physics involved): 0.132319\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012364 - Val Loss (simple RMSE, no physics involved): 0.133605\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012282 - Val Loss (simple RMSE, no physics involved): 0.132944\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011926 - Val Loss (simple RMSE, no physics involved): 0.132084\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011722 - Val Loss (simple RMSE, no physics involved): 0.131822\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012500 - Val Loss (simple RMSE, no physics involved): 0.132257\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011789 - Val Loss (simple RMSE, no physics involved): 0.134140\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012311 - Val Loss (simple RMSE, no physics involved): 0.133416\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011867 - Val Loss (simple RMSE, no physics involved): 0.133146\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012033 - Val Loss (simple RMSE, no physics involved): 0.133420\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011804 - Val Loss (simple RMSE, no physics involved): 0.133079\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011665 - Val Loss (simple RMSE, no physics involved): 0.133614\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011992 - Val Loss (simple RMSE, no physics involved): 0.133430\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011878 - Val Loss (simple RMSE, no physics involved): 0.133261\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011876 - Val Loss (simple RMSE, no physics involved): 0.134922\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011849 - Val Loss (simple RMSE, no physics involved): 0.136369\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:03:54,230] Trial 66 finished with value: 0.1318219155073166 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 235, 'lr': 0.00044606811015744234, 'weight_decay': 2.7026185109588824e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011850 - Val Loss (simple RMSE, no physics involved): 0.134826\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.084262 - Val Loss (simple RMSE, no physics involved): 0.319828\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.049149 - Val Loss (simple RMSE, no physics involved): 0.219929\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.030263 - Val Loss (simple RMSE, no physics involved): 0.235163\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.028468 - Val Loss (simple RMSE, no physics involved): 0.187707\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.022694 - Val Loss (simple RMSE, no physics involved): 0.166983\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.018383 - Val Loss (simple RMSE, no physics involved): 0.145064\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015533 - Val Loss (simple RMSE, no physics involved): 0.145319\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014957 - Val Loss (simple RMSE, no physics involved): 0.145613\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014173 - Val Loss (simple RMSE, no physics involved): 0.142538\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014529 - Val Loss (simple RMSE, no physics involved): 0.141762\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013830 - Val Loss (simple RMSE, no physics involved): 0.136147\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012965 - Val Loss (simple RMSE, no physics involved): 0.136125\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013048 - Val Loss (simple RMSE, no physics involved): 0.132953\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013306 - Val Loss (simple RMSE, no physics involved): 0.135940\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.014080 - Val Loss (simple RMSE, no physics involved): 0.134462\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013193 - Val Loss (simple RMSE, no physics involved): 0.133617\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013714 - Val Loss (simple RMSE, no physics involved): 0.136375\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.015007 - Val Loss (simple RMSE, no physics involved): 0.141642\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013860 - Val Loss (simple RMSE, no physics involved): 0.139395\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013428 - Val Loss (simple RMSE, no physics involved): 0.132117\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013157 - Val Loss (simple RMSE, no physics involved): 0.132312\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013251 - Val Loss (simple RMSE, no physics involved): 0.134239\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013242 - Val Loss (simple RMSE, no physics involved): 0.132585\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012962 - Val Loss (simple RMSE, no physics involved): 0.132954\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013242 - Val Loss (simple RMSE, no physics involved): 0.132307\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012863 - Val Loss (simple RMSE, no physics involved): 0.130863\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013102 - Val Loss (simple RMSE, no physics involved): 0.133477\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013007 - Val Loss (simple RMSE, no physics involved): 0.131901\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012775 - Val Loss (simple RMSE, no physics involved): 0.138001\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013372 - Val Loss (simple RMSE, no physics involved): 0.140871\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013492 - Val Loss (simple RMSE, no physics involved): 0.145797\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.014195 - Val Loss (simple RMSE, no physics involved): 0.139325\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.013864 - Val Loss (simple RMSE, no physics involved): 0.137645\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013856 - Val Loss (simple RMSE, no physics involved): 0.132621\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.014053 - Val Loss (simple RMSE, no physics involved): 0.134033\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012959 - Val Loss (simple RMSE, no physics involved): 0.134076\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012465 - Val Loss (simple RMSE, no physics involved): 0.135015\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012973 - Val Loss (simple RMSE, no physics involved): 0.132583\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013041 - Val Loss (simple RMSE, no physics involved): 0.134655\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012829 - Val Loss (simple RMSE, no physics involved): 0.133321\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012451 - Val Loss (simple RMSE, no physics involved): 0.132225\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012880 - Val Loss (simple RMSE, no physics involved): 0.131897\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013082 - Val Loss (simple RMSE, no physics involved): 0.131118\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013296 - Val Loss (simple RMSE, no physics involved): 0.132797\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.013250 - Val Loss (simple RMSE, no physics involved): 0.132612\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012748 - Val Loss (simple RMSE, no physics involved): 0.132450\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012901 - Val Loss (simple RMSE, no physics involved): 0.131596\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.013107 - Val Loss (simple RMSE, no physics involved): 0.132777\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.014076 - Val Loss (simple RMSE, no physics involved): 0.145422\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:04:17,308] Trial 67 finished with value: 0.1308634988963604 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 164, 'lr': 0.004355820762164031, 'weight_decay': 0.0007688889756834434, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.013602 - Val Loss (simple RMSE, no physics involved): 0.138595\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.146451 - Val Loss (simple RMSE, no physics involved): 0.463137\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.130193 - Val Loss (simple RMSE, no physics involved): 0.444048\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.119663 - Val Loss (simple RMSE, no physics involved): 0.424770\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.104000 - Val Loss (simple RMSE, no physics involved): 0.402610\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.090609 - Val Loss (simple RMSE, no physics involved): 0.376940\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.076725 - Val Loss (simple RMSE, no physics involved): 0.345026\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.060685 - Val Loss (simple RMSE, no physics involved): 0.306713\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.044465 - Val Loss (simple RMSE, no physics involved): 0.261107\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.032677 - Val Loss (simple RMSE, no physics involved): 0.219402\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.029839 - Val Loss (simple RMSE, no physics involved): 0.199213\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.029515 - Val Loss (simple RMSE, no physics involved): 0.200481\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.028796 - Val Loss (simple RMSE, no physics involved): 0.208625\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.027894 - Val Loss (simple RMSE, no physics involved): 0.209488\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.027223 - Val Loss (simple RMSE, no physics involved): 0.204648\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.026480 - Val Loss (simple RMSE, no physics involved): 0.201824\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.026773 - Val Loss (simple RMSE, no physics involved): 0.197588\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.026282 - Val Loss (simple RMSE, no physics involved): 0.195387\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.024477 - Val Loss (simple RMSE, no physics involved): 0.189499\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.023822 - Val Loss (simple RMSE, no physics involved): 0.188277\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.022870 - Val Loss (simple RMSE, no physics involved): 0.183146\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.022331 - Val Loss (simple RMSE, no physics involved): 0.182144\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.021687 - Val Loss (simple RMSE, no physics involved): 0.174526\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.019880 - Val Loss (simple RMSE, no physics involved): 0.169564\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.019677 - Val Loss (simple RMSE, no physics involved): 0.166175\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.017911 - Val Loss (simple RMSE, no physics involved): 0.160877\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.017277 - Val Loss (simple RMSE, no physics involved): 0.156679\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.016567 - Val Loss (simple RMSE, no physics involved): 0.152484\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.016082 - Val Loss (simple RMSE, no physics involved): 0.149728\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.015386 - Val Loss (simple RMSE, no physics involved): 0.147978\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.015327 - Val Loss (simple RMSE, no physics involved): 0.145567\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.014591 - Val Loss (simple RMSE, no physics involved): 0.144300\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.014317 - Val Loss (simple RMSE, no physics involved): 0.143023\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.014173 - Val Loss (simple RMSE, no physics involved): 0.141986\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013952 - Val Loss (simple RMSE, no physics involved): 0.140809\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.014510 - Val Loss (simple RMSE, no physics involved): 0.139646\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.013962 - Val Loss (simple RMSE, no physics involved): 0.139750\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013912 - Val Loss (simple RMSE, no physics involved): 0.137799\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.013900 - Val Loss (simple RMSE, no physics involved): 0.137627\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013362 - Val Loss (simple RMSE, no physics involved): 0.136570\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.014000 - Val Loss (simple RMSE, no physics involved): 0.135895\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.013621 - Val Loss (simple RMSE, no physics involved): 0.135446\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013204 - Val Loss (simple RMSE, no physics involved): 0.135133\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013389 - Val Loss (simple RMSE, no physics involved): 0.134482\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013560 - Val Loss (simple RMSE, no physics involved): 0.134648\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.013049 - Val Loss (simple RMSE, no physics involved): 0.134044\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.013084 - Val Loss (simple RMSE, no physics involved): 0.133815\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.013092 - Val Loss (simple RMSE, no physics involved): 0.133589\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012981 - Val Loss (simple RMSE, no physics involved): 0.133318\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012921 - Val Loss (simple RMSE, no physics involved): 0.133085\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:04:45,621] Trial 68 finished with value: 0.1329438015818596 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 191, 'lr': 7.797853304804836e-05, 'weight_decay': 2.4919690185952098e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012743 - Val Loss (simple RMSE, no physics involved): 0.132944\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.105888 - Val Loss (simple RMSE, no physics involved): 0.257580\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.034076 - Val Loss (simple RMSE, no physics involved): 0.235081\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.027569 - Val Loss (simple RMSE, no physics involved): 0.184877\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.022633 - Val Loss (simple RMSE, no physics involved): 0.182455\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.019130 - Val Loss (simple RMSE, no physics involved): 0.153591\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.016566 - Val Loss (simple RMSE, no physics involved): 0.146672\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014778 - Val Loss (simple RMSE, no physics involved): 0.142457\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014105 - Val Loss (simple RMSE, no physics involved): 0.139977\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014019 - Val Loss (simple RMSE, no physics involved): 0.139945\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013618 - Val Loss (simple RMSE, no physics involved): 0.142258\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013623 - Val Loss (simple RMSE, no physics involved): 0.142142\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013779 - Val Loss (simple RMSE, no physics involved): 0.139907\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013515 - Val Loss (simple RMSE, no physics involved): 0.135675\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013134 - Val Loss (simple RMSE, no physics involved): 0.136108\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012917 - Val Loss (simple RMSE, no physics involved): 0.133943\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012641 - Val Loss (simple RMSE, no physics involved): 0.133165\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012557 - Val Loss (simple RMSE, no physics involved): 0.133317\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012457 - Val Loss (simple RMSE, no physics involved): 0.133737\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012847 - Val Loss (simple RMSE, no physics involved): 0.136058\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012796 - Val Loss (simple RMSE, no physics involved): 0.134342\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012637 - Val Loss (simple RMSE, no physics involved): 0.136380\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012369 - Val Loss (simple RMSE, no physics involved): 0.136191\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012325 - Val Loss (simple RMSE, no physics involved): 0.134587\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012270 - Val Loss (simple RMSE, no physics involved): 0.132909\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012226 - Val Loss (simple RMSE, no physics involved): 0.132633\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012101 - Val Loss (simple RMSE, no physics involved): 0.135271\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012039 - Val Loss (simple RMSE, no physics involved): 0.132648\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012458 - Val Loss (simple RMSE, no physics involved): 0.137420\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012171 - Val Loss (simple RMSE, no physics involved): 0.136018\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012215 - Val Loss (simple RMSE, no physics involved): 0.133528\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012701 - Val Loss (simple RMSE, no physics involved): 0.136613\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012627 - Val Loss (simple RMSE, no physics involved): 0.133593\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011950 - Val Loss (simple RMSE, no physics involved): 0.133394\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011865 - Val Loss (simple RMSE, no physics involved): 0.133580\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011840 - Val Loss (simple RMSE, no physics involved): 0.133496\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012020 - Val Loss (simple RMSE, no physics involved): 0.133859\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012070 - Val Loss (simple RMSE, no physics involved): 0.134723\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012000 - Val Loss (simple RMSE, no physics involved): 0.134396\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011849 - Val Loss (simple RMSE, no physics involved): 0.133268\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011875 - Val Loss (simple RMSE, no physics involved): 0.133893\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011746 - Val Loss (simple RMSE, no physics involved): 0.133024\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011828 - Val Loss (simple RMSE, no physics involved): 0.137078\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011816 - Val Loss (simple RMSE, no physics involved): 0.133567\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012115 - Val Loss (simple RMSE, no physics involved): 0.142714\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.013102 - Val Loss (simple RMSE, no physics involved): 0.139305\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012542 - Val Loss (simple RMSE, no physics involved): 0.135066\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011661 - Val Loss (simple RMSE, no physics involved): 0.134997\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011620 - Val Loss (simple RMSE, no physics involved): 0.133778\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011587 - Val Loss (simple RMSE, no physics involved): 0.134077\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:05:25,665] Trial 69 finished with value: 0.13263308505217233 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 136, 'lr': 0.0007181747346716181, 'weight_decay': 1.1197645979839517e-06, 'batch_size': 8}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011536 - Val Loss (simple RMSE, no physics involved): 0.134655\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.088941 - Val Loss (simple RMSE, no physics involved): 0.408003\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.099714 - Val Loss (simple RMSE, no physics involved): 0.406880\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.096121 - Val Loss (simple RMSE, no physics involved): 0.405750\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.097666 - Val Loss (simple RMSE, no physics involved): 0.404632\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.100237 - Val Loss (simple RMSE, no physics involved): 0.403513\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.090348 - Val Loss (simple RMSE, no physics involved): 0.402397\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.095213 - Val Loss (simple RMSE, no physics involved): 0.401288\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.090744 - Val Loss (simple RMSE, no physics involved): 0.400194\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.086150 - Val Loss (simple RMSE, no physics involved): 0.399107\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.091700 - Val Loss (simple RMSE, no physics involved): 0.398025\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.088412 - Val Loss (simple RMSE, no physics involved): 0.396941\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.086270 - Val Loss (simple RMSE, no physics involved): 0.395857\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.080381 - Val Loss (simple RMSE, no physics involved): 0.394769\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.075884 - Val Loss (simple RMSE, no physics involved): 0.393687\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.085529 - Val Loss (simple RMSE, no physics involved): 0.392614\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.079110 - Val Loss (simple RMSE, no physics involved): 0.391530\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.075996 - Val Loss (simple RMSE, no physics involved): 0.390436\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.080316 - Val Loss (simple RMSE, no physics involved): 0.389339\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.077314 - Val Loss (simple RMSE, no physics involved): 0.388227\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.074218 - Val Loss (simple RMSE, no physics involved): 0.387101\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.088093 - Val Loss (simple RMSE, no physics involved): 0.385970\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.077356 - Val Loss (simple RMSE, no physics involved): 0.384788\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.078234 - Val Loss (simple RMSE, no physics involved): 0.383596\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.091024 - Val Loss (simple RMSE, no physics involved): 0.382387\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.075991 - Val Loss (simple RMSE, no physics involved): 0.381134\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.076396 - Val Loss (simple RMSE, no physics involved): 0.379866\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.076816 - Val Loss (simple RMSE, no physics involved): 0.378603\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.078465 - Val Loss (simple RMSE, no physics involved): 0.377337\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.076682 - Val Loss (simple RMSE, no physics involved): 0.376045\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.074734 - Val Loss (simple RMSE, no physics involved): 0.374742\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.074523 - Val Loss (simple RMSE, no physics involved): 0.373431\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.073402 - Val Loss (simple RMSE, no physics involved): 0.372107\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.071880 - Val Loss (simple RMSE, no physics involved): 0.370772\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.077668 - Val Loss (simple RMSE, no physics involved): 0.369429\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.082351 - Val Loss (simple RMSE, no physics involved): 0.368056\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.071674 - Val Loss (simple RMSE, no physics involved): 0.366652\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.071125 - Val Loss (simple RMSE, no physics involved): 0.365251\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.064529 - Val Loss (simple RMSE, no physics involved): 0.363843\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.075080 - Val Loss (simple RMSE, no physics involved): 0.362447\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.071297 - Val Loss (simple RMSE, no physics involved): 0.361013\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.066615 - Val Loss (simple RMSE, no physics involved): 0.359546\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.070620 - Val Loss (simple RMSE, no physics involved): 0.358080\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.070901 - Val Loss (simple RMSE, no physics involved): 0.356592\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.059842 - Val Loss (simple RMSE, no physics involved): 0.355077\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.067455 - Val Loss (simple RMSE, no physics involved): 0.353596\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.061260 - Val Loss (simple RMSE, no physics involved): 0.352095\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.063549 - Val Loss (simple RMSE, no physics involved): 0.350594\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.061568 - Val Loss (simple RMSE, no physics involved): 0.349096\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.062002 - Val Loss (simple RMSE, no physics involved): 0.347579\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:05:39,097] Trial 70 finished with value: 0.34603866934776306 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 145, 'lr': 1.090154354233463e-05, 'weight_decay': 1.6689189703344666e-06, 'batch_size': 32}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.065499 - Val Loss (simple RMSE, no physics involved): 0.346039\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.110550 - Val Loss (simple RMSE, no physics involved): 0.398196\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.082996 - Val Loss (simple RMSE, no physics involved): 0.353369\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.059340 - Val Loss (simple RMSE, no physics involved): 0.299103\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.038941 - Val Loss (simple RMSE, no physics involved): 0.236120\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.029712 - Val Loss (simple RMSE, no physics involved): 0.197189\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.029534 - Val Loss (simple RMSE, no physics involved): 0.202110\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.026884 - Val Loss (simple RMSE, no physics involved): 0.208102\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.026976 - Val Loss (simple RMSE, no physics involved): 0.203673\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.025053 - Val Loss (simple RMSE, no physics involved): 0.193167\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.024839 - Val Loss (simple RMSE, no physics involved): 0.189776\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.022555 - Val Loss (simple RMSE, no physics involved): 0.182351\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.020475 - Val Loss (simple RMSE, no physics involved): 0.174242\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.019445 - Val Loss (simple RMSE, no physics involved): 0.165513\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.016833 - Val Loss (simple RMSE, no physics involved): 0.155303\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.015907 - Val Loss (simple RMSE, no physics involved): 0.151264\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.014859 - Val Loss (simple RMSE, no physics involved): 0.147331\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.014362 - Val Loss (simple RMSE, no physics involved): 0.142096\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013989 - Val Loss (simple RMSE, no physics involved): 0.140301\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013406 - Val Loss (simple RMSE, no physics involved): 0.136881\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013594 - Val Loss (simple RMSE, no physics involved): 0.135738\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012825 - Val Loss (simple RMSE, no physics involved): 0.133584\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013003 - Val Loss (simple RMSE, no physics involved): 0.135538\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012745 - Val Loss (simple RMSE, no physics involved): 0.133956\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013106 - Val Loss (simple RMSE, no physics involved): 0.133798\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012897 - Val Loss (simple RMSE, no physics involved): 0.133557\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012769 - Val Loss (simple RMSE, no physics involved): 0.131824\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012973 - Val Loss (simple RMSE, no physics involved): 0.131503\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012825 - Val Loss (simple RMSE, no physics involved): 0.131195\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012799 - Val Loss (simple RMSE, no physics involved): 0.131215\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012401 - Val Loss (simple RMSE, no physics involved): 0.131559\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012335 - Val Loss (simple RMSE, no physics involved): 0.131281\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012557 - Val Loss (simple RMSE, no physics involved): 0.131210\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012364 - Val Loss (simple RMSE, no physics involved): 0.130608\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012431 - Val Loss (simple RMSE, no physics involved): 0.130551\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012337 - Val Loss (simple RMSE, no physics involved): 0.131409\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012315 - Val Loss (simple RMSE, no physics involved): 0.131933\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012330 - Val Loss (simple RMSE, no physics involved): 0.130944\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012328 - Val Loss (simple RMSE, no physics involved): 0.130673\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012271 - Val Loss (simple RMSE, no physics involved): 0.130524\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011996 - Val Loss (simple RMSE, no physics involved): 0.131053\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012764 - Val Loss (simple RMSE, no physics involved): 0.130625\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011914 - Val Loss (simple RMSE, no physics involved): 0.130276\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012247 - Val Loss (simple RMSE, no physics involved): 0.130100\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012109 - Val Loss (simple RMSE, no physics involved): 0.130130\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012136 - Val Loss (simple RMSE, no physics involved): 0.130432\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012432 - Val Loss (simple RMSE, no physics involved): 0.130510\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012120 - Val Loss (simple RMSE, no physics involved): 0.130652\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012219 - Val Loss (simple RMSE, no physics involved): 0.131110\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011911 - Val Loss (simple RMSE, no physics involved): 0.131031\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:06:04,132] Trial 71 finished with value: 0.13009962439537048 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 199, 'lr': 0.00017341474018604114, 'weight_decay': 1.2120890422787088e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012425 - Val Loss (simple RMSE, no physics involved): 0.130358\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.157163 - Val Loss (simple RMSE, no physics involved): 0.443380\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.099712 - Val Loss (simple RMSE, no physics involved): 0.346337\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.048310 - Val Loss (simple RMSE, no physics involved): 0.228683\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.030410 - Val Loss (simple RMSE, no physics involved): 0.183314\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.030175 - Val Loss (simple RMSE, no physics involved): 0.184838\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.023877 - Val Loss (simple RMSE, no physics involved): 0.202192\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.024148 - Val Loss (simple RMSE, no physics involved): 0.193839\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.021800 - Val Loss (simple RMSE, no physics involved): 0.173498\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.019633 - Val Loss (simple RMSE, no physics involved): 0.166359\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.018043 - Val Loss (simple RMSE, no physics involved): 0.163995\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.017090 - Val Loss (simple RMSE, no physics involved): 0.158905\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.016223 - Val Loss (simple RMSE, no physics involved): 0.154908\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.015471 - Val Loss (simple RMSE, no physics involved): 0.152311\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.014554 - Val Loss (simple RMSE, no physics involved): 0.150921\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.014606 - Val Loss (simple RMSE, no physics involved): 0.148972\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.014039 - Val Loss (simple RMSE, no physics involved): 0.147725\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013851 - Val Loss (simple RMSE, no physics involved): 0.144252\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013740 - Val Loss (simple RMSE, no physics involved): 0.144699\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013529 - Val Loss (simple RMSE, no physics involved): 0.141877\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013913 - Val Loss (simple RMSE, no physics involved): 0.142117\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013150 - Val Loss (simple RMSE, no physics involved): 0.140355\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013102 - Val Loss (simple RMSE, no physics involved): 0.139339\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013426 - Val Loss (simple RMSE, no physics involved): 0.139380\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013147 - Val Loss (simple RMSE, no physics involved): 0.138185\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013460 - Val Loss (simple RMSE, no physics involved): 0.137707\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013256 - Val Loss (simple RMSE, no physics involved): 0.137730\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012981 - Val Loss (simple RMSE, no physics involved): 0.136783\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012597 - Val Loss (simple RMSE, no physics involved): 0.136935\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012640 - Val Loss (simple RMSE, no physics involved): 0.135907\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012859 - Val Loss (simple RMSE, no physics involved): 0.135775\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012685 - Val Loss (simple RMSE, no physics involved): 0.135884\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013000 - Val Loss (simple RMSE, no physics involved): 0.135130\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012986 - Val Loss (simple RMSE, no physics involved): 0.135216\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012793 - Val Loss (simple RMSE, no physics involved): 0.134781\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012244 - Val Loss (simple RMSE, no physics involved): 0.134835\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012851 - Val Loss (simple RMSE, no physics involved): 0.134461\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012190 - Val Loss (simple RMSE, no physics involved): 0.134272\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012552 - Val Loss (simple RMSE, no physics involved): 0.134486\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012387 - Val Loss (simple RMSE, no physics involved): 0.133942\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011989 - Val Loss (simple RMSE, no physics involved): 0.134539\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012145 - Val Loss (simple RMSE, no physics involved): 0.133925\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012668 - Val Loss (simple RMSE, no physics involved): 0.133839\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012234 - Val Loss (simple RMSE, no physics involved): 0.134314\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012607 - Val Loss (simple RMSE, no physics involved): 0.133936\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012317 - Val Loss (simple RMSE, no physics involved): 0.135107\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012262 - Val Loss (simple RMSE, no physics involved): 0.133402\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012333 - Val Loss (simple RMSE, no physics involved): 0.134680\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011936 - Val Loss (simple RMSE, no physics involved): 0.133285\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012249 - Val Loss (simple RMSE, no physics involved): 0.134508\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:06:24,735] Trial 72 finished with value: 0.1332845650613308 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 211, 'lr': 0.0002184540935610324, 'weight_decay': 2.184824744940932e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011908 - Val Loss (simple RMSE, no physics involved): 0.133462\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.146171 - Val Loss (simple RMSE, no physics involved): 0.454297\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.126144 - Val Loss (simple RMSE, no physics involved): 0.422779\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.098543 - Val Loss (simple RMSE, no physics involved): 0.388987\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.080567 - Val Loss (simple RMSE, no physics involved): 0.350638\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.057976 - Val Loss (simple RMSE, no physics involved): 0.299515\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.039332 - Val Loss (simple RMSE, no physics involved): 0.235797\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.029848 - Val Loss (simple RMSE, no physics involved): 0.195911\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.029704 - Val Loss (simple RMSE, no physics involved): 0.195745\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.027986 - Val Loss (simple RMSE, no physics involved): 0.204644\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.026224 - Val Loss (simple RMSE, no physics involved): 0.204674\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.025763 - Val Loss (simple RMSE, no physics involved): 0.197142\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.024171 - Val Loss (simple RMSE, no physics involved): 0.185612\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.022847 - Val Loss (simple RMSE, no physics involved): 0.184934\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.021789 - Val Loss (simple RMSE, no physics involved): 0.183658\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.020669 - Val Loss (simple RMSE, no physics involved): 0.176269\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.020132 - Val Loss (simple RMSE, no physics involved): 0.166532\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.018590 - Val Loss (simple RMSE, no physics involved): 0.158734\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.017235 - Val Loss (simple RMSE, no physics involved): 0.153104\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.016817 - Val Loss (simple RMSE, no physics involved): 0.150181\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.015976 - Val Loss (simple RMSE, no physics involved): 0.144367\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.015419 - Val Loss (simple RMSE, no physics involved): 0.142953\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.014921 - Val Loss (simple RMSE, no physics involved): 0.140580\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.014162 - Val Loss (simple RMSE, no physics involved): 0.139478\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.014477 - Val Loss (simple RMSE, no physics involved): 0.138291\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.014046 - Val Loss (simple RMSE, no physics involved): 0.137460\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013875 - Val Loss (simple RMSE, no physics involved): 0.136459\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013278 - Val Loss (simple RMSE, no physics involved): 0.135757\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013464 - Val Loss (simple RMSE, no physics involved): 0.134833\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013493 - Val Loss (simple RMSE, no physics involved): 0.134280\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013347 - Val Loss (simple RMSE, no physics involved): 0.133959\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013499 - Val Loss (simple RMSE, no physics involved): 0.133508\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013142 - Val Loss (simple RMSE, no physics involved): 0.133318\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.013084 - Val Loss (simple RMSE, no physics involved): 0.132726\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012841 - Val Loss (simple RMSE, no physics involved): 0.132625\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012785 - Val Loss (simple RMSE, no physics involved): 0.132283\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012956 - Val Loss (simple RMSE, no physics involved): 0.131834\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012800 - Val Loss (simple RMSE, no physics involved): 0.131566\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012691 - Val Loss (simple RMSE, no physics involved): 0.131370\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012660 - Val Loss (simple RMSE, no physics involved): 0.131428\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012674 - Val Loss (simple RMSE, no physics involved): 0.130790\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.013101 - Val Loss (simple RMSE, no physics involved): 0.131647\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012944 - Val Loss (simple RMSE, no physics involved): 0.130222\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012341 - Val Loss (simple RMSE, no physics involved): 0.130481\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012387 - Val Loss (simple RMSE, no physics involved): 0.130144\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012690 - Val Loss (simple RMSE, no physics involved): 0.130003\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012568 - Val Loss (simple RMSE, no physics involved): 0.130331\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012659 - Val Loss (simple RMSE, no physics involved): 0.129549\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012390 - Val Loss (simple RMSE, no physics involved): 0.129259\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012480 - Val Loss (simple RMSE, no physics involved): 0.129862\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:06:48,903] Trial 73 finished with value: 0.12925922870635986 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 197, 'lr': 0.0001441028868163513, 'weight_decay': 5.663006587006543e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012126 - Val Loss (simple RMSE, no physics involved): 0.129280\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.095650 - Val Loss (simple RMSE, no physics involved): 0.356761\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.057363 - Val Loss (simple RMSE, no physics involved): 0.269072\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.031944 - Val Loss (simple RMSE, no physics involved): 0.186332\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.032542 - Val Loss (simple RMSE, no physics involved): 0.189537\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.027259 - Val Loss (simple RMSE, no physics involved): 0.219546\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.027032 - Val Loss (simple RMSE, no physics involved): 0.205455\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.024352 - Val Loss (simple RMSE, no physics involved): 0.178988\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.023781 - Val Loss (simple RMSE, no physics involved): 0.174577\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.020787 - Val Loss (simple RMSE, no physics involved): 0.178812\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.020198 - Val Loss (simple RMSE, no physics involved): 0.158592\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.018209 - Val Loss (simple RMSE, no physics involved): 0.152196\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.016219 - Val Loss (simple RMSE, no physics involved): 0.145609\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.015183 - Val Loss (simple RMSE, no physics involved): 0.144175\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.014638 - Val Loss (simple RMSE, no physics involved): 0.139998\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013961 - Val Loss (simple RMSE, no physics involved): 0.137364\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013872 - Val Loss (simple RMSE, no physics involved): 0.137589\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013394 - Val Loss (simple RMSE, no physics involved): 0.135998\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013716 - Val Loss (simple RMSE, no physics involved): 0.135824\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013510 - Val Loss (simple RMSE, no physics involved): 0.134060\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012863 - Val Loss (simple RMSE, no physics involved): 0.133683\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013013 - Val Loss (simple RMSE, no physics involved): 0.133448\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013082 - Val Loss (simple RMSE, no physics involved): 0.133051\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012932 - Val Loss (simple RMSE, no physics involved): 0.132352\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012898 - Val Loss (simple RMSE, no physics involved): 0.132293\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012968 - Val Loss (simple RMSE, no physics involved): 0.131420\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013140 - Val Loss (simple RMSE, no physics involved): 0.131929\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012719 - Val Loss (simple RMSE, no physics involved): 0.135178\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013236 - Val Loss (simple RMSE, no physics involved): 0.131775\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012143 - Val Loss (simple RMSE, no physics involved): 0.133483\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012638 - Val Loss (simple RMSE, no physics involved): 0.131694\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012508 - Val Loss (simple RMSE, no physics involved): 0.131184\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012764 - Val Loss (simple RMSE, no physics involved): 0.131953\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012777 - Val Loss (simple RMSE, no physics involved): 0.131403\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012632 - Val Loss (simple RMSE, no physics involved): 0.132480\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.013264 - Val Loss (simple RMSE, no physics involved): 0.132240\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012746 - Val Loss (simple RMSE, no physics involved): 0.130688\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012288 - Val Loss (simple RMSE, no physics involved): 0.131526\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012768 - Val Loss (simple RMSE, no physics involved): 0.131398\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012180 - Val Loss (simple RMSE, no physics involved): 0.131233\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012247 - Val Loss (simple RMSE, no physics involved): 0.130743\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012439 - Val Loss (simple RMSE, no physics involved): 0.131077\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012288 - Val Loss (simple RMSE, no physics involved): 0.130221\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012720 - Val Loss (simple RMSE, no physics involved): 0.130701\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012767 - Val Loss (simple RMSE, no physics involved): 0.131147\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012666 - Val Loss (simple RMSE, no physics involved): 0.131068\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011884 - Val Loss (simple RMSE, no physics involved): 0.131093\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012127 - Val Loss (simple RMSE, no physics involved): 0.130882\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012107 - Val Loss (simple RMSE, no physics involved): 0.131612\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011988 - Val Loss (simple RMSE, no physics involved): 0.131406\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:07:15,551] Trial 74 finished with value: 0.1302211955189705 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 177, 'lr': 0.0003438817069254561, 'weight_decay': 7.524040574038353e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011854 - Val Loss (simple RMSE, no physics involved): 0.131182\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.060344 - Val Loss (simple RMSE, no physics involved): 0.249753\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.027005 - Val Loss (simple RMSE, no physics involved): 0.167913\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.022543 - Val Loss (simple RMSE, no physics involved): 0.165465\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.017712 - Val Loss (simple RMSE, no physics involved): 0.157437\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.016737 - Val Loss (simple RMSE, no physics involved): 0.147939\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015250 - Val Loss (simple RMSE, no physics involved): 0.141628\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014298 - Val Loss (simple RMSE, no physics involved): 0.137520\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013698 - Val Loss (simple RMSE, no physics involved): 0.135751\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013761 - Val Loss (simple RMSE, no physics involved): 0.135621\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013925 - Val Loss (simple RMSE, no physics involved): 0.137456\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013983 - Val Loss (simple RMSE, no physics involved): 0.133116\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013153 - Val Loss (simple RMSE, no physics involved): 0.132601\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012256 - Val Loss (simple RMSE, no physics involved): 0.132303\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012547 - Val Loss (simple RMSE, no physics involved): 0.130948\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012525 - Val Loss (simple RMSE, no physics involved): 0.131014\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012458 - Val Loss (simple RMSE, no physics involved): 0.130292\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012275 - Val Loss (simple RMSE, no physics involved): 0.133413\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012623 - Val Loss (simple RMSE, no physics involved): 0.132273\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012274 - Val Loss (simple RMSE, no physics involved): 0.134159\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012977 - Val Loss (simple RMSE, no physics involved): 0.136983\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013112 - Val Loss (simple RMSE, no physics involved): 0.136976\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012519 - Val Loss (simple RMSE, no physics involved): 0.130375\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012441 - Val Loss (simple RMSE, no physics involved): 0.131380\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.011936 - Val Loss (simple RMSE, no physics involved): 0.131461\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012205 - Val Loss (simple RMSE, no physics involved): 0.131293\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012131 - Val Loss (simple RMSE, no physics involved): 0.132405\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012215 - Val Loss (simple RMSE, no physics involved): 0.131323\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012038 - Val Loss (simple RMSE, no physics involved): 0.132191\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012244 - Val Loss (simple RMSE, no physics involved): 0.134234\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012581 - Val Loss (simple RMSE, no physics involved): 0.134935\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011988 - Val Loss (simple RMSE, no physics involved): 0.130515\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011793 - Val Loss (simple RMSE, no physics involved): 0.132621\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011745 - Val Loss (simple RMSE, no physics involved): 0.132806\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012035 - Val Loss (simple RMSE, no physics involved): 0.131592\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012286 - Val Loss (simple RMSE, no physics involved): 0.132071\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011779 - Val Loss (simple RMSE, no physics involved): 0.135416\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011902 - Val Loss (simple RMSE, no physics involved): 0.131405\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011919 - Val Loss (simple RMSE, no physics involved): 0.134233\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011905 - Val Loss (simple RMSE, no physics involved): 0.132740\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011599 - Val Loss (simple RMSE, no physics involved): 0.135558\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011612 - Val Loss (simple RMSE, no physics involved): 0.132688\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011629 - Val Loss (simple RMSE, no physics involved): 0.132387\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011304 - Val Loss (simple RMSE, no physics involved): 0.131489\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011193 - Val Loss (simple RMSE, no physics involved): 0.132058\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011813 - Val Loss (simple RMSE, no physics involved): 0.138729\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011553 - Val Loss (simple RMSE, no physics involved): 0.136005\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011347 - Val Loss (simple RMSE, no physics involved): 0.134931\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011856 - Val Loss (simple RMSE, no physics involved): 0.132727\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011478 - Val Loss (simple RMSE, no physics involved): 0.143942\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:07:38,738] Trial 75 finished with value: 0.13029198348522186 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 185, 'lr': 0.0023861603394165548, 'weight_decay': 3.5828804829200236e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011709 - Val Loss (simple RMSE, no physics involved): 0.136116\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.122056 - Val Loss (simple RMSE, no physics involved): 0.339803\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.039383 - Val Loss (simple RMSE, no physics involved): 0.189348\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.024755 - Val Loss (simple RMSE, no physics involved): 0.158468\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.017705 - Val Loss (simple RMSE, no physics involved): 0.142162\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.015001 - Val Loss (simple RMSE, no physics involved): 0.139818\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014117 - Val Loss (simple RMSE, no physics involved): 0.134009\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013451 - Val Loss (simple RMSE, no physics involved): 0.132696\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.012721 - Val Loss (simple RMSE, no physics involved): 0.131397\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.012866 - Val Loss (simple RMSE, no physics involved): 0.130370\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012724 - Val Loss (simple RMSE, no physics involved): 0.135069\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013034 - Val Loss (simple RMSE, no physics involved): 0.136965\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013966 - Val Loss (simple RMSE, no physics involved): 0.152173\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013738 - Val Loss (simple RMSE, no physics involved): 0.140459\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012887 - Val Loss (simple RMSE, no physics involved): 0.132667\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012122 - Val Loss (simple RMSE, no physics involved): 0.134219\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012188 - Val Loss (simple RMSE, no physics involved): 0.134252\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012634 - Val Loss (simple RMSE, no physics involved): 0.132429\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012259 - Val Loss (simple RMSE, no physics involved): 0.136178\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.011980 - Val Loss (simple RMSE, no physics involved): 0.137176\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.011859 - Val Loss (simple RMSE, no physics involved): 0.143111\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012183 - Val Loss (simple RMSE, no physics involved): 0.134885\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.011595 - Val Loss (simple RMSE, no physics involved): 0.139826\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.011828 - Val Loss (simple RMSE, no physics involved): 0.142034\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.011609 - Val Loss (simple RMSE, no physics involved): 0.136985\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011983 - Val Loss (simple RMSE, no physics involved): 0.136959\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012339 - Val Loss (simple RMSE, no physics involved): 0.134867\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011761 - Val Loss (simple RMSE, no physics involved): 0.136018\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011876 - Val Loss (simple RMSE, no physics involved): 0.138814\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012471 - Val Loss (simple RMSE, no physics involved): 0.148497\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011793 - Val Loss (simple RMSE, no physics involved): 0.139110\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012285 - Val Loss (simple RMSE, no physics involved): 0.145619\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011502 - Val Loss (simple RMSE, no physics involved): 0.146665\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011521 - Val Loss (simple RMSE, no physics involved): 0.144410\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011787 - Val Loss (simple RMSE, no physics involved): 0.167400\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012509 - Val Loss (simple RMSE, no physics involved): 0.142268\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011443 - Val Loss (simple RMSE, no physics involved): 0.142056\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011450 - Val Loss (simple RMSE, no physics involved): 0.143278\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011196 - Val Loss (simple RMSE, no physics involved): 0.138160\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011232 - Val Loss (simple RMSE, no physics involved): 0.138460\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011895 - Val Loss (simple RMSE, no physics involved): 0.136888\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012874 - Val Loss (simple RMSE, no physics involved): 0.153514\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011601 - Val Loss (simple RMSE, no physics involved): 0.154875\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011820 - Val Loss (simple RMSE, no physics involved): 0.144615\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011853 - Val Loss (simple RMSE, no physics involved): 0.150775\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011342 - Val Loss (simple RMSE, no physics involved): 0.165578\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011453 - Val Loss (simple RMSE, no physics involved): 0.153206\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011165 - Val Loss (simple RMSE, no physics involved): 0.152025\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.010762 - Val Loss (simple RMSE, no physics involved): 0.146766\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.010728 - Val Loss (simple RMSE, no physics involved): 0.170110\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:07:59,080] Trial 76 finished with value: 0.1303698718547821 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 202, 'lr': 0.008310513508007092, 'weight_decay': 3.475402953531647e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.010889 - Val Loss (simple RMSE, no physics involved): 0.151181\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.076001 - Val Loss (simple RMSE, no physics involved): 0.246204\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.034384 - Val Loss (simple RMSE, no physics involved): 0.188599\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029219 - Val Loss (simple RMSE, no physics involved): 0.216333\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025374 - Val Loss (simple RMSE, no physics involved): 0.173523\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.021023 - Val Loss (simple RMSE, no physics involved): 0.167818\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.018060 - Val Loss (simple RMSE, no physics involved): 0.154858\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.016183 - Val Loss (simple RMSE, no physics involved): 0.149107\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015634 - Val Loss (simple RMSE, no physics involved): 0.146492\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014324 - Val Loss (simple RMSE, no physics involved): 0.142970\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014760 - Val Loss (simple RMSE, no physics involved): 0.139224\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013819 - Val Loss (simple RMSE, no physics involved): 0.137414\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013588 - Val Loss (simple RMSE, no physics involved): 0.137787\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013279 - Val Loss (simple RMSE, no physics involved): 0.135351\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012917 - Val Loss (simple RMSE, no physics involved): 0.135663\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013341 - Val Loss (simple RMSE, no physics involved): 0.134382\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012816 - Val Loss (simple RMSE, no physics involved): 0.137492\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013121 - Val Loss (simple RMSE, no physics involved): 0.135845\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013158 - Val Loss (simple RMSE, no physics involved): 0.134339\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013276 - Val Loss (simple RMSE, no physics involved): 0.136798\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012661 - Val Loss (simple RMSE, no physics involved): 0.134086\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012408 - Val Loss (simple RMSE, no physics involved): 0.133776\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012769 - Val Loss (simple RMSE, no physics involved): 0.133022\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012385 - Val Loss (simple RMSE, no physics involved): 0.133457\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012778 - Val Loss (simple RMSE, no physics involved): 0.134844\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012057 - Val Loss (simple RMSE, no physics involved): 0.133026\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012291 - Val Loss (simple RMSE, no physics involved): 0.134255\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012218 - Val Loss (simple RMSE, no physics involved): 0.133705\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012690 - Val Loss (simple RMSE, no physics involved): 0.137431\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012525 - Val Loss (simple RMSE, no physics involved): 0.135370\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012829 - Val Loss (simple RMSE, no physics involved): 0.137305\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011814 - Val Loss (simple RMSE, no physics involved): 0.134976\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012047 - Val Loss (simple RMSE, no physics involved): 0.133817\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012252 - Val Loss (simple RMSE, no physics involved): 0.133931\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012074 - Val Loss (simple RMSE, no physics involved): 0.134588\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011989 - Val Loss (simple RMSE, no physics involved): 0.135724\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012249 - Val Loss (simple RMSE, no physics involved): 0.135143\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012293 - Val Loss (simple RMSE, no physics involved): 0.135621\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011708 - Val Loss (simple RMSE, no physics involved): 0.134462\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011997 - Val Loss (simple RMSE, no physics involved): 0.134296\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011854 - Val Loss (simple RMSE, no physics involved): 0.134474\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011966 - Val Loss (simple RMSE, no physics involved): 0.135640\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011866 - Val Loss (simple RMSE, no physics involved): 0.140056\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011939 - Val Loss (simple RMSE, no physics involved): 0.135994\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011641 - Val Loss (simple RMSE, no physics involved): 0.133950\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011795 - Val Loss (simple RMSE, no physics involved): 0.134919\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012119 - Val Loss (simple RMSE, no physics involved): 0.134767\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011869 - Val Loss (simple RMSE, no physics involved): 0.135975\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011814 - Val Loss (simple RMSE, no physics involved): 0.136995\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011542 - Val Loss (simple RMSE, no physics involved): 0.133832\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:08:24,503] Trial 77 finished with value: 0.13302215188741684 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 224, 'lr': 0.00046263174461416733, 'weight_decay': 4.9760258998710865e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011672 - Val Loss (simple RMSE, no physics involved): 0.138252\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.093631 - Val Loss (simple RMSE, no physics involved): 0.389478\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.083526 - Val Loss (simple RMSE, no physics involved): 0.375227\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.079349 - Val Loss (simple RMSE, no physics involved): 0.361058\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.073153 - Val Loss (simple RMSE, no physics involved): 0.345785\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.063803 - Val Loss (simple RMSE, no physics involved): 0.329080\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.055133 - Val Loss (simple RMSE, no physics involved): 0.311437\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.048665 - Val Loss (simple RMSE, no physics involved): 0.292363\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.041536 - Val Loss (simple RMSE, no physics involved): 0.271684\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.036162 - Val Loss (simple RMSE, no physics involved): 0.249774\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.031208 - Val Loss (simple RMSE, no physics involved): 0.229945\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.028566 - Val Loss (simple RMSE, no physics involved): 0.214283\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.029021 - Val Loss (simple RMSE, no physics involved): 0.207974\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.028171 - Val Loss (simple RMSE, no physics involved): 0.203578\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.027609 - Val Loss (simple RMSE, no physics involved): 0.204072\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.026521 - Val Loss (simple RMSE, no physics involved): 0.206051\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.026392 - Val Loss (simple RMSE, no physics involved): 0.205033\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.025333 - Val Loss (simple RMSE, no physics involved): 0.199787\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.025111 - Val Loss (simple RMSE, no physics involved): 0.197032\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.024589 - Val Loss (simple RMSE, no physics involved): 0.193379\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.023055 - Val Loss (simple RMSE, no physics involved): 0.189235\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.022612 - Val Loss (simple RMSE, no physics involved): 0.186447\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.021635 - Val Loss (simple RMSE, no physics involved): 0.180968\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.020808 - Val Loss (simple RMSE, no physics involved): 0.176776\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.019775 - Val Loss (simple RMSE, no physics involved): 0.173215\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.019072 - Val Loss (simple RMSE, no physics involved): 0.166996\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.018258 - Val Loss (simple RMSE, no physics involved): 0.159258\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.016707 - Val Loss (simple RMSE, no physics involved): 0.156676\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.016023 - Val Loss (simple RMSE, no physics involved): 0.151557\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.015340 - Val Loss (simple RMSE, no physics involved): 0.148076\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.015305 - Val Loss (simple RMSE, no physics involved): 0.146162\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.015151 - Val Loss (simple RMSE, no physics involved): 0.144692\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.014389 - Val Loss (simple RMSE, no physics involved): 0.143322\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.014697 - Val Loss (simple RMSE, no physics involved): 0.142048\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.014028 - Val Loss (simple RMSE, no physics involved): 0.141133\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.013781 - Val Loss (simple RMSE, no physics involved): 0.140832\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.014129 - Val Loss (simple RMSE, no physics involved): 0.139757\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013927 - Val Loss (simple RMSE, no physics involved): 0.139244\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.013872 - Val Loss (simple RMSE, no physics involved): 0.139175\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013562 - Val Loss (simple RMSE, no physics involved): 0.138225\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.013560 - Val Loss (simple RMSE, no physics involved): 0.137701\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.013067 - Val Loss (simple RMSE, no physics involved): 0.137966\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013359 - Val Loss (simple RMSE, no physics involved): 0.136871\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.013467 - Val Loss (simple RMSE, no physics involved): 0.136370\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.013469 - Val Loss (simple RMSE, no physics involved): 0.136363\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.013312 - Val Loss (simple RMSE, no physics involved): 0.135863\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.013144 - Val Loss (simple RMSE, no physics involved): 0.135828\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.013184 - Val Loss (simple RMSE, no physics involved): 0.135214\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.013136 - Val Loss (simple RMSE, no physics involved): 0.135236\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.013021 - Val Loss (simple RMSE, no physics involved): 0.134824\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:08:47,327] Trial 78 finished with value: 0.13474925607442856 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 127, 'lr': 9.66189457509811e-05, 'weight_decay': 1.1443560479202683e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012779 - Val Loss (simple RMSE, no physics involved): 0.134749\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.128651 - Val Loss (simple RMSE, no physics involved): 0.452892\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.116560 - Val Loss (simple RMSE, no physics involved): 0.438322\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.110781 - Val Loss (simple RMSE, no physics involved): 0.424156\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.102823 - Val Loss (simple RMSE, no physics involved): 0.410430\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.094639 - Val Loss (simple RMSE, no physics involved): 0.395689\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.083382 - Val Loss (simple RMSE, no physics involved): 0.379611\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.076463 - Val Loss (simple RMSE, no physics involved): 0.361911\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.065606 - Val Loss (simple RMSE, no physics involved): 0.341022\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.057607 - Val Loss (simple RMSE, no physics involved): 0.317664\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.046711 - Val Loss (simple RMSE, no physics involved): 0.290650\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.038011 - Val Loss (simple RMSE, no physics involved): 0.262015\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.031925 - Val Loss (simple RMSE, no physics involved): 0.234495\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.030485 - Val Loss (simple RMSE, no physics involved): 0.215916\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.032327 - Val Loss (simple RMSE, no physics involved): 0.209415\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.033598 - Val Loss (simple RMSE, no physics involved): 0.208382\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.032601 - Val Loss (simple RMSE, no physics involved): 0.211561\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.030549 - Val Loss (simple RMSE, no physics involved): 0.218833\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.028965 - Val Loss (simple RMSE, no physics involved): 0.227432\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.027869 - Val Loss (simple RMSE, no physics involved): 0.233504\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.028657 - Val Loss (simple RMSE, no physics involved): 0.236198\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.028310 - Val Loss (simple RMSE, no physics involved): 0.234997\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.027708 - Val Loss (simple RMSE, no physics involved): 0.230273\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.027628 - Val Loss (simple RMSE, no physics involved): 0.223650\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.026185 - Val Loss (simple RMSE, no physics involved): 0.215561\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.025479 - Val Loss (simple RMSE, no physics involved): 0.207985\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.025668 - Val Loss (simple RMSE, no physics involved): 0.202781\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.025157 - Val Loss (simple RMSE, no physics involved): 0.199479\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.025768 - Val Loss (simple RMSE, no physics involved): 0.198701\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.023893 - Val Loss (simple RMSE, no physics involved): 0.199137\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.023429 - Val Loss (simple RMSE, no physics involved): 0.200371\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.022859 - Val Loss (simple RMSE, no physics involved): 0.200691\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.023021 - Val Loss (simple RMSE, no physics involved): 0.199453\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.022789 - Val Loss (simple RMSE, no physics involved): 0.195941\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.022608 - Val Loss (simple RMSE, no physics involved): 0.190636\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.021645 - Val Loss (simple RMSE, no physics involved): 0.184064\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.020546 - Val Loss (simple RMSE, no physics involved): 0.178186\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.020588 - Val Loss (simple RMSE, no physics involved): 0.174202\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.019757 - Val Loss (simple RMSE, no physics involved): 0.172073\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.019294 - Val Loss (simple RMSE, no physics involved): 0.170691\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.018641 - Val Loss (simple RMSE, no physics involved): 0.168337\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.017599 - Val Loss (simple RMSE, no physics involved): 0.165280\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.017097 - Val Loss (simple RMSE, no physics involved): 0.160708\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.017154 - Val Loss (simple RMSE, no physics involved): 0.156431\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.016296 - Val Loss (simple RMSE, no physics involved): 0.153889\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.016148 - Val Loss (simple RMSE, no physics involved): 0.152498\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.016302 - Val Loss (simple RMSE, no physics involved): 0.151462\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.015273 - Val Loss (simple RMSE, no physics involved): 0.150066\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.015246 - Val Loss (simple RMSE, no physics involved): 0.148831\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.014744 - Val Loss (simple RMSE, no physics involved): 0.147822\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:08:58,296] Trial 79 finished with value: 0.14687107503414154 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 173, 'lr': 0.0002756521238981914, 'weight_decay': 1.7741724306334735e-06, 'batch_size': 64}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.014901 - Val Loss (simple RMSE, no physics involved): 0.146871\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.059020 - Val Loss (simple RMSE, no physics involved): 0.189700\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.028130 - Val Loss (simple RMSE, no physics involved): 0.229369\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.026166 - Val Loss (simple RMSE, no physics involved): 0.174373\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.023990 - Val Loss (simple RMSE, no physics involved): 0.176382\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.017992 - Val Loss (simple RMSE, no physics involved): 0.150983\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015589 - Val Loss (simple RMSE, no physics involved): 0.157160\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015302 - Val Loss (simple RMSE, no physics involved): 0.142283\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014775 - Val Loss (simple RMSE, no physics involved): 0.141245\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013698 - Val Loss (simple RMSE, no physics involved): 0.135546\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013661 - Val Loss (simple RMSE, no physics involved): 0.134881\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012877 - Val Loss (simple RMSE, no physics involved): 0.133993\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012902 - Val Loss (simple RMSE, no physics involved): 0.133873\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013175 - Val Loss (simple RMSE, no physics involved): 0.133146\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013710 - Val Loss (simple RMSE, no physics involved): 0.132296\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013319 - Val Loss (simple RMSE, no physics involved): 0.133059\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013117 - Val Loss (simple RMSE, no physics involved): 0.136357\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013073 - Val Loss (simple RMSE, no physics involved): 0.135948\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013531 - Val Loss (simple RMSE, no physics involved): 0.136562\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013490 - Val Loss (simple RMSE, no physics involved): 0.134048\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013312 - Val Loss (simple RMSE, no physics involved): 0.132220\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012567 - Val Loss (simple RMSE, no physics involved): 0.131680\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013347 - Val Loss (simple RMSE, no physics involved): 0.132126\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012722 - Val Loss (simple RMSE, no physics involved): 0.130946\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012730 - Val Loss (simple RMSE, no physics involved): 0.130422\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012643 - Val Loss (simple RMSE, no physics involved): 0.131580\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012674 - Val Loss (simple RMSE, no physics involved): 0.132052\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012895 - Val Loss (simple RMSE, no physics involved): 0.132368\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012490 - Val Loss (simple RMSE, no physics involved): 0.130690\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012983 - Val Loss (simple RMSE, no physics involved): 0.130628\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012680 - Val Loss (simple RMSE, no physics involved): 0.132033\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012648 - Val Loss (simple RMSE, no physics involved): 0.130047\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013303 - Val Loss (simple RMSE, no physics involved): 0.129652\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012746 - Val Loss (simple RMSE, no physics involved): 0.131467\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012755 - Val Loss (simple RMSE, no physics involved): 0.134279\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012889 - Val Loss (simple RMSE, no physics involved): 0.140483\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.014023 - Val Loss (simple RMSE, no physics involved): 0.134229\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012992 - Val Loss (simple RMSE, no physics involved): 0.130603\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012977 - Val Loss (simple RMSE, no physics involved): 0.131174\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.013010 - Val Loss (simple RMSE, no physics involved): 0.130064\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012403 - Val Loss (simple RMSE, no physics involved): 0.130321\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012819 - Val Loss (simple RMSE, no physics involved): 0.131602\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012857 - Val Loss (simple RMSE, no physics involved): 0.131372\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012727 - Val Loss (simple RMSE, no physics involved): 0.131368\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012662 - Val Loss (simple RMSE, no physics involved): 0.130698\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012292 - Val Loss (simple RMSE, no physics involved): 0.130060\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012208 - Val Loss (simple RMSE, no physics involved): 0.131795\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012574 - Val Loss (simple RMSE, no physics involved): 0.132734\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012590 - Val Loss (simple RMSE, no physics involved): 0.137955\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.013025 - Val Loss (simple RMSE, no physics involved): 0.132738\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:09:21,965] Trial 80 finished with value: 0.1296522431075573 and parameters: {'n_hidden_layers': 4, 'n_hidden_units': 193, 'lr': 0.0013780633222461864, 'weight_decay': 0.0003873905205138571, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012982 - Val Loss (simple RMSE, no physics involved): 0.130725\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.091417 - Val Loss (simple RMSE, no physics involved): 0.356163\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.050897 - Val Loss (simple RMSE, no physics involved): 0.171368\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.027229 - Val Loss (simple RMSE, no physics involved): 0.169552\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.017566 - Val Loss (simple RMSE, no physics involved): 0.148539\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.015552 - Val Loss (simple RMSE, no physics involved): 0.146612\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014014 - Val Loss (simple RMSE, no physics involved): 0.141021\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013533 - Val Loss (simple RMSE, no physics involved): 0.137860\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013238 - Val Loss (simple RMSE, no physics involved): 0.134494\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.012530 - Val Loss (simple RMSE, no physics involved): 0.134175\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012915 - Val Loss (simple RMSE, no physics involved): 0.131303\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012377 - Val Loss (simple RMSE, no physics involved): 0.133168\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013026 - Val Loss (simple RMSE, no physics involved): 0.131396\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012359 - Val Loss (simple RMSE, no physics involved): 0.130765\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012276 - Val Loss (simple RMSE, no physics involved): 0.134089\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012332 - Val Loss (simple RMSE, no physics involved): 0.137848\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013175 - Val Loss (simple RMSE, no physics involved): 0.136860\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013760 - Val Loss (simple RMSE, no physics involved): 0.135811\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012506 - Val Loss (simple RMSE, no physics involved): 0.132229\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012446 - Val Loss (simple RMSE, no physics involved): 0.129955\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.011755 - Val Loss (simple RMSE, no physics involved): 0.131055\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012330 - Val Loss (simple RMSE, no physics involved): 0.133491\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012406 - Val Loss (simple RMSE, no physics involved): 0.130320\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012180 - Val Loss (simple RMSE, no physics involved): 0.130183\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012321 - Val Loss (simple RMSE, no physics involved): 0.130655\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011834 - Val Loss (simple RMSE, no physics involved): 0.139192\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011750 - Val Loss (simple RMSE, no physics involved): 0.130534\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011727 - Val Loss (simple RMSE, no physics involved): 0.129286\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011775 - Val Loss (simple RMSE, no physics involved): 0.133533\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012117 - Val Loss (simple RMSE, no physics involved): 0.130507\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011757 - Val Loss (simple RMSE, no physics involved): 0.130687\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012306 - Val Loss (simple RMSE, no physics involved): 0.134174\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011865 - Val Loss (simple RMSE, no physics involved): 0.131512\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012162 - Val Loss (simple RMSE, no physics involved): 0.132672\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012017 - Val Loss (simple RMSE, no physics involved): 0.131238\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011816 - Val Loss (simple RMSE, no physics involved): 0.130175\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012152 - Val Loss (simple RMSE, no physics involved): 0.132001\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011608 - Val Loss (simple RMSE, no physics involved): 0.128497\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011421 - Val Loss (simple RMSE, no physics involved): 0.131238\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011851 - Val Loss (simple RMSE, no physics involved): 0.137704\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011770 - Val Loss (simple RMSE, no physics involved): 0.138128\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011524 - Val Loss (simple RMSE, no physics involved): 0.131659\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011787 - Val Loss (simple RMSE, no physics involved): 0.137367\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011778 - Val Loss (simple RMSE, no physics involved): 0.136305\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011612 - Val Loss (simple RMSE, no physics involved): 0.131896\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011833 - Val Loss (simple RMSE, no physics involved): 0.133519\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011470 - Val Loss (simple RMSE, no physics involved): 0.134613\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011806 - Val Loss (simple RMSE, no physics involved): 0.138984\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011267 - Val Loss (simple RMSE, no physics involved): 0.136061\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011334 - Val Loss (simple RMSE, no physics involved): 0.130380\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:09:36,997] Trial 81 finished with value: 0.12849657237529755 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 169, 'lr': 0.005590550872038208, 'weight_decay': 9.718244844909129e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011348 - Val Loss (simple RMSE, no physics involved): 0.131028\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.041544 - Val Loss (simple RMSE, no physics involved): 0.166024\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.019724 - Val Loss (simple RMSE, no physics involved): 0.173243\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.016609 - Val Loss (simple RMSE, no physics involved): 0.158417\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.014244 - Val Loss (simple RMSE, no physics involved): 0.149104\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.014289 - Val Loss (simple RMSE, no physics involved): 0.139103\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.013771 - Val Loss (simple RMSE, no physics involved): 0.138014\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013271 - Val Loss (simple RMSE, no physics involved): 0.135980\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.012950 - Val Loss (simple RMSE, no physics involved): 0.133347\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.012833 - Val Loss (simple RMSE, no physics involved): 0.132534\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012484 - Val Loss (simple RMSE, no physics involved): 0.135167\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012407 - Val Loss (simple RMSE, no physics involved): 0.133680\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012147 - Val Loss (simple RMSE, no physics involved): 0.132470\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012301 - Val Loss (simple RMSE, no physics involved): 0.131568\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.011943 - Val Loss (simple RMSE, no physics involved): 0.137275\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012425 - Val Loss (simple RMSE, no physics involved): 0.133144\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012002 - Val Loss (simple RMSE, no physics involved): 0.133911\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012006 - Val Loss (simple RMSE, no physics involved): 0.132486\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.011492 - Val Loss (simple RMSE, no physics involved): 0.132943\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.011797 - Val Loss (simple RMSE, no physics involved): 0.136986\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.011780 - Val Loss (simple RMSE, no physics involved): 0.132213\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.011676 - Val Loss (simple RMSE, no physics involved): 0.132580\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.011840 - Val Loss (simple RMSE, no physics involved): 0.139256\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.011798 - Val Loss (simple RMSE, no physics involved): 0.131273\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.011602 - Val Loss (simple RMSE, no physics involved): 0.131102\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011498 - Val Loss (simple RMSE, no physics involved): 0.134413\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011718 - Val Loss (simple RMSE, no physics involved): 0.131830\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011902 - Val Loss (simple RMSE, no physics involved): 0.137442\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012137 - Val Loss (simple RMSE, no physics involved): 0.148099\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012476 - Val Loss (simple RMSE, no physics involved): 0.137396\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011505 - Val Loss (simple RMSE, no physics involved): 0.134283\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011619 - Val Loss (simple RMSE, no physics involved): 0.132624\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011709 - Val Loss (simple RMSE, no physics involved): 0.132228\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012160 - Val Loss (simple RMSE, no physics involved): 0.130356\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011859 - Val Loss (simple RMSE, no physics involved): 0.135766\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011537 - Val Loss (simple RMSE, no physics involved): 0.142205\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011365 - Val Loss (simple RMSE, no physics involved): 0.130276\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011279 - Val Loss (simple RMSE, no physics involved): 0.132572\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011044 - Val Loss (simple RMSE, no physics involved): 0.133521\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011218 - Val Loss (simple RMSE, no physics involved): 0.135775\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011128 - Val Loss (simple RMSE, no physics involved): 0.139941\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011482 - Val Loss (simple RMSE, no physics involved): 0.133359\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011248 - Val Loss (simple RMSE, no physics involved): 0.146655\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012780 - Val Loss (simple RMSE, no physics involved): 0.149192\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011636 - Val Loss (simple RMSE, no physics involved): 0.137137\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011108 - Val Loss (simple RMSE, no physics involved): 0.131597\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011066 - Val Loss (simple RMSE, no physics involved): 0.133103\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011172 - Val Loss (simple RMSE, no physics involved): 0.132248\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.010840 - Val Loss (simple RMSE, no physics involved): 0.132721\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011126 - Val Loss (simple RMSE, no physics involved): 0.138803\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:09:51,871] Trial 82 finished with value: 0.1302763745188713 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 167, 'lr': 0.004971138093599739, 'weight_decay': 2.6121876803993434e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011528 - Val Loss (simple RMSE, no physics involved): 0.145077\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.093015 - Val Loss (simple RMSE, no physics involved): 0.352682\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.046729 - Val Loss (simple RMSE, no physics involved): 0.172149\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.024299 - Val Loss (simple RMSE, no physics involved): 0.173396\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.018059 - Val Loss (simple RMSE, no physics involved): 0.150430\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.015389 - Val Loss (simple RMSE, no physics involved): 0.148633\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.013946 - Val Loss (simple RMSE, no physics involved): 0.142053\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014057 - Val Loss (simple RMSE, no physics involved): 0.139813\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013233 - Val Loss (simple RMSE, no physics involved): 0.136528\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013099 - Val Loss (simple RMSE, no physics involved): 0.134925\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012969 - Val Loss (simple RMSE, no physics involved): 0.135091\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013189 - Val Loss (simple RMSE, no physics involved): 0.133785\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012690 - Val Loss (simple RMSE, no physics involved): 0.135784\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012752 - Val Loss (simple RMSE, no physics involved): 0.137069\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012742 - Val Loss (simple RMSE, no physics involved): 0.133718\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012239 - Val Loss (simple RMSE, no physics involved): 0.131995\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012611 - Val Loss (simple RMSE, no physics involved): 0.133553\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012540 - Val Loss (simple RMSE, no physics involved): 0.133202\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012534 - Val Loss (simple RMSE, no physics involved): 0.131225\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.011993 - Val Loss (simple RMSE, no physics involved): 0.132939\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012265 - Val Loss (simple RMSE, no physics involved): 0.133610\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012016 - Val Loss (simple RMSE, no physics involved): 0.134267\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012164 - Val Loss (simple RMSE, no physics involved): 0.135713\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.011838 - Val Loss (simple RMSE, no physics involved): 0.135391\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.011687 - Val Loss (simple RMSE, no physics involved): 0.134573\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012051 - Val Loss (simple RMSE, no physics involved): 0.132832\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011848 - Val Loss (simple RMSE, no physics involved): 0.143402\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012551 - Val Loss (simple RMSE, no physics involved): 0.137635\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011984 - Val Loss (simple RMSE, no physics involved): 0.133971\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011801 - Val Loss (simple RMSE, no physics involved): 0.137736\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011664 - Val Loss (simple RMSE, no physics involved): 0.134485\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012122 - Val Loss (simple RMSE, no physics involved): 0.134209\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.013003 - Val Loss (simple RMSE, no physics involved): 0.139154\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012586 - Val Loss (simple RMSE, no physics involved): 0.140119\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012511 - Val Loss (simple RMSE, no physics involved): 0.139793\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012539 - Val Loss (simple RMSE, no physics involved): 0.134943\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012031 - Val Loss (simple RMSE, no physics involved): 0.139265\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011828 - Val Loss (simple RMSE, no physics involved): 0.141546\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011523 - Val Loss (simple RMSE, no physics involved): 0.134758\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011811 - Val Loss (simple RMSE, no physics involved): 0.136658\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011465 - Val Loss (simple RMSE, no physics involved): 0.139630\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011281 - Val Loss (simple RMSE, no physics involved): 0.134953\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011464 - Val Loss (simple RMSE, no physics involved): 0.136761\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011439 - Val Loss (simple RMSE, no physics involved): 0.134418\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011188 - Val Loss (simple RMSE, no physics involved): 0.134421\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011080 - Val Loss (simple RMSE, no physics involved): 0.136236\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011605 - Val Loss (simple RMSE, no physics involved): 0.135290\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011714 - Val Loss (simple RMSE, no physics involved): 0.143449\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011551 - Val Loss (simple RMSE, no physics involved): 0.143554\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011085 - Val Loss (simple RMSE, no physics involved): 0.135096\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:10:06,156] Trial 83 finished with value: 0.13122494518756866 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 150, 'lr': 0.006235184809716656, 'weight_decay': 6.590708931289658e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011351 - Val Loss (simple RMSE, no physics involved): 0.136007\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.044207 - Val Loss (simple RMSE, no physics involved): 0.175545\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.017847 - Val Loss (simple RMSE, no physics involved): 0.149670\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.015708 - Val Loss (simple RMSE, no physics involved): 0.159452\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.014400 - Val Loss (simple RMSE, no physics involved): 0.145887\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.013885 - Val Loss (simple RMSE, no physics involved): 0.136014\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.013489 - Val Loss (simple RMSE, no physics involved): 0.137517\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013271 - Val Loss (simple RMSE, no physics involved): 0.134043\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013116 - Val Loss (simple RMSE, no physics involved): 0.134507\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.012875 - Val Loss (simple RMSE, no physics involved): 0.134228\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012876 - Val Loss (simple RMSE, no physics involved): 0.133503\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012418 - Val Loss (simple RMSE, no physics involved): 0.132541\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012386 - Val Loss (simple RMSE, no physics involved): 0.132406\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012778 - Val Loss (simple RMSE, no physics involved): 0.142395\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012509 - Val Loss (simple RMSE, no physics involved): 0.136842\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012189 - Val Loss (simple RMSE, no physics involved): 0.132340\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012301 - Val Loss (simple RMSE, no physics involved): 0.131351\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012223 - Val Loss (simple RMSE, no physics involved): 0.131531\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012356 - Val Loss (simple RMSE, no physics involved): 0.132948\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012254 - Val Loss (simple RMSE, no physics involved): 0.130842\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.011980 - Val Loss (simple RMSE, no physics involved): 0.132521\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012297 - Val Loss (simple RMSE, no physics involved): 0.132912\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012597 - Val Loss (simple RMSE, no physics involved): 0.135772\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012915 - Val Loss (simple RMSE, no physics involved): 0.141057\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012982 - Val Loss (simple RMSE, no physics involved): 0.140700\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013470 - Val Loss (simple RMSE, no physics involved): 0.147025\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013203 - Val Loss (simple RMSE, no physics involved): 0.147312\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012987 - Val Loss (simple RMSE, no physics involved): 0.136362\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012160 - Val Loss (simple RMSE, no physics involved): 0.133790\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011861 - Val Loss (simple RMSE, no physics involved): 0.135563\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012271 - Val Loss (simple RMSE, no physics involved): 0.137834\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012325 - Val Loss (simple RMSE, no physics involved): 0.133625\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012140 - Val Loss (simple RMSE, no physics involved): 0.136065\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011682 - Val Loss (simple RMSE, no physics involved): 0.132900\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012157 - Val Loss (simple RMSE, no physics involved): 0.136803\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012272 - Val Loss (simple RMSE, no physics involved): 0.135317\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011716 - Val Loss (simple RMSE, no physics involved): 0.134646\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011605 - Val Loss (simple RMSE, no physics involved): 0.132957\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011998 - Val Loss (simple RMSE, no physics involved): 0.133578\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011655 - Val Loss (simple RMSE, no physics involved): 0.132211\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012027 - Val Loss (simple RMSE, no physics involved): 0.132471\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011806 - Val Loss (simple RMSE, no physics involved): 0.134982\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012279 - Val Loss (simple RMSE, no physics involved): 0.135426\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011589 - Val Loss (simple RMSE, no physics involved): 0.139444\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011772 - Val Loss (simple RMSE, no physics involved): 0.136891\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012072 - Val Loss (simple RMSE, no physics involved): 0.134266\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012650 - Val Loss (simple RMSE, no physics involved): 0.133830\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012579 - Val Loss (simple RMSE, no physics involved): 0.135653\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.013476 - Val Loss (simple RMSE, no physics involved): 0.133205\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011824 - Val Loss (simple RMSE, no physics involved): 0.133045\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:10:17,557] Trial 84 finished with value: 0.13084232434630394 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 180, 'lr': 0.003522351311628336, 'weight_decay': 6.995860617381276e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011427 - Val Loss (simple RMSE, no physics involved): 0.132828\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.221651 - Val Loss (simple RMSE, no physics involved): 0.561021\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.219138 - Val Loss (simple RMSE, no physics involved): 0.558358\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.216010 - Val Loss (simple RMSE, no physics involved): 0.555695\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.212990 - Val Loss (simple RMSE, no physics involved): 0.553054\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.209344 - Val Loss (simple RMSE, no physics involved): 0.550411\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.207361 - Val Loss (simple RMSE, no physics involved): 0.547790\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.206281 - Val Loss (simple RMSE, no physics involved): 0.545198\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.203131 - Val Loss (simple RMSE, no physics involved): 0.542610\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.197562 - Val Loss (simple RMSE, no physics involved): 0.540021\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.202583 - Val Loss (simple RMSE, no physics involved): 0.537463\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.201901 - Val Loss (simple RMSE, no physics involved): 0.534893\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.194416 - Val Loss (simple RMSE, no physics involved): 0.532315\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.195937 - Val Loss (simple RMSE, no physics involved): 0.529765\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.194251 - Val Loss (simple RMSE, no physics involved): 0.527217\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.190824 - Val Loss (simple RMSE, no physics involved): 0.524667\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.186895 - Val Loss (simple RMSE, no physics involved): 0.522107\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.190168 - Val Loss (simple RMSE, no physics involved): 0.519569\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.183505 - Val Loss (simple RMSE, no physics involved): 0.517018\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.183577 - Val Loss (simple RMSE, no physics involved): 0.514488\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.180410 - Val Loss (simple RMSE, no physics involved): 0.511955\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.180192 - Val Loss (simple RMSE, no physics involved): 0.509441\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.171643 - Val Loss (simple RMSE, no physics involved): 0.506965\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.175013 - Val Loss (simple RMSE, no physics involved): 0.504552\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.168617 - Val Loss (simple RMSE, no physics involved): 0.502140\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.166868 - Val Loss (simple RMSE, no physics involved): 0.499739\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.165362 - Val Loss (simple RMSE, no physics involved): 0.497356\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.164987 - Val Loss (simple RMSE, no physics involved): 0.494965\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.164235 - Val Loss (simple RMSE, no physics involved): 0.492566\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.160487 - Val Loss (simple RMSE, no physics involved): 0.490132\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.158548 - Val Loss (simple RMSE, no physics involved): 0.487678\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.156754 - Val Loss (simple RMSE, no physics involved): 0.485160\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.158015 - Val Loss (simple RMSE, no physics involved): 0.482574\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.150730 - Val Loss (simple RMSE, no physics involved): 0.479881\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.150192 - Val Loss (simple RMSE, no physics involved): 0.477097\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.149719 - Val Loss (simple RMSE, no physics involved): 0.474249\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.148331 - Val Loss (simple RMSE, no physics involved): 0.471322\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.140208 - Val Loss (simple RMSE, no physics involved): 0.468356\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.137226 - Val Loss (simple RMSE, no physics involved): 0.465384\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.136116 - Val Loss (simple RMSE, no physics involved): 0.462384\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.135675 - Val Loss (simple RMSE, no physics involved): 0.459349\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.132685 - Val Loss (simple RMSE, no physics involved): 0.456288\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.129941 - Val Loss (simple RMSE, no physics involved): 0.453165\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.132179 - Val Loss (simple RMSE, no physics involved): 0.450011\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.127963 - Val Loss (simple RMSE, no physics involved): 0.446796\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.125337 - Val Loss (simple RMSE, no physics involved): 0.443565\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.122365 - Val Loss (simple RMSE, no physics involved): 0.440313\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.120808 - Val Loss (simple RMSE, no physics involved): 0.437059\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.121576 - Val Loss (simple RMSE, no physics involved): 0.433766\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.117541 - Val Loss (simple RMSE, no physics involved): 0.430414\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:10:30,228] Trial 85 finished with value: 0.42705389857292175 and parameters: {'n_hidden_layers': 3, 'n_hidden_units': 48, 'lr': 2.9375892280129892e-05, 'weight_decay': 1.3741376462803381e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.114057 - Val Loss (simple RMSE, no physics involved): 0.427054\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.061697 - Val Loss (simple RMSE, no physics involved): 0.186032\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.025163 - Val Loss (simple RMSE, no physics involved): 0.178363\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.019720 - Val Loss (simple RMSE, no physics involved): 0.144454\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.016845 - Val Loss (simple RMSE, no physics involved): 0.159331\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.016119 - Val Loss (simple RMSE, no physics involved): 0.166695\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.016149 - Val Loss (simple RMSE, no physics involved): 0.149017\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014519 - Val Loss (simple RMSE, no physics involved): 0.137081\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013118 - Val Loss (simple RMSE, no physics involved): 0.136396\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013076 - Val Loss (simple RMSE, no physics involved): 0.132512\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012773 - Val Loss (simple RMSE, no physics involved): 0.132611\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012826 - Val Loss (simple RMSE, no physics involved): 0.132398\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012590 - Val Loss (simple RMSE, no physics involved): 0.134337\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012339 - Val Loss (simple RMSE, no physics involved): 0.132057\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012389 - Val Loss (simple RMSE, no physics involved): 0.132377\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012501 - Val Loss (simple RMSE, no physics involved): 0.132273\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012277 - Val Loss (simple RMSE, no physics involved): 0.134496\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012760 - Val Loss (simple RMSE, no physics involved): 0.130943\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013105 - Val Loss (simple RMSE, no physics involved): 0.151047\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013830 - Val Loss (simple RMSE, no physics involved): 0.135040\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013157 - Val Loss (simple RMSE, no physics involved): 0.139891\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013717 - Val Loss (simple RMSE, no physics involved): 0.147447\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013630 - Val Loss (simple RMSE, no physics involved): 0.135327\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012695 - Val Loss (simple RMSE, no physics involved): 0.133806\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012184 - Val Loss (simple RMSE, no physics involved): 0.134296\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012513 - Val Loss (simple RMSE, no physics involved): 0.135995\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012679 - Val Loss (simple RMSE, no physics involved): 0.135562\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012375 - Val Loss (simple RMSE, no physics involved): 0.135505\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012473 - Val Loss (simple RMSE, no physics involved): 0.139142\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012761 - Val Loss (simple RMSE, no physics involved): 0.131387\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012034 - Val Loss (simple RMSE, no physics involved): 0.136087\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012216 - Val Loss (simple RMSE, no physics involved): 0.134778\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012128 - Val Loss (simple RMSE, no physics involved): 0.132386\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012161 - Val Loss (simple RMSE, no physics involved): 0.145430\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012329 - Val Loss (simple RMSE, no physics involved): 0.140577\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012509 - Val Loss (simple RMSE, no physics involved): 0.135129\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012591 - Val Loss (simple RMSE, no physics involved): 0.151700\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013141 - Val Loss (simple RMSE, no physics involved): 0.140743\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012330 - Val Loss (simple RMSE, no physics involved): 0.150461\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012402 - Val Loss (simple RMSE, no physics involved): 0.140228\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012200 - Val Loss (simple RMSE, no physics involved): 0.137652\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012289 - Val Loss (simple RMSE, no physics involved): 0.133514\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012121 - Val Loss (simple RMSE, no physics involved): 0.135578\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011782 - Val Loss (simple RMSE, no physics involved): 0.138952\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011351 - Val Loss (simple RMSE, no physics involved): 0.138115\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011467 - Val Loss (simple RMSE, no physics involved): 0.135335\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011449 - Val Loss (simple RMSE, no physics involved): 0.137045\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011196 - Val Loss (simple RMSE, no physics involved): 0.137336\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011208 - Val Loss (simple RMSE, no physics involved): 0.134523\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011082 - Val Loss (simple RMSE, no physics involved): 0.135856\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:10:54,448] Trial 86 finished with value: 0.13094255700707436 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 161, 'lr': 0.004866551528270533, 'weight_decay': 8.803204832480248e-07, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.010950 - Val Loss (simple RMSE, no physics involved): 0.136772\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.090306 - Val Loss (simple RMSE, no physics involved): 0.298102\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.037751 - Val Loss (simple RMSE, no physics involved): 0.212063\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029790 - Val Loss (simple RMSE, no physics involved): 0.215443\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.028194 - Val Loss (simple RMSE, no physics involved): 0.199724\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.025800 - Val Loss (simple RMSE, no physics involved): 0.166664\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.018632 - Val Loss (simple RMSE, no physics involved): 0.146364\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.016222 - Val Loss (simple RMSE, no physics involved): 0.148958\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014866 - Val Loss (simple RMSE, no physics involved): 0.138996\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014329 - Val Loss (simple RMSE, no physics involved): 0.141913\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014147 - Val Loss (simple RMSE, no physics involved): 0.139872\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014584 - Val Loss (simple RMSE, no physics involved): 0.146977\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014367 - Val Loss (simple RMSE, no physics involved): 0.139351\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.014659 - Val Loss (simple RMSE, no physics involved): 0.134653\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013149 - Val Loss (simple RMSE, no physics involved): 0.134196\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012713 - Val Loss (simple RMSE, no physics involved): 0.131388\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012545 - Val Loss (simple RMSE, no physics involved): 0.132157\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012372 - Val Loss (simple RMSE, no physics involved): 0.131899\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012528 - Val Loss (simple RMSE, no physics involved): 0.131744\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012105 - Val Loss (simple RMSE, no physics involved): 0.131705\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012083 - Val Loss (simple RMSE, no physics involved): 0.136251\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012319 - Val Loss (simple RMSE, no physics involved): 0.131392\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012724 - Val Loss (simple RMSE, no physics involved): 0.136797\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012449 - Val Loss (simple RMSE, no physics involved): 0.136330\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013426 - Val Loss (simple RMSE, no physics involved): 0.142975\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013471 - Val Loss (simple RMSE, no physics involved): 0.133718\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012423 - Val Loss (simple RMSE, no physics involved): 0.131994\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012765 - Val Loss (simple RMSE, no physics involved): 0.135411\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012330 - Val Loss (simple RMSE, no physics involved): 0.133293\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011898 - Val Loss (simple RMSE, no physics involved): 0.131414\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011980 - Val Loss (simple RMSE, no physics involved): 0.131506\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012078 - Val Loss (simple RMSE, no physics involved): 0.135536\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011661 - Val Loss (simple RMSE, no physics involved): 0.137823\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012027 - Val Loss (simple RMSE, no physics involved): 0.132962\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011829 - Val Loss (simple RMSE, no physics involved): 0.142694\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012829 - Val Loss (simple RMSE, no physics involved): 0.135350\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011892 - Val Loss (simple RMSE, no physics involved): 0.134935\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011911 - Val Loss (simple RMSE, no physics involved): 0.132716\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011911 - Val Loss (simple RMSE, no physics involved): 0.137432\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011985 - Val Loss (simple RMSE, no physics involved): 0.133245\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011915 - Val Loss (simple RMSE, no physics involved): 0.133770\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012337 - Val Loss (simple RMSE, no physics involved): 0.147756\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.013723 - Val Loss (simple RMSE, no physics involved): 0.154574\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.014246 - Val Loss (simple RMSE, no physics involved): 0.142628\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012611 - Val Loss (simple RMSE, no physics involved): 0.134897\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011622 - Val Loss (simple RMSE, no physics involved): 0.133918\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011670 - Val Loss (simple RMSE, no physics involved): 0.153204\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012373 - Val Loss (simple RMSE, no physics involved): 0.154317\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012531 - Val Loss (simple RMSE, no physics involved): 0.135864\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011816 - Val Loss (simple RMSE, no physics involved): 0.132600\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:11:17,757] Trial 87 finished with value: 0.13138766214251518 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 120, 'lr': 0.009243361648588177, 'weight_decay': 4.109179473415374e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011668 - Val Loss (simple RMSE, no physics involved): 0.142896\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.037372 - Val Loss (simple RMSE, no physics involved): 0.183858\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.017429 - Val Loss (simple RMSE, no physics involved): 0.151529\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.014742 - Val Loss (simple RMSE, no physics involved): 0.144680\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.013746 - Val Loss (simple RMSE, no physics involved): 0.139262\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.013365 - Val Loss (simple RMSE, no physics involved): 0.138155\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.013027 - Val Loss (simple RMSE, no physics involved): 0.138854\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.012758 - Val Loss (simple RMSE, no physics involved): 0.137034\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.012670 - Val Loss (simple RMSE, no physics involved): 0.138527\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.012488 - Val Loss (simple RMSE, no physics involved): 0.135764\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012422 - Val Loss (simple RMSE, no physics involved): 0.135992\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012474 - Val Loss (simple RMSE, no physics involved): 0.136208\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012215 - Val Loss (simple RMSE, no physics involved): 0.135930\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012308 - Val Loss (simple RMSE, no physics involved): 0.136353\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012037 - Val Loss (simple RMSE, no physics involved): 0.137330\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012186 - Val Loss (simple RMSE, no physics involved): 0.135498\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012085 - Val Loss (simple RMSE, no physics involved): 0.137410\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.011886 - Val Loss (simple RMSE, no physics involved): 0.137419\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.011765 - Val Loss (simple RMSE, no physics involved): 0.134936\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.011917 - Val Loss (simple RMSE, no physics involved): 0.136806\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.011862 - Val Loss (simple RMSE, no physics involved): 0.141494\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.011906 - Val Loss (simple RMSE, no physics involved): 0.136369\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.011943 - Val Loss (simple RMSE, no physics involved): 0.143424\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012416 - Val Loss (simple RMSE, no physics involved): 0.136996\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012156 - Val Loss (simple RMSE, no physics involved): 0.138984\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011919 - Val Loss (simple RMSE, no physics involved): 0.137447\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011684 - Val Loss (simple RMSE, no physics involved): 0.135852\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011729 - Val Loss (simple RMSE, no physics involved): 0.139004\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011512 - Val Loss (simple RMSE, no physics involved): 0.136973\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011454 - Val Loss (simple RMSE, no physics involved): 0.142975\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011731 - Val Loss (simple RMSE, no physics involved): 0.137382\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011916 - Val Loss (simple RMSE, no physics involved): 0.142414\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011832 - Val Loss (simple RMSE, no physics involved): 0.137680\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012069 - Val Loss (simple RMSE, no physics involved): 0.137932\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011660 - Val Loss (simple RMSE, no physics involved): 0.137829\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011378 - Val Loss (simple RMSE, no physics involved): 0.137662\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011324 - Val Loss (simple RMSE, no physics involved): 0.136756\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011403 - Val Loss (simple RMSE, no physics involved): 0.143642\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011400 - Val Loss (simple RMSE, no physics involved): 0.138357\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011326 - Val Loss (simple RMSE, no physics involved): 0.141953\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011381 - Val Loss (simple RMSE, no physics involved): 0.141041\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011254 - Val Loss (simple RMSE, no physics involved): 0.137238\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011335 - Val Loss (simple RMSE, no physics involved): 0.144417\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011190 - Val Loss (simple RMSE, no physics involved): 0.137617\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011223 - Val Loss (simple RMSE, no physics involved): 0.138016\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011360 - Val Loss (simple RMSE, no physics involved): 0.147957\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012097 - Val Loss (simple RMSE, no physics involved): 0.137125\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011384 - Val Loss (simple RMSE, no physics involved): 0.140909\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011068 - Val Loss (simple RMSE, no physics involved): 0.140678\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011149 - Val Loss (simple RMSE, no physics involved): 0.137322\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:11:35,711] Trial 88 finished with value: 0.13493632028500238 and parameters: {'n_hidden_layers': 1, 'n_hidden_units': 135, 'lr': 0.003196548552931415, 'weight_decay': 2.9586362901087705e-06, 'batch_size': 8}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011001 - Val Loss (simple RMSE, no physics involved): 0.143463\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.064867 - Val Loss (simple RMSE, no physics involved): 0.202915\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.038780 - Val Loss (simple RMSE, no physics involved): 0.231412\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.027041 - Val Loss (simple RMSE, no physics involved): 0.219283\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.022087 - Val Loss (simple RMSE, no physics involved): 0.177992\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.020794 - Val Loss (simple RMSE, no physics involved): 0.172830\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.017162 - Val Loss (simple RMSE, no physics involved): 0.155778\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.016146 - Val Loss (simple RMSE, no physics involved): 0.150410\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014837 - Val Loss (simple RMSE, no physics involved): 0.147264\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013147 - Val Loss (simple RMSE, no physics involved): 0.145866\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014140 - Val Loss (simple RMSE, no physics involved): 0.143338\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014220 - Val Loss (simple RMSE, no physics involved): 0.142924\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013294 - Val Loss (simple RMSE, no physics involved): 0.143713\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012977 - Val Loss (simple RMSE, no physics involved): 0.142416\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012509 - Val Loss (simple RMSE, no physics involved): 0.142393\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013225 - Val Loss (simple RMSE, no physics involved): 0.141233\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012545 - Val Loss (simple RMSE, no physics involved): 0.141045\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012986 - Val Loss (simple RMSE, no physics involved): 0.140679\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.011986 - Val Loss (simple RMSE, no physics involved): 0.141089\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012033 - Val Loss (simple RMSE, no physics involved): 0.140755\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.011962 - Val Loss (simple RMSE, no physics involved): 0.140521\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.011853 - Val Loss (simple RMSE, no physics involved): 0.140153\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012444 - Val Loss (simple RMSE, no physics involved): 0.139976\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012387 - Val Loss (simple RMSE, no physics involved): 0.142304\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013070 - Val Loss (simple RMSE, no physics involved): 0.140829\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012958 - Val Loss (simple RMSE, no physics involved): 0.142810\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011970 - Val Loss (simple RMSE, no physics involved): 0.141137\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012223 - Val Loss (simple RMSE, no physics involved): 0.141502\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011970 - Val Loss (simple RMSE, no physics involved): 0.141360\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012077 - Val Loss (simple RMSE, no physics involved): 0.140112\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011645 - Val Loss (simple RMSE, no physics involved): 0.142196\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013241 - Val Loss (simple RMSE, no physics involved): 0.141658\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011837 - Val Loss (simple RMSE, no physics involved): 0.140970\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012151 - Val Loss (simple RMSE, no physics involved): 0.140857\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012565 - Val Loss (simple RMSE, no physics involved): 0.142874\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012912 - Val Loss (simple RMSE, no physics involved): 0.141885\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012265 - Val Loss (simple RMSE, no physics involved): 0.144260\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012630 - Val Loss (simple RMSE, no physics involved): 0.142476\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011681 - Val Loss (simple RMSE, no physics involved): 0.142839\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011827 - Val Loss (simple RMSE, no physics involved): 0.141142\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012406 - Val Loss (simple RMSE, no physics involved): 0.141006\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012116 - Val Loss (simple RMSE, no physics involved): 0.141845\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012141 - Val Loss (simple RMSE, no physics involved): 0.141844\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011953 - Val Loss (simple RMSE, no physics involved): 0.143005\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012230 - Val Loss (simple RMSE, no physics involved): 0.144162\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012645 - Val Loss (simple RMSE, no physics involved): 0.143683\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011584 - Val Loss (simple RMSE, no physics involved): 0.144756\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011609 - Val Loss (simple RMSE, no physics involved): 0.143998\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012430 - Val Loss (simple RMSE, no physics involved): 0.144997\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:11:44,641] Trial 89 finished with value: 0.13997633755207062 and parameters: {'n_hidden_layers': 2, 'n_hidden_units': 158, 'lr': 0.0019476571646594837, 'weight_decay': 1.8418407509218775e-08, 'batch_size': 32}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 - Train Loss: 0.011854 - Val Loss (simple RMSE, no physics involved): 0.143793\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.011558 - Val Loss (simple RMSE, no physics involved): 0.146038\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.153567 - Val Loss (simple RMSE, no physics involved): 0.377879\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.057984 - Val Loss (simple RMSE, no physics involved): 0.222624\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029069 - Val Loss (simple RMSE, no physics involved): 0.188539\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025232 - Val Loss (simple RMSE, no physics involved): 0.181804\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.018209 - Val Loss (simple RMSE, no physics involved): 0.146326\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.015021 - Val Loss (simple RMSE, no physics involved): 0.142371\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.014253 - Val Loss (simple RMSE, no physics involved): 0.133060\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013939 - Val Loss (simple RMSE, no physics involved): 0.136544\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013113 - Val Loss (simple RMSE, no physics involved): 0.128977\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012875 - Val Loss (simple RMSE, no physics involved): 0.130193\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013445 - Val Loss (simple RMSE, no physics involved): 0.128817\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012650 - Val Loss (simple RMSE, no physics involved): 0.133589\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012661 - Val Loss (simple RMSE, no physics involved): 0.136081\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013238 - Val Loss (simple RMSE, no physics involved): 0.144257\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.014998 - Val Loss (simple RMSE, no physics involved): 0.128722\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.014245 - Val Loss (simple RMSE, no physics involved): 0.135521\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013877 - Val Loss (simple RMSE, no physics involved): 0.135803\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013182 - Val Loss (simple RMSE, no physics involved): 0.129231\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012393 - Val Loss (simple RMSE, no physics involved): 0.130143\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012536 - Val Loss (simple RMSE, no physics involved): 0.130046\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012906 - Val Loss (simple RMSE, no physics involved): 0.131231\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.011985 - Val Loss (simple RMSE, no physics involved): 0.129421\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.011950 - Val Loss (simple RMSE, no physics involved): 0.129268\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012685 - Val Loss (simple RMSE, no physics involved): 0.131021\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011990 - Val Loss (simple RMSE, no physics involved): 0.130894\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012179 - Val Loss (simple RMSE, no physics involved): 0.147432\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013096 - Val Loss (simple RMSE, no physics involved): 0.132584\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012183 - Val Loss (simple RMSE, no physics involved): 0.131249\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012003 - Val Loss (simple RMSE, no physics involved): 0.134506\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012316 - Val Loss (simple RMSE, no physics involved): 0.133422\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011716 - Val Loss (simple RMSE, no physics involved): 0.130787\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012329 - Val Loss (simple RMSE, no physics involved): 0.138212\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012531 - Val Loss (simple RMSE, no physics involved): 0.141715\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012668 - Val Loss (simple RMSE, no physics involved): 0.132577\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012512 - Val Loss (simple RMSE, no physics involved): 0.133965\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.013099 - Val Loss (simple RMSE, no physics involved): 0.148320\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012642 - Val Loss (simple RMSE, no physics involved): 0.133175\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011876 - Val Loss (simple RMSE, no physics involved): 0.130596\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011919 - Val Loss (simple RMSE, no physics involved): 0.132813\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012003 - Val Loss (simple RMSE, no physics involved): 0.137545\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011835 - Val Loss (simple RMSE, no physics involved): 0.132037\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011994 - Val Loss (simple RMSE, no physics involved): 0.131995\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012866 - Val Loss (simple RMSE, no physics involved): 0.132403\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011790 - Val Loss (simple RMSE, no physics involved): 0.130579\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011553 - Val Loss (simple RMSE, no physics involved): 0.135457\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011959 - Val Loss (simple RMSE, no physics involved): 0.132265\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011307 - Val Loss (simple RMSE, no physics involved): 0.133189\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011354 - Val Loss (simple RMSE, no physics involved): 0.134437\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012336 - Val Loss (simple RMSE, no physics involved): 0.131502\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:12:11,224] Trial 90 finished with value: 0.1287224069237709 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 189, 'lr': 0.006229120641051047, 'weight_decay': 1.2698052916457507e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011069 - Val Loss (simple RMSE, no physics involved): 0.135613\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.115225 - Val Loss (simple RMSE, no physics involved): 0.358858\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.048612 - Val Loss (simple RMSE, no physics involved): 0.211536\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.029842 - Val Loss (simple RMSE, no physics involved): 0.191829\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.031243 - Val Loss (simple RMSE, no physics involved): 0.216620\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.029760 - Val Loss (simple RMSE, no physics involved): 0.199902\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.024466 - Val Loss (simple RMSE, no physics involved): 0.152147\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.016362 - Val Loss (simple RMSE, no physics involved): 0.138910\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014237 - Val Loss (simple RMSE, no physics involved): 0.138854\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014299 - Val Loss (simple RMSE, no physics involved): 0.143740\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013437 - Val Loss (simple RMSE, no physics involved): 0.134309\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013161 - Val Loss (simple RMSE, no physics involved): 0.133508\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.012883 - Val Loss (simple RMSE, no physics involved): 0.132149\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013208 - Val Loss (simple RMSE, no physics involved): 0.134105\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012949 - Val Loss (simple RMSE, no physics involved): 0.141113\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013638 - Val Loss (simple RMSE, no physics involved): 0.134806\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012249 - Val Loss (simple RMSE, no physics involved): 0.133991\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012236 - Val Loss (simple RMSE, no physics involved): 0.133275\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012197 - Val Loss (simple RMSE, no physics involved): 0.134781\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012570 - Val Loss (simple RMSE, no physics involved): 0.132822\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013159 - Val Loss (simple RMSE, no physics involved): 0.137697\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012436 - Val Loss (simple RMSE, no physics involved): 0.134922\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012265 - Val Loss (simple RMSE, no physics involved): 0.132757\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012070 - Val Loss (simple RMSE, no physics involved): 0.133509\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012498 - Val Loss (simple RMSE, no physics involved): 0.139671\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012493 - Val Loss (simple RMSE, no physics involved): 0.135480\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012148 - Val Loss (simple RMSE, no physics involved): 0.132802\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012063 - Val Loss (simple RMSE, no physics involved): 0.134355\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011425 - Val Loss (simple RMSE, no physics involved): 0.138932\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012373 - Val Loss (simple RMSE, no physics involved): 0.148322\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.013322 - Val Loss (simple RMSE, no physics involved): 0.139361\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.013440 - Val Loss (simple RMSE, no physics involved): 0.131713\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012069 - Val Loss (simple RMSE, no physics involved): 0.137825\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012674 - Val Loss (simple RMSE, no physics involved): 0.131848\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.013146 - Val Loss (simple RMSE, no physics involved): 0.133158\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011768 - Val Loss (simple RMSE, no physics involved): 0.133670\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011601 - Val Loss (simple RMSE, no physics involved): 0.133806\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012327 - Val Loss (simple RMSE, no physics involved): 0.137090\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012203 - Val Loss (simple RMSE, no physics involved): 0.134022\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012011 - Val Loss (simple RMSE, no physics involved): 0.134764\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011587 - Val Loss (simple RMSE, no physics involved): 0.142443\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012717 - Val Loss (simple RMSE, no physics involved): 0.133069\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012363 - Val Loss (simple RMSE, no physics involved): 0.135204\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012062 - Val Loss (simple RMSE, no physics involved): 0.136962\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011202 - Val Loss (simple RMSE, no physics involved): 0.132024\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011569 - Val Loss (simple RMSE, no physics involved): 0.132846\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011098 - Val Loss (simple RMSE, no physics involved): 0.132531\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011367 - Val Loss (simple RMSE, no physics involved): 0.134305\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011402 - Val Loss (simple RMSE, no physics involved): 0.146330\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.012452 - Val Loss (simple RMSE, no physics involved): 0.130112\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:12:37,456] Trial 91 finished with value: 0.13011182472109795 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 188, 'lr': 0.00627000002632458, 'weight_decay': 8.22899722089507e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011947 - Val Loss (simple RMSE, no physics involved): 0.133572\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.044384 - Val Loss (simple RMSE, no physics involved): 0.229003\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.026350 - Val Loss (simple RMSE, no physics involved): 0.190704\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.018195 - Val Loss (simple RMSE, no physics involved): 0.150157\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.015528 - Val Loss (simple RMSE, no physics involved): 0.150438\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.013985 - Val Loss (simple RMSE, no physics involved): 0.138208\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.013606 - Val Loss (simple RMSE, no physics involved): 0.147698\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013314 - Val Loss (simple RMSE, no physics involved): 0.135293\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013635 - Val Loss (simple RMSE, no physics involved): 0.169765\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014164 - Val Loss (simple RMSE, no physics involved): 0.173220\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.015364 - Val Loss (simple RMSE, no physics involved): 0.152903\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014724 - Val Loss (simple RMSE, no physics involved): 0.146108\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013547 - Val Loss (simple RMSE, no physics involved): 0.149074\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013787 - Val Loss (simple RMSE, no physics involved): 0.140199\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013340 - Val Loss (simple RMSE, no physics involved): 0.132430\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012509 - Val Loss (simple RMSE, no physics involved): 0.134859\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013186 - Val Loss (simple RMSE, no physics involved): 0.137667\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013143 - Val Loss (simple RMSE, no physics involved): 0.135446\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012987 - Val Loss (simple RMSE, no physics involved): 0.134727\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012485 - Val Loss (simple RMSE, no physics involved): 0.134953\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012488 - Val Loss (simple RMSE, no physics involved): 0.132863\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.011989 - Val Loss (simple RMSE, no physics involved): 0.139209\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.011697 - Val Loss (simple RMSE, no physics involved): 0.133550\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012273 - Val Loss (simple RMSE, no physics involved): 0.136602\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012401 - Val Loss (simple RMSE, no physics involved): 0.133262\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012325 - Val Loss (simple RMSE, no physics involved): 0.134468\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012397 - Val Loss (simple RMSE, no physics involved): 0.137713\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012202 - Val Loss (simple RMSE, no physics involved): 0.135105\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.011798 - Val Loss (simple RMSE, no physics involved): 0.136922\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011936 - Val Loss (simple RMSE, no physics involved): 0.137874\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012306 - Val Loss (simple RMSE, no physics involved): 0.134646\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012436 - Val Loss (simple RMSE, no physics involved): 0.144705\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012079 - Val Loss (simple RMSE, no physics involved): 0.137049\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011644 - Val Loss (simple RMSE, no physics involved): 0.140308\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011438 - Val Loss (simple RMSE, no physics involved): 0.143434\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012176 - Val Loss (simple RMSE, no physics involved): 0.137907\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011771 - Val Loss (simple RMSE, no physics involved): 0.140063\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011818 - Val Loss (simple RMSE, no physics involved): 0.142237\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012450 - Val Loss (simple RMSE, no physics involved): 0.140357\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012822 - Val Loss (simple RMSE, no physics involved): 0.140696\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011254 - Val Loss (simple RMSE, no physics involved): 0.136795\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011565 - Val Loss (simple RMSE, no physics involved): 0.137595\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011238 - Val Loss (simple RMSE, no physics involved): 0.140243\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012045 - Val Loss (simple RMSE, no physics involved): 0.143590\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011110 - Val Loss (simple RMSE, no physics involved): 0.151251\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011193 - Val Loss (simple RMSE, no physics involved): 0.140620\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011745 - Val Loss (simple RMSE, no physics involved): 0.144546\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011361 - Val Loss (simple RMSE, no physics involved): 0.145341\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011989 - Val Loss (simple RMSE, no physics involved): 0.141735\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011138 - Val Loss (simple RMSE, no physics involved): 0.138392\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:13:02,505] Trial 92 finished with value: 0.1324303112924099 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 168, 'lr': 0.004448041319270398, 'weight_decay': 5.788112205452747e-06, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012790 - Val Loss (simple RMSE, no physics involved): 0.142990\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.088055 - Val Loss (simple RMSE, no physics involved): 0.278112\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.036938 - Val Loss (simple RMSE, no physics involved): 0.193547\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.032314 - Val Loss (simple RMSE, no physics involved): 0.243942\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.029195 - Val Loss (simple RMSE, no physics involved): 0.196515\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.027829 - Val Loss (simple RMSE, no physics involved): 0.188380\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.025121 - Val Loss (simple RMSE, no physics involved): 0.191260\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.022102 - Val Loss (simple RMSE, no physics involved): 0.163710\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.018692 - Val Loss (simple RMSE, no physics involved): 0.152541\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.016141 - Val Loss (simple RMSE, no physics involved): 0.155029\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.015795 - Val Loss (simple RMSE, no physics involved): 0.143316\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014449 - Val Loss (simple RMSE, no physics involved): 0.142257\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.014174 - Val Loss (simple RMSE, no physics involved): 0.137567\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013777 - Val Loss (simple RMSE, no physics involved): 0.135215\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013559 - Val Loss (simple RMSE, no physics involved): 0.136344\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013577 - Val Loss (simple RMSE, no physics involved): 0.137288\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.014016 - Val Loss (simple RMSE, no physics involved): 0.134745\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.013187 - Val Loss (simple RMSE, no physics involved): 0.131416\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013039 - Val Loss (simple RMSE, no physics involved): 0.133011\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012736 - Val Loss (simple RMSE, no physics involved): 0.131120\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012417 - Val Loss (simple RMSE, no physics involved): 0.130194\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012437 - Val Loss (simple RMSE, no physics involved): 0.130091\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012287 - Val Loss (simple RMSE, no physics involved): 0.129415\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012343 - Val Loss (simple RMSE, no physics involved): 0.130741\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012449 - Val Loss (simple RMSE, no physics involved): 0.129530\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012461 - Val Loss (simple RMSE, no physics involved): 0.129404\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012663 - Val Loss (simple RMSE, no physics involved): 0.129255\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012229 - Val Loss (simple RMSE, no physics involved): 0.129298\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012409 - Val Loss (simple RMSE, no physics involved): 0.129933\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012554 - Val Loss (simple RMSE, no physics involved): 0.129397\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012040 - Val Loss (simple RMSE, no physics involved): 0.129531\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012539 - Val Loss (simple RMSE, no physics involved): 0.130698\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012313 - Val Loss (simple RMSE, no physics involved): 0.129354\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011840 - Val Loss (simple RMSE, no physics involved): 0.129823\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012098 - Val Loss (simple RMSE, no physics involved): 0.129858\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012120 - Val Loss (simple RMSE, no physics involved): 0.132173\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012891 - Val Loss (simple RMSE, no physics involved): 0.128951\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012970 - Val Loss (simple RMSE, no physics involved): 0.136865\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012324 - Val Loss (simple RMSE, no physics involved): 0.133062\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012101 - Val Loss (simple RMSE, no physics involved): 0.133811\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012047 - Val Loss (simple RMSE, no physics involved): 0.130934\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012595 - Val Loss (simple RMSE, no physics involved): 0.133198\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012625 - Val Loss (simple RMSE, no physics involved): 0.129867\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012300 - Val Loss (simple RMSE, no physics involved): 0.130113\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012294 - Val Loss (simple RMSE, no physics involved): 0.133800\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012656 - Val Loss (simple RMSE, no physics involved): 0.129972\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012504 - Val Loss (simple RMSE, no physics involved): 0.136700\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012360 - Val Loss (simple RMSE, no physics involved): 0.134914\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012492 - Val Loss (simple RMSE, no physics involved): 0.130960\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011647 - Val Loss (simple RMSE, no physics involved): 0.130170\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:13:33,061] Trial 93 finished with value: 0.1289505437016487 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 209, 'lr': 0.0006070103770490416, 'weight_decay': 1.2550677965480448e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011932 - Val Loss (simple RMSE, no physics involved): 0.130268\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.112376 - Val Loss (simple RMSE, no physics involved): 0.289054\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.040249 - Val Loss (simple RMSE, no physics involved): 0.186731\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028763 - Val Loss (simple RMSE, no physics involved): 0.231326\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.025964 - Val Loss (simple RMSE, no physics involved): 0.174408\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.023031 - Val Loss (simple RMSE, no physics involved): 0.172010\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.019478 - Val Loss (simple RMSE, no physics involved): 0.159001\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.017235 - Val Loss (simple RMSE, no physics involved): 0.149653\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015616 - Val Loss (simple RMSE, no physics involved): 0.147651\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014798 - Val Loss (simple RMSE, no physics involved): 0.140434\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014115 - Val Loss (simple RMSE, no physics involved): 0.143925\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.014246 - Val Loss (simple RMSE, no physics involved): 0.136191\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013498 - Val Loss (simple RMSE, no physics involved): 0.134699\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013777 - Val Loss (simple RMSE, no physics involved): 0.135397\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013272 - Val Loss (simple RMSE, no physics involved): 0.133653\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013174 - Val Loss (simple RMSE, no physics involved): 0.133565\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013192 - Val Loss (simple RMSE, no physics involved): 0.132168\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012708 - Val Loss (simple RMSE, no physics involved): 0.132030\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012953 - Val Loss (simple RMSE, no physics involved): 0.132569\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013298 - Val Loss (simple RMSE, no physics involved): 0.130765\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.013090 - Val Loss (simple RMSE, no physics involved): 0.131142\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013011 - Val Loss (simple RMSE, no physics involved): 0.131197\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012319 - Val Loss (simple RMSE, no physics involved): 0.131328\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012269 - Val Loss (simple RMSE, no physics involved): 0.135601\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012680 - Val Loss (simple RMSE, no physics involved): 0.132203\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012213 - Val Loss (simple RMSE, no physics involved): 0.130248\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012557 - Val Loss (simple RMSE, no physics involved): 0.130620\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012782 - Val Loss (simple RMSE, no physics involved): 0.129686\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012346 - Val Loss (simple RMSE, no physics involved): 0.130279\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011995 - Val Loss (simple RMSE, no physics involved): 0.129427\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012476 - Val Loss (simple RMSE, no physics involved): 0.129184\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012073 - Val Loss (simple RMSE, no physics involved): 0.129632\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012425 - Val Loss (simple RMSE, no physics involved): 0.130183\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012218 - Val Loss (simple RMSE, no physics involved): 0.131001\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012027 - Val Loss (simple RMSE, no physics involved): 0.130017\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012335 - Val Loss (simple RMSE, no physics involved): 0.131389\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012320 - Val Loss (simple RMSE, no physics involved): 0.133681\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012486 - Val Loss (simple RMSE, no physics involved): 0.131657\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012156 - Val Loss (simple RMSE, no physics involved): 0.130843\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011999 - Val Loss (simple RMSE, no physics involved): 0.130652\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011905 - Val Loss (simple RMSE, no physics involved): 0.132137\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011872 - Val Loss (simple RMSE, no physics involved): 0.131250\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011838 - Val Loss (simple RMSE, no physics involved): 0.130774\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011694 - Val Loss (simple RMSE, no physics involved): 0.131294\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012004 - Val Loss (simple RMSE, no physics involved): 0.130681\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012033 - Val Loss (simple RMSE, no physics involved): 0.130743\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011996 - Val Loss (simple RMSE, no physics involved): 0.131070\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011858 - Val Loss (simple RMSE, no physics involved): 0.131650\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011781 - Val Loss (simple RMSE, no physics involved): 0.130697\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011553 - Val Loss (simple RMSE, no physics involved): 0.131840\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:14:09,038] Trial 94 finished with value: 0.12918396666646004 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 180, 'lr': 0.0007365817762727385, 'weight_decay': 3.571326285951423e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011829 - Val Loss (simple RMSE, no physics involved): 0.131561\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.081714 - Val Loss (simple RMSE, no physics involved): 0.287337\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.036364 - Val Loss (simple RMSE, no physics involved): 0.191633\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.026568 - Val Loss (simple RMSE, no physics involved): 0.227785\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.027707 - Val Loss (simple RMSE, no physics involved): 0.204778\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.025215 - Val Loss (simple RMSE, no physics involved): 0.181399\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.022314 - Val Loss (simple RMSE, no physics involved): 0.182981\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.019548 - Val Loss (simple RMSE, no physics involved): 0.155118\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.015549 - Val Loss (simple RMSE, no physics involved): 0.144523\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014936 - Val Loss (simple RMSE, no physics involved): 0.139073\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014210 - Val Loss (simple RMSE, no physics involved): 0.136816\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013358 - Val Loss (simple RMSE, no physics involved): 0.137707\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013483 - Val Loss (simple RMSE, no physics involved): 0.133224\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013233 - Val Loss (simple RMSE, no physics involved): 0.135558\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012582 - Val Loss (simple RMSE, no physics involved): 0.141066\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013213 - Val Loss (simple RMSE, no physics involved): 0.135615\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013180 - Val Loss (simple RMSE, no physics involved): 0.130229\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012508 - Val Loss (simple RMSE, no physics involved): 0.129759\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012903 - Val Loss (simple RMSE, no physics involved): 0.130190\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012674 - Val Loss (simple RMSE, no physics involved): 0.130176\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012493 - Val Loss (simple RMSE, no physics involved): 0.130005\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012365 - Val Loss (simple RMSE, no physics involved): 0.131374\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012360 - Val Loss (simple RMSE, no physics involved): 0.133013\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012852 - Val Loss (simple RMSE, no physics involved): 0.130287\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012644 - Val Loss (simple RMSE, no physics involved): 0.130239\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012532 - Val Loss (simple RMSE, no physics involved): 0.130418\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012346 - Val Loss (simple RMSE, no physics involved): 0.130208\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012093 - Val Loss (simple RMSE, no physics involved): 0.130900\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012512 - Val Loss (simple RMSE, no physics involved): 0.130693\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012658 - Val Loss (simple RMSE, no physics involved): 0.130918\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012087 - Val Loss (simple RMSE, no physics involved): 0.130163\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012370 - Val Loss (simple RMSE, no physics involved): 0.130109\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012291 - Val Loss (simple RMSE, no physics involved): 0.131620\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012321 - Val Loss (simple RMSE, no physics involved): 0.132692\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012136 - Val Loss (simple RMSE, no physics involved): 0.131792\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012036 - Val Loss (simple RMSE, no physics involved): 0.130428\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011998 - Val Loss (simple RMSE, no physics involved): 0.129880\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.011884 - Val Loss (simple RMSE, no physics involved): 0.129912\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012217 - Val Loss (simple RMSE, no physics involved): 0.129662\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011672 - Val Loss (simple RMSE, no physics involved): 0.130030\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011896 - Val Loss (simple RMSE, no physics involved): 0.131099\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012024 - Val Loss (simple RMSE, no physics involved): 0.131043\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012012 - Val Loss (simple RMSE, no physics involved): 0.131475\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011946 - Val Loss (simple RMSE, no physics involved): 0.130954\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011996 - Val Loss (simple RMSE, no physics involved): 0.130214\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011615 - Val Loss (simple RMSE, no physics involved): 0.130262\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011779 - Val Loss (simple RMSE, no physics involved): 0.130354\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011803 - Val Loss (simple RMSE, no physics involved): 0.130336\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011473 - Val Loss (simple RMSE, no physics involved): 0.131114\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011637 - Val Loss (simple RMSE, no physics involved): 0.130591\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:14:41,361] Trial 95 finished with value: 0.12966158613562584 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 221, 'lr': 0.0005806693693459621, 'weight_decay': 2.30727030053117e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011540 - Val Loss (simple RMSE, no physics involved): 0.132651\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.071091 - Val Loss (simple RMSE, no physics involved): 0.194949\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.031488 - Val Loss (simple RMSE, no physics involved): 0.241836\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028583 - Val Loss (simple RMSE, no physics involved): 0.187013\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.024911 - Val Loss (simple RMSE, no physics involved): 0.188932\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.021541 - Val Loss (simple RMSE, no physics involved): 0.165371\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.017466 - Val Loss (simple RMSE, no physics involved): 0.150162\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.015271 - Val Loss (simple RMSE, no physics involved): 0.145131\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.014586 - Val Loss (simple RMSE, no physics involved): 0.141281\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.014592 - Val Loss (simple RMSE, no physics involved): 0.140637\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013428 - Val Loss (simple RMSE, no physics involved): 0.141147\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013147 - Val Loss (simple RMSE, no physics involved): 0.138596\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013125 - Val Loss (simple RMSE, no physics involved): 0.134242\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012735 - Val Loss (simple RMSE, no physics involved): 0.132538\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.012416 - Val Loss (simple RMSE, no physics involved): 0.133002\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012383 - Val Loss (simple RMSE, no physics involved): 0.131722\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012828 - Val Loss (simple RMSE, no physics involved): 0.132244\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012347 - Val Loss (simple RMSE, no physics involved): 0.131816\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012179 - Val Loss (simple RMSE, no physics involved): 0.131609\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012214 - Val Loss (simple RMSE, no physics involved): 0.134052\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012354 - Val Loss (simple RMSE, no physics involved): 0.133106\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012382 - Val Loss (simple RMSE, no physics involved): 0.131181\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012174 - Val Loss (simple RMSE, no physics involved): 0.131404\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012234 - Val Loss (simple RMSE, no physics involved): 0.132732\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012774 - Val Loss (simple RMSE, no physics involved): 0.131042\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012541 - Val Loss (simple RMSE, no physics involved): 0.131644\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012326 - Val Loss (simple RMSE, no physics involved): 0.131743\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011793 - Val Loss (simple RMSE, no physics involved): 0.134750\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012572 - Val Loss (simple RMSE, no physics involved): 0.137120\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012200 - Val Loss (simple RMSE, no physics involved): 0.132755\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012136 - Val Loss (simple RMSE, no physics involved): 0.135024\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011676 - Val Loss (simple RMSE, no physics involved): 0.133644\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011821 - Val Loss (simple RMSE, no physics involved): 0.133896\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011613 - Val Loss (simple RMSE, no physics involved): 0.137746\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012310 - Val Loss (simple RMSE, no physics involved): 0.139225\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011828 - Val Loss (simple RMSE, no physics involved): 0.133040\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011992 - Val Loss (simple RMSE, no physics involved): 0.135577\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.013006 - Val Loss (simple RMSE, no physics involved): 0.139198\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012085 - Val Loss (simple RMSE, no physics involved): 0.134247\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011663 - Val Loss (simple RMSE, no physics involved): 0.134725\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012190 - Val Loss (simple RMSE, no physics involved): 0.133178\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011490 - Val Loss (simple RMSE, no physics involved): 0.133648\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011725 - Val Loss (simple RMSE, no physics involved): 0.136639\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012429 - Val Loss (simple RMSE, no physics involved): 0.135353\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012528 - Val Loss (simple RMSE, no physics involved): 0.134957\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011814 - Val Loss (simple RMSE, no physics involved): 0.134266\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011739 - Val Loss (simple RMSE, no physics involved): 0.134244\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011417 - Val Loss (simple RMSE, no physics involved): 0.134577\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011503 - Val Loss (simple RMSE, no physics involved): 0.136150\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011379 - Val Loss (simple RMSE, no physics involved): 0.134375\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:15:18,323] Trial 96 finished with value: 0.13104235008358955 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 230, 'lr': 0.0009385300131385448, 'weight_decay': 2.0680211644864844e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011463 - Val Loss (simple RMSE, no physics involved): 0.134102\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.077377 - Val Loss (simple RMSE, no physics involved): 0.641946\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.294810 - Val Loss (simple RMSE, no physics involved): 0.297610\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.045500 - Val Loss (simple RMSE, no physics involved): 0.332556\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.055663 - Val Loss (simple RMSE, no physics involved): 0.321730\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.047479 - Val Loss (simple RMSE, no physics involved): 0.273223\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.032711 - Val Loss (simple RMSE, no physics involved): 0.201904\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.035015 - Val Loss (simple RMSE, no physics involved): 0.212614\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.028664 - Val Loss (simple RMSE, no physics involved): 0.237343\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.028445 - Val Loss (simple RMSE, no physics involved): 0.238033\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.028681 - Val Loss (simple RMSE, no physics involved): 0.226249\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.027143 - Val Loss (simple RMSE, no physics involved): 0.214233\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.027089 - Val Loss (simple RMSE, no physics involved): 0.211621\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.026011 - Val Loss (simple RMSE, no physics involved): 0.201991\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.021662 - Val Loss (simple RMSE, no physics involved): 0.179471\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.017148 - Val Loss (simple RMSE, no physics involved): 0.153930\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.017149 - Val Loss (simple RMSE, no physics involved): 0.151675\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.016895 - Val Loss (simple RMSE, no physics involved): 0.145769\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.014768 - Val Loss (simple RMSE, no physics involved): 0.149902\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.014181 - Val Loss (simple RMSE, no physics involved): 0.153802\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.015168 - Val Loss (simple RMSE, no physics involved): 0.145445\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.013979 - Val Loss (simple RMSE, no physics involved): 0.141716\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.013706 - Val Loss (simple RMSE, no physics involved): 0.142059\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.013940 - Val Loss (simple RMSE, no physics involved): 0.143485\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.013487 - Val Loss (simple RMSE, no physics involved): 0.145351\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.013738 - Val Loss (simple RMSE, no physics involved): 0.142152\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.013238 - Val Loss (simple RMSE, no physics involved): 0.147120\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.013142 - Val Loss (simple RMSE, no physics involved): 0.144536\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.013592 - Val Loss (simple RMSE, no physics involved): 0.142794\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.013169 - Val Loss (simple RMSE, no physics involved): 0.141338\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012845 - Val Loss (simple RMSE, no physics involved): 0.143510\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012591 - Val Loss (simple RMSE, no physics involved): 0.141529\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012877 - Val Loss (simple RMSE, no physics involved): 0.141039\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012744 - Val Loss (simple RMSE, no physics involved): 0.141691\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012637 - Val Loss (simple RMSE, no physics involved): 0.140176\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012366 - Val Loss (simple RMSE, no physics involved): 0.142925\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012724 - Val Loss (simple RMSE, no physics involved): 0.139985\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012875 - Val Loss (simple RMSE, no physics involved): 0.141661\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012508 - Val Loss (simple RMSE, no physics involved): 0.139823\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012710 - Val Loss (simple RMSE, no physics involved): 0.141980\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.012236 - Val Loss (simple RMSE, no physics involved): 0.140027\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012133 - Val Loss (simple RMSE, no physics involved): 0.140800\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012404 - Val Loss (simple RMSE, no physics involved): 0.140560\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012222 - Val Loss (simple RMSE, no physics involved): 0.140698\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011874 - Val Loss (simple RMSE, no physics involved): 0.142769\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012003 - Val Loss (simple RMSE, no physics involved): 0.140484\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012232 - Val Loss (simple RMSE, no physics involved): 0.139995\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011957 - Val Loss (simple RMSE, no physics involved): 0.159580\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.013157 - Val Loss (simple RMSE, no physics involved): 0.140869\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.013299 - Val Loss (simple RMSE, no physics involved): 0.140687\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:15:34,476] Trial 97 finished with value: 0.13982316851615906 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 207, 'lr': 0.005565384201555387, 'weight_decay': 1.3930947402730545e-05, 'batch_size': 64}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011911 - Val Loss (simple RMSE, no physics involved): 0.141303\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.066225 - Val Loss (simple RMSE, no physics involved): 0.229074\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.027301 - Val Loss (simple RMSE, no physics involved): 0.177973\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.020744 - Val Loss (simple RMSE, no physics involved): 0.156126\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.016384 - Val Loss (simple RMSE, no physics involved): 0.148056\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.014479 - Val Loss (simple RMSE, no physics involved): 0.143584\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.013875 - Val Loss (simple RMSE, no physics involved): 0.135372\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013311 - Val Loss (simple RMSE, no physics involved): 0.144567\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013657 - Val Loss (simple RMSE, no physics involved): 0.133884\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.012767 - Val Loss (simple RMSE, no physics involved): 0.133661\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.012618 - Val Loss (simple RMSE, no physics involved): 0.133057\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012384 - Val Loss (simple RMSE, no physics involved): 0.131389\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013110 - Val Loss (simple RMSE, no physics involved): 0.131581\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.012495 - Val Loss (simple RMSE, no physics involved): 0.147375\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013416 - Val Loss (simple RMSE, no physics involved): 0.136943\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012993 - Val Loss (simple RMSE, no physics involved): 0.132718\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012934 - Val Loss (simple RMSE, no physics involved): 0.136004\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012375 - Val Loss (simple RMSE, no physics involved): 0.132285\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012583 - Val Loss (simple RMSE, no physics involved): 0.146628\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012741 - Val Loss (simple RMSE, no physics involved): 0.134117\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012640 - Val Loss (simple RMSE, no physics involved): 0.131985\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012506 - Val Loss (simple RMSE, no physics involved): 0.138278\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012860 - Val Loss (simple RMSE, no physics involved): 0.139391\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012563 - Val Loss (simple RMSE, no physics involved): 0.135922\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.011901 - Val Loss (simple RMSE, no physics involved): 0.134690\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011704 - Val Loss (simple RMSE, no physics involved): 0.134624\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012113 - Val Loss (simple RMSE, no physics involved): 0.133214\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012011 - Val Loss (simple RMSE, no physics involved): 0.137096\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012420 - Val Loss (simple RMSE, no physics involved): 0.135201\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011936 - Val Loss (simple RMSE, no physics involved): 0.136101\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012055 - Val Loss (simple RMSE, no physics involved): 0.134568\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011633 - Val Loss (simple RMSE, no physics involved): 0.133318\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011482 - Val Loss (simple RMSE, no physics involved): 0.135833\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011546 - Val Loss (simple RMSE, no physics involved): 0.133787\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011601 - Val Loss (simple RMSE, no physics involved): 0.135435\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.011667 - Val Loss (simple RMSE, no physics involved): 0.134073\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011576 - Val Loss (simple RMSE, no physics involved): 0.139398\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012329 - Val Loss (simple RMSE, no physics involved): 0.134549\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.011867 - Val Loss (simple RMSE, no physics involved): 0.132281\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011709 - Val Loss (simple RMSE, no physics involved): 0.133319\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011355 - Val Loss (simple RMSE, no physics involved): 0.143914\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011807 - Val Loss (simple RMSE, no physics involved): 0.138927\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012632 - Val Loss (simple RMSE, no physics involved): 0.141489\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.012077 - Val Loss (simple RMSE, no physics involved): 0.137079\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012518 - Val Loss (simple RMSE, no physics involved): 0.132027\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011665 - Val Loss (simple RMSE, no physics involved): 0.148691\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.012147 - Val Loss (simple RMSE, no physics involved): 0.148109\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012136 - Val Loss (simple RMSE, no physics involved): 0.141770\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011473 - Val Loss (simple RMSE, no physics involved): 0.136424\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011540 - Val Loss (simple RMSE, no physics involved): 0.131962\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:16:10,146] Trial 98 finished with value: 0.13138946145772934 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 215, 'lr': 0.002435208740202573, 'weight_decay': 1.1660162565916681e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.011612 - Val Loss (simple RMSE, no physics involved): 0.138326\n",
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.081370 - Val Loss (simple RMSE, no physics involved): 0.213515\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.035702 - Val Loss (simple RMSE, no physics involved): 0.234044\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.033180 - Val Loss (simple RMSE, no physics involved): 0.234501\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.024878 - Val Loss (simple RMSE, no physics involved): 0.177666\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.024472 - Val Loss (simple RMSE, no physics involved): 0.193784\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.022815 - Val Loss (simple RMSE, no physics involved): 0.171018\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.019415 - Val Loss (simple RMSE, no physics involved): 0.157568\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.017110 - Val Loss (simple RMSE, no physics involved): 0.151900\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.015587 - Val Loss (simple RMSE, no physics involved): 0.149917\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.014862 - Val Loss (simple RMSE, no physics involved): 0.144889\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.013888 - Val Loss (simple RMSE, no physics involved): 0.145777\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013753 - Val Loss (simple RMSE, no physics involved): 0.146495\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013748 - Val Loss (simple RMSE, no physics involved): 0.137247\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013571 - Val Loss (simple RMSE, no physics involved): 0.140064\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.013865 - Val Loss (simple RMSE, no physics involved): 0.137064\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.013316 - Val Loss (simple RMSE, no physics involved): 0.135009\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012775 - Val Loss (simple RMSE, no physics involved): 0.134359\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.013104 - Val Loss (simple RMSE, no physics involved): 0.134398\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.013272 - Val Loss (simple RMSE, no physics involved): 0.132895\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012423 - Val Loss (simple RMSE, no physics involved): 0.133492\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012688 - Val Loss (simple RMSE, no physics involved): 0.131938\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012437 - Val Loss (simple RMSE, no physics involved): 0.131219\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012522 - Val Loss (simple RMSE, no physics involved): 0.131078\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012104 - Val Loss (simple RMSE, no physics involved): 0.132123\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.012527 - Val Loss (simple RMSE, no physics involved): 0.131377\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.012443 - Val Loss (simple RMSE, no physics involved): 0.131659\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.012667 - Val Loss (simple RMSE, no physics involved): 0.130778\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012291 - Val Loss (simple RMSE, no physics involved): 0.131925\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.012648 - Val Loss (simple RMSE, no physics involved): 0.131187\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.012585 - Val Loss (simple RMSE, no physics involved): 0.134293\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.012705 - Val Loss (simple RMSE, no physics involved): 0.132221\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.012306 - Val Loss (simple RMSE, no physics involved): 0.132648\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.012498 - Val Loss (simple RMSE, no physics involved): 0.134372\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.012982 - Val Loss (simple RMSE, no physics involved): 0.136283\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012280 - Val Loss (simple RMSE, no physics involved): 0.132610\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.012337 - Val Loss (simple RMSE, no physics involved): 0.133775\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012204 - Val Loss (simple RMSE, no physics involved): 0.136227\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012967 - Val Loss (simple RMSE, no physics involved): 0.131958\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.012105 - Val Loss (simple RMSE, no physics involved): 0.133681\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011826 - Val Loss (simple RMSE, no physics involved): 0.132365\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.012425 - Val Loss (simple RMSE, no physics involved): 0.131217\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.012179 - Val Loss (simple RMSE, no physics involved): 0.133805\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011774 - Val Loss (simple RMSE, no physics involved): 0.131392\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.012058 - Val Loss (simple RMSE, no physics involved): 0.137949\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.012519 - Val Loss (simple RMSE, no physics involved): 0.133126\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011911 - Val Loss (simple RMSE, no physics involved): 0.132415\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.012103 - Val Loss (simple RMSE, no physics involved): 0.131752\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.012536 - Val Loss (simple RMSE, no physics involved): 0.132802\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011615 - Val Loss (simple RMSE, no physics involved): 0.134014\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-22 18:16:40,935] Trial 99 finished with value: 0.1307782456278801 and parameters: {'n_hidden_layers': 5, 'n_hidden_units': 173, 'lr': 0.0010674450768760814, 'weight_decay': 3.793294570693262e-05, 'batch_size': 16}. Best is trial 41 with value: 0.12673278152942657.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 - Train Loss: 0.012416 - Val Loss (simple RMSE, no physics involved): 0.133420\n",
      "Best Hyperparameters: {'n_hidden_layers': 5, 'n_hidden_units': 163, 'lr': 0.0031656932205590947, 'weight_decay': 3.408518000104593e-06, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    # Define hyperparameters to search over\n",
    "    n_hidden_layers = trial.suggest_int(\"n_hidden_layers\", 1, 5)\n",
    "    n_hidden_units = trial.suggest_int(\"n_hidden_units\", 32, 256)\n",
    "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-2)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-8, 1e-3)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])  # Match the original hp['batch_sz']\n",
    "\n",
    "    # Create train & validation loaders (following the original code)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize MLP model\n",
    "    model = BasicMLP(\n",
    "        N_INPUT_UNITS=train_dataset.__n_features_in__(),\n",
    "        N_HIDDEN_LAYERS=n_hidden_layers,\n",
    "        N_HIDDEN_UNITS=n_hidden_units,\n",
    "        N_OUTPUT_UNITS=train_dataset.__n_features_out__(),\n",
    "        loss_function=LOSS_FUNC,\n",
    "    )\n",
    "\n",
    "    # Train and return validation loss\n",
    "    val_loss = model.train_model(train_loader, val_loader, epochs=50, lr=lr, weight_decay=weight_decay, device=device)\n",
    "    \n",
    "    return val_loss\n",
    "\n",
    "\n",
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"mlp_hyperparameter_optimization_baseline_2017\", storage=\"sqlite:///mlp_hyperparameter_optimization.db\", load_if_exists=True)\n",
    "\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Print best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for baseline mlp 2017: {'n_hidden_layers': 5, 'n_hidden_units': 163, 'lr': 0.0031656932205590947, 'weight_decay': 3.408518000104593e-06, 'batch_size': 16}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Hyperparameters for baseline mlp 2017:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'best_params_MLP_no2_MSE_2017.txt'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BESTPARAMS_FILENAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters saved to file /home/rachel/forecasting_smog_PEML/src/results/best_params/best_params_MLP_no2_MSE_2017.txt\n"
     ]
    }
   ],
   "source": [
    "# save best params to a file\n",
    "with open(f'{RESULTS_PATH}/best_params/{BESTPARAMS_FILENAME}', 'w') as f:\n",
    "    for key in best_params.keys():\n",
    "        f.write(\"%s: %s\\n\" % (key, best_params[key]))\n",
    "print(f\"Best Hyperparameters saved to file {RESULTS_PATH}/best_params/{BESTPARAMS_FILENAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Epoch 1/50 - Train Loss: 0.081395 - Val Loss (simple RMSE, no physics involved): 0.269474\n",
      "Epoch 2/50\n",
      "Epoch 2/50 - Train Loss: 0.039733 - Val Loss (simple RMSE, no physics involved): 0.221283\n",
      "Epoch 3/50\n",
      "Epoch 3/50 - Train Loss: 0.028459 - Val Loss (simple RMSE, no physics involved): 0.184024\n",
      "Epoch 4/50\n",
      "Epoch 4/50 - Train Loss: 0.024721 - Val Loss (simple RMSE, no physics involved): 0.171037\n",
      "Epoch 5/50\n",
      "Epoch 5/50 - Train Loss: 0.017346 - Val Loss (simple RMSE, no physics involved): 0.147850\n",
      "Epoch 6/50\n",
      "Epoch 6/50 - Train Loss: 0.014795 - Val Loss (simple RMSE, no physics involved): 0.138990\n",
      "Epoch 7/50\n",
      "Epoch 7/50 - Train Loss: 0.013961 - Val Loss (simple RMSE, no physics involved): 0.131829\n",
      "Epoch 8/50\n",
      "Epoch 8/50 - Train Loss: 0.013865 - Val Loss (simple RMSE, no physics involved): 0.140893\n",
      "Epoch 9/50\n",
      "Epoch 9/50 - Train Loss: 0.013808 - Val Loss (simple RMSE, no physics involved): 0.135290\n",
      "Epoch 10/50\n",
      "Epoch 10/50 - Train Loss: 0.013720 - Val Loss (simple RMSE, no physics involved): 0.130140\n",
      "Epoch 11/50\n",
      "Epoch 11/50 - Train Loss: 0.012870 - Val Loss (simple RMSE, no physics involved): 0.129358\n",
      "Epoch 12/50\n",
      "Epoch 12/50 - Train Loss: 0.013022 - Val Loss (simple RMSE, no physics involved): 0.129102\n",
      "Epoch 13/50\n",
      "Epoch 13/50 - Train Loss: 0.013518 - Val Loss (simple RMSE, no physics involved): 0.132455\n",
      "Epoch 14/50\n",
      "Epoch 14/50 - Train Loss: 0.013172 - Val Loss (simple RMSE, no physics involved): 0.130445\n",
      "Epoch 15/50\n",
      "Epoch 15/50 - Train Loss: 0.012851 - Val Loss (simple RMSE, no physics involved): 0.129192\n",
      "Epoch 16/50\n",
      "Epoch 16/50 - Train Loss: 0.012601 - Val Loss (simple RMSE, no physics involved): 0.129633\n",
      "Epoch 17/50\n",
      "Epoch 17/50 - Train Loss: 0.012964 - Val Loss (simple RMSE, no physics involved): 0.129964\n",
      "Epoch 18/50\n",
      "Epoch 18/50 - Train Loss: 0.012390 - Val Loss (simple RMSE, no physics involved): 0.129257\n",
      "Epoch 19/50\n",
      "Epoch 19/50 - Train Loss: 0.012410 - Val Loss (simple RMSE, no physics involved): 0.130389\n",
      "Epoch 20/50\n",
      "Epoch 20/50 - Train Loss: 0.012447 - Val Loss (simple RMSE, no physics involved): 0.129618\n",
      "Epoch 21/50\n",
      "Epoch 21/50 - Train Loss: 0.012325 - Val Loss (simple RMSE, no physics involved): 0.130633\n",
      "Epoch 22/50\n",
      "Epoch 22/50 - Train Loss: 0.012088 - Val Loss (simple RMSE, no physics involved): 0.129228\n",
      "Epoch 23/50\n",
      "Epoch 23/50 - Train Loss: 0.012364 - Val Loss (simple RMSE, no physics involved): 0.128890\n",
      "Epoch 24/50\n",
      "Epoch 24/50 - Train Loss: 0.012036 - Val Loss (simple RMSE, no physics involved): 0.133287\n",
      "Epoch 25/50\n",
      "Epoch 25/50 - Train Loss: 0.011946 - Val Loss (simple RMSE, no physics involved): 0.129534\n",
      "Epoch 26/50\n",
      "Epoch 26/50 - Train Loss: 0.011590 - Val Loss (simple RMSE, no physics involved): 0.129499\n",
      "Epoch 27/50\n",
      "Epoch 27/50 - Train Loss: 0.011976 - Val Loss (simple RMSE, no physics involved): 0.139823\n",
      "Epoch 28/50\n",
      "Epoch 28/50 - Train Loss: 0.012244 - Val Loss (simple RMSE, no physics involved): 0.129497\n",
      "Epoch 29/50\n",
      "Epoch 29/50 - Train Loss: 0.011996 - Val Loss (simple RMSE, no physics involved): 0.133039\n",
      "Epoch 30/50\n",
      "Epoch 30/50 - Train Loss: 0.011945 - Val Loss (simple RMSE, no physics involved): 0.130495\n",
      "Epoch 31/50\n",
      "Epoch 31/50 - Train Loss: 0.011636 - Val Loss (simple RMSE, no physics involved): 0.130394\n",
      "Epoch 32/50\n",
      "Epoch 32/50 - Train Loss: 0.011599 - Val Loss (simple RMSE, no physics involved): 0.135768\n",
      "Epoch 33/50\n",
      "Epoch 33/50 - Train Loss: 0.011827 - Val Loss (simple RMSE, no physics involved): 0.139664\n",
      "Epoch 34/50\n",
      "Epoch 34/50 - Train Loss: 0.011882 - Val Loss (simple RMSE, no physics involved): 0.131995\n",
      "Epoch 35/50\n",
      "Epoch 35/50 - Train Loss: 0.012143 - Val Loss (simple RMSE, no physics involved): 0.132787\n",
      "Epoch 36/50\n",
      "Epoch 36/50 - Train Loss: 0.011795 - Val Loss (simple RMSE, no physics involved): 0.138480\n",
      "Epoch 37/50\n",
      "Epoch 37/50 - Train Loss: 0.012072 - Val Loss (simple RMSE, no physics involved): 0.146230\n",
      "Epoch 38/50\n",
      "Epoch 38/50 - Train Loss: 0.012125 - Val Loss (simple RMSE, no physics involved): 0.135604\n",
      "Epoch 39/50\n",
      "Epoch 39/50 - Train Loss: 0.011968 - Val Loss (simple RMSE, no physics involved): 0.133375\n",
      "Epoch 40/50\n",
      "Epoch 40/50 - Train Loss: 0.011899 - Val Loss (simple RMSE, no physics involved): 0.132471\n",
      "Epoch 41/50\n",
      "Epoch 41/50 - Train Loss: 0.011785 - Val Loss (simple RMSE, no physics involved): 0.136735\n",
      "Epoch 42/50\n",
      "Epoch 42/50 - Train Loss: 0.011190 - Val Loss (simple RMSE, no physics involved): 0.136820\n",
      "Epoch 43/50\n",
      "Epoch 43/50 - Train Loss: 0.011775 - Val Loss (simple RMSE, no physics involved): 0.132564\n",
      "Epoch 44/50\n",
      "Epoch 44/50 - Train Loss: 0.011693 - Val Loss (simple RMSE, no physics involved): 0.135108\n",
      "Epoch 45/50\n",
      "Epoch 45/50 - Train Loss: 0.011668 - Val Loss (simple RMSE, no physics involved): 0.138776\n",
      "Epoch 46/50\n",
      "Epoch 46/50 - Train Loss: 0.011194 - Val Loss (simple RMSE, no physics involved): 0.136300\n",
      "Epoch 47/50\n",
      "Epoch 47/50 - Train Loss: 0.011384 - Val Loss (simple RMSE, no physics involved): 0.148119\n",
      "Epoch 48/50\n",
      "Epoch 48/50 - Train Loss: 0.011103 - Val Loss (simple RMSE, no physics involved): 0.137593\n",
      "Epoch 49/50\n",
      "Epoch 49/50 - Train Loss: 0.011142 - Val Loss (simple RMSE, no physics involved): 0.142859\n",
      "Epoch 50/50\n",
      "Epoch 50/50 - Train Loss: 0.012498 - Val Loss (simple RMSE, no physics involved): 0.137475\n",
      "Total training time: 23.34 seconds\n",
      "Training time: 23.343350410461426\n",
      "Model saved as best_MLP_no2_MSE_2017.pth in Model folder\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(34)\n",
    "# Train the model with the best hyperparameters\n",
    "best_model_baseline = BasicMLP(\n",
    "    N_INPUT_UNITS=train_dataset.__n_features_in__(),\n",
    "    N_HIDDEN_LAYERS=best_params[\"n_hidden_layers\"],\n",
    "    N_HIDDEN_UNITS=best_params[\"n_hidden_units\"],\n",
    "    N_OUTPUT_UNITS=train_dataset.__n_features_out__(),\n",
    "    loss_function=\"MSE\",\n",
    ")\n",
    "\n",
    "# Create train & validation loaders with the best batch size\n",
    "train_loader = DataLoader(train_dataset, batch_size=best_params[\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "# Train the model\n",
    "_, training_time = best_model_baseline.train_model(train_loader, val_loader, epochs=50, lr=best_params[\"lr\"], weight_decay=best_params[\"weight_decay\"], device=device)\n",
    "\n",
    "print(f\"Training time: {training_time}\")\n",
    "# Save the trained model\n",
    "torch.save(best_model_baseline.state_dict(), f\"{MODEL_PATH}/{MODEL_PATH_NAME}\")\n",
    "print(f\"Model saved as {MODEL_PATH_NAME} in Model folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE Loss: 128.045925\n",
      "Test RMSE Loss: 12.601719\n",
      "Test SMAPE Loss: 32.458074%\n",
      "Total Inference Time: 0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(34)  # Set seed for reproducibility\n",
    "best_model_baseline.load_state_dict(torch.load(f\"{MODEL_PATH}/{MODEL_PATH_NAME}\"))\n",
    "best_model_baseline.eval()\n",
    "\n",
    "# Create the DataLoader for the test dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_params[\"batch_size\"], shuffle=False)\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "df_minmax = pd.read_csv(MINMAX_PATH, sep=';')\n",
    "min_value = df_minmax[\"min\"].values\n",
    "max_value = df_minmax[\"max\"].values\n",
    "mse, rmse, smape, inference_time = best_model_baseline.test_model(test_loader, min_value=min_value, max_value=max_value, device=\"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as results_MLP_no2_MSE_2017.csv in Results/metrics folder\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Define the CSV file path\n",
    "results_csv_path = f\"{RESULTS_PATH}/metrics/{RESULTS_METRICS_FILENAME}\"\n",
    "\n",
    "# Save metrics in a proper CSV format (header + values in one row)\n",
    "with open(results_csv_path, mode=\"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    # Write header\n",
    "    writer.writerow([\"MSE\", \"RMSE\", \"SMAPE\", \"Inference Time\", \"Training Time\"])\n",
    "    \n",
    "    # Write values\n",
    "    writer.writerow([mse, rmse, smape, inference_time, training_time])\n",
    "\n",
    "print(f\"Results saved as {RESULTS_METRICS_FILENAME} in Results/metrics folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "best_model_baseline.eval()\n",
    "\n",
    "y_preds = []\n",
    "y_trues = []\n",
    "\n",
    "# Iterate through the test set and collect predictions & ground truth\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_test, y_true = batch  # Get input and ground truth\n",
    "        x_test = x_test.to(\"cpu\")  # Ensure data is on CPU if needed\n",
    "\n",
    "        # Get predictions\n",
    "        y_pred = best_model_baseline(x_test)\n",
    "\n",
    "        # Store results\n",
    "        y_preds.append(y_pred.cpu())\n",
    "        y_trues.append(y_true.cpu())\n",
    "\n",
    "# Convert lists to tensors\n",
    "y_preds = torch.cat(y_preds, dim=0).numpy()\n",
    "y_trues = torch.cat(y_trues, dim=0).numpy()\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(y_trues.flatten(), label=\"Ground Truth (NO)\", linestyle=\"-\", color=\"blue\")\n",
    "plt.scatter(range(len(y_preds.flatten())), y_preds.flatten(), label=\"Predictions\", color=\"black\", s=10)\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"NO Level\")\n",
    "plt.title(\"Predictions vs. Ground Truth\")\n",
    "plt.legend()\n",
    "#save the plot\n",
    "plt.savefig(f\"{RESULTS_PATH}/plots/{PLOT_FILENAME}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
